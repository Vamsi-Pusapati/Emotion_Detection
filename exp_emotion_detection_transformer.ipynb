{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f29c917e5b654a57aa1537fa4902345c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d16060304fa749eead3d61dba464b3a0",
              "IPY_MODEL_a3f03374ce604c5c8f5bdf4bc65a5311",
              "IPY_MODEL_54def0b76f034994b944e4d3c272d5e6"
            ],
            "layout": "IPY_MODEL_0323ae1dbe8f4d91bc70056c921f3df1"
          }
        },
        "d16060304fa749eead3d61dba464b3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8077433ad9864ba3a3c8112982a1e396",
            "placeholder": "​",
            "style": "IPY_MODEL_1fbef709c4f94a6c814bc276f54fff61",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a3f03374ce604c5c8f5bdf4bc65a5311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08ab67956bcb4593ae994943d9cbef60",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_318159f8c38a472a9596787fc32d9780",
            "value": 28
          }
        },
        "54def0b76f034994b944e4d3c272d5e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef31aca51b24449291acb53a61edf936",
            "placeholder": "​",
            "style": "IPY_MODEL_ee4b2059879749f5a223196e7df4a5fd",
            "value": " 28.0/28.0 [00:00&lt;00:00, 108B/s]"
          }
        },
        "0323ae1dbe8f4d91bc70056c921f3df1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8077433ad9864ba3a3c8112982a1e396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fbef709c4f94a6c814bc276f54fff61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08ab67956bcb4593ae994943d9cbef60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "318159f8c38a472a9596787fc32d9780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef31aca51b24449291acb53a61edf936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee4b2059879749f5a223196e7df4a5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4cf4bf0b4f743b395f58b9a02f0d35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52530fd195934f3999e6753aa9ccf380",
              "IPY_MODEL_1c01e979df134a3987f4b660c457c004",
              "IPY_MODEL_f781714c35954cc5b0c047df76c215aa"
            ],
            "layout": "IPY_MODEL_e06791e3de4f44efa315527bd73bf5f7"
          }
        },
        "52530fd195934f3999e6753aa9ccf380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_128d36f91478444181df50d9054407fb",
            "placeholder": "​",
            "style": "IPY_MODEL_f6db435c2f814369865ca303423a1c80",
            "value": "vocab.txt: 100%"
          }
        },
        "1c01e979df134a3987f4b660c457c004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c8a09a7e9984a4999bf89d520a10a01",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf4fb602985b474ca37b8f69b24b23e3",
            "value": 231508
          }
        },
        "f781714c35954cc5b0c047df76c215aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ef810b2eba14771b2ea04ed7eef8d6c",
            "placeholder": "​",
            "style": "IPY_MODEL_83a2e555d0e14cd0b879f55968d192ec",
            "value": " 232k/232k [00:00&lt;00:00, 5.37MB/s]"
          }
        },
        "e06791e3de4f44efa315527bd73bf5f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "128d36f91478444181df50d9054407fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6db435c2f814369865ca303423a1c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c8a09a7e9984a4999bf89d520a10a01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf4fb602985b474ca37b8f69b24b23e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ef810b2eba14771b2ea04ed7eef8d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a2e555d0e14cd0b879f55968d192ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64c10bbab2d244fcac994168cd55ac27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50ac2efe27234c1181c934049371aa39",
              "IPY_MODEL_00c785370b934094b863686dbad3c5a0",
              "IPY_MODEL_98385356f9a14218873cebca0607bc84"
            ],
            "layout": "IPY_MODEL_bb755950db5e4c9e8bb20358165000b6"
          }
        },
        "50ac2efe27234c1181c934049371aa39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97fc8564d94c4d589cc3c067b5404491",
            "placeholder": "​",
            "style": "IPY_MODEL_d98a719b6ecc4191900f05ac28cf9e1a",
            "value": "tokenizer.json: 100%"
          }
        },
        "00c785370b934094b863686dbad3c5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab19933d76ce46a08fa1bf5a887d2760",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d53d43e15f414e818b80624ef728e3de",
            "value": 466062
          }
        },
        "98385356f9a14218873cebca0607bc84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fa317e373f946bbb23bfdefe762d10d",
            "placeholder": "​",
            "style": "IPY_MODEL_cd41acebb20b4ae78b4f14be2eb8bd5c",
            "value": " 466k/466k [00:00&lt;00:00, 15.1MB/s]"
          }
        },
        "bb755950db5e4c9e8bb20358165000b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97fc8564d94c4d589cc3c067b5404491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d98a719b6ecc4191900f05ac28cf9e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab19933d76ce46a08fa1bf5a887d2760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d53d43e15f414e818b80624ef728e3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fa317e373f946bbb23bfdefe762d10d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd41acebb20b4ae78b4f14be2eb8bd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e8f0ca9a84f4ba59fa35de2230160e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a70a75c2274a4b8ebed21cf472a8f19c",
              "IPY_MODEL_84ee4e1270a148ef89688fb5cbf0b867",
              "IPY_MODEL_9e4a78f8c212458b8de6fdfc1ac1f097"
            ],
            "layout": "IPY_MODEL_0de6bb32141e4a52841ce5d2c655fd7f"
          }
        },
        "a70a75c2274a4b8ebed21cf472a8f19c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb4dd90da6d541ea99d1906a22319427",
            "placeholder": "​",
            "style": "IPY_MODEL_bb3cc633c2ef4fc09cd21ddb3bf4f09f",
            "value": "config.json: 100%"
          }
        },
        "84ee4e1270a148ef89688fb5cbf0b867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c3ea0c37b7f4999ada2189f5f16e143",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e95fcf3b33949d7a2e2b9fe7ac72c7a",
            "value": 570
          }
        },
        "9e4a78f8c212458b8de6fdfc1ac1f097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9786338d8f64dbba81dea7d28bad9c3",
            "placeholder": "​",
            "style": "IPY_MODEL_2eec9564728a4b7582d34bc3ce1ba685",
            "value": " 570/570 [00:00&lt;00:00, 15.2kB/s]"
          }
        },
        "0de6bb32141e4a52841ce5d2c655fd7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb4dd90da6d541ea99d1906a22319427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb3cc633c2ef4fc09cd21ddb3bf4f09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c3ea0c37b7f4999ada2189f5f16e143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e95fcf3b33949d7a2e2b9fe7ac72c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9786338d8f64dbba81dea7d28bad9c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eec9564728a4b7582d34bc3ce1ba685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5261ee913f734018b283068d8fc85270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4848957828b94e6cae5c7b9f47ef260e",
              "IPY_MODEL_769ba1d7ff054a2cb10245dfe511b2e1",
              "IPY_MODEL_c851f65d3416440aa073c1c9e48d844c"
            ],
            "layout": "IPY_MODEL_bab18c0b78d04311b267658a2b4ad74c"
          }
        },
        "4848957828b94e6cae5c7b9f47ef260e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_057dbadc86fc480daa13893c162650fe",
            "placeholder": "​",
            "style": "IPY_MODEL_ccd2dbb1f04549eab0af5f477787b6d0",
            "value": "model.safetensors: 100%"
          }
        },
        "769ba1d7ff054a2cb10245dfe511b2e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18fdc935cc99465f9538632bc27b08a5",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_751227072476476090a7b68e6135c95e",
            "value": 440449768
          }
        },
        "c851f65d3416440aa073c1c9e48d844c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14c2e4b371004bc3a9008b6c895a1d82",
            "placeholder": "​",
            "style": "IPY_MODEL_791ee1abaa5f43ca8056d8553dae7169",
            "value": " 440M/440M [00:05&lt;00:00, 65.1MB/s]"
          }
        },
        "bab18c0b78d04311b267658a2b4ad74c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "057dbadc86fc480daa13893c162650fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccd2dbb1f04549eab0af5f477787b6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18fdc935cc99465f9538632bc27b08a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "751227072476476090a7b68e6135c95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14c2e4b371004bc3a9008b6c895a1d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "791ee1abaa5f43ca8056d8553dae7169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "GwuozKWySEX2",
        "outputId": "04629cf4-80e4-4a8e-f065-1a1379a50f6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Clean_text  admiration  amusement  \\\n",
              "0  my favourite food is anything i did not have t...           0          0   \n",
              "1  now if he does off himself everyone will think...           0          0   \n",
              "2                     why the fuck is bayless isoing           0          0   \n",
              "3                        to make her feel threatened           0          0   \n",
              "4                             dirty southern wankers           0          0   \n",
              "\n",
              "   anger  annoyance  approval  caring  confusion  curiosity  desire  ...  \\\n",
              "0      0          0         0       0          0          0       0  ...   \n",
              "1      0          0         0       0          0          0       0  ...   \n",
              "2      1          0         0       0          0          0       0  ...   \n",
              "3      0          0         0       0          0          0       0  ...   \n",
              "4      0          1         0       0          0          0       0  ...   \n",
              "\n",
              "   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
              "0     0            0         0      0            0       0        0        0   \n",
              "1     0            0         0      0            0       0        0        0   \n",
              "2     0            0         0      0            0       0        0        0   \n",
              "3     0            0         0      0            0       0        0        0   \n",
              "4     0            0         0      0            0       0        0        0   \n",
              "\n",
              "   surprise  neutral  \n",
              "0         0        1  \n",
              "1         0        1  \n",
              "2         0        0  \n",
              "3         0        0  \n",
              "4         0        0  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd8fce0a-1447-4678-941e-71c19cb5d82d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clean_text</th>\n",
              "      <th>admiration</th>\n",
              "      <th>amusement</th>\n",
              "      <th>anger</th>\n",
              "      <th>annoyance</th>\n",
              "      <th>approval</th>\n",
              "      <th>caring</th>\n",
              "      <th>confusion</th>\n",
              "      <th>curiosity</th>\n",
              "      <th>desire</th>\n",
              "      <th>...</th>\n",
              "      <th>love</th>\n",
              "      <th>nervousness</th>\n",
              "      <th>optimism</th>\n",
              "      <th>pride</th>\n",
              "      <th>realization</th>\n",
              "      <th>relief</th>\n",
              "      <th>remorse</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my favourite food is anything i did not have t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>now if he does off himself everyone will think...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>why the fuck is bayless isoing</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to make her feel threatened</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dirty southern wankers</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd8fce0a-1447-4678-941e-71c19cb5d82d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd8fce0a-1447-4678-941e-71c19cb5d82d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd8fce0a-1447-4678-941e-71c19cb5d82d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-51457087-e237-4ca2-bd2b-1a914b2a14f5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51457087-e237-4ca2-bd2b-1a914b2a14f5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-51457087-e237-4ca2-bd2b-1a914b2a14f5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# I am doing this in colab so please change the  code to import csv file using eric code in local machine\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv('train_clean.csv')\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('test_clean.csv')\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "OFbzXDO4SjFA",
        "outputId": "4c3504c8-2dd1-4699-9e76-ba0b8c60da80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Clean_text  admiration  amusement  \\\n",
              "0  i am really sorry about your situation frownin...           0          0   \n",
              "1    it is wonderful because it is awful at not with           1          0   \n",
              "2  kings fan here good luck to you guys ! will be...           0          0   \n",
              "3  i did not know that thank you for teaching me ...           0          0   \n",
              "4  they got bored from haunting earth for thousan...           0          0   \n",
              "\n",
              "   anger  annoyance  approval  caring  confusion  curiosity  desire  ...  \\\n",
              "0      0          0         0       0          0          0       0  ...   \n",
              "1      0          0         0       0          0          0       0  ...   \n",
              "2      0          0         0       0          0          0       0  ...   \n",
              "3      0          0         0       0          0          0       0  ...   \n",
              "4      0          0         0       0          0          0       0  ...   \n",
              "\n",
              "   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
              "0     0            0         0      0            0       0        0        1   \n",
              "1     0            0         0      0            0       0        0        0   \n",
              "2     0            0         0      0            0       0        0        0   \n",
              "3     0            0         0      0            0       0        0        0   \n",
              "4     0            0         0      0            0       0        0        0   \n",
              "\n",
              "   surprise  neutral  \n",
              "0         0        0  \n",
              "1         0        0  \n",
              "2         0        0  \n",
              "3         0        0  \n",
              "4         0        1  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5bd948c2-d037-4654-8125-8f512c794808\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clean_text</th>\n",
              "      <th>admiration</th>\n",
              "      <th>amusement</th>\n",
              "      <th>anger</th>\n",
              "      <th>annoyance</th>\n",
              "      <th>approval</th>\n",
              "      <th>caring</th>\n",
              "      <th>confusion</th>\n",
              "      <th>curiosity</th>\n",
              "      <th>desire</th>\n",
              "      <th>...</th>\n",
              "      <th>love</th>\n",
              "      <th>nervousness</th>\n",
              "      <th>optimism</th>\n",
              "      <th>pride</th>\n",
              "      <th>realization</th>\n",
              "      <th>relief</th>\n",
              "      <th>remorse</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i am really sorry about your situation frownin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it is wonderful because it is awful at not with</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kings fan here good luck to you guys ! will be...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i did not know that thank you for teaching me ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>they got bored from haunting earth for thousan...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bd948c2-d037-4654-8125-8f512c794808')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5bd948c2-d037-4654-8125-8f512c794808 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5bd948c2-d037-4654-8125-8f512c794808');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-699946a2-9e5e-4a3b-b750-cabf260bfa43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-699946a2-9e5e-4a3b-b750-cabf260bfa43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-699946a2-9e5e-4a3b-b750-cabf260bfa43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_with_emotion_df = pd.concat([train_df, train_df.apply(lambda row: row[row == 1].index[0], axis=1)], axis=1)\n",
        "train_with_emotion_df.rename(columns={0: 'emotion'}, inplace=True)\n",
        "# train_with_emotion_df.drop(train_with_emotion_df.columns.difference(['Clean_text','emotion']), 1, inplace=True)\n",
        "train_with_emotion_df = train_with_emotion_df[['Clean_text','emotion']].copy()"
      ],
      "metadata": {
        "id": "EY8lCqsnS0uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "positiveSet = ['Clean_text','admiration','desire','love','amusement','excitement',\n",
        "               'optimism','approval','gratitude','pride','caring','joy','relief']\n",
        "negativeSet = ['Clean_text','anger','disgust','nervousness','annoyance','embarrassment',\n",
        "               'remorse','disappointment', 'fear', 'sadness', 'disapproval', 'grief']\n",
        "neutralSet = ['Clean_text','confusion','curiosity','realization','surprise']\n",
        "\n"
      ],
      "metadata": {
        "id": "J3N0cOV8S4lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##change this ti eric code to import terain and test csv files\n",
        "def loadTrainData():\n",
        "  df = pd.read_csv('train_clean.csv')\n",
        "  return df\n",
        "\n",
        "def loadTestData():\n",
        "  df = pd.read_csv('test_clean.csv')\n",
        "  return df"
      ],
      "metadata": {
        "id": "65Chd-z4S6nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getEmotionTestTrainDF( set ):\n",
        "    trainSet = pd.DataFrame( loadTrainData() )[ set ]\n",
        "    testSet = pd.DataFrame( loadTestData() )[ set ]\n",
        "\n",
        "    trainDF = trainSet.copy()\n",
        "    testDF = testSet.copy()\n",
        "\n",
        "    # remove all rows without emotion (all rows with '0' emotion columns)\n",
        "    trainDF = trainDF[ ~trainDF[set[1:]].eq(0).all(axis=1) ]\n",
        "    testDF = testDF[ ~testDF[set[1:]].eq(0).all(axis=1) ]\n",
        "\n",
        "    # just to do a sanity check, let's make sure all irrelevant rows have been removed\n",
        "    print( '\\ndf shapes after cleanup: \\ntrain - \\told: {} \\tnew: {} \\ntest - \\t\\told: {} \\tnew: {}'.format(trainSet.shape, trainDF.shape, testSet.shape, testDF.shape) )\n",
        "\n",
        "    # now that all rows have (associated) set of emotions, conflate!\n",
        "    trainDF_conflated = pd.concat([trainDF, trainDF.apply(lambda row: row[row == 1].index[0], axis=1)], axis=1)\n",
        "    trainDF_conflated.rename(columns={0: 'emotion'}, inplace=True)\n",
        "    trainDF_conflated = trainDF_conflated[['Clean_text','emotion']].copy()\n",
        "\n",
        "    testDF_conflated = pd.concat([testDF, testDF.apply(lambda row: row[row == 1].index[0], axis=1)], axis=1)\n",
        "    testDF_conflated.rename(columns={0: 'emotion'}, inplace=True)\n",
        "    testDF_conflated = testDF_conflated[['Clean_text','emotion']].copy()\n",
        "\n",
        "    return trainDF, testDF, trainDF_conflated, testDF_conflated"
      ],
      "metadata": {
        "id": "ZEQm1NIkTC3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posTrainDF, posTestDF, posTrainDF_conflated, posTestDF_conflated = getEmotionTestTrainDF( positiveSet )\n",
        "negTrainDF, negTestDF, negTrainDF_conflated, negTestDF_conflated = getEmotionTestTrainDF( negativeSet )\n",
        "neuTrainDF, neuTestDF, neuTrainDF_conflated, neuTestDF_conflated = getEmotionTestTrainDF( neutralSet )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqGYE0usTFvf",
        "outputId": "355214cf-0c31-4709-c8b8-3c364d582311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "df shapes after cleanup: \n",
            "train - \told: (43410, 13) \tnew: (17410, 13) \n",
            "test - \t\told: (5427, 13) \tnew: (2104, 13)\n",
            "\n",
            "df shapes after cleanup: \n",
            "train - \told: (43410, 12) \tnew: (9839, 12) \n",
            "test - \t\told: (5427, 12) \tnew: (1262, 12)\n",
            "\n",
            "df shapes after cleanup: \n",
            "train - \told: (43410, 5) \tnew: (5367, 5) \n",
            "test - \t\told: (5427, 5) \tnew: (677, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##My Experiment"
      ],
      "metadata": {
        "id": "vBuPIMXkTLo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this experiment i want to create a model that can classify the emotion to either positive, negative or neutral based on the input text. My goal here is not to classify it to the minute emotion level here maybe in the further experiments i will try to achieve that.\n",
        "\n",
        "I recommend running the below experiment on a GPU as it would drastically increase the speed of execution. (I ran it on my mac first it showed around 9 hours to complete 1 epoch. So i switched to colab to utilize free GPU)"
      ],
      "metadata": {
        "id": "AplqxyFiTLhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the output labels to categorical values for positive, negative, neutral\n",
        "# Code by Gautham\n",
        "def add_label(data_frame, category):\n",
        "    df = data_frame.copy()\n",
        "    df[\"label\"] = category\n",
        "    return df\n",
        "\n",
        "train_pos_df = add_label(posTrainDF_conflated,\"positive\")\n",
        "train_neg_df = add_label(negTrainDF_conflated,\"negative\")\n",
        "train_neu_df = add_label(neuTrainDF_conflated,\"neutral\")\n",
        "\n",
        "test_pos_df = add_label(posTestDF_conflated,\"positive\")\n",
        "test_neg_df = add_label(negTestDF_conflated,\"negative\")\n",
        "test_neu_df = add_label(neuTestDF_conflated,\"neutral\")\n",
        "\n",
        "print(\"Positive train datasets\")\n",
        "print(train_pos_df.head())\n",
        "print(\"Negative train datasets\")\n",
        "print(train_neg_df.head())\n",
        "print(\"Neutral train datasets\")\n",
        "print(train_neu_df.head())\n",
        "\n",
        "\n",
        "print(\"Positive test datasets\")\n",
        "print(test_pos_df.head())\n",
        "print(\"Negative test datasets\")\n",
        "print(test_neg_df.head())\n",
        "print(\"Neutral test datasets\")\n",
        "print(test_neu_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMBv5Xm3TIj7",
        "outputId": "f88d1a38-a267-4ab7-9540-7428ec30e95e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive train datasets\n",
            "                                           Clean_text     emotion     label\n",
            "6   yes i heard abt the fuck bombs ! that has to b...   gratitude  positive\n",
            "7   we need more boards and to create a bit more s...      desire  positive\n",
            "8   damn youtube and outrage drama is super lucrat...  admiration  positive\n",
            "11  aww she will probably come around eventually i...   amusement  positive\n",
            "13  r sleeptrain might be time for some sleep trai...      caring  positive\n",
            "Negative train datasets\n",
            "                                           Clean_text    emotion     label\n",
            "2                      why the fuck is bayless isoing      anger  negative\n",
            "3                         to make her feel threatened       fear  negative\n",
            "4                              dirty southern wankers  annoyance  negative\n",
            "14  name same fucking problem slightly better comm...  annoyance  negative\n",
            "15  shit i guess i accidentally bought a pay per v...  annoyance  negative\n",
            "Neutral train datasets\n",
            "                                           Clean_text    emotion    label\n",
            "5   omg peyton is not good enough to help us in th...   surprise  neutral\n",
            "10  demographics ? i do not know anybody under who...  confusion  neutral\n",
            "19  maybe that is what happened to the great white...  confusion  neutral\n",
            "20  i never thought it was at the same moment but ...  confusion  neutral\n",
            "31  all sounds possible except the key i can not s...  confusion  neutral\n",
            "Positive test datasets\n",
            "                                          Clean_text     emotion     label\n",
            "1    it is wonderful because it is awful at not with  admiration  positive\n",
            "2  kings fan here good luck to you guys ! will be...  excitement  positive\n",
            "3  i did not know that thank you for teaching me ...   gratitude  positive\n",
            "5  thank you for asking questions and recognizing...   gratitude  positive\n",
            "6                                    you are welcome   gratitude  positive\n",
            "Negative test datasets\n",
            "                                           Clean_text    emotion     label\n",
            "0   i am really sorry about your situation frownin...    sadness  negative\n",
            "8   i am sorry to hear that friend frowning_face i...    remorse  negative\n",
            "9      girlfriend weak as well that jump was pathetic    sadness  negative\n",
            "10  name has towed the line of the dark side he wo...  annoyance  negative\n",
            "14  i have also heard that intriguing but also kin...       fear  negative\n",
            "Neutral test datasets\n",
            "                                           Clean_text    emotion    label\n",
            "13  it is great that you are a recovering addict t...  curiosity  neutral\n",
            "24  watch vegan gains video on that he had it when...  confusion  neutral\n",
            "29  what is your source for that ? just curious an...  curiosity  neutral\n",
            "44  a surprise turn of events ! i am so glad you h...   surprise  neutral\n",
            "67  i know people around here may mock me from my ...  confusion  neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Gautham\n",
        "total_train_lenght = len(train_pos_df[\"Clean_text\"]) +len(train_neg_df[\"Clean_text\"])+len(train_neu_df[\"Clean_text\"])\n",
        "ratio_of_pos = len(train_pos_df[\"Clean_text\"])/total_train_lenght\n",
        "ratio_of_neg = len(train_neg_df[\"Clean_text\"])/total_train_lenght\n",
        "ratio_of_neu = len(train_neu_df[\"Clean_text\"])/total_train_lenght\n",
        "\n",
        "print(\"the Positive, Negative, Neutal train ratio are as follows\")\n",
        "print(\"Positive - \" + str(ratio_of_pos))\n",
        "print(\"Negative - \" + str(ratio_of_neg))\n",
        "print(\"Neutral - \" + str(ratio_of_neu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3WAZx8gTVFE",
        "outputId": "1fd2b616-659e-4ec2-d962-c0052eae9cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the Positive, Negative, Neutal train ratio are as follows\n",
            "Positive - 0.5337870983566347\n",
            "Negative - 0.3016617610988472\n",
            "Neutral - 0.16455114054451803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The stats are as follows\n",
        "Pos Train -> 17410, Pos Test -> 2104 Neg Train -> 9839, Neg Test -> 1262 Neu Train -> 5367, Neu Test -> 667\n",
        "we can observe that the train dataset is an imbalaned dataset with positive text are greater that 50% followed by negative text ~ 30% and Neutral Comments ~16%"
      ],
      "metadata": {
        "id": "mGMKU76uTX3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Gautham\n",
        "# Creating Test and train dataframes by combining all the positive, negative, neutral dataframes\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "\n",
        "#creating a combined dataframe for train\n",
        "train_df =pd.concat([train_pos_df, train_neg_df, train_neu_df], axis=0)\n",
        "# randomly shuffling the dataframe so that all the rows will be randomly mixed.\n",
        "train_df = train_df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "\n",
        "#creating a combined dataframe for test no need shuffle test df as we are not using this to train our model\n",
        "test_df = pd.concat([test_pos_df, test_neg_df, test_neu_df], axis=0)\n",
        "\n",
        "print(train_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCT0cbRETVii",
        "outputId": "21febbaa-4bef-4bd4-f87a-dc0bd14afc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Clean_text         emotion     label\n",
            "0                                      i love cowboy            love  positive\n",
            "1  i promise you it would for most people you are...  disappointment  negative\n",
            "2  congratulations ! your kids are very lucky to ...      admiration  positive\n",
            "3  i am happy you were able to have a child ! tha...             joy  positive\n",
            "4              i appreciate this reference very much      admiration  positive\n",
            "5  literally loving this where are all the guys l...            love  positive\n",
            "6  so is liking name enormous eyebrows biological...      admiration  positive\n",
            "7      what are the ajax players complaining about ?       curiosity   neutral\n",
            "8  tell her to stop eating shit and start using m...         disgust  negative\n",
            "9  i am reading homegoing by name and it is so go...     realization   neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Gautham\n",
        "#creating a dict to map the lables\n",
        "label_dict = {\n",
        "    \"positive\":0,\n",
        "    \"negative\":1,\n",
        "    \"neutral\":2\n",
        "}\n",
        "train_df.label = train_df[\"label\"].map(label_dict)\n",
        "test_df.label = test_df[\"label\"].map(label_dict)"
      ],
      "metadata": {
        "id": "JG52WA-bTcHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Gautham\n",
        "#extracting the text from train dataframe\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(train_df[\"Clean_text\"],\n",
        "                                                  train_df[\"label\"],\n",
        "                                                  test_size=0.1,\n",
        "                                                  random_state=34,\n",
        "                                                  stratify=train_df[\"label\"])\n",
        "\n",
        "\n",
        "test_text = test_df[\"Clean_text\"]\n",
        "Y_test = test_df[\"label\"]\n",
        "print(Y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omp6aFA8TeG5",
        "outputId": "9ace7aa4-ce90-47f6-f3ba-37fee5a980f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22474    0\n",
            "3396     0\n",
            "6142     1\n",
            "7369     0\n",
            "29320    0\n",
            "        ..\n",
            "3288     0\n",
            "6531     2\n",
            "28594    0\n",
            "21628    2\n",
            "30556    1\n",
            "Name: label, Length: 3262, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "from transformers import BertTokenizer\n",
        "# using the pretrained tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_encoding_texts = tokenizer.batch_encode_plus(X_train, padding=\"max_length\", truncation=True, return_tensors=\"pt\",)\n",
        "val_encoding_texts = tokenizer.batch_encode_plus(X_val, padding=\"max_length\", truncation=True, return_tensors=\"pt\",)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "f29c917e5b654a57aa1537fa4902345c",
            "d16060304fa749eead3d61dba464b3a0",
            "a3f03374ce604c5c8f5bdf4bc65a5311",
            "54def0b76f034994b944e4d3c272d5e6",
            "0323ae1dbe8f4d91bc70056c921f3df1",
            "8077433ad9864ba3a3c8112982a1e396",
            "1fbef709c4f94a6c814bc276f54fff61",
            "08ab67956bcb4593ae994943d9cbef60",
            "318159f8c38a472a9596787fc32d9780",
            "ef31aca51b24449291acb53a61edf936",
            "ee4b2059879749f5a223196e7df4a5fd",
            "c4cf4bf0b4f743b395f58b9a02f0d35b",
            "52530fd195934f3999e6753aa9ccf380",
            "1c01e979df134a3987f4b660c457c004",
            "f781714c35954cc5b0c047df76c215aa",
            "e06791e3de4f44efa315527bd73bf5f7",
            "128d36f91478444181df50d9054407fb",
            "f6db435c2f814369865ca303423a1c80",
            "5c8a09a7e9984a4999bf89d520a10a01",
            "bf4fb602985b474ca37b8f69b24b23e3",
            "2ef810b2eba14771b2ea04ed7eef8d6c",
            "83a2e555d0e14cd0b879f55968d192ec",
            "64c10bbab2d244fcac994168cd55ac27",
            "50ac2efe27234c1181c934049371aa39",
            "00c785370b934094b863686dbad3c5a0",
            "98385356f9a14218873cebca0607bc84",
            "bb755950db5e4c9e8bb20358165000b6",
            "97fc8564d94c4d589cc3c067b5404491",
            "d98a719b6ecc4191900f05ac28cf9e1a",
            "ab19933d76ce46a08fa1bf5a887d2760",
            "d53d43e15f414e818b80624ef728e3de",
            "5fa317e373f946bbb23bfdefe762d10d",
            "cd41acebb20b4ae78b4f14be2eb8bd5c",
            "7e8f0ca9a84f4ba59fa35de2230160e6",
            "a70a75c2274a4b8ebed21cf472a8f19c",
            "84ee4e1270a148ef89688fb5cbf0b867",
            "9e4a78f8c212458b8de6fdfc1ac1f097",
            "0de6bb32141e4a52841ce5d2c655fd7f",
            "fb4dd90da6d541ea99d1906a22319427",
            "bb3cc633c2ef4fc09cd21ddb3bf4f09f",
            "7c3ea0c37b7f4999ada2189f5f16e143",
            "5e95fcf3b33949d7a2e2b9fe7ac72c7a",
            "b9786338d8f64dbba81dea7d28bad9c3",
            "2eec9564728a4b7582d34bc3ce1ba685"
          ]
        },
        "id": "9HvDh7i5Thuv",
        "outputId": "53b9c7d3-d444-4e2e-a714-fbb1d624e0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f29c917e5b654a57aa1537fa4902345c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4cf4bf0b4f743b395f58b9a02f0d35b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64c10bbab2d244fcac994168cd55ac27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e8f0ca9a84f4ba59fa35de2230160e6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "import torch\n",
        "\n",
        "train_input = train_encoding_texts['input_ids']\n",
        "train_attention = train_encoding_texts['attention_mask']\n",
        "train_labels = torch.tensor(Y_train.values)\n",
        "\n",
        "val_input_ids_val = val_encoding_texts['input_ids']\n",
        "val_attention_masks_val = val_encoding_texts['attention_mask']\n",
        "val_labels_val = torch.tensor(Y_val.values)"
      ],
      "metadata": {
        "id": "3ox-Fpy3TlBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_tensor_data = TensorDataset(train_input, train_attention, train_labels)\n",
        "\n",
        "val_tensor_data = TensorDataset(val_input_ids_val, val_attention_masks_val, val_labels_val)"
      ],
      "metadata": {
        "id": "1eq435OHTnw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "from transformers import BertForSequenceClassification\n",
        "#using an existing BertForSequenceClassification model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "                                      'bert-base-uncased',\n",
        "                                      num_labels = 3,\n",
        "                                      output_attentions = True,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "5261ee913f734018b283068d8fc85270",
            "4848957828b94e6cae5c7b9f47ef260e",
            "769ba1d7ff054a2cb10245dfe511b2e1",
            "c851f65d3416440aa073c1c9e48d844c",
            "bab18c0b78d04311b267658a2b4ad74c",
            "057dbadc86fc480daa13893c162650fe",
            "ccd2dbb1f04549eab0af5f477787b6d0",
            "18fdc935cc99465f9538632bc27b08a5",
            "751227072476476090a7b68e6135c95e",
            "14c2e4b371004bc3a9008b6c895a1d82",
            "791ee1abaa5f43ca8056d8553dae7169"
          ]
        },
        "id": "DjAD_eEXTtMy",
        "outputId": "faac7327-c6ce-43f2-dea9-b675a311f4d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5261ee913f734018b283068d8fc85270"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "import random\n",
        "#setting seed value so that i can get the same random samples.\n",
        "seed = 10\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "LEapfbGHab2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "batch_size = 16\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    train_tensor_data,\n",
        "    sampler=RandomSampler(train_tensor_data),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    val_tensor_data,\n",
        "    sampler=RandomSampler(val_tensor_data),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "gdvgKo6dTuyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 1e-4,\n",
        "    eps = 1e-6\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sary1TukTwoJ",
        "outputId": "81b991d2-aa82-4c27-dc65-b81a4e85ec39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "\"\"\"I didont have GPU in my PC so i am using google colab to run the code on GPU\n",
        "#previously i tried with 5 epochs and the executio stopped around 4 epochs due to GPU\n",
        "compute time exceded the time limitation so limiting the epoch to 3.\"\"\"\n",
        "epochs = 3\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "metadata": {
        "id": "Zyugl3EDTyId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def get_f1_score(preds, labels):\n",
        "    preds = np.argmax(preds, axis=1).flatten()\n",
        "    label = labels.flatten()\n",
        "    return f1_score(label, preds, average = 'weighted')\n",
        "\n",
        "\"\"\"\n",
        "    The below function is used to get the accuracy of each labels\n",
        "\"\"\"\n",
        "def get_accuracy_perclass(preds, labels):\n",
        "    label_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "    preds = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        accuracy = len(y_preds[y_preds==label])/ len(y_true)\n",
        "        print(f'Class: {label_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)} = {accuracy}\\n')"
      ],
      "metadata": {
        "id": "DHgDOkK4T0WZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeORrnMuU_vO",
        "outputId": "5ef1d4b9-c61e-4e25-ec17-e33bb4f4e774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "def evaluate(batch_dataloder):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in batch_dataloder:\n",
        "        batch = tuple(bat.to(device) for bat in batch)\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        predicts = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        predicts = predicts.detach().cpu().numpy()\n",
        "        labels= inputs['labels'].cpu().numpy()\n",
        "        predictions.append(predicts)\n",
        "        true_vals.append(labels)\n",
        "\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "metadata": {
        "id": "7aXIsCAjVnqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the evaluation function i am doing the following\n",
        "\n",
        "\n",
        "1.   First i am sending the dataloaders and using the Berth model i am evaluating by passing inputs.\n",
        "2.    inouts For I am creating a inputs dictionary of \"input_ids\", \"attention_mask\", \"labels\"\n",
        "3.  Once i get the model outputs i am calculating the loss , predictions, and i am returing the total loss and the predicted value and the original valus\n",
        "\n"
      ],
      "metadata": {
        "id": "mmNoKlt5WooN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the below code i am training the model. i am using tqdm library to show the progress on each step.\n"
      ],
      "metadata": {
        "id": "kSkzN6DJYazm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train,\n",
        "                        desc='Epoch {:1d}'.format(epoch),\n",
        "                        leave=False,\n",
        "                        disable=False)\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "\n",
        "        batch = tuple(bat.to(device) for bat in batch)\n",
        "\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        total_train_loss +=loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training loss': '{:.4f}'.format(loss.item()/len(batch))})\n",
        "\n",
        "\n",
        "\n",
        "    tqdm.write('\\nEpoch {epoch}')\n",
        "\n",
        "    avg_training_loss = total_train_loss/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {avg_training_loss}')\n",
        "\n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = get_f1_score(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (weighted): {val_f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad4T4HirVuhg",
        "outputId": "f9da4e79-ecc8-45f3-ebfe-75da715e981f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/1835 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 0/1835 [00:04<?, ?it/s, training loss=0.3768]\u001b[A\n",
            "Epoch 1:   0%|          | 1/1835 [00:04<2:25:23,  4.76s/it, training loss=0.3768]\u001b[A\n",
            "Epoch 1:   0%|          | 1/1835 [00:06<2:25:23,  4.76s/it, training loss=0.3299]\u001b[A\n",
            "Epoch 1:   0%|          | 2/1835 [00:06<1:22:35,  2.70s/it, training loss=0.3299]\u001b[A\n",
            "Epoch 1:   0%|          | 2/1835 [00:07<1:22:35,  2.70s/it, training loss=0.3457]\u001b[A\n",
            "Epoch 1:   0%|          | 3/1835 [00:07<1:02:41,  2.05s/it, training loss=0.3457]\u001b[A\n",
            "Epoch 1:   0%|          | 3/1835 [00:08<1:02:41,  2.05s/it, training loss=0.2308]\u001b[A\n",
            "Epoch 1:   0%|          | 4/1835 [00:08<53:09,  1.74s/it, training loss=0.2308]  \u001b[A\n",
            "Epoch 1:   0%|          | 4/1835 [00:09<53:09,  1.74s/it, training loss=0.3348]\u001b[A\n",
            "Epoch 1:   0%|          | 5/1835 [00:09<48:01,  1.57s/it, training loss=0.3348]\u001b[A\n",
            "Epoch 1:   0%|          | 5/1835 [00:11<48:01,  1.57s/it, training loss=0.3534]\u001b[A\n",
            "Epoch 1:   0%|          | 6/1835 [00:11<44:44,  1.47s/it, training loss=0.3534]\u001b[A\n",
            "Epoch 1:   0%|          | 6/1835 [00:12<44:44,  1.47s/it, training loss=0.3225]\u001b[A\n",
            "Epoch 1:   0%|          | 7/1835 [00:12<42:45,  1.40s/it, training loss=0.3225]\u001b[A\n",
            "Epoch 1:   0%|          | 7/1835 [00:13<42:45,  1.40s/it, training loss=0.2861]\u001b[A\n",
            "Epoch 1:   0%|          | 8/1835 [00:13<41:26,  1.36s/it, training loss=0.2861]\u001b[A\n",
            "Epoch 1:   0%|          | 8/1835 [00:14<41:26,  1.36s/it, training loss=0.3631]\u001b[A\n",
            "Epoch 1:   0%|          | 9/1835 [00:14<40:32,  1.33s/it, training loss=0.3631]\u001b[A\n",
            "Epoch 1:   0%|          | 9/1835 [00:16<40:32,  1.33s/it, training loss=0.2912]\u001b[A\n",
            "Epoch 1:   1%|          | 10/1835 [00:16<39:58,  1.31s/it, training loss=0.2912]\u001b[A\n",
            "Epoch 1:   1%|          | 10/1835 [00:17<39:58,  1.31s/it, training loss=0.2791]\u001b[A\n",
            "Epoch 1:   1%|          | 11/1835 [00:17<39:38,  1.30s/it, training loss=0.2791]\u001b[A\n",
            "Epoch 1:   1%|          | 11/1835 [00:18<39:38,  1.30s/it, training loss=0.2498]\u001b[A\n",
            "Epoch 1:   1%|          | 12/1835 [00:18<39:20,  1.29s/it, training loss=0.2498]\u001b[A\n",
            "Epoch 1:   1%|          | 12/1835 [00:20<39:20,  1.29s/it, training loss=0.2779]\u001b[A\n",
            "Epoch 1:   1%|          | 13/1835 [00:20<39:08,  1.29s/it, training loss=0.2779]\u001b[A\n",
            "Epoch 1:   1%|          | 13/1835 [00:21<39:08,  1.29s/it, training loss=0.3242]\u001b[A\n",
            "Epoch 1:   1%|          | 14/1835 [00:21<39:01,  1.29s/it, training loss=0.3242]\u001b[A\n",
            "Epoch 1:   1%|          | 14/1835 [00:22<39:01,  1.29s/it, training loss=0.4136]\u001b[A\n",
            "Epoch 1:   1%|          | 15/1835 [00:22<39:02,  1.29s/it, training loss=0.4136]\u001b[A\n",
            "Epoch 1:   1%|          | 15/1835 [00:23<39:02,  1.29s/it, training loss=0.3023]\u001b[A\n",
            "Epoch 1:   1%|          | 16/1835 [00:23<39:04,  1.29s/it, training loss=0.3023]\u001b[A\n",
            "Epoch 1:   1%|          | 16/1835 [00:25<39:04,  1.29s/it, training loss=0.3247]\u001b[A\n",
            "Epoch 1:   1%|          | 17/1835 [00:25<39:00,  1.29s/it, training loss=0.3247]\u001b[A\n",
            "Epoch 1:   1%|          | 17/1835 [00:26<39:00,  1.29s/it, training loss=0.3300]\u001b[A\n",
            "Epoch 1:   1%|          | 18/1835 [00:26<38:58,  1.29s/it, training loss=0.3300]\u001b[A\n",
            "Epoch 1:   1%|          | 18/1835 [00:27<38:58,  1.29s/it, training loss=0.2588]\u001b[A\n",
            "Epoch 1:   1%|          | 19/1835 [00:27<38:54,  1.29s/it, training loss=0.2588]\u001b[A\n",
            "Epoch 1:   1%|          | 19/1835 [00:29<38:54,  1.29s/it, training loss=0.3245]\u001b[A\n",
            "Epoch 1:   1%|          | 20/1835 [00:29<38:57,  1.29s/it, training loss=0.3245]\u001b[A\n",
            "Epoch 1:   1%|          | 20/1835 [00:30<38:57,  1.29s/it, training loss=0.2716]\u001b[A\n",
            "Epoch 1:   1%|          | 21/1835 [00:30<38:59,  1.29s/it, training loss=0.2716]\u001b[A\n",
            "Epoch 1:   1%|          | 21/1835 [00:31<38:59,  1.29s/it, training loss=0.3219]\u001b[A\n",
            "Epoch 1:   1%|          | 22/1835 [00:31<38:53,  1.29s/it, training loss=0.3219]\u001b[A\n",
            "Epoch 1:   1%|          | 22/1835 [00:32<38:53,  1.29s/it, training loss=0.2453]\u001b[A\n",
            "Epoch 1:   1%|▏         | 23/1835 [00:32<38:56,  1.29s/it, training loss=0.2453]\u001b[A\n",
            "Epoch 1:   1%|▏         | 23/1835 [00:34<38:56,  1.29s/it, training loss=0.3028]\u001b[A\n",
            "Epoch 1:   1%|▏         | 24/1835 [00:34<39:04,  1.29s/it, training loss=0.3028]\u001b[A\n",
            "Epoch 1:   1%|▏         | 24/1835 [00:35<39:04,  1.29s/it, training loss=0.3086]\u001b[A\n",
            "Epoch 1:   1%|▏         | 25/1835 [00:35<39:09,  1.30s/it, training loss=0.3086]\u001b[A\n",
            "Epoch 1:   1%|▏         | 25/1835 [00:36<39:09,  1.30s/it, training loss=0.2350]\u001b[A\n",
            "Epoch 1:   1%|▏         | 26/1835 [00:36<39:06,  1.30s/it, training loss=0.2350]\u001b[A\n",
            "Epoch 1:   1%|▏         | 26/1835 [00:38<39:06,  1.30s/it, training loss=0.2779]\u001b[A\n",
            "Epoch 1:   1%|▏         | 27/1835 [00:38<39:11,  1.30s/it, training loss=0.2779]\u001b[A\n",
            "Epoch 1:   1%|▏         | 27/1835 [00:39<39:11,  1.30s/it, training loss=0.1956]\u001b[A\n",
            "Epoch 1:   2%|▏         | 28/1835 [00:39<39:15,  1.30s/it, training loss=0.1956]\u001b[A\n",
            "Epoch 1:   2%|▏         | 28/1835 [00:40<39:15,  1.30s/it, training loss=0.2960]\u001b[A\n",
            "Epoch 1:   2%|▏         | 29/1835 [00:40<39:14,  1.30s/it, training loss=0.2960]\u001b[A\n",
            "Epoch 1:   2%|▏         | 29/1835 [00:42<39:14,  1.30s/it, training loss=0.3448]\u001b[A\n",
            "Epoch 1:   2%|▏         | 30/1835 [00:42<39:14,  1.30s/it, training loss=0.3448]\u001b[A\n",
            "Epoch 1:   2%|▏         | 30/1835 [00:43<39:14,  1.30s/it, training loss=0.2194]\u001b[A\n",
            "Epoch 1:   2%|▏         | 31/1835 [00:43<39:17,  1.31s/it, training loss=0.2194]\u001b[A\n",
            "Epoch 1:   2%|▏         | 31/1835 [00:44<39:17,  1.31s/it, training loss=0.3770]\u001b[A\n",
            "Epoch 1:   2%|▏         | 32/1835 [00:44<39:16,  1.31s/it, training loss=0.3770]\u001b[A\n",
            "Epoch 1:   2%|▏         | 32/1835 [00:45<39:16,  1.31s/it, training loss=0.2633]\u001b[A\n",
            "Epoch 1:   2%|▏         | 33/1835 [00:45<39:16,  1.31s/it, training loss=0.2633]\u001b[A\n",
            "Epoch 1:   2%|▏         | 33/1835 [00:47<39:16,  1.31s/it, training loss=0.1706]\u001b[A\n",
            "Epoch 1:   2%|▏         | 34/1835 [00:47<39:21,  1.31s/it, training loss=0.1706]\u001b[A\n",
            "Epoch 1:   2%|▏         | 34/1835 [00:48<39:21,  1.31s/it, training loss=0.2656]\u001b[A\n",
            "Epoch 1:   2%|▏         | 35/1835 [00:48<39:23,  1.31s/it, training loss=0.2656]\u001b[A\n",
            "Epoch 1:   2%|▏         | 35/1835 [00:49<39:23,  1.31s/it, training loss=0.3037]\u001b[A\n",
            "Epoch 1:   2%|▏         | 36/1835 [00:49<39:24,  1.31s/it, training loss=0.3037]\u001b[A\n",
            "Epoch 1:   2%|▏         | 36/1835 [00:51<39:24,  1.31s/it, training loss=0.2505]\u001b[A\n",
            "Epoch 1:   2%|▏         | 37/1835 [00:51<39:23,  1.31s/it, training loss=0.2505]\u001b[A\n",
            "Epoch 1:   2%|▏         | 37/1835 [00:52<39:23,  1.31s/it, training loss=0.2532]\u001b[A\n",
            "Epoch 1:   2%|▏         | 38/1835 [00:52<39:25,  1.32s/it, training loss=0.2532]\u001b[A\n",
            "Epoch 1:   2%|▏         | 38/1835 [00:53<39:25,  1.32s/it, training loss=0.1917]\u001b[A\n",
            "Epoch 1:   2%|▏         | 39/1835 [00:53<39:30,  1.32s/it, training loss=0.1917]\u001b[A\n",
            "Epoch 1:   2%|▏         | 39/1835 [00:55<39:30,  1.32s/it, training loss=0.2503]\u001b[A\n",
            "Epoch 1:   2%|▏         | 40/1835 [00:55<39:34,  1.32s/it, training loss=0.2503]\u001b[A\n",
            "Epoch 1:   2%|▏         | 40/1835 [00:56<39:34,  1.32s/it, training loss=0.3273]\u001b[A\n",
            "Epoch 1:   2%|▏         | 41/1835 [00:56<39:37,  1.33s/it, training loss=0.3273]\u001b[A\n",
            "Epoch 1:   2%|▏         | 41/1835 [00:57<39:37,  1.33s/it, training loss=0.1514]\u001b[A\n",
            "Epoch 1:   2%|▏         | 42/1835 [00:57<39:41,  1.33s/it, training loss=0.1514]\u001b[A\n",
            "Epoch 1:   2%|▏         | 42/1835 [00:59<39:41,  1.33s/it, training loss=0.1616]\u001b[A\n",
            "Epoch 1:   2%|▏         | 43/1835 [00:59<39:41,  1.33s/it, training loss=0.1616]\u001b[A\n",
            "Epoch 1:   2%|▏         | 43/1835 [01:00<39:41,  1.33s/it, training loss=0.1353]\u001b[A\n",
            "Epoch 1:   2%|▏         | 44/1835 [01:00<39:44,  1.33s/it, training loss=0.1353]\u001b[A\n",
            "Epoch 1:   2%|▏         | 44/1835 [01:01<39:44,  1.33s/it, training loss=0.1421]\u001b[A\n",
            "Epoch 1:   2%|▏         | 45/1835 [01:01<39:46,  1.33s/it, training loss=0.1421]\u001b[A\n",
            "Epoch 1:   2%|▏         | 45/1835 [01:03<39:46,  1.33s/it, training loss=0.1816]\u001b[A\n",
            "Epoch 1:   3%|▎         | 46/1835 [01:03<39:51,  1.34s/it, training loss=0.1816]\u001b[A\n",
            "Epoch 1:   3%|▎         | 46/1835 [01:04<39:51,  1.34s/it, training loss=0.4543]\u001b[A\n",
            "Epoch 1:   3%|▎         | 47/1835 [01:04<39:51,  1.34s/it, training loss=0.4543]\u001b[A\n",
            "Epoch 1:   3%|▎         | 47/1835 [01:05<39:51,  1.34s/it, training loss=0.4454]\u001b[A\n",
            "Epoch 1:   3%|▎         | 48/1835 [01:05<39:57,  1.34s/it, training loss=0.4454]\u001b[A\n",
            "Epoch 1:   3%|▎         | 48/1835 [01:07<39:57,  1.34s/it, training loss=0.2822]\u001b[A\n",
            "Epoch 1:   3%|▎         | 49/1835 [01:07<40:02,  1.34s/it, training loss=0.2822]\u001b[A\n",
            "Epoch 1:   3%|▎         | 49/1835 [01:08<40:02,  1.34s/it, training loss=0.3239]\u001b[A\n",
            "Epoch 1:   3%|▎         | 50/1835 [01:08<40:03,  1.35s/it, training loss=0.3239]\u001b[A\n",
            "Epoch 1:   3%|▎         | 50/1835 [01:09<40:03,  1.35s/it, training loss=0.2283]\u001b[A\n",
            "Epoch 1:   3%|▎         | 51/1835 [01:09<40:07,  1.35s/it, training loss=0.2283]\u001b[A\n",
            "Epoch 1:   3%|▎         | 51/1835 [01:11<40:07,  1.35s/it, training loss=0.2231]\u001b[A\n",
            "Epoch 1:   3%|▎         | 52/1835 [01:11<40:09,  1.35s/it, training loss=0.2231]\u001b[A\n",
            "Epoch 1:   3%|▎         | 52/1835 [01:12<40:09,  1.35s/it, training loss=0.3202]\u001b[A\n",
            "Epoch 1:   3%|▎         | 53/1835 [01:12<40:08,  1.35s/it, training loss=0.3202]\u001b[A\n",
            "Epoch 1:   3%|▎         | 53/1835 [01:14<40:08,  1.35s/it, training loss=0.3501]\u001b[A\n",
            "Epoch 1:   3%|▎         | 54/1835 [01:14<40:15,  1.36s/it, training loss=0.3501]\u001b[A\n",
            "Epoch 1:   3%|▎         | 54/1835 [01:15<40:15,  1.36s/it, training loss=0.2936]\u001b[A\n",
            "Epoch 1:   3%|▎         | 55/1835 [01:15<40:12,  1.36s/it, training loss=0.2936]\u001b[A\n",
            "Epoch 1:   3%|▎         | 55/1835 [01:16<40:12,  1.36s/it, training loss=0.2263]\u001b[A\n",
            "Epoch 1:   3%|▎         | 56/1835 [01:16<40:16,  1.36s/it, training loss=0.2263]\u001b[A\n",
            "Epoch 1:   3%|▎         | 56/1835 [01:18<40:16,  1.36s/it, training loss=0.2393]\u001b[A\n",
            "Epoch 1:   3%|▎         | 57/1835 [01:18<40:17,  1.36s/it, training loss=0.2393]\u001b[A\n",
            "Epoch 1:   3%|▎         | 57/1835 [01:19<40:17,  1.36s/it, training loss=0.2106]\u001b[A\n",
            "Epoch 1:   3%|▎         | 58/1835 [01:19<40:21,  1.36s/it, training loss=0.2106]\u001b[A\n",
            "Epoch 1:   3%|▎         | 58/1835 [01:20<40:21,  1.36s/it, training loss=0.4080]\u001b[A\n",
            "Epoch 1:   3%|▎         | 59/1835 [01:20<40:24,  1.36s/it, training loss=0.4080]\u001b[A\n",
            "Epoch 1:   3%|▎         | 59/1835 [01:22<40:24,  1.36s/it, training loss=0.2742]\u001b[A\n",
            "Epoch 1:   3%|▎         | 60/1835 [01:22<40:29,  1.37s/it, training loss=0.2742]\u001b[A\n",
            "Epoch 1:   3%|▎         | 60/1835 [01:23<40:29,  1.37s/it, training loss=0.1434]\u001b[A\n",
            "Epoch 1:   3%|▎         | 61/1835 [01:23<40:29,  1.37s/it, training loss=0.1434]\u001b[A\n",
            "Epoch 1:   3%|▎         | 61/1835 [01:24<40:29,  1.37s/it, training loss=0.1809]\u001b[A\n",
            "Epoch 1:   3%|▎         | 62/1835 [01:25<40:36,  1.37s/it, training loss=0.1809]\u001b[A\n",
            "Epoch 1:   3%|▎         | 62/1835 [01:26<40:36,  1.37s/it, training loss=0.3024]\u001b[A\n",
            "Epoch 1:   3%|▎         | 63/1835 [01:26<40:36,  1.37s/it, training loss=0.3024]\u001b[A\n",
            "Epoch 1:   3%|▎         | 63/1835 [01:27<40:36,  1.37s/it, training loss=0.1894]\u001b[A\n",
            "Epoch 1:   3%|▎         | 64/1835 [01:27<40:41,  1.38s/it, training loss=0.1894]\u001b[A\n",
            "Epoch 1:   3%|▎         | 64/1835 [01:29<40:41,  1.38s/it, training loss=0.1778]\u001b[A\n",
            "Epoch 1:   4%|▎         | 65/1835 [01:29<40:48,  1.38s/it, training loss=0.1778]\u001b[A\n",
            "Epoch 1:   4%|▎         | 65/1835 [01:30<40:48,  1.38s/it, training loss=0.2581]\u001b[A\n",
            "Epoch 1:   4%|▎         | 66/1835 [01:30<40:51,  1.39s/it, training loss=0.2581]\u001b[A\n",
            "Epoch 1:   4%|▎         | 66/1835 [01:31<40:51,  1.39s/it, training loss=0.1292]\u001b[A\n",
            "Epoch 1:   4%|▎         | 67/1835 [01:31<40:52,  1.39s/it, training loss=0.1292]\u001b[A\n",
            "Epoch 1:   4%|▎         | 67/1835 [01:33<40:52,  1.39s/it, training loss=0.1712]\u001b[A\n",
            "Epoch 1:   4%|▎         | 68/1835 [01:33<41:00,  1.39s/it, training loss=0.1712]\u001b[A\n",
            "Epoch 1:   4%|▎         | 68/1835 [01:34<41:00,  1.39s/it, training loss=0.2410]\u001b[A\n",
            "Epoch 1:   4%|▍         | 69/1835 [01:34<41:04,  1.40s/it, training loss=0.2410]\u001b[A\n",
            "Epoch 1:   4%|▍         | 69/1835 [01:36<41:04,  1.40s/it, training loss=0.4093]\u001b[A\n",
            "Epoch 1:   4%|▍         | 70/1835 [01:36<41:03,  1.40s/it, training loss=0.4093]\u001b[A\n",
            "Epoch 1:   4%|▍         | 70/1835 [01:37<41:03,  1.40s/it, training loss=0.3189]\u001b[A\n",
            "Epoch 1:   4%|▍         | 71/1835 [01:37<41:07,  1.40s/it, training loss=0.3189]\u001b[A\n",
            "Epoch 1:   4%|▍         | 71/1835 [01:38<41:07,  1.40s/it, training loss=0.2507]\u001b[A\n",
            "Epoch 1:   4%|▍         | 72/1835 [01:38<41:14,  1.40s/it, training loss=0.2507]\u001b[A\n",
            "Epoch 1:   4%|▍         | 72/1835 [01:40<41:14,  1.40s/it, training loss=0.2649]\u001b[A\n",
            "Epoch 1:   4%|▍         | 73/1835 [01:40<41:15,  1.40s/it, training loss=0.2649]\u001b[A\n",
            "Epoch 1:   4%|▍         | 73/1835 [01:41<41:15,  1.40s/it, training loss=0.2560]\u001b[A\n",
            "Epoch 1:   4%|▍         | 74/1835 [01:41<41:18,  1.41s/it, training loss=0.2560]\u001b[A\n",
            "Epoch 1:   4%|▍         | 74/1835 [01:43<41:18,  1.41s/it, training loss=0.2763]\u001b[A\n",
            "Epoch 1:   4%|▍         | 75/1835 [01:43<41:22,  1.41s/it, training loss=0.2763]\u001b[A\n",
            "Epoch 1:   4%|▍         | 75/1835 [01:44<41:22,  1.41s/it, training loss=0.1738]\u001b[A\n",
            "Epoch 1:   4%|▍         | 76/1835 [01:44<41:26,  1.41s/it, training loss=0.1738]\u001b[A\n",
            "Epoch 1:   4%|▍         | 76/1835 [01:46<41:26,  1.41s/it, training loss=0.1727]\u001b[A\n",
            "Epoch 1:   4%|▍         | 77/1835 [01:46<41:28,  1.42s/it, training loss=0.1727]\u001b[A\n",
            "Epoch 1:   4%|▍         | 77/1835 [01:47<41:28,  1.42s/it, training loss=0.3812]\u001b[A\n",
            "Epoch 1:   4%|▍         | 78/1835 [01:47<41:29,  1.42s/it, training loss=0.3812]\u001b[A\n",
            "Epoch 1:   4%|▍         | 78/1835 [01:48<41:29,  1.42s/it, training loss=0.1782]\u001b[A\n",
            "Epoch 1:   4%|▍         | 79/1835 [01:48<41:30,  1.42s/it, training loss=0.1782]\u001b[A\n",
            "Epoch 1:   4%|▍         | 79/1835 [01:50<41:30,  1.42s/it, training loss=0.2867]\u001b[A\n",
            "Epoch 1:   4%|▍         | 80/1835 [01:50<41:36,  1.42s/it, training loss=0.2867]\u001b[A\n",
            "Epoch 1:   4%|▍         | 80/1835 [01:51<41:36,  1.42s/it, training loss=0.2529]\u001b[A\n",
            "Epoch 1:   4%|▍         | 81/1835 [01:51<41:34,  1.42s/it, training loss=0.2529]\u001b[A\n",
            "Epoch 1:   4%|▍         | 81/1835 [01:53<41:34,  1.42s/it, training loss=0.2800]\u001b[A\n",
            "Epoch 1:   4%|▍         | 82/1835 [01:53<41:35,  1.42s/it, training loss=0.2800]\u001b[A\n",
            "Epoch 1:   4%|▍         | 82/1835 [01:54<41:35,  1.42s/it, training loss=0.2508]\u001b[A\n",
            "Epoch 1:   5%|▍         | 83/1835 [01:54<41:38,  1.43s/it, training loss=0.2508]\u001b[A\n",
            "Epoch 1:   5%|▍         | 83/1835 [01:56<41:38,  1.43s/it, training loss=0.1841]\u001b[A\n",
            "Epoch 1:   5%|▍         | 84/1835 [01:56<41:39,  1.43s/it, training loss=0.1841]\u001b[A\n",
            "Epoch 1:   5%|▍         | 84/1835 [01:57<41:39,  1.43s/it, training loss=0.1401]\u001b[A\n",
            "Epoch 1:   5%|▍         | 85/1835 [01:57<41:34,  1.43s/it, training loss=0.1401]\u001b[A\n",
            "Epoch 1:   5%|▍         | 85/1835 [01:58<41:34,  1.43s/it, training loss=0.1551]\u001b[A\n",
            "Epoch 1:   5%|▍         | 86/1835 [01:58<41:28,  1.42s/it, training loss=0.1551]\u001b[A\n",
            "Epoch 1:   5%|▍         | 86/1835 [02:00<41:28,  1.42s/it, training loss=0.0909]\u001b[A\n",
            "Epoch 1:   5%|▍         | 87/1835 [02:00<41:21,  1.42s/it, training loss=0.0909]\u001b[A\n",
            "Epoch 1:   5%|▍         | 87/1835 [02:01<41:21,  1.42s/it, training loss=0.2758]\u001b[A\n",
            "Epoch 1:   5%|▍         | 88/1835 [02:01<41:16,  1.42s/it, training loss=0.2758]\u001b[A\n",
            "Epoch 1:   5%|▍         | 88/1835 [02:03<41:16,  1.42s/it, training loss=0.0868]\u001b[A\n",
            "Epoch 1:   5%|▍         | 89/1835 [02:03<41:12,  1.42s/it, training loss=0.0868]\u001b[A\n",
            "Epoch 1:   5%|▍         | 89/1835 [02:04<41:12,  1.42s/it, training loss=0.1483]\u001b[A\n",
            "Epoch 1:   5%|▍         | 90/1835 [02:04<41:05,  1.41s/it, training loss=0.1483]\u001b[A\n",
            "Epoch 1:   5%|▍         | 90/1835 [02:05<41:05,  1.41s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 1:   5%|▍         | 91/1835 [02:05<40:59,  1.41s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 1:   5%|▍         | 91/1835 [02:07<40:59,  1.41s/it, training loss=0.1983]\u001b[A\n",
            "Epoch 1:   5%|▌         | 92/1835 [02:07<40:52,  1.41s/it, training loss=0.1983]\u001b[A\n",
            "Epoch 1:   5%|▌         | 92/1835 [02:08<40:52,  1.41s/it, training loss=0.2219]\u001b[A\n",
            "Epoch 1:   5%|▌         | 93/1835 [02:08<40:49,  1.41s/it, training loss=0.2219]\u001b[A\n",
            "Epoch 1:   5%|▌         | 93/1835 [02:10<40:49,  1.41s/it, training loss=0.2249]\u001b[A\n",
            "Epoch 1:   5%|▌         | 94/1835 [02:10<40:47,  1.41s/it, training loss=0.2249]\u001b[A\n",
            "Epoch 1:   5%|▌         | 94/1835 [02:11<40:47,  1.41s/it, training loss=0.2272]\u001b[A\n",
            "Epoch 1:   5%|▌         | 95/1835 [02:11<40:41,  1.40s/it, training loss=0.2272]\u001b[A\n",
            "Epoch 1:   5%|▌         | 95/1835 [02:12<40:41,  1.40s/it, training loss=0.2367]\u001b[A\n",
            "Epoch 1:   5%|▌         | 96/1835 [02:12<40:39,  1.40s/it, training loss=0.2367]\u001b[A\n",
            "Epoch 1:   5%|▌         | 96/1835 [02:14<40:39,  1.40s/it, training loss=0.4112]\u001b[A\n",
            "Epoch 1:   5%|▌         | 97/1835 [02:14<40:37,  1.40s/it, training loss=0.4112]\u001b[A\n",
            "Epoch 1:   5%|▌         | 97/1835 [02:15<40:37,  1.40s/it, training loss=0.3249]\u001b[A\n",
            "Epoch 1:   5%|▌         | 98/1835 [02:15<40:31,  1.40s/it, training loss=0.3249]\u001b[A\n",
            "Epoch 1:   5%|▌         | 98/1835 [02:17<40:31,  1.40s/it, training loss=0.2278]\u001b[A\n",
            "Epoch 1:   5%|▌         | 99/1835 [02:17<40:27,  1.40s/it, training loss=0.2278]\u001b[A\n",
            "Epoch 1:   5%|▌         | 99/1835 [02:18<40:27,  1.40s/it, training loss=0.2708]\u001b[A\n",
            "Epoch 1:   5%|▌         | 100/1835 [02:18<40:23,  1.40s/it, training loss=0.2708]\u001b[A\n",
            "Epoch 1:   5%|▌         | 100/1835 [02:19<40:23,  1.40s/it, training loss=0.3279]\u001b[A\n",
            "Epoch 1:   6%|▌         | 101/1835 [02:19<40:18,  1.39s/it, training loss=0.3279]\u001b[A\n",
            "Epoch 1:   6%|▌         | 101/1835 [02:21<40:18,  1.39s/it, training loss=0.2078]\u001b[A\n",
            "Epoch 1:   6%|▌         | 102/1835 [02:21<40:10,  1.39s/it, training loss=0.2078]\u001b[A\n",
            "Epoch 1:   6%|▌         | 102/1835 [02:22<40:10,  1.39s/it, training loss=0.1891]\u001b[A\n",
            "Epoch 1:   6%|▌         | 103/1835 [02:22<40:06,  1.39s/it, training loss=0.1891]\u001b[A\n",
            "Epoch 1:   6%|▌         | 103/1835 [02:24<40:06,  1.39s/it, training loss=0.2350]\u001b[A\n",
            "Epoch 1:   6%|▌         | 104/1835 [02:24<39:59,  1.39s/it, training loss=0.2350]\u001b[A\n",
            "Epoch 1:   6%|▌         | 104/1835 [02:25<39:59,  1.39s/it, training loss=0.1786]\u001b[A\n",
            "Epoch 1:   6%|▌         | 105/1835 [02:25<39:54,  1.38s/it, training loss=0.1786]\u001b[A\n",
            "Epoch 1:   6%|▌         | 105/1835 [02:26<39:54,  1.38s/it, training loss=0.2005]\u001b[A\n",
            "Epoch 1:   6%|▌         | 106/1835 [02:26<39:53,  1.38s/it, training loss=0.2005]\u001b[A\n",
            "Epoch 1:   6%|▌         | 106/1835 [02:28<39:53,  1.38s/it, training loss=0.1591]\u001b[A\n",
            "Epoch 1:   6%|▌         | 107/1835 [02:28<39:53,  1.39s/it, training loss=0.1591]\u001b[A\n",
            "Epoch 1:   6%|▌         | 107/1835 [02:29<39:53,  1.39s/it, training loss=0.2157]\u001b[A\n",
            "Epoch 1:   6%|▌         | 108/1835 [02:29<39:53,  1.39s/it, training loss=0.2157]\u001b[A\n",
            "Epoch 1:   6%|▌         | 108/1835 [02:30<39:53,  1.39s/it, training loss=0.3206]\u001b[A\n",
            "Epoch 1:   6%|▌         | 109/1835 [02:30<39:50,  1.38s/it, training loss=0.3206]\u001b[A\n",
            "Epoch 1:   6%|▌         | 109/1835 [02:32<39:50,  1.38s/it, training loss=0.1719]\u001b[A\n",
            "Epoch 1:   6%|▌         | 110/1835 [02:32<39:47,  1.38s/it, training loss=0.1719]\u001b[A\n",
            "Epoch 1:   6%|▌         | 110/1835 [02:33<39:47,  1.38s/it, training loss=0.2250]\u001b[A\n",
            "Epoch 1:   6%|▌         | 111/1835 [02:33<39:44,  1.38s/it, training loss=0.2250]\u001b[A\n",
            "Epoch 1:   6%|▌         | 111/1835 [02:35<39:44,  1.38s/it, training loss=0.2594]\u001b[A\n",
            "Epoch 1:   6%|▌         | 112/1835 [02:35<39:47,  1.39s/it, training loss=0.2594]\u001b[A\n",
            "Epoch 1:   6%|▌         | 112/1835 [02:36<39:47,  1.39s/it, training loss=0.3241]\u001b[A\n",
            "Epoch 1:   6%|▌         | 113/1835 [02:36<39:42,  1.38s/it, training loss=0.3241]\u001b[A\n",
            "Epoch 1:   6%|▌         | 113/1835 [02:37<39:42,  1.38s/it, training loss=0.2711]\u001b[A\n",
            "Epoch 1:   6%|▌         | 114/1835 [02:37<39:42,  1.38s/it, training loss=0.2711]\u001b[A\n",
            "Epoch 1:   6%|▌         | 114/1835 [02:39<39:42,  1.38s/it, training loss=0.2857]\u001b[A\n",
            "Epoch 1:   6%|▋         | 115/1835 [02:39<39:40,  1.38s/it, training loss=0.2857]\u001b[A\n",
            "Epoch 1:   6%|▋         | 115/1835 [02:40<39:40,  1.38s/it, training loss=0.3519]\u001b[A\n",
            "Epoch 1:   6%|▋         | 116/1835 [02:40<39:38,  1.38s/it, training loss=0.3519]\u001b[A\n",
            "Epoch 1:   6%|▋         | 116/1835 [02:42<39:38,  1.38s/it, training loss=0.2240]\u001b[A\n",
            "Epoch 1:   6%|▋         | 117/1835 [02:42<39:39,  1.38s/it, training loss=0.2240]\u001b[A\n",
            "Epoch 1:   6%|▋         | 117/1835 [02:43<39:39,  1.38s/it, training loss=0.1891]\u001b[A\n",
            "Epoch 1:   6%|▋         | 118/1835 [02:43<39:39,  1.39s/it, training loss=0.1891]\u001b[A\n",
            "Epoch 1:   6%|▋         | 118/1835 [02:44<39:39,  1.39s/it, training loss=0.2873]\u001b[A\n",
            "Epoch 1:   6%|▋         | 119/1835 [02:44<39:38,  1.39s/it, training loss=0.2873]\u001b[A\n",
            "Epoch 1:   6%|▋         | 119/1835 [02:46<39:38,  1.39s/it, training loss=0.2524]\u001b[A\n",
            "Epoch 1:   7%|▋         | 120/1835 [02:46<39:34,  1.38s/it, training loss=0.2524]\u001b[A\n",
            "Epoch 1:   7%|▋         | 120/1835 [02:47<39:34,  1.38s/it, training loss=0.2329]\u001b[A\n",
            "Epoch 1:   7%|▋         | 121/1835 [02:47<39:32,  1.38s/it, training loss=0.2329]\u001b[A\n",
            "Epoch 1:   7%|▋         | 121/1835 [02:48<39:32,  1.38s/it, training loss=0.1949]\u001b[A\n",
            "Epoch 1:   7%|▋         | 122/1835 [02:48<39:33,  1.39s/it, training loss=0.1949]\u001b[A\n",
            "Epoch 1:   7%|▋         | 122/1835 [02:50<39:33,  1.39s/it, training loss=0.2183]\u001b[A\n",
            "Epoch 1:   7%|▋         | 123/1835 [02:50<39:30,  1.38s/it, training loss=0.2183]\u001b[A\n",
            "Epoch 1:   7%|▋         | 123/1835 [02:51<39:30,  1.38s/it, training loss=0.2377]\u001b[A\n",
            "Epoch 1:   7%|▋         | 124/1835 [02:51<39:30,  1.39s/it, training loss=0.2377]\u001b[A\n",
            "Epoch 1:   7%|▋         | 124/1835 [02:53<39:30,  1.39s/it, training loss=0.2397]\u001b[A\n",
            "Epoch 1:   7%|▋         | 125/1835 [02:53<39:33,  1.39s/it, training loss=0.2397]\u001b[A\n",
            "Epoch 1:   7%|▋         | 125/1835 [02:54<39:33,  1.39s/it, training loss=0.2558]\u001b[A\n",
            "Epoch 1:   7%|▋         | 126/1835 [02:54<39:31,  1.39s/it, training loss=0.2558]\u001b[A\n",
            "Epoch 1:   7%|▋         | 126/1835 [02:55<39:31,  1.39s/it, training loss=0.2335]\u001b[A\n",
            "Epoch 1:   7%|▋         | 127/1835 [02:55<39:37,  1.39s/it, training loss=0.2335]\u001b[A\n",
            "Epoch 1:   7%|▋         | 127/1835 [02:57<39:37,  1.39s/it, training loss=0.2529]\u001b[A\n",
            "Epoch 1:   7%|▋         | 128/1835 [02:57<39:40,  1.39s/it, training loss=0.2529]\u001b[A\n",
            "Epoch 1:   7%|▋         | 128/1835 [02:58<39:40,  1.39s/it, training loss=0.1955]\u001b[A\n",
            "Epoch 1:   7%|▋         | 129/1835 [02:58<39:39,  1.39s/it, training loss=0.1955]\u001b[A\n",
            "Epoch 1:   7%|▋         | 129/1835 [03:00<39:39,  1.39s/it, training loss=0.2429]\u001b[A\n",
            "Epoch 1:   7%|▋         | 130/1835 [03:00<39:38,  1.39s/it, training loss=0.2429]\u001b[A\n",
            "Epoch 1:   7%|▋         | 130/1835 [03:01<39:38,  1.39s/it, training loss=0.2175]\u001b[A\n",
            "Epoch 1:   7%|▋         | 131/1835 [03:01<39:37,  1.40s/it, training loss=0.2175]\u001b[A\n",
            "Epoch 1:   7%|▋         | 131/1835 [03:02<39:37,  1.40s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 1:   7%|▋         | 132/1835 [03:02<39:36,  1.40s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 1:   7%|▋         | 132/1835 [03:04<39:36,  1.40s/it, training loss=0.2887]\u001b[A\n",
            "Epoch 1:   7%|▋         | 133/1835 [03:04<39:38,  1.40s/it, training loss=0.2887]\u001b[A\n",
            "Epoch 1:   7%|▋         | 133/1835 [03:05<39:38,  1.40s/it, training loss=0.1635]\u001b[A\n",
            "Epoch 1:   7%|▋         | 134/1835 [03:05<39:35,  1.40s/it, training loss=0.1635]\u001b[A\n",
            "Epoch 1:   7%|▋         | 134/1835 [03:07<39:35,  1.40s/it, training loss=0.1598]\u001b[A\n",
            "Epoch 1:   7%|▋         | 135/1835 [03:07<39:29,  1.39s/it, training loss=0.1598]\u001b[A\n",
            "Epoch 1:   7%|▋         | 135/1835 [03:08<39:29,  1.39s/it, training loss=0.3239]\u001b[A\n",
            "Epoch 1:   7%|▋         | 136/1835 [03:08<39:33,  1.40s/it, training loss=0.3239]\u001b[A\n",
            "Epoch 1:   7%|▋         | 136/1835 [03:09<39:33,  1.40s/it, training loss=0.1896]\u001b[A\n",
            "Epoch 1:   7%|▋         | 137/1835 [03:09<39:30,  1.40s/it, training loss=0.1896]\u001b[A\n",
            "Epoch 1:   7%|▋         | 137/1835 [03:11<39:30,  1.40s/it, training loss=0.2476]\u001b[A\n",
            "Epoch 1:   8%|▊         | 138/1835 [03:11<39:27,  1.39s/it, training loss=0.2476]\u001b[A\n",
            "Epoch 1:   8%|▊         | 138/1835 [03:12<39:27,  1.39s/it, training loss=0.2570]\u001b[A\n",
            "Epoch 1:   8%|▊         | 139/1835 [03:12<39:33,  1.40s/it, training loss=0.2570]\u001b[A\n",
            "Epoch 1:   8%|▊         | 139/1835 [03:14<39:33,  1.40s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 1:   8%|▊         | 140/1835 [03:14<39:34,  1.40s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 1:   8%|▊         | 140/1835 [03:15<39:34,  1.40s/it, training loss=0.2430]\u001b[A\n",
            "Epoch 1:   8%|▊         | 141/1835 [03:15<39:31,  1.40s/it, training loss=0.2430]\u001b[A\n",
            "Epoch 1:   8%|▊         | 141/1835 [03:16<39:31,  1.40s/it, training loss=0.2341]\u001b[A\n",
            "Epoch 1:   8%|▊         | 142/1835 [03:16<39:29,  1.40s/it, training loss=0.2341]\u001b[A\n",
            "Epoch 1:   8%|▊         | 142/1835 [03:18<39:29,  1.40s/it, training loss=0.2416]\u001b[A\n",
            "Epoch 1:   8%|▊         | 143/1835 [03:18<39:28,  1.40s/it, training loss=0.2416]\u001b[A\n",
            "Epoch 1:   8%|▊         | 143/1835 [03:19<39:28,  1.40s/it, training loss=0.2941]\u001b[A\n",
            "Epoch 1:   8%|▊         | 144/1835 [03:19<39:28,  1.40s/it, training loss=0.2941]\u001b[A\n",
            "Epoch 1:   8%|▊         | 144/1835 [03:21<39:28,  1.40s/it, training loss=0.1842]\u001b[A\n",
            "Epoch 1:   8%|▊         | 145/1835 [03:21<39:27,  1.40s/it, training loss=0.1842]\u001b[A\n",
            "Epoch 1:   8%|▊         | 145/1835 [03:22<39:27,  1.40s/it, training loss=0.1224]\u001b[A\n",
            "Epoch 1:   8%|▊         | 146/1835 [03:22<39:26,  1.40s/it, training loss=0.1224]\u001b[A\n",
            "Epoch 1:   8%|▊         | 146/1835 [03:23<39:26,  1.40s/it, training loss=0.2864]\u001b[A\n",
            "Epoch 1:   8%|▊         | 147/1835 [03:23<39:31,  1.40s/it, training loss=0.2864]\u001b[A\n",
            "Epoch 1:   8%|▊         | 147/1835 [03:25<39:31,  1.40s/it, training loss=0.4044]\u001b[A\n",
            "Epoch 1:   8%|▊         | 148/1835 [03:25<39:27,  1.40s/it, training loss=0.4044]\u001b[A\n",
            "Epoch 1:   8%|▊         | 148/1835 [03:26<39:27,  1.40s/it, training loss=0.2096]\u001b[A\n",
            "Epoch 1:   8%|▊         | 149/1835 [03:26<39:26,  1.40s/it, training loss=0.2096]\u001b[A\n",
            "Epoch 1:   8%|▊         | 149/1835 [03:28<39:26,  1.40s/it, training loss=0.2482]\u001b[A\n",
            "Epoch 1:   8%|▊         | 150/1835 [03:28<39:25,  1.40s/it, training loss=0.2482]\u001b[A\n",
            "Epoch 1:   8%|▊         | 150/1835 [03:29<39:25,  1.40s/it, training loss=0.2755]\u001b[A\n",
            "Epoch 1:   8%|▊         | 151/1835 [03:29<39:20,  1.40s/it, training loss=0.2755]\u001b[A\n",
            "Epoch 1:   8%|▊         | 151/1835 [03:30<39:20,  1.40s/it, training loss=0.2334]\u001b[A\n",
            "Epoch 1:   8%|▊         | 152/1835 [03:30<39:17,  1.40s/it, training loss=0.2334]\u001b[A\n",
            "Epoch 1:   8%|▊         | 152/1835 [03:32<39:17,  1.40s/it, training loss=0.1526]\u001b[A\n",
            "Epoch 1:   8%|▊         | 153/1835 [03:32<39:15,  1.40s/it, training loss=0.1526]\u001b[A\n",
            "Epoch 1:   8%|▊         | 153/1835 [03:33<39:15,  1.40s/it, training loss=0.1045]\u001b[A\n",
            "Epoch 1:   8%|▊         | 154/1835 [03:33<39:14,  1.40s/it, training loss=0.1045]\u001b[A\n",
            "Epoch 1:   8%|▊         | 154/1835 [03:35<39:14,  1.40s/it, training loss=0.2151]\u001b[A\n",
            "Epoch 1:   8%|▊         | 155/1835 [03:35<39:12,  1.40s/it, training loss=0.2151]\u001b[A\n",
            "Epoch 1:   8%|▊         | 155/1835 [03:36<39:12,  1.40s/it, training loss=0.1333]\u001b[A\n",
            "Epoch 1:   9%|▊         | 156/1835 [03:36<39:12,  1.40s/it, training loss=0.1333]\u001b[A\n",
            "Epoch 1:   9%|▊         | 156/1835 [03:37<39:12,  1.40s/it, training loss=0.2007]\u001b[A\n",
            "Epoch 1:   9%|▊         | 157/1835 [03:37<39:08,  1.40s/it, training loss=0.2007]\u001b[A\n",
            "Epoch 1:   9%|▊         | 157/1835 [03:39<39:08,  1.40s/it, training loss=0.1565]\u001b[A\n",
            "Epoch 1:   9%|▊         | 158/1835 [03:39<39:09,  1.40s/it, training loss=0.1565]\u001b[A\n",
            "Epoch 1:   9%|▊         | 158/1835 [03:40<39:09,  1.40s/it, training loss=0.2364]\u001b[A\n",
            "Epoch 1:   9%|▊         | 159/1835 [03:40<39:06,  1.40s/it, training loss=0.2364]\u001b[A\n",
            "Epoch 1:   9%|▊         | 159/1835 [03:42<39:06,  1.40s/it, training loss=0.1458]\u001b[A\n",
            "Epoch 1:   9%|▊         | 160/1835 [03:42<39:03,  1.40s/it, training loss=0.1458]\u001b[A\n",
            "Epoch 1:   9%|▊         | 160/1835 [03:43<39:03,  1.40s/it, training loss=0.5052]\u001b[A\n",
            "Epoch 1:   9%|▉         | 161/1835 [03:43<38:59,  1.40s/it, training loss=0.5052]\u001b[A\n",
            "Epoch 1:   9%|▉         | 161/1835 [03:44<38:59,  1.40s/it, training loss=0.2462]\u001b[A\n",
            "Epoch 1:   9%|▉         | 162/1835 [03:44<38:57,  1.40s/it, training loss=0.2462]\u001b[A\n",
            "Epoch 1:   9%|▉         | 162/1835 [03:46<38:57,  1.40s/it, training loss=0.2522]\u001b[A\n",
            "Epoch 1:   9%|▉         | 163/1835 [03:46<38:53,  1.40s/it, training loss=0.2522]\u001b[A\n",
            "Epoch 1:   9%|▉         | 163/1835 [03:47<38:53,  1.40s/it, training loss=0.2824]\u001b[A\n",
            "Epoch 1:   9%|▉         | 164/1835 [03:47<38:52,  1.40s/it, training loss=0.2824]\u001b[A\n",
            "Epoch 1:   9%|▉         | 164/1835 [03:49<38:52,  1.40s/it, training loss=0.2310]\u001b[A\n",
            "Epoch 1:   9%|▉         | 165/1835 [03:49<38:50,  1.40s/it, training loss=0.2310]\u001b[A\n",
            "Epoch 1:   9%|▉         | 165/1835 [03:50<38:50,  1.40s/it, training loss=0.1853]\u001b[A\n",
            "Epoch 1:   9%|▉         | 166/1835 [03:50<38:49,  1.40s/it, training loss=0.1853]\u001b[A\n",
            "Epoch 1:   9%|▉         | 166/1835 [03:51<38:49,  1.40s/it, training loss=0.1105]\u001b[A\n",
            "Epoch 1:   9%|▉         | 167/1835 [03:51<38:49,  1.40s/it, training loss=0.1105]\u001b[A\n",
            "Epoch 1:   9%|▉         | 167/1835 [03:53<38:49,  1.40s/it, training loss=0.3093]\u001b[A\n",
            "Epoch 1:   9%|▉         | 168/1835 [03:53<38:49,  1.40s/it, training loss=0.3093]\u001b[A\n",
            "Epoch 1:   9%|▉         | 168/1835 [03:54<38:49,  1.40s/it, training loss=0.1370]\u001b[A\n",
            "Epoch 1:   9%|▉         | 169/1835 [03:54<38:48,  1.40s/it, training loss=0.1370]\u001b[A\n",
            "Epoch 1:   9%|▉         | 169/1835 [03:56<38:48,  1.40s/it, training loss=0.1598]\u001b[A\n",
            "Epoch 1:   9%|▉         | 170/1835 [03:56<38:45,  1.40s/it, training loss=0.1598]\u001b[A\n",
            "Epoch 1:   9%|▉         | 170/1835 [03:57<38:45,  1.40s/it, training loss=0.3364]\u001b[A\n",
            "Epoch 1:   9%|▉         | 171/1835 [03:57<38:42,  1.40s/it, training loss=0.3364]\u001b[A\n",
            "Epoch 1:   9%|▉         | 171/1835 [03:58<38:42,  1.40s/it, training loss=0.1493]\u001b[A\n",
            "Epoch 1:   9%|▉         | 172/1835 [03:58<38:38,  1.39s/it, training loss=0.1493]\u001b[A\n",
            "Epoch 1:   9%|▉         | 172/1835 [04:00<38:38,  1.39s/it, training loss=0.2514]\u001b[A\n",
            "Epoch 1:   9%|▉         | 173/1835 [04:00<38:36,  1.39s/it, training loss=0.2514]\u001b[A\n",
            "Epoch 1:   9%|▉         | 173/1835 [04:01<38:36,  1.39s/it, training loss=0.1213]\u001b[A\n",
            "Epoch 1:   9%|▉         | 174/1835 [04:01<38:33,  1.39s/it, training loss=0.1213]\u001b[A\n",
            "Epoch 1:   9%|▉         | 174/1835 [04:03<38:33,  1.39s/it, training loss=0.1798]\u001b[A\n",
            "Epoch 1:  10%|▉         | 175/1835 [04:03<38:34,  1.39s/it, training loss=0.1798]\u001b[A\n",
            "Epoch 1:  10%|▉         | 175/1835 [04:04<38:34,  1.39s/it, training loss=0.2127]\u001b[A\n",
            "Epoch 1:  10%|▉         | 176/1835 [04:04<38:37,  1.40s/it, training loss=0.2127]\u001b[A\n",
            "Epoch 1:  10%|▉         | 176/1835 [04:05<38:37,  1.40s/it, training loss=0.3695]\u001b[A\n",
            "Epoch 1:  10%|▉         | 177/1835 [04:05<38:32,  1.39s/it, training loss=0.3695]\u001b[A\n",
            "Epoch 1:  10%|▉         | 177/1835 [04:07<38:32,  1.39s/it, training loss=0.2311]\u001b[A\n",
            "Epoch 1:  10%|▉         | 178/1835 [04:07<38:30,  1.39s/it, training loss=0.2311]\u001b[A\n",
            "Epoch 1:  10%|▉         | 178/1835 [04:08<38:30,  1.39s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 1:  10%|▉         | 179/1835 [04:08<38:29,  1.39s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 1:  10%|▉         | 179/1835 [04:10<38:29,  1.39s/it, training loss=0.2914]\u001b[A\n",
            "Epoch 1:  10%|▉         | 180/1835 [04:10<38:28,  1.39s/it, training loss=0.2914]\u001b[A\n",
            "Epoch 1:  10%|▉         | 180/1835 [04:11<38:28,  1.39s/it, training loss=0.1602]\u001b[A\n",
            "Epoch 1:  10%|▉         | 181/1835 [04:11<38:24,  1.39s/it, training loss=0.1602]\u001b[A\n",
            "Epoch 1:  10%|▉         | 181/1835 [04:12<38:24,  1.39s/it, training loss=0.2453]\u001b[A\n",
            "Epoch 1:  10%|▉         | 182/1835 [04:12<38:20,  1.39s/it, training loss=0.2453]\u001b[A\n",
            "Epoch 1:  10%|▉         | 182/1835 [04:14<38:20,  1.39s/it, training loss=0.1168]\u001b[A\n",
            "Epoch 1:  10%|▉         | 183/1835 [04:14<38:21,  1.39s/it, training loss=0.1168]\u001b[A\n",
            "Epoch 1:  10%|▉         | 183/1835 [04:15<38:21,  1.39s/it, training loss=0.3341]\u001b[A\n",
            "Epoch 1:  10%|█         | 184/1835 [04:15<38:22,  1.39s/it, training loss=0.3341]\u001b[A\n",
            "Epoch 1:  10%|█         | 184/1835 [04:16<38:22,  1.39s/it, training loss=0.2516]\u001b[A\n",
            "Epoch 1:  10%|█         | 185/1835 [04:16<38:19,  1.39s/it, training loss=0.2516]\u001b[A\n",
            "Epoch 1:  10%|█         | 185/1835 [04:18<38:19,  1.39s/it, training loss=0.1484]\u001b[A\n",
            "Epoch 1:  10%|█         | 186/1835 [04:18<38:16,  1.39s/it, training loss=0.1484]\u001b[A\n",
            "Epoch 1:  10%|█         | 186/1835 [04:19<38:16,  1.39s/it, training loss=0.2260]\u001b[A\n",
            "Epoch 1:  10%|█         | 187/1835 [04:19<38:14,  1.39s/it, training loss=0.2260]\u001b[A\n",
            "Epoch 1:  10%|█         | 187/1835 [04:21<38:14,  1.39s/it, training loss=0.1245]\u001b[A\n",
            "Epoch 1:  10%|█         | 188/1835 [04:21<38:16,  1.39s/it, training loss=0.1245]\u001b[A\n",
            "Epoch 1:  10%|█         | 188/1835 [04:22<38:16,  1.39s/it, training loss=0.1928]\u001b[A\n",
            "Epoch 1:  10%|█         | 189/1835 [04:22<38:17,  1.40s/it, training loss=0.1928]\u001b[A\n",
            "Epoch 1:  10%|█         | 189/1835 [04:23<38:17,  1.40s/it, training loss=0.2240]\u001b[A\n",
            "Epoch 1:  10%|█         | 190/1835 [04:23<38:15,  1.40s/it, training loss=0.2240]\u001b[A\n",
            "Epoch 1:  10%|█         | 190/1835 [04:25<38:15,  1.40s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 1:  10%|█         | 191/1835 [04:25<38:15,  1.40s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 1:  10%|█         | 191/1835 [04:26<38:15,  1.40s/it, training loss=0.2180]\u001b[A\n",
            "Epoch 1:  10%|█         | 192/1835 [04:26<38:12,  1.40s/it, training loss=0.2180]\u001b[A\n",
            "Epoch 1:  10%|█         | 192/1835 [04:28<38:12,  1.40s/it, training loss=0.1602]\u001b[A\n",
            "Epoch 1:  11%|█         | 193/1835 [04:28<38:08,  1.39s/it, training loss=0.1602]\u001b[A\n",
            "Epoch 1:  11%|█         | 193/1835 [04:29<38:08,  1.39s/it, training loss=0.1718]\u001b[A\n",
            "Epoch 1:  11%|█         | 194/1835 [04:29<38:05,  1.39s/it, training loss=0.1718]\u001b[A\n",
            "Epoch 1:  11%|█         | 194/1835 [04:30<38:05,  1.39s/it, training loss=0.1625]\u001b[A\n",
            "Epoch 1:  11%|█         | 195/1835 [04:30<38:04,  1.39s/it, training loss=0.1625]\u001b[A\n",
            "Epoch 1:  11%|█         | 195/1835 [04:32<38:04,  1.39s/it, training loss=0.2319]\u001b[A\n",
            "Epoch 1:  11%|█         | 196/1835 [04:32<38:01,  1.39s/it, training loss=0.2319]\u001b[A\n",
            "Epoch 1:  11%|█         | 196/1835 [04:33<38:01,  1.39s/it, training loss=0.2706]\u001b[A\n",
            "Epoch 1:  11%|█         | 197/1835 [04:33<37:59,  1.39s/it, training loss=0.2706]\u001b[A\n",
            "Epoch 1:  11%|█         | 197/1835 [04:35<37:59,  1.39s/it, training loss=0.0742]\u001b[A\n",
            "Epoch 1:  11%|█         | 198/1835 [04:35<38:00,  1.39s/it, training loss=0.0742]\u001b[A\n",
            "Epoch 1:  11%|█         | 198/1835 [04:36<38:00,  1.39s/it, training loss=0.1565]\u001b[A\n",
            "Epoch 1:  11%|█         | 199/1835 [04:36<37:55,  1.39s/it, training loss=0.1565]\u001b[A\n",
            "Epoch 1:  11%|█         | 199/1835 [04:37<37:55,  1.39s/it, training loss=0.3419]\u001b[A\n",
            "Epoch 1:  11%|█         | 200/1835 [04:37<37:53,  1.39s/it, training loss=0.3419]\u001b[A\n",
            "Epoch 1:  11%|█         | 200/1835 [04:39<37:53,  1.39s/it, training loss=0.0995]\u001b[A\n",
            "Epoch 1:  11%|█         | 201/1835 [04:39<37:55,  1.39s/it, training loss=0.0995]\u001b[A\n",
            "Epoch 1:  11%|█         | 201/1835 [04:40<37:55,  1.39s/it, training loss=0.0824]\u001b[A\n",
            "Epoch 1:  11%|█         | 202/1835 [04:40<37:54,  1.39s/it, training loss=0.0824]\u001b[A\n",
            "Epoch 1:  11%|█         | 202/1835 [04:42<37:54,  1.39s/it, training loss=0.4143]\u001b[A\n",
            "Epoch 1:  11%|█         | 203/1835 [04:42<37:49,  1.39s/it, training loss=0.4143]\u001b[A\n",
            "Epoch 1:  11%|█         | 203/1835 [04:43<37:49,  1.39s/it, training loss=0.1780]\u001b[A\n",
            "Epoch 1:  11%|█         | 204/1835 [04:43<37:48,  1.39s/it, training loss=0.1780]\u001b[A\n",
            "Epoch 1:  11%|█         | 204/1835 [04:44<37:48,  1.39s/it, training loss=0.2651]\u001b[A\n",
            "Epoch 1:  11%|█         | 205/1835 [04:44<37:47,  1.39s/it, training loss=0.2651]\u001b[A\n",
            "Epoch 1:  11%|█         | 205/1835 [04:46<37:47,  1.39s/it, training loss=0.1556]\u001b[A\n",
            "Epoch 1:  11%|█         | 206/1835 [04:46<37:50,  1.39s/it, training loss=0.1556]\u001b[A\n",
            "Epoch 1:  11%|█         | 206/1835 [04:47<37:50,  1.39s/it, training loss=0.1988]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 207/1835 [04:47<37:48,  1.39s/it, training loss=0.1988]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 207/1835 [04:49<37:48,  1.39s/it, training loss=0.2590]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 208/1835 [04:49<37:45,  1.39s/it, training loss=0.2590]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 208/1835 [04:50<37:45,  1.39s/it, training loss=0.2467]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 209/1835 [04:50<37:46,  1.39s/it, training loss=0.2467]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 209/1835 [04:51<37:46,  1.39s/it, training loss=0.3283]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 210/1835 [04:51<37:47,  1.40s/it, training loss=0.3283]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 210/1835 [04:53<37:47,  1.40s/it, training loss=0.2722]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 211/1835 [04:53<37:47,  1.40s/it, training loss=0.2722]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 211/1835 [04:54<37:47,  1.40s/it, training loss=0.3511]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 212/1835 [04:54<37:44,  1.40s/it, training loss=0.3511]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 212/1835 [04:55<37:44,  1.40s/it, training loss=0.1752]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 213/1835 [04:55<37:41,  1.39s/it, training loss=0.1752]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 213/1835 [04:57<37:41,  1.39s/it, training loss=0.2167]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 214/1835 [04:57<37:39,  1.39s/it, training loss=0.2167]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 214/1835 [04:58<37:39,  1.39s/it, training loss=0.2038]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 215/1835 [04:58<37:39,  1.39s/it, training loss=0.2038]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 215/1835 [05:00<37:39,  1.39s/it, training loss=0.2323]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 216/1835 [05:00<37:39,  1.40s/it, training loss=0.2323]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 216/1835 [05:01<37:39,  1.40s/it, training loss=0.1784]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 217/1835 [05:01<37:40,  1.40s/it, training loss=0.1784]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 217/1835 [05:02<37:40,  1.40s/it, training loss=0.1789]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 218/1835 [05:02<37:35,  1.39s/it, training loss=0.1789]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 218/1835 [05:04<37:35,  1.39s/it, training loss=0.2816]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 219/1835 [05:04<37:33,  1.39s/it, training loss=0.2816]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 219/1835 [05:05<37:33,  1.39s/it, training loss=0.1588]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 220/1835 [05:05<37:34,  1.40s/it, training loss=0.1588]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 220/1835 [05:07<37:34,  1.40s/it, training loss=0.2067]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 221/1835 [05:07<37:33,  1.40s/it, training loss=0.2067]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 221/1835 [05:08<37:33,  1.40s/it, training loss=0.1919]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 222/1835 [05:08<37:31,  1.40s/it, training loss=0.1919]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 222/1835 [05:09<37:31,  1.40s/it, training loss=0.3462]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 223/1835 [05:09<37:29,  1.40s/it, training loss=0.3462]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 223/1835 [05:11<37:29,  1.40s/it, training loss=0.2663]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 224/1835 [05:11<37:28,  1.40s/it, training loss=0.2663]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 224/1835 [05:12<37:28,  1.40s/it, training loss=0.2353]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 225/1835 [05:12<37:23,  1.39s/it, training loss=0.2353]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 225/1835 [05:14<37:23,  1.39s/it, training loss=0.2960]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 226/1835 [05:14<37:24,  1.39s/it, training loss=0.2960]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 226/1835 [05:15<37:24,  1.39s/it, training loss=0.2718]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 227/1835 [05:15<37:21,  1.39s/it, training loss=0.2718]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 227/1835 [05:16<37:21,  1.39s/it, training loss=0.2550]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 228/1835 [05:16<37:21,  1.39s/it, training loss=0.2550]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 228/1835 [05:18<37:21,  1.39s/it, training loss=0.2983]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 229/1835 [05:18<37:22,  1.40s/it, training loss=0.2983]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 229/1835 [05:19<37:22,  1.40s/it, training loss=0.1848]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 230/1835 [05:19<37:17,  1.39s/it, training loss=0.1848]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 230/1835 [05:21<37:17,  1.39s/it, training loss=0.2142]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 231/1835 [05:21<37:16,  1.39s/it, training loss=0.2142]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 231/1835 [05:22<37:16,  1.39s/it, training loss=0.1629]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 232/1835 [05:22<37:16,  1.40s/it, training loss=0.1629]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 232/1835 [05:23<37:16,  1.40s/it, training loss=0.2085]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 233/1835 [05:23<37:13,  1.39s/it, training loss=0.2085]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 233/1835 [05:25<37:13,  1.39s/it, training loss=0.2393]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 234/1835 [05:25<37:14,  1.40s/it, training loss=0.2393]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 234/1835 [05:26<37:14,  1.40s/it, training loss=0.2959]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 235/1835 [05:26<37:13,  1.40s/it, training loss=0.2959]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 235/1835 [05:28<37:13,  1.40s/it, training loss=0.1434]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 236/1835 [05:28<37:13,  1.40s/it, training loss=0.1434]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 236/1835 [05:29<37:13,  1.40s/it, training loss=0.2371]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 237/1835 [05:29<37:12,  1.40s/it, training loss=0.2371]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 237/1835 [05:30<37:12,  1.40s/it, training loss=0.1038]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 238/1835 [05:30<37:09,  1.40s/it, training loss=0.1038]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 238/1835 [05:32<37:09,  1.40s/it, training loss=0.0782]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 239/1835 [05:32<37:06,  1.40s/it, training loss=0.0782]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 239/1835 [05:33<37:06,  1.40s/it, training loss=0.1531]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 240/1835 [05:33<37:03,  1.39s/it, training loss=0.1531]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 240/1835 [05:35<37:03,  1.39s/it, training loss=0.1576]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 241/1835 [05:35<37:02,  1.39s/it, training loss=0.1576]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 241/1835 [05:36<37:02,  1.39s/it, training loss=0.2296]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 242/1835 [05:36<37:01,  1.39s/it, training loss=0.2296]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 242/1835 [05:37<37:01,  1.39s/it, training loss=0.1706]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 243/1835 [05:37<37:02,  1.40s/it, training loss=0.1706]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 243/1835 [05:39<37:02,  1.40s/it, training loss=0.2362]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 244/1835 [05:39<37:02,  1.40s/it, training loss=0.2362]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 244/1835 [05:40<37:02,  1.40s/it, training loss=0.2215]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 245/1835 [05:40<37:03,  1.40s/it, training loss=0.2215]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 245/1835 [05:42<37:03,  1.40s/it, training loss=0.2630]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 246/1835 [05:42<37:00,  1.40s/it, training loss=0.2630]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 246/1835 [05:43<37:00,  1.40s/it, training loss=0.2320]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 247/1835 [05:43<36:57,  1.40s/it, training loss=0.2320]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 247/1835 [05:44<36:57,  1.40s/it, training loss=0.2537]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 248/1835 [05:44<36:55,  1.40s/it, training loss=0.2537]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 248/1835 [05:46<36:55,  1.40s/it, training loss=0.1773]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 249/1835 [05:46<36:53,  1.40s/it, training loss=0.1773]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 249/1835 [05:47<36:53,  1.40s/it, training loss=0.1810]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 250/1835 [05:47<36:49,  1.39s/it, training loss=0.1810]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 250/1835 [05:49<36:49,  1.39s/it, training loss=0.3028]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 251/1835 [05:49<36:44,  1.39s/it, training loss=0.3028]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 251/1835 [05:50<36:44,  1.39s/it, training loss=0.2500]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 252/1835 [05:50<36:45,  1.39s/it, training loss=0.2500]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 252/1835 [05:51<36:45,  1.39s/it, training loss=0.2094]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 253/1835 [05:51<36:45,  1.39s/it, training loss=0.2094]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 253/1835 [05:53<36:45,  1.39s/it, training loss=0.2375]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 254/1835 [05:53<36:45,  1.40s/it, training loss=0.2375]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 254/1835 [05:54<36:45,  1.40s/it, training loss=0.1373]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 255/1835 [05:54<36:46,  1.40s/it, training loss=0.1373]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 255/1835 [05:55<36:46,  1.40s/it, training loss=0.1852]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 256/1835 [05:55<36:43,  1.40s/it, training loss=0.1852]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 256/1835 [05:57<36:43,  1.40s/it, training loss=0.2613]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 257/1835 [05:57<36:40,  1.39s/it, training loss=0.2613]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 257/1835 [05:58<36:40,  1.39s/it, training loss=0.1733]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 258/1835 [05:58<36:40,  1.40s/it, training loss=0.1733]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 258/1835 [06:00<36:40,  1.40s/it, training loss=0.1621]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 259/1835 [06:00<36:38,  1.40s/it, training loss=0.1621]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 259/1835 [06:01<36:38,  1.40s/it, training loss=0.3109]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 260/1835 [06:01<36:38,  1.40s/it, training loss=0.3109]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 260/1835 [06:02<36:38,  1.40s/it, training loss=0.1244]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 261/1835 [06:02<36:38,  1.40s/it, training loss=0.1244]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 261/1835 [06:04<36:38,  1.40s/it, training loss=0.2790]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 262/1835 [06:04<36:36,  1.40s/it, training loss=0.2790]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 262/1835 [06:05<36:36,  1.40s/it, training loss=0.1205]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 263/1835 [06:05<36:38,  1.40s/it, training loss=0.1205]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 263/1835 [06:07<36:38,  1.40s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 264/1835 [06:07<36:35,  1.40s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 264/1835 [06:08<36:35,  1.40s/it, training loss=0.1531]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 265/1835 [06:08<36:33,  1.40s/it, training loss=0.1531]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 265/1835 [06:09<36:33,  1.40s/it, training loss=0.1779]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 266/1835 [06:09<36:32,  1.40s/it, training loss=0.1779]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 266/1835 [06:11<36:32,  1.40s/it, training loss=0.0783]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 267/1835 [06:11<36:29,  1.40s/it, training loss=0.0783]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 267/1835 [06:12<36:29,  1.40s/it, training loss=0.2469]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 268/1835 [06:12<36:27,  1.40s/it, training loss=0.2469]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 268/1835 [06:14<36:27,  1.40s/it, training loss=0.1531]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 269/1835 [06:14<36:28,  1.40s/it, training loss=0.1531]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 269/1835 [06:15<36:28,  1.40s/it, training loss=0.1587]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 270/1835 [06:15<36:26,  1.40s/it, training loss=0.1587]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 270/1835 [06:16<36:26,  1.40s/it, training loss=0.1900]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 271/1835 [06:16<36:23,  1.40s/it, training loss=0.1900]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 271/1835 [06:18<36:23,  1.40s/it, training loss=0.1983]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 272/1835 [06:18<36:26,  1.40s/it, training loss=0.1983]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 272/1835 [06:19<36:26,  1.40s/it, training loss=0.5119]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 273/1835 [06:19<36:23,  1.40s/it, training loss=0.5119]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 273/1835 [06:21<36:23,  1.40s/it, training loss=0.1884]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 274/1835 [06:21<36:25,  1.40s/it, training loss=0.1884]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 274/1835 [06:22<36:25,  1.40s/it, training loss=0.1481]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 275/1835 [06:22<36:19,  1.40s/it, training loss=0.1481]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 275/1835 [06:23<36:19,  1.40s/it, training loss=0.3759]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 276/1835 [06:23<36:16,  1.40s/it, training loss=0.3759]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 276/1835 [06:25<36:16,  1.40s/it, training loss=0.1839]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 277/1835 [06:25<36:11,  1.39s/it, training loss=0.1839]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 277/1835 [06:26<36:11,  1.39s/it, training loss=0.2159]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 278/1835 [06:26<36:07,  1.39s/it, training loss=0.2159]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 278/1835 [06:28<36:07,  1.39s/it, training loss=0.2932]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 279/1835 [06:28<36:05,  1.39s/it, training loss=0.2932]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 279/1835 [06:29<36:05,  1.39s/it, training loss=0.2224]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 280/1835 [06:29<36:07,  1.39s/it, training loss=0.2224]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 280/1835 [06:30<36:07,  1.39s/it, training loss=0.2848]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 281/1835 [06:30<36:05,  1.39s/it, training loss=0.2848]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 281/1835 [06:32<36:05,  1.39s/it, training loss=0.2551]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 282/1835 [06:32<36:07,  1.40s/it, training loss=0.2551]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 282/1835 [06:33<36:07,  1.40s/it, training loss=0.1908]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 283/1835 [06:33<36:04,  1.39s/it, training loss=0.1908]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 283/1835 [06:35<36:04,  1.39s/it, training loss=0.2403]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 284/1835 [06:35<36:03,  1.39s/it, training loss=0.2403]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 284/1835 [06:36<36:03,  1.39s/it, training loss=0.2250]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 285/1835 [06:36<35:59,  1.39s/it, training loss=0.2250]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 285/1835 [06:37<35:59,  1.39s/it, training loss=0.2378]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 286/1835 [06:37<35:58,  1.39s/it, training loss=0.2378]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 286/1835 [06:39<35:58,  1.39s/it, training loss=0.3711]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 287/1835 [06:39<35:58,  1.39s/it, training loss=0.3711]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 287/1835 [06:40<35:58,  1.39s/it, training loss=0.1021]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 288/1835 [06:40<35:58,  1.40s/it, training loss=0.1021]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 288/1835 [06:42<35:58,  1.40s/it, training loss=0.1986]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 289/1835 [06:42<35:57,  1.40s/it, training loss=0.1986]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 289/1835 [06:43<35:57,  1.40s/it, training loss=0.0918]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 290/1835 [06:43<35:53,  1.39s/it, training loss=0.0918]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 290/1835 [06:44<35:53,  1.39s/it, training loss=0.1416]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 291/1835 [06:44<35:48,  1.39s/it, training loss=0.1416]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 291/1835 [06:46<35:48,  1.39s/it, training loss=0.2582]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 292/1835 [06:46<35:48,  1.39s/it, training loss=0.2582]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 292/1835 [06:47<35:48,  1.39s/it, training loss=0.2578]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 293/1835 [06:47<35:50,  1.39s/it, training loss=0.2578]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 293/1835 [06:49<35:50,  1.39s/it, training loss=0.3767]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 294/1835 [06:49<35:50,  1.40s/it, training loss=0.3767]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 294/1835 [06:50<35:50,  1.40s/it, training loss=0.1904]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 295/1835 [06:50<35:47,  1.39s/it, training loss=0.1904]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 295/1835 [06:51<35:47,  1.39s/it, training loss=0.3130]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 296/1835 [06:51<35:46,  1.39s/it, training loss=0.3130]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 296/1835 [06:53<35:46,  1.39s/it, training loss=0.1811]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 297/1835 [06:53<35:46,  1.40s/it, training loss=0.1811]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 297/1835 [06:54<35:46,  1.40s/it, training loss=0.2277]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 298/1835 [06:54<35:44,  1.39s/it, training loss=0.2277]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 298/1835 [06:55<35:44,  1.39s/it, training loss=0.0891]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 299/1835 [06:55<35:43,  1.40s/it, training loss=0.0891]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 299/1835 [06:57<35:43,  1.40s/it, training loss=0.0807]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 300/1835 [06:57<35:43,  1.40s/it, training loss=0.0807]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 300/1835 [06:58<35:43,  1.40s/it, training loss=0.1784]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 301/1835 [06:58<35:42,  1.40s/it, training loss=0.1784]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 301/1835 [07:00<35:42,  1.40s/it, training loss=0.2496]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 302/1835 [07:00<35:40,  1.40s/it, training loss=0.2496]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 302/1835 [07:01<35:40,  1.40s/it, training loss=0.2038]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 303/1835 [07:01<35:41,  1.40s/it, training loss=0.2038]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 303/1835 [07:02<35:41,  1.40s/it, training loss=0.1275]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 304/1835 [07:02<35:37,  1.40s/it, training loss=0.1275]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 304/1835 [07:04<35:37,  1.40s/it, training loss=0.3373]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 305/1835 [07:04<35:39,  1.40s/it, training loss=0.3373]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 305/1835 [07:05<35:39,  1.40s/it, training loss=0.4833]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 306/1835 [07:05<35:34,  1.40s/it, training loss=0.4833]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 306/1835 [07:07<35:34,  1.40s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 307/1835 [07:07<35:28,  1.39s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 307/1835 [07:08<35:28,  1.39s/it, training loss=0.2953]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 308/1835 [07:08<35:29,  1.39s/it, training loss=0.2953]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 308/1835 [07:09<35:29,  1.39s/it, training loss=0.2389]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 309/1835 [07:09<35:24,  1.39s/it, training loss=0.2389]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 309/1835 [07:11<35:24,  1.39s/it, training loss=0.1890]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 310/1835 [07:11<35:23,  1.39s/it, training loss=0.1890]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 310/1835 [07:12<35:23,  1.39s/it, training loss=0.1583]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 311/1835 [07:12<35:21,  1.39s/it, training loss=0.1583]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 311/1835 [07:14<35:21,  1.39s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 312/1835 [07:14<35:19,  1.39s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 312/1835 [07:15<35:19,  1.39s/it, training loss=0.3040]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 313/1835 [07:15<35:22,  1.39s/it, training loss=0.3040]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 313/1835 [07:16<35:22,  1.39s/it, training loss=0.1483]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 314/1835 [07:16<35:20,  1.39s/it, training loss=0.1483]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 314/1835 [07:18<35:20,  1.39s/it, training loss=0.2753]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 315/1835 [07:18<35:21,  1.40s/it, training loss=0.2753]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 315/1835 [07:19<35:21,  1.40s/it, training loss=0.1474]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 316/1835 [07:19<35:20,  1.40s/it, training loss=0.1474]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 316/1835 [07:21<35:20,  1.40s/it, training loss=0.1234]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 317/1835 [07:21<35:20,  1.40s/it, training loss=0.1234]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 317/1835 [07:22<35:20,  1.40s/it, training loss=0.1419]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 318/1835 [07:22<35:17,  1.40s/it, training loss=0.1419]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 318/1835 [07:23<35:17,  1.40s/it, training loss=0.1598]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 319/1835 [07:23<35:13,  1.39s/it, training loss=0.1598]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 319/1835 [07:25<35:13,  1.39s/it, training loss=0.2435]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 320/1835 [07:25<35:13,  1.40s/it, training loss=0.2435]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 320/1835 [07:26<35:13,  1.40s/it, training loss=0.2993]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 321/1835 [07:26<35:11,  1.39s/it, training loss=0.2993]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 321/1835 [07:28<35:11,  1.39s/it, training loss=0.2555]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 322/1835 [07:28<35:12,  1.40s/it, training loss=0.2555]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 322/1835 [07:29<35:12,  1.40s/it, training loss=0.3153]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 323/1835 [07:29<35:10,  1.40s/it, training loss=0.3153]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 323/1835 [07:30<35:10,  1.40s/it, training loss=0.0565]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 324/1835 [07:30<35:05,  1.39s/it, training loss=0.0565]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 324/1835 [07:32<35:05,  1.39s/it, training loss=0.2252]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 325/1835 [07:32<35:03,  1.39s/it, training loss=0.2252]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 325/1835 [07:33<35:03,  1.39s/it, training loss=0.3748]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 326/1835 [07:33<35:01,  1.39s/it, training loss=0.3748]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 326/1835 [07:35<35:01,  1.39s/it, training loss=0.2031]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 327/1835 [07:35<35:01,  1.39s/it, training loss=0.2031]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 327/1835 [07:36<35:01,  1.39s/it, training loss=0.1302]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 328/1835 [07:36<34:57,  1.39s/it, training loss=0.1302]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 328/1835 [07:37<34:57,  1.39s/it, training loss=0.1826]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 329/1835 [07:37<34:57,  1.39s/it, training loss=0.1826]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 329/1835 [07:39<34:57,  1.39s/it, training loss=0.1744]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 330/1835 [07:39<34:57,  1.39s/it, training loss=0.1744]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 330/1835 [07:40<34:57,  1.39s/it, training loss=0.3259]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 331/1835 [07:40<34:58,  1.40s/it, training loss=0.3259]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 331/1835 [07:42<34:58,  1.40s/it, training loss=0.3150]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 332/1835 [07:42<34:58,  1.40s/it, training loss=0.3150]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 332/1835 [07:43<34:58,  1.40s/it, training loss=0.2819]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 333/1835 [07:43<35:00,  1.40s/it, training loss=0.2819]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 333/1835 [07:44<35:00,  1.40s/it, training loss=0.1935]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 334/1835 [07:44<34:58,  1.40s/it, training loss=0.1935]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 334/1835 [07:46<34:58,  1.40s/it, training loss=0.0958]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 335/1835 [07:46<34:55,  1.40s/it, training loss=0.0958]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 335/1835 [07:47<34:55,  1.40s/it, training loss=0.2672]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 336/1835 [07:47<34:53,  1.40s/it, training loss=0.2672]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 336/1835 [07:49<34:53,  1.40s/it, training loss=0.1435]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 337/1835 [07:49<34:54,  1.40s/it, training loss=0.1435]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 337/1835 [07:50<34:54,  1.40s/it, training loss=0.3498]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 338/1835 [07:50<34:52,  1.40s/it, training loss=0.3498]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 338/1835 [07:51<34:52,  1.40s/it, training loss=0.1649]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 339/1835 [07:51<34:50,  1.40s/it, training loss=0.1649]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 339/1835 [07:53<34:50,  1.40s/it, training loss=0.1736]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 340/1835 [07:53<34:48,  1.40s/it, training loss=0.1736]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 340/1835 [07:54<34:48,  1.40s/it, training loss=0.2153]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 341/1835 [07:54<34:45,  1.40s/it, training loss=0.2153]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 341/1835 [07:55<34:45,  1.40s/it, training loss=0.1523]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 342/1835 [07:55<34:41,  1.39s/it, training loss=0.1523]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 342/1835 [07:57<34:41,  1.39s/it, training loss=0.2482]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 343/1835 [07:57<34:39,  1.39s/it, training loss=0.2482]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 343/1835 [07:58<34:39,  1.39s/it, training loss=0.2242]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 344/1835 [07:58<34:35,  1.39s/it, training loss=0.2242]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 344/1835 [08:00<34:35,  1.39s/it, training loss=0.2358]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 345/1835 [08:00<34:33,  1.39s/it, training loss=0.2358]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 345/1835 [08:01<34:33,  1.39s/it, training loss=0.2118]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 346/1835 [08:01<34:33,  1.39s/it, training loss=0.2118]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 346/1835 [08:02<34:33,  1.39s/it, training loss=0.2714]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 347/1835 [08:02<34:32,  1.39s/it, training loss=0.2714]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 347/1835 [08:04<34:32,  1.39s/it, training loss=0.3387]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 348/1835 [08:04<34:34,  1.40s/it, training loss=0.3387]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 348/1835 [08:05<34:34,  1.40s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 349/1835 [08:05<34:35,  1.40s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 349/1835 [08:07<34:35,  1.40s/it, training loss=0.2103]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 350/1835 [08:07<34:32,  1.40s/it, training loss=0.2103]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 350/1835 [08:08<34:32,  1.40s/it, training loss=0.2069]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 351/1835 [08:08<34:32,  1.40s/it, training loss=0.2069]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 351/1835 [08:09<34:32,  1.40s/it, training loss=0.2665]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 352/1835 [08:09<34:30,  1.40s/it, training loss=0.2665]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 352/1835 [08:11<34:30,  1.40s/it, training loss=0.2464]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 353/1835 [08:11<34:29,  1.40s/it, training loss=0.2464]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 353/1835 [08:12<34:29,  1.40s/it, training loss=0.1820]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 354/1835 [08:12<34:30,  1.40s/it, training loss=0.1820]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 354/1835 [08:14<34:30,  1.40s/it, training loss=0.1799]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 355/1835 [08:14<34:27,  1.40s/it, training loss=0.1799]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 355/1835 [08:15<34:27,  1.40s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 356/1835 [08:15<34:23,  1.40s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 356/1835 [08:16<34:23,  1.40s/it, training loss=0.0741]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 357/1835 [08:16<34:22,  1.40s/it, training loss=0.0741]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 357/1835 [08:18<34:22,  1.40s/it, training loss=0.1120]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 358/1835 [08:18<34:22,  1.40s/it, training loss=0.1120]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 358/1835 [08:19<34:22,  1.40s/it, training loss=0.2825]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 359/1835 [08:19<34:20,  1.40s/it, training loss=0.2825]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 359/1835 [08:21<34:20,  1.40s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 360/1835 [08:21<34:20,  1.40s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 360/1835 [08:22<34:20,  1.40s/it, training loss=0.2089]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 361/1835 [08:22<34:20,  1.40s/it, training loss=0.2089]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 361/1835 [08:23<34:20,  1.40s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 362/1835 [08:23<34:19,  1.40s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 362/1835 [08:25<34:19,  1.40s/it, training loss=0.0883]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 363/1835 [08:25<34:15,  1.40s/it, training loss=0.0883]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 363/1835 [08:26<34:15,  1.40s/it, training loss=0.1975]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 364/1835 [08:26<34:13,  1.40s/it, training loss=0.1975]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 364/1835 [08:28<34:13,  1.40s/it, training loss=0.1840]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 365/1835 [08:28<34:11,  1.40s/it, training loss=0.1840]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 365/1835 [08:29<34:11,  1.40s/it, training loss=0.2118]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 366/1835 [08:29<34:10,  1.40s/it, training loss=0.2118]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 366/1835 [08:30<34:10,  1.40s/it, training loss=0.2597]\u001b[A\n",
            "Epoch 1:  20%|██        | 367/1835 [08:30<34:10,  1.40s/it, training loss=0.2597]\u001b[A\n",
            "Epoch 1:  20%|██        | 367/1835 [08:32<34:10,  1.40s/it, training loss=0.2383]\u001b[A\n",
            "Epoch 1:  20%|██        | 368/1835 [08:32<34:10,  1.40s/it, training loss=0.2383]\u001b[A\n",
            "Epoch 1:  20%|██        | 368/1835 [08:33<34:10,  1.40s/it, training loss=0.5036]\u001b[A\n",
            "Epoch 1:  20%|██        | 369/1835 [08:33<34:08,  1.40s/it, training loss=0.5036]\u001b[A\n",
            "Epoch 1:  20%|██        | 369/1835 [08:35<34:08,  1.40s/it, training loss=0.2854]\u001b[A\n",
            "Epoch 1:  20%|██        | 370/1835 [08:35<34:07,  1.40s/it, training loss=0.2854]\u001b[A\n",
            "Epoch 1:  20%|██        | 370/1835 [08:36<34:07,  1.40s/it, training loss=0.2077]\u001b[A\n",
            "Epoch 1:  20%|██        | 371/1835 [08:36<34:06,  1.40s/it, training loss=0.2077]\u001b[A\n",
            "Epoch 1:  20%|██        | 371/1835 [08:37<34:06,  1.40s/it, training loss=0.2046]\u001b[A\n",
            "Epoch 1:  20%|██        | 372/1835 [08:37<34:03,  1.40s/it, training loss=0.2046]\u001b[A\n",
            "Epoch 1:  20%|██        | 372/1835 [08:39<34:03,  1.40s/it, training loss=0.1170]\u001b[A\n",
            "Epoch 1:  20%|██        | 373/1835 [08:39<34:03,  1.40s/it, training loss=0.1170]\u001b[A\n",
            "Epoch 1:  20%|██        | 373/1835 [08:40<34:03,  1.40s/it, training loss=0.1998]\u001b[A\n",
            "Epoch 1:  20%|██        | 374/1835 [08:40<33:59,  1.40s/it, training loss=0.1998]\u001b[A\n",
            "Epoch 1:  20%|██        | 374/1835 [08:42<33:59,  1.40s/it, training loss=0.1433]\u001b[A\n",
            "Epoch 1:  20%|██        | 375/1835 [08:42<33:57,  1.40s/it, training loss=0.1433]\u001b[A\n",
            "Epoch 1:  20%|██        | 375/1835 [08:43<33:57,  1.40s/it, training loss=0.0935]\u001b[A\n",
            "Epoch 1:  20%|██        | 376/1835 [08:43<33:57,  1.40s/it, training loss=0.0935]\u001b[A\n",
            "Epoch 1:  20%|██        | 376/1835 [08:44<33:57,  1.40s/it, training loss=0.2137]\u001b[A\n",
            "Epoch 1:  21%|██        | 377/1835 [08:44<33:56,  1.40s/it, training loss=0.2137]\u001b[A\n",
            "Epoch 1:  21%|██        | 377/1835 [08:46<33:56,  1.40s/it, training loss=0.1652]\u001b[A\n",
            "Epoch 1:  21%|██        | 378/1835 [08:46<33:54,  1.40s/it, training loss=0.1652]\u001b[A\n",
            "Epoch 1:  21%|██        | 378/1835 [08:47<33:54,  1.40s/it, training loss=0.3129]\u001b[A\n",
            "Epoch 1:  21%|██        | 379/1835 [08:47<33:50,  1.39s/it, training loss=0.3129]\u001b[A\n",
            "Epoch 1:  21%|██        | 379/1835 [08:49<33:50,  1.39s/it, training loss=0.1708]\u001b[A\n",
            "Epoch 1:  21%|██        | 380/1835 [08:49<33:48,  1.39s/it, training loss=0.1708]\u001b[A\n",
            "Epoch 1:  21%|██        | 380/1835 [08:50<33:48,  1.39s/it, training loss=0.1334]\u001b[A\n",
            "Epoch 1:  21%|██        | 381/1835 [08:50<33:47,  1.39s/it, training loss=0.1334]\u001b[A\n",
            "Epoch 1:  21%|██        | 381/1835 [08:51<33:47,  1.39s/it, training loss=0.1665]\u001b[A\n",
            "Epoch 1:  21%|██        | 382/1835 [08:51<33:45,  1.39s/it, training loss=0.1665]\u001b[A\n",
            "Epoch 1:  21%|██        | 382/1835 [08:53<33:45,  1.39s/it, training loss=0.3532]\u001b[A\n",
            "Epoch 1:  21%|██        | 383/1835 [08:53<33:44,  1.39s/it, training loss=0.3532]\u001b[A\n",
            "Epoch 1:  21%|██        | 383/1835 [08:54<33:44,  1.39s/it, training loss=0.4118]\u001b[A\n",
            "Epoch 1:  21%|██        | 384/1835 [08:54<33:43,  1.39s/it, training loss=0.4118]\u001b[A\n",
            "Epoch 1:  21%|██        | 384/1835 [08:56<33:43,  1.39s/it, training loss=0.2709]\u001b[A\n",
            "Epoch 1:  21%|██        | 385/1835 [08:56<33:42,  1.40s/it, training loss=0.2709]\u001b[A\n",
            "Epoch 1:  21%|██        | 385/1835 [08:57<33:42,  1.40s/it, training loss=0.1207]\u001b[A\n",
            "Epoch 1:  21%|██        | 386/1835 [08:57<33:43,  1.40s/it, training loss=0.1207]\u001b[A\n",
            "Epoch 1:  21%|██        | 386/1835 [08:58<33:43,  1.40s/it, training loss=0.2403]\u001b[A\n",
            "Epoch 1:  21%|██        | 387/1835 [08:58<33:40,  1.40s/it, training loss=0.2403]\u001b[A\n",
            "Epoch 1:  21%|██        | 387/1835 [09:00<33:40,  1.40s/it, training loss=0.1545]\u001b[A\n",
            "Epoch 1:  21%|██        | 388/1835 [09:00<33:39,  1.40s/it, training loss=0.1545]\u001b[A\n",
            "Epoch 1:  21%|██        | 388/1835 [09:01<33:39,  1.40s/it, training loss=0.0648]\u001b[A\n",
            "Epoch 1:  21%|██        | 389/1835 [09:01<33:37,  1.40s/it, training loss=0.0648]\u001b[A\n",
            "Epoch 1:  21%|██        | 389/1835 [09:02<33:37,  1.40s/it, training loss=0.3039]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 390/1835 [09:02<33:34,  1.39s/it, training loss=0.3039]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 390/1835 [09:04<33:34,  1.39s/it, training loss=0.1288]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 391/1835 [09:04<33:33,  1.39s/it, training loss=0.1288]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 391/1835 [09:05<33:33,  1.39s/it, training loss=0.1769]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 392/1835 [09:05<33:31,  1.39s/it, training loss=0.1769]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 392/1835 [09:07<33:31,  1.39s/it, training loss=0.1387]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 393/1835 [09:07<33:31,  1.40s/it, training loss=0.1387]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 393/1835 [09:08<33:31,  1.40s/it, training loss=0.0894]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 394/1835 [09:08<33:27,  1.39s/it, training loss=0.0894]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 394/1835 [09:09<33:27,  1.39s/it, training loss=0.2501]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 395/1835 [09:09<33:27,  1.39s/it, training loss=0.2501]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 395/1835 [09:11<33:27,  1.39s/it, training loss=0.1852]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 396/1835 [09:11<33:28,  1.40s/it, training loss=0.1852]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 396/1835 [09:12<33:28,  1.40s/it, training loss=0.2211]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 397/1835 [09:12<33:28,  1.40s/it, training loss=0.2211]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 397/1835 [09:14<33:28,  1.40s/it, training loss=0.1720]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 398/1835 [09:14<33:25,  1.40s/it, training loss=0.1720]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 398/1835 [09:15<33:25,  1.40s/it, training loss=0.3982]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 399/1835 [09:15<33:25,  1.40s/it, training loss=0.3982]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 399/1835 [09:16<33:25,  1.40s/it, training loss=0.1117]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 400/1835 [09:16<33:24,  1.40s/it, training loss=0.1117]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 400/1835 [09:18<33:24,  1.40s/it, training loss=0.3104]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 401/1835 [09:18<33:22,  1.40s/it, training loss=0.3104]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 401/1835 [09:19<33:22,  1.40s/it, training loss=0.2066]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 402/1835 [09:19<33:22,  1.40s/it, training loss=0.2066]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 402/1835 [09:21<33:22,  1.40s/it, training loss=0.0949]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 403/1835 [09:21<33:17,  1.40s/it, training loss=0.0949]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 403/1835 [09:22<33:17,  1.40s/it, training loss=0.2468]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 404/1835 [09:22<33:13,  1.39s/it, training loss=0.2468]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 404/1835 [09:23<33:13,  1.39s/it, training loss=0.2858]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 405/1835 [09:23<33:09,  1.39s/it, training loss=0.2858]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 405/1835 [09:25<33:09,  1.39s/it, training loss=0.2323]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 406/1835 [09:25<33:12,  1.39s/it, training loss=0.2323]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 406/1835 [09:26<33:12,  1.39s/it, training loss=0.3043]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 407/1835 [09:26<33:11,  1.39s/it, training loss=0.3043]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 407/1835 [09:28<33:11,  1.39s/it, training loss=0.4062]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 408/1835 [09:28<33:09,  1.39s/it, training loss=0.4062]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 408/1835 [09:29<33:09,  1.39s/it, training loss=0.1384]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 409/1835 [09:29<33:07,  1.39s/it, training loss=0.1384]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 409/1835 [09:30<33:07,  1.39s/it, training loss=0.2389]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 410/1835 [09:30<33:07,  1.39s/it, training loss=0.2389]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 410/1835 [09:32<33:07,  1.39s/it, training loss=0.1967]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 411/1835 [09:32<33:01,  1.39s/it, training loss=0.1967]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 411/1835 [09:33<33:01,  1.39s/it, training loss=0.1132]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 412/1835 [09:33<33:02,  1.39s/it, training loss=0.1132]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 412/1835 [09:35<33:02,  1.39s/it, training loss=0.2687]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 413/1835 [09:35<33:03,  1.39s/it, training loss=0.2687]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 413/1835 [09:36<33:03,  1.39s/it, training loss=0.1460]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 414/1835 [09:36<33:01,  1.39s/it, training loss=0.1460]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 414/1835 [09:37<33:01,  1.39s/it, training loss=0.2328]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 415/1835 [09:37<32:59,  1.39s/it, training loss=0.2328]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 415/1835 [09:39<32:59,  1.39s/it, training loss=0.2497]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 416/1835 [09:39<33:01,  1.40s/it, training loss=0.2497]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 416/1835 [09:40<33:01,  1.40s/it, training loss=0.2790]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 417/1835 [09:40<33:01,  1.40s/it, training loss=0.2790]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 417/1835 [09:42<33:01,  1.40s/it, training loss=0.1653]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 418/1835 [09:42<32:59,  1.40s/it, training loss=0.1653]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 418/1835 [09:43<32:59,  1.40s/it, training loss=0.1873]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 419/1835 [09:43<32:54,  1.39s/it, training loss=0.1873]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 419/1835 [09:44<32:54,  1.39s/it, training loss=0.1747]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 420/1835 [09:44<32:55,  1.40s/it, training loss=0.1747]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 420/1835 [09:46<32:55,  1.40s/it, training loss=0.3436]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 421/1835 [09:46<32:52,  1.39s/it, training loss=0.3436]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 421/1835 [09:47<32:52,  1.39s/it, training loss=0.1892]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 422/1835 [09:47<32:51,  1.40s/it, training loss=0.1892]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 422/1835 [09:49<32:51,  1.40s/it, training loss=0.2198]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 423/1835 [09:49<32:51,  1.40s/it, training loss=0.2198]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 423/1835 [09:50<32:51,  1.40s/it, training loss=0.2229]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 424/1835 [09:50<32:50,  1.40s/it, training loss=0.2229]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 424/1835 [09:51<32:50,  1.40s/it, training loss=0.3431]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 425/1835 [09:51<32:52,  1.40s/it, training loss=0.3431]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 425/1835 [09:53<32:52,  1.40s/it, training loss=0.2651]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 426/1835 [09:53<32:53,  1.40s/it, training loss=0.2651]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 426/1835 [09:54<32:53,  1.40s/it, training loss=0.2810]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 427/1835 [09:54<32:48,  1.40s/it, training loss=0.2810]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 427/1835 [09:56<32:48,  1.40s/it, training loss=0.2243]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 428/1835 [09:56<32:49,  1.40s/it, training loss=0.2243]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 428/1835 [09:57<32:49,  1.40s/it, training loss=0.2360]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 429/1835 [09:57<32:48,  1.40s/it, training loss=0.2360]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 429/1835 [09:58<32:48,  1.40s/it, training loss=0.1123]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 430/1835 [09:58<32:45,  1.40s/it, training loss=0.1123]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 430/1835 [10:00<32:45,  1.40s/it, training loss=0.1825]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 431/1835 [10:00<32:44,  1.40s/it, training loss=0.1825]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 431/1835 [10:01<32:44,  1.40s/it, training loss=0.3001]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 432/1835 [10:01<32:43,  1.40s/it, training loss=0.3001]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 432/1835 [10:03<32:43,  1.40s/it, training loss=0.1689]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 433/1835 [10:03<32:41,  1.40s/it, training loss=0.1689]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 433/1835 [10:04<32:41,  1.40s/it, training loss=0.1562]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 434/1835 [10:04<32:34,  1.40s/it, training loss=0.1562]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 434/1835 [10:05<32:34,  1.40s/it, training loss=0.2313]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 435/1835 [10:05<32:36,  1.40s/it, training loss=0.2313]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 435/1835 [10:07<32:36,  1.40s/it, training loss=0.1777]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 436/1835 [10:07<32:32,  1.40s/it, training loss=0.1777]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 436/1835 [10:08<32:32,  1.40s/it, training loss=0.1670]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 437/1835 [10:08<32:31,  1.40s/it, training loss=0.1670]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 437/1835 [10:09<32:31,  1.40s/it, training loss=0.1948]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 438/1835 [10:10<32:31,  1.40s/it, training loss=0.1948]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 438/1835 [10:11<32:31,  1.40s/it, training loss=0.2204]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 439/1835 [10:11<32:30,  1.40s/it, training loss=0.2204]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 439/1835 [10:12<32:30,  1.40s/it, training loss=0.3218]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 440/1835 [10:12<32:28,  1.40s/it, training loss=0.3218]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 440/1835 [10:14<32:28,  1.40s/it, training loss=0.2255]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 441/1835 [10:14<32:27,  1.40s/it, training loss=0.2255]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 441/1835 [10:15<32:27,  1.40s/it, training loss=0.1873]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 442/1835 [10:15<32:27,  1.40s/it, training loss=0.1873]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 442/1835 [10:16<32:27,  1.40s/it, training loss=0.1158]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 443/1835 [10:16<32:24,  1.40s/it, training loss=0.1158]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 443/1835 [10:18<32:24,  1.40s/it, training loss=0.3579]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 444/1835 [10:18<32:21,  1.40s/it, training loss=0.3579]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 444/1835 [10:19<32:21,  1.40s/it, training loss=0.1394]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 445/1835 [10:19<32:19,  1.40s/it, training loss=0.1394]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 445/1835 [10:21<32:19,  1.40s/it, training loss=0.2027]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 446/1835 [10:21<32:17,  1.39s/it, training loss=0.2027]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 446/1835 [10:22<32:17,  1.39s/it, training loss=0.1383]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 447/1835 [10:22<32:15,  1.39s/it, training loss=0.1383]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 447/1835 [10:23<32:15,  1.39s/it, training loss=0.1921]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 448/1835 [10:23<32:12,  1.39s/it, training loss=0.1921]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 448/1835 [10:25<32:12,  1.39s/it, training loss=0.2458]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 449/1835 [10:25<32:10,  1.39s/it, training loss=0.2458]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 449/1835 [10:26<32:10,  1.39s/it, training loss=0.2914]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 450/1835 [10:26<32:10,  1.39s/it, training loss=0.2914]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 450/1835 [10:28<32:10,  1.39s/it, training loss=0.1605]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 451/1835 [10:28<32:10,  1.39s/it, training loss=0.1605]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 451/1835 [10:29<32:10,  1.39s/it, training loss=0.2121]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 452/1835 [10:29<32:08,  1.39s/it, training loss=0.2121]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 452/1835 [10:30<32:08,  1.39s/it, training loss=0.2563]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 453/1835 [10:30<32:11,  1.40s/it, training loss=0.2563]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 453/1835 [10:32<32:11,  1.40s/it, training loss=0.1925]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 454/1835 [10:32<32:09,  1.40s/it, training loss=0.1925]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 454/1835 [10:33<32:09,  1.40s/it, training loss=0.3337]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 455/1835 [10:33<32:04,  1.39s/it, training loss=0.3337]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 455/1835 [10:35<32:04,  1.39s/it, training loss=0.1613]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 456/1835 [10:35<32:04,  1.40s/it, training loss=0.1613]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 456/1835 [10:36<32:04,  1.40s/it, training loss=0.1646]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 457/1835 [10:36<32:05,  1.40s/it, training loss=0.1646]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 457/1835 [10:37<32:05,  1.40s/it, training loss=0.2392]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 458/1835 [10:37<32:03,  1.40s/it, training loss=0.2392]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 458/1835 [10:39<32:03,  1.40s/it, training loss=0.2737]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 459/1835 [10:39<32:00,  1.40s/it, training loss=0.2737]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 459/1835 [10:40<32:00,  1.40s/it, training loss=0.2267]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 460/1835 [10:40<32:00,  1.40s/it, training loss=0.2267]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 460/1835 [10:42<32:00,  1.40s/it, training loss=0.1394]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 461/1835 [10:42<32:01,  1.40s/it, training loss=0.1394]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 461/1835 [10:43<32:01,  1.40s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 462/1835 [10:43<32:00,  1.40s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 462/1835 [10:44<32:00,  1.40s/it, training loss=0.1986]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 463/1835 [10:44<31:56,  1.40s/it, training loss=0.1986]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 463/1835 [10:46<31:56,  1.40s/it, training loss=0.1221]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 464/1835 [10:46<31:52,  1.39s/it, training loss=0.1221]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 464/1835 [10:47<31:52,  1.39s/it, training loss=0.2109]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 465/1835 [10:47<31:51,  1.40s/it, training loss=0.2109]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 465/1835 [10:49<31:51,  1.40s/it, training loss=0.1709]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 466/1835 [10:49<31:51,  1.40s/it, training loss=0.1709]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 466/1835 [10:50<31:51,  1.40s/it, training loss=0.2003]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 467/1835 [10:50<31:49,  1.40s/it, training loss=0.2003]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 467/1835 [10:51<31:49,  1.40s/it, training loss=0.3843]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 468/1835 [10:51<31:48,  1.40s/it, training loss=0.3843]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 468/1835 [10:53<31:48,  1.40s/it, training loss=0.2807]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 469/1835 [10:53<31:44,  1.39s/it, training loss=0.2807]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 469/1835 [10:54<31:44,  1.39s/it, training loss=0.3685]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 470/1835 [10:54<31:41,  1.39s/it, training loss=0.3685]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 470/1835 [10:56<31:41,  1.39s/it, training loss=0.2402]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 471/1835 [10:56<31:42,  1.39s/it, training loss=0.2402]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 471/1835 [10:57<31:42,  1.39s/it, training loss=0.3791]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 472/1835 [10:57<31:39,  1.39s/it, training loss=0.3791]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 472/1835 [10:58<31:39,  1.39s/it, training loss=0.1946]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 473/1835 [10:58<31:40,  1.40s/it, training loss=0.1946]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 473/1835 [11:00<31:40,  1.40s/it, training loss=0.2350]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 474/1835 [11:00<31:39,  1.40s/it, training loss=0.2350]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 474/1835 [11:01<31:39,  1.40s/it, training loss=0.3207]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 475/1835 [11:01<31:35,  1.39s/it, training loss=0.3207]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 475/1835 [11:03<31:35,  1.39s/it, training loss=0.1444]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 476/1835 [11:03<31:34,  1.39s/it, training loss=0.1444]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 476/1835 [11:04<31:34,  1.39s/it, training loss=0.2339]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 477/1835 [11:04<31:33,  1.39s/it, training loss=0.2339]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 477/1835 [11:05<31:33,  1.39s/it, training loss=0.1257]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 478/1835 [11:05<31:28,  1.39s/it, training loss=0.1257]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 478/1835 [11:07<31:28,  1.39s/it, training loss=0.2531]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 479/1835 [11:07<31:28,  1.39s/it, training loss=0.2531]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 479/1835 [11:08<31:28,  1.39s/it, training loss=0.2298]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 480/1835 [11:08<31:27,  1.39s/it, training loss=0.2298]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 480/1835 [11:09<31:27,  1.39s/it, training loss=0.1474]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 481/1835 [11:09<31:27,  1.39s/it, training loss=0.1474]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 481/1835 [11:11<31:27,  1.39s/it, training loss=0.1939]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 482/1835 [11:11<31:27,  1.40s/it, training loss=0.1939]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 482/1835 [11:12<31:27,  1.40s/it, training loss=0.2723]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 483/1835 [11:12<31:25,  1.39s/it, training loss=0.2723]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 483/1835 [11:14<31:25,  1.39s/it, training loss=0.1048]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 484/1835 [11:14<31:22,  1.39s/it, training loss=0.1048]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 484/1835 [11:15<31:22,  1.39s/it, training loss=0.2090]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 485/1835 [11:15<31:19,  1.39s/it, training loss=0.2090]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 485/1835 [11:16<31:19,  1.39s/it, training loss=0.2403]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 486/1835 [11:16<31:15,  1.39s/it, training loss=0.2403]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 486/1835 [11:18<31:15,  1.39s/it, training loss=0.1417]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 487/1835 [11:18<31:13,  1.39s/it, training loss=0.1417]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 487/1835 [11:19<31:13,  1.39s/it, training loss=0.1319]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 488/1835 [11:19<31:11,  1.39s/it, training loss=0.1319]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 488/1835 [11:21<31:11,  1.39s/it, training loss=0.2157]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 489/1835 [11:21<31:11,  1.39s/it, training loss=0.2157]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 489/1835 [11:22<31:11,  1.39s/it, training loss=0.1983]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 490/1835 [11:22<31:13,  1.39s/it, training loss=0.1983]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 490/1835 [11:23<31:13,  1.39s/it, training loss=0.2558]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 491/1835 [11:23<31:10,  1.39s/it, training loss=0.2558]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 491/1835 [11:25<31:10,  1.39s/it, training loss=0.2401]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 492/1835 [11:25<31:10,  1.39s/it, training loss=0.2401]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 492/1835 [11:26<31:10,  1.39s/it, training loss=0.1459]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 493/1835 [11:26<31:10,  1.39s/it, training loss=0.1459]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 493/1835 [11:28<31:10,  1.39s/it, training loss=0.2071]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 494/1835 [11:28<31:09,  1.39s/it, training loss=0.2071]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 494/1835 [11:29<31:09,  1.39s/it, training loss=0.1742]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 495/1835 [11:29<31:07,  1.39s/it, training loss=0.1742]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 495/1835 [11:30<31:07,  1.39s/it, training loss=0.1446]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 496/1835 [11:30<31:04,  1.39s/it, training loss=0.1446]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 496/1835 [11:32<31:04,  1.39s/it, training loss=0.1124]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 497/1835 [11:32<31:03,  1.39s/it, training loss=0.1124]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 497/1835 [11:33<31:03,  1.39s/it, training loss=0.2206]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 498/1835 [11:33<31:04,  1.39s/it, training loss=0.2206]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 498/1835 [11:35<31:04,  1.39s/it, training loss=0.2692]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 499/1835 [11:35<31:04,  1.40s/it, training loss=0.2692]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 499/1835 [11:36<31:04,  1.40s/it, training loss=0.2260]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 500/1835 [11:36<31:02,  1.40s/it, training loss=0.2260]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 500/1835 [11:37<31:02,  1.40s/it, training loss=0.2211]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 501/1835 [11:37<31:10,  1.40s/it, training loss=0.2211]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 501/1835 [11:39<31:10,  1.40s/it, training loss=0.1684]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 502/1835 [11:39<31:12,  1.40s/it, training loss=0.1684]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 502/1835 [11:40<31:12,  1.40s/it, training loss=0.1784]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 503/1835 [11:40<31:08,  1.40s/it, training loss=0.1784]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 503/1835 [11:42<31:08,  1.40s/it, training loss=0.2074]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 504/1835 [11:42<31:05,  1.40s/it, training loss=0.2074]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 504/1835 [11:43<31:05,  1.40s/it, training loss=0.3556]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 505/1835 [11:43<31:03,  1.40s/it, training loss=0.3556]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 505/1835 [11:44<31:03,  1.40s/it, training loss=0.1654]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 506/1835 [11:44<30:59,  1.40s/it, training loss=0.1654]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 506/1835 [11:46<30:59,  1.40s/it, training loss=0.1042]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 507/1835 [11:46<30:56,  1.40s/it, training loss=0.1042]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 507/1835 [11:47<30:56,  1.40s/it, training loss=0.2883]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 508/1835 [11:47<30:53,  1.40s/it, training loss=0.2883]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 508/1835 [11:49<30:53,  1.40s/it, training loss=0.3352]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 509/1835 [11:49<30:49,  1.39s/it, training loss=0.3352]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 509/1835 [11:50<30:49,  1.39s/it, training loss=0.1867]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 510/1835 [11:50<30:46,  1.39s/it, training loss=0.1867]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 510/1835 [11:51<30:46,  1.39s/it, training loss=0.1221]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 511/1835 [11:51<30:47,  1.40s/it, training loss=0.1221]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 511/1835 [11:53<30:47,  1.40s/it, training loss=0.1097]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 512/1835 [11:53<30:46,  1.40s/it, training loss=0.1097]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 512/1835 [11:54<30:46,  1.40s/it, training loss=0.2418]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 513/1835 [11:54<30:42,  1.39s/it, training loss=0.2418]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 513/1835 [11:56<30:42,  1.39s/it, training loss=0.1592]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 514/1835 [11:56<30:40,  1.39s/it, training loss=0.1592]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 514/1835 [11:57<30:40,  1.39s/it, training loss=0.1864]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 515/1835 [11:57<30:40,  1.39s/it, training loss=0.1864]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 515/1835 [11:58<30:40,  1.39s/it, training loss=0.2375]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 516/1835 [11:58<30:37,  1.39s/it, training loss=0.2375]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 516/1835 [12:00<30:37,  1.39s/it, training loss=0.2032]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 517/1835 [12:00<30:33,  1.39s/it, training loss=0.2032]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 517/1835 [12:01<30:33,  1.39s/it, training loss=0.1692]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 518/1835 [12:01<30:32,  1.39s/it, training loss=0.1692]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 518/1835 [12:02<30:32,  1.39s/it, training loss=0.2198]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 519/1835 [12:02<30:29,  1.39s/it, training loss=0.2198]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 519/1835 [12:04<30:29,  1.39s/it, training loss=0.1956]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 520/1835 [12:04<30:28,  1.39s/it, training loss=0.1956]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 520/1835 [12:05<30:28,  1.39s/it, training loss=0.2693]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 521/1835 [12:05<30:31,  1.39s/it, training loss=0.2693]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 521/1835 [12:07<30:31,  1.39s/it, training loss=0.1036]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 522/1835 [12:07<30:32,  1.40s/it, training loss=0.1036]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 522/1835 [12:08<30:32,  1.40s/it, training loss=0.2863]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 523/1835 [12:08<30:31,  1.40s/it, training loss=0.2863]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 523/1835 [12:09<30:31,  1.40s/it, training loss=0.2134]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 524/1835 [12:09<30:32,  1.40s/it, training loss=0.2134]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 524/1835 [12:11<30:32,  1.40s/it, training loss=0.2927]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 525/1835 [12:11<30:31,  1.40s/it, training loss=0.2927]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 525/1835 [12:12<30:31,  1.40s/it, training loss=0.3001]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 526/1835 [12:12<30:38,  1.40s/it, training loss=0.3001]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 526/1835 [12:14<30:38,  1.40s/it, training loss=0.2967]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 527/1835 [12:14<30:35,  1.40s/it, training loss=0.2967]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 527/1835 [12:15<30:35,  1.40s/it, training loss=0.1683]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 528/1835 [12:15<30:30,  1.40s/it, training loss=0.1683]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 528/1835 [12:16<30:30,  1.40s/it, training loss=0.2686]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 529/1835 [12:16<30:26,  1.40s/it, training loss=0.2686]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 529/1835 [12:18<30:26,  1.40s/it, training loss=0.2256]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 530/1835 [12:18<30:26,  1.40s/it, training loss=0.2256]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 530/1835 [12:19<30:26,  1.40s/it, training loss=0.1816]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 531/1835 [12:19<30:20,  1.40s/it, training loss=0.1816]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 531/1835 [12:21<30:20,  1.40s/it, training loss=0.1439]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 532/1835 [12:21<30:16,  1.39s/it, training loss=0.1439]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 532/1835 [12:22<30:16,  1.39s/it, training loss=0.2011]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 533/1835 [12:22<30:14,  1.39s/it, training loss=0.2011]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 533/1835 [12:23<30:14,  1.39s/it, training loss=0.1569]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 534/1835 [12:23<30:14,  1.39s/it, training loss=0.1569]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 534/1835 [12:25<30:14,  1.39s/it, training loss=0.2012]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 535/1835 [12:25<30:12,  1.39s/it, training loss=0.2012]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 535/1835 [12:26<30:12,  1.39s/it, training loss=0.1102]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 536/1835 [12:26<30:13,  1.40s/it, training loss=0.1102]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 536/1835 [12:28<30:13,  1.40s/it, training loss=0.1124]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 537/1835 [12:28<30:08,  1.39s/it, training loss=0.1124]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 537/1835 [12:29<30:08,  1.39s/it, training loss=0.0942]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 538/1835 [12:29<30:13,  1.40s/it, training loss=0.0942]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 538/1835 [12:30<30:13,  1.40s/it, training loss=0.1574]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 539/1835 [12:30<30:12,  1.40s/it, training loss=0.1574]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 539/1835 [12:32<30:12,  1.40s/it, training loss=0.1915]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 540/1835 [12:32<30:11,  1.40s/it, training loss=0.1915]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 540/1835 [12:33<30:11,  1.40s/it, training loss=0.2802]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 541/1835 [12:33<30:13,  1.40s/it, training loss=0.2802]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 541/1835 [12:35<30:13,  1.40s/it, training loss=0.2348]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 542/1835 [12:35<30:10,  1.40s/it, training loss=0.2348]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 542/1835 [12:36<30:10,  1.40s/it, training loss=0.3419]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 543/1835 [12:36<30:05,  1.40s/it, training loss=0.3419]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 543/1835 [12:37<30:05,  1.40s/it, training loss=0.1819]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 544/1835 [12:37<30:06,  1.40s/it, training loss=0.1819]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 544/1835 [12:39<30:06,  1.40s/it, training loss=0.1070]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 545/1835 [12:39<30:09,  1.40s/it, training loss=0.1070]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 545/1835 [12:40<30:09,  1.40s/it, training loss=0.2195]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 546/1835 [12:40<30:12,  1.41s/it, training loss=0.2195]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 546/1835 [12:42<30:12,  1.41s/it, training loss=0.1436]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 547/1835 [12:42<30:08,  1.40s/it, training loss=0.1436]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 547/1835 [12:43<30:08,  1.40s/it, training loss=0.0851]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 548/1835 [12:43<30:05,  1.40s/it, training loss=0.0851]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 548/1835 [12:44<30:05,  1.40s/it, training loss=0.1047]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 549/1835 [12:44<29:59,  1.40s/it, training loss=0.1047]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 549/1835 [12:46<29:59,  1.40s/it, training loss=0.1187]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 550/1835 [12:46<29:55,  1.40s/it, training loss=0.1187]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 550/1835 [12:47<29:55,  1.40s/it, training loss=0.3415]\u001b[A\n",
            "Epoch 1:  30%|███       | 551/1835 [12:47<29:53,  1.40s/it, training loss=0.3415]\u001b[A\n",
            "Epoch 1:  30%|███       | 551/1835 [12:49<29:53,  1.40s/it, training loss=0.0534]\u001b[A\n",
            "Epoch 1:  30%|███       | 552/1835 [12:49<29:49,  1.39s/it, training loss=0.0534]\u001b[A\n",
            "Epoch 1:  30%|███       | 552/1835 [12:50<29:49,  1.39s/it, training loss=0.1781]\u001b[A\n",
            "Epoch 1:  30%|███       | 553/1835 [12:50<29:46,  1.39s/it, training loss=0.1781]\u001b[A\n",
            "Epoch 1:  30%|███       | 553/1835 [12:51<29:46,  1.39s/it, training loss=0.3175]\u001b[A\n",
            "Epoch 1:  30%|███       | 554/1835 [12:51<29:53,  1.40s/it, training loss=0.3175]\u001b[A\n",
            "Epoch 1:  30%|███       | 554/1835 [12:53<29:53,  1.40s/it, training loss=0.0578]\u001b[A\n",
            "Epoch 1:  30%|███       | 555/1835 [12:53<30:00,  1.41s/it, training loss=0.0578]\u001b[A\n",
            "Epoch 1:  30%|███       | 555/1835 [12:54<30:00,  1.41s/it, training loss=0.2507]\u001b[A\n",
            "Epoch 1:  30%|███       | 556/1835 [12:54<30:08,  1.41s/it, training loss=0.2507]\u001b[A\n",
            "Epoch 1:  30%|███       | 556/1835 [12:56<30:08,  1.41s/it, training loss=0.1613]\u001b[A\n",
            "Epoch 1:  30%|███       | 557/1835 [12:56<30:05,  1.41s/it, training loss=0.1613]\u001b[A\n",
            "Epoch 1:  30%|███       | 557/1835 [12:57<30:05,  1.41s/it, training loss=0.1162]\u001b[A\n",
            "Epoch 1:  30%|███       | 558/1835 [12:57<30:00,  1.41s/it, training loss=0.1162]\u001b[A\n",
            "Epoch 1:  30%|███       | 558/1835 [12:58<30:00,  1.41s/it, training loss=0.1550]\u001b[A\n",
            "Epoch 1:  30%|███       | 559/1835 [12:59<29:58,  1.41s/it, training loss=0.1550]\u001b[A\n",
            "Epoch 1:  30%|███       | 559/1835 [13:00<29:58,  1.41s/it, training loss=0.1960]\u001b[A\n",
            "Epoch 1:  31%|███       | 560/1835 [13:00<30:00,  1.41s/it, training loss=0.1960]\u001b[A\n",
            "Epoch 1:  31%|███       | 560/1835 [13:01<30:00,  1.41s/it, training loss=0.2755]\u001b[A\n",
            "Epoch 1:  31%|███       | 561/1835 [13:01<29:51,  1.41s/it, training loss=0.2755]\u001b[A\n",
            "Epoch 1:  31%|███       | 561/1835 [13:03<29:51,  1.41s/it, training loss=0.2414]\u001b[A\n",
            "Epoch 1:  31%|███       | 562/1835 [13:03<29:48,  1.41s/it, training loss=0.2414]\u001b[A\n",
            "Epoch 1:  31%|███       | 562/1835 [13:04<29:48,  1.41s/it, training loss=0.1414]\u001b[A\n",
            "Epoch 1:  31%|███       | 563/1835 [13:04<29:48,  1.41s/it, training loss=0.1414]\u001b[A\n",
            "Epoch 1:  31%|███       | 563/1835 [13:06<29:48,  1.41s/it, training loss=0.3739]\u001b[A\n",
            "Epoch 1:  31%|███       | 564/1835 [13:06<29:42,  1.40s/it, training loss=0.3739]\u001b[A\n",
            "Epoch 1:  31%|███       | 564/1835 [13:07<29:42,  1.40s/it, training loss=0.2722]\u001b[A\n",
            "Epoch 1:  31%|███       | 565/1835 [13:07<29:47,  1.41s/it, training loss=0.2722]\u001b[A\n",
            "Epoch 1:  31%|███       | 565/1835 [13:08<29:47,  1.41s/it, training loss=0.4187]\u001b[A\n",
            "Epoch 1:  31%|███       | 566/1835 [13:08<29:49,  1.41s/it, training loss=0.4187]\u001b[A\n",
            "Epoch 1:  31%|███       | 566/1835 [13:10<29:49,  1.41s/it, training loss=0.2162]\u001b[A\n",
            "Epoch 1:  31%|███       | 567/1835 [13:10<29:45,  1.41s/it, training loss=0.2162]\u001b[A\n",
            "Epoch 1:  31%|███       | 567/1835 [13:11<29:45,  1.41s/it, training loss=0.3641]\u001b[A\n",
            "Epoch 1:  31%|███       | 568/1835 [13:11<29:39,  1.40s/it, training loss=0.3641]\u001b[A\n",
            "Epoch 1:  31%|███       | 568/1835 [13:13<29:39,  1.40s/it, training loss=0.3508]\u001b[A\n",
            "Epoch 1:  31%|███       | 569/1835 [13:13<29:33,  1.40s/it, training loss=0.3508]\u001b[A\n",
            "Epoch 1:  31%|███       | 569/1835 [13:14<29:33,  1.40s/it, training loss=0.1984]\u001b[A\n",
            "Epoch 1:  31%|███       | 570/1835 [13:14<29:33,  1.40s/it, training loss=0.1984]\u001b[A\n",
            "Epoch 1:  31%|███       | 570/1835 [13:15<29:33,  1.40s/it, training loss=0.2950]\u001b[A\n",
            "Epoch 1:  31%|███       | 571/1835 [13:15<29:34,  1.40s/it, training loss=0.2950]\u001b[A\n",
            "Epoch 1:  31%|███       | 571/1835 [13:17<29:34,  1.40s/it, training loss=0.2384]\u001b[A\n",
            "Epoch 1:  31%|███       | 572/1835 [13:17<29:33,  1.40s/it, training loss=0.2384]\u001b[A\n",
            "Epoch 1:  31%|███       | 572/1835 [13:18<29:33,  1.40s/it, training loss=0.1494]\u001b[A\n",
            "Epoch 1:  31%|███       | 573/1835 [13:18<29:32,  1.40s/it, training loss=0.1494]\u001b[A\n",
            "Epoch 1:  31%|███       | 573/1835 [13:20<29:32,  1.40s/it, training loss=0.0868]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 574/1835 [13:20<29:28,  1.40s/it, training loss=0.0868]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 574/1835 [13:21<29:28,  1.40s/it, training loss=0.1611]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 575/1835 [13:21<29:24,  1.40s/it, training loss=0.1611]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 575/1835 [13:22<29:24,  1.40s/it, training loss=0.1992]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 576/1835 [13:22<29:21,  1.40s/it, training loss=0.1992]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 576/1835 [13:24<29:21,  1.40s/it, training loss=0.2762]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 577/1835 [13:24<29:20,  1.40s/it, training loss=0.2762]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 577/1835 [13:25<29:20,  1.40s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 578/1835 [13:25<29:22,  1.40s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 578/1835 [13:27<29:22,  1.40s/it, training loss=0.0561]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 579/1835 [13:27<29:18,  1.40s/it, training loss=0.0561]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 579/1835 [13:28<29:18,  1.40s/it, training loss=0.3195]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 580/1835 [13:28<29:15,  1.40s/it, training loss=0.3195]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 580/1835 [13:29<29:15,  1.40s/it, training loss=0.2064]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 581/1835 [13:29<29:20,  1.40s/it, training loss=0.2064]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 581/1835 [13:31<29:20,  1.40s/it, training loss=0.0681]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 582/1835 [13:31<29:17,  1.40s/it, training loss=0.0681]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 582/1835 [13:32<29:17,  1.40s/it, training loss=0.1902]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 583/1835 [13:32<29:29,  1.41s/it, training loss=0.1902]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 583/1835 [13:34<29:29,  1.41s/it, training loss=0.2038]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 584/1835 [13:34<29:22,  1.41s/it, training loss=0.2038]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 584/1835 [13:35<29:22,  1.41s/it, training loss=0.1685]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 585/1835 [13:35<29:16,  1.41s/it, training loss=0.1685]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 585/1835 [13:36<29:16,  1.41s/it, training loss=0.2694]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 586/1835 [13:36<29:18,  1.41s/it, training loss=0.2694]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 586/1835 [13:38<29:18,  1.41s/it, training loss=0.1585]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 587/1835 [13:38<29:20,  1.41s/it, training loss=0.1585]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 587/1835 [13:39<29:20,  1.41s/it, training loss=0.2825]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 588/1835 [13:39<29:23,  1.41s/it, training loss=0.2825]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 588/1835 [13:41<29:23,  1.41s/it, training loss=0.2105]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 589/1835 [13:41<29:17,  1.41s/it, training loss=0.2105]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 589/1835 [13:42<29:17,  1.41s/it, training loss=0.2323]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 590/1835 [13:42<29:11,  1.41s/it, training loss=0.2323]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 590/1835 [13:43<29:11,  1.41s/it, training loss=0.3252]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 591/1835 [13:43<29:05,  1.40s/it, training loss=0.3252]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 591/1835 [13:45<29:05,  1.40s/it, training loss=0.2664]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 592/1835 [13:45<29:19,  1.42s/it, training loss=0.2664]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 592/1835 [13:46<29:19,  1.42s/it, training loss=0.1344]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 593/1835 [13:46<29:10,  1.41s/it, training loss=0.1344]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 593/1835 [13:48<29:10,  1.41s/it, training loss=0.4013]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 594/1835 [13:48<29:10,  1.41s/it, training loss=0.4013]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 594/1835 [13:49<29:10,  1.41s/it, training loss=0.1750]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 595/1835 [13:49<29:25,  1.42s/it, training loss=0.1750]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 595/1835 [13:51<29:25,  1.42s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 596/1835 [13:51<29:19,  1.42s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 596/1835 [13:52<29:19,  1.42s/it, training loss=0.1418]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 597/1835 [13:52<29:05,  1.41s/it, training loss=0.1418]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 597/1835 [13:53<29:05,  1.41s/it, training loss=0.2331]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 598/1835 [13:53<28:57,  1.40s/it, training loss=0.2331]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 598/1835 [13:55<28:57,  1.40s/it, training loss=0.2516]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 599/1835 [13:55<28:52,  1.40s/it, training loss=0.2516]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 599/1835 [13:56<28:52,  1.40s/it, training loss=0.2889]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 600/1835 [13:56<28:49,  1.40s/it, training loss=0.2889]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 600/1835 [13:58<28:49,  1.40s/it, training loss=0.1702]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 601/1835 [13:58<28:48,  1.40s/it, training loss=0.1702]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 601/1835 [13:59<28:48,  1.40s/it, training loss=0.2517]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 602/1835 [13:59<28:43,  1.40s/it, training loss=0.2517]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 602/1835 [14:00<28:43,  1.40s/it, training loss=0.1751]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 603/1835 [14:00<28:39,  1.40s/it, training loss=0.1751]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 603/1835 [14:02<28:39,  1.40s/it, training loss=0.1650]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 604/1835 [14:02<28:35,  1.39s/it, training loss=0.1650]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 604/1835 [14:03<28:35,  1.39s/it, training loss=0.2807]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 605/1835 [14:03<28:34,  1.39s/it, training loss=0.2807]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 605/1835 [14:05<28:34,  1.39s/it, training loss=0.1384]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 606/1835 [14:05<28:34,  1.39s/it, training loss=0.1384]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 606/1835 [14:06<28:34,  1.39s/it, training loss=0.1454]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 607/1835 [14:06<28:33,  1.40s/it, training loss=0.1454]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 607/1835 [14:07<28:33,  1.40s/it, training loss=0.1291]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 608/1835 [14:07<28:30,  1.39s/it, training loss=0.1291]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 608/1835 [14:09<28:30,  1.39s/it, training loss=0.2288]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 609/1835 [14:09<28:31,  1.40s/it, training loss=0.2288]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 609/1835 [14:10<28:31,  1.40s/it, training loss=0.1597]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 610/1835 [14:10<28:29,  1.40s/it, training loss=0.1597]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 610/1835 [14:11<28:29,  1.40s/it, training loss=0.1474]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 611/1835 [14:11<28:28,  1.40s/it, training loss=0.1474]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 611/1835 [14:13<28:28,  1.40s/it, training loss=0.1871]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 612/1835 [14:13<28:27,  1.40s/it, training loss=0.1871]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 612/1835 [14:14<28:27,  1.40s/it, training loss=0.2162]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 613/1835 [14:14<28:24,  1.39s/it, training loss=0.2162]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 613/1835 [14:16<28:24,  1.39s/it, training loss=0.2694]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 614/1835 [14:16<28:20,  1.39s/it, training loss=0.2694]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 614/1835 [14:17<28:20,  1.39s/it, training loss=0.0504]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 615/1835 [14:17<28:23,  1.40s/it, training loss=0.0504]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 615/1835 [14:18<28:23,  1.40s/it, training loss=0.1019]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 616/1835 [14:18<28:20,  1.39s/it, training loss=0.1019]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 616/1835 [14:20<28:20,  1.39s/it, training loss=0.1048]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 617/1835 [14:20<28:17,  1.39s/it, training loss=0.1048]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 617/1835 [14:21<28:17,  1.39s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 618/1835 [14:21<28:13,  1.39s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 618/1835 [14:23<28:13,  1.39s/it, training loss=0.2025]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 619/1835 [14:23<28:16,  1.40s/it, training loss=0.2025]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 619/1835 [14:24<28:16,  1.40s/it, training loss=0.2648]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 620/1835 [14:24<28:16,  1.40s/it, training loss=0.2648]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 620/1835 [14:25<28:16,  1.40s/it, training loss=0.3971]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 621/1835 [14:25<28:25,  1.40s/it, training loss=0.3971]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 621/1835 [14:27<28:25,  1.40s/it, training loss=0.3436]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 622/1835 [14:27<28:21,  1.40s/it, training loss=0.3436]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 622/1835 [14:28<28:21,  1.40s/it, training loss=0.2483]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 623/1835 [14:28<28:35,  1.42s/it, training loss=0.2483]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 623/1835 [14:30<28:35,  1.42s/it, training loss=0.1968]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 624/1835 [14:30<28:28,  1.41s/it, training loss=0.1968]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 624/1835 [14:31<28:28,  1.41s/it, training loss=0.1790]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 625/1835 [14:31<28:24,  1.41s/it, training loss=0.1790]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 625/1835 [14:33<28:24,  1.41s/it, training loss=0.2739]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 626/1835 [14:33<28:21,  1.41s/it, training loss=0.2739]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 626/1835 [14:34<28:21,  1.41s/it, training loss=0.2188]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 627/1835 [14:34<28:16,  1.40s/it, training loss=0.2188]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 627/1835 [14:35<28:16,  1.40s/it, training loss=0.2742]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 628/1835 [14:35<28:12,  1.40s/it, training loss=0.2742]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 628/1835 [14:37<28:12,  1.40s/it, training loss=0.2196]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 629/1835 [14:37<28:09,  1.40s/it, training loss=0.2196]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 629/1835 [14:38<28:09,  1.40s/it, training loss=0.1288]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 630/1835 [14:38<28:08,  1.40s/it, training loss=0.1288]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 630/1835 [14:40<28:08,  1.40s/it, training loss=0.1072]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 631/1835 [14:40<28:11,  1.40s/it, training loss=0.1072]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 631/1835 [14:41<28:11,  1.40s/it, training loss=0.2188]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 632/1835 [14:41<28:27,  1.42s/it, training loss=0.2188]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 632/1835 [14:42<28:27,  1.42s/it, training loss=0.1614]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 633/1835 [14:42<28:50,  1.44s/it, training loss=0.1614]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 633/1835 [14:44<28:50,  1.44s/it, training loss=0.3751]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 634/1835 [14:44<28:51,  1.44s/it, training loss=0.3751]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 634/1835 [14:45<28:51,  1.44s/it, training loss=0.1760]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 635/1835 [14:45<28:31,  1.43s/it, training loss=0.1760]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 635/1835 [14:47<28:31,  1.43s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 636/1835 [14:47<28:19,  1.42s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 636/1835 [14:48<28:19,  1.42s/it, training loss=0.1570]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 637/1835 [14:48<28:09,  1.41s/it, training loss=0.1570]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 637/1835 [14:49<28:09,  1.41s/it, training loss=0.2824]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 638/1835 [14:49<28:00,  1.40s/it, training loss=0.2824]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 638/1835 [14:51<28:00,  1.40s/it, training loss=0.2789]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 639/1835 [14:51<27:54,  1.40s/it, training loss=0.2789]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 639/1835 [14:52<27:54,  1.40s/it, training loss=0.3067]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 640/1835 [14:52<27:49,  1.40s/it, training loss=0.3067]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 640/1835 [14:54<27:49,  1.40s/it, training loss=0.2785]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 641/1835 [14:54<27:44,  1.39s/it, training loss=0.2785]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 641/1835 [14:55<27:44,  1.39s/it, training loss=0.1428]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 642/1835 [14:55<27:45,  1.40s/it, training loss=0.1428]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 642/1835 [14:56<27:45,  1.40s/it, training loss=0.3783]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 643/1835 [14:56<27:45,  1.40s/it, training loss=0.3783]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 643/1835 [14:58<27:45,  1.40s/it, training loss=0.1152]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 644/1835 [14:58<27:42,  1.40s/it, training loss=0.1152]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 644/1835 [14:59<27:42,  1.40s/it, training loss=0.1657]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 645/1835 [14:59<27:42,  1.40s/it, training loss=0.1657]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 645/1835 [15:01<27:42,  1.40s/it, training loss=0.0982]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 646/1835 [15:01<27:38,  1.39s/it, training loss=0.0982]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 646/1835 [15:02<27:38,  1.39s/it, training loss=0.2197]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 647/1835 [15:02<27:35,  1.39s/it, training loss=0.2197]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 647/1835 [15:03<27:35,  1.39s/it, training loss=0.0988]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 648/1835 [15:03<27:39,  1.40s/it, training loss=0.0988]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 648/1835 [15:05<27:39,  1.40s/it, training loss=0.2607]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 649/1835 [15:05<27:36,  1.40s/it, training loss=0.2607]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 649/1835 [15:06<27:36,  1.40s/it, training loss=0.2222]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 650/1835 [15:06<27:35,  1.40s/it, training loss=0.2222]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 650/1835 [15:08<27:35,  1.40s/it, training loss=0.1337]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 651/1835 [15:08<27:32,  1.40s/it, training loss=0.1337]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 651/1835 [15:09<27:32,  1.40s/it, training loss=0.2945]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 652/1835 [15:09<27:32,  1.40s/it, training loss=0.2945]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 652/1835 [15:10<27:32,  1.40s/it, training loss=0.2807]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 653/1835 [15:10<27:33,  1.40s/it, training loss=0.2807]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 653/1835 [15:12<27:33,  1.40s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 654/1835 [15:12<27:33,  1.40s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 654/1835 [15:13<27:33,  1.40s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 655/1835 [15:13<27:31,  1.40s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 655/1835 [15:15<27:31,  1.40s/it, training loss=0.4490]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 656/1835 [15:15<27:30,  1.40s/it, training loss=0.4490]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 656/1835 [15:16<27:30,  1.40s/it, training loss=0.0663]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 657/1835 [15:16<27:26,  1.40s/it, training loss=0.0663]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 657/1835 [15:17<27:26,  1.40s/it, training loss=0.1261]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 658/1835 [15:17<27:26,  1.40s/it, training loss=0.1261]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 658/1835 [15:19<27:26,  1.40s/it, training loss=0.2813]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 659/1835 [15:19<27:26,  1.40s/it, training loss=0.2813]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 659/1835 [15:20<27:26,  1.40s/it, training loss=0.2797]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 660/1835 [15:20<27:22,  1.40s/it, training loss=0.2797]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 660/1835 [15:22<27:22,  1.40s/it, training loss=0.2724]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 661/1835 [15:22<27:19,  1.40s/it, training loss=0.2724]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 661/1835 [15:23<27:19,  1.40s/it, training loss=0.1676]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 662/1835 [15:23<27:19,  1.40s/it, training loss=0.1676]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 662/1835 [15:24<27:19,  1.40s/it, training loss=0.2613]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 663/1835 [15:24<27:18,  1.40s/it, training loss=0.2613]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 663/1835 [15:26<27:18,  1.40s/it, training loss=0.1295]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 664/1835 [15:26<27:15,  1.40s/it, training loss=0.1295]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 664/1835 [15:27<27:15,  1.40s/it, training loss=0.2168]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 665/1835 [15:27<27:18,  1.40s/it, training loss=0.2168]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 665/1835 [15:29<27:18,  1.40s/it, training loss=0.1264]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 666/1835 [15:29<27:17,  1.40s/it, training loss=0.1264]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 666/1835 [15:30<27:17,  1.40s/it, training loss=0.2626]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 667/1835 [15:30<27:15,  1.40s/it, training loss=0.2626]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 667/1835 [15:31<27:15,  1.40s/it, training loss=0.1786]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 668/1835 [15:31<27:13,  1.40s/it, training loss=0.1786]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 668/1835 [15:33<27:13,  1.40s/it, training loss=0.1292]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 669/1835 [15:33<27:09,  1.40s/it, training loss=0.1292]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 669/1835 [15:34<27:09,  1.40s/it, training loss=0.0953]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 670/1835 [15:34<27:09,  1.40s/it, training loss=0.0953]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 670/1835 [15:36<27:09,  1.40s/it, training loss=0.0996]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 671/1835 [15:36<27:07,  1.40s/it, training loss=0.0996]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 671/1835 [15:37<27:07,  1.40s/it, training loss=0.1468]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 672/1835 [15:37<27:05,  1.40s/it, training loss=0.1468]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 672/1835 [15:38<27:05,  1.40s/it, training loss=0.1302]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 673/1835 [15:38<27:02,  1.40s/it, training loss=0.1302]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 673/1835 [15:40<27:02,  1.40s/it, training loss=0.2762]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 674/1835 [15:40<27:01,  1.40s/it, training loss=0.2762]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 674/1835 [15:41<27:01,  1.40s/it, training loss=0.3213]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 675/1835 [15:41<26:59,  1.40s/it, training loss=0.3213]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 675/1835 [15:43<26:59,  1.40s/it, training loss=0.1305]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 676/1835 [15:43<26:59,  1.40s/it, training loss=0.1305]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 676/1835 [15:44<26:59,  1.40s/it, training loss=0.3361]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 677/1835 [15:44<26:57,  1.40s/it, training loss=0.3361]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 677/1835 [15:45<26:57,  1.40s/it, training loss=0.0846]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 678/1835 [15:45<26:57,  1.40s/it, training loss=0.0846]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 678/1835 [15:47<26:57,  1.40s/it, training loss=0.2286]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 679/1835 [15:47<26:57,  1.40s/it, training loss=0.2286]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 679/1835 [15:48<26:57,  1.40s/it, training loss=0.2976]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 680/1835 [15:48<26:54,  1.40s/it, training loss=0.2976]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 680/1835 [15:50<26:54,  1.40s/it, training loss=0.2258]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 681/1835 [15:50<26:50,  1.40s/it, training loss=0.2258]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 681/1835 [15:51<26:50,  1.40s/it, training loss=0.1731]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 682/1835 [15:51<26:50,  1.40s/it, training loss=0.1731]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 682/1835 [15:52<26:50,  1.40s/it, training loss=0.3463]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 683/1835 [15:52<26:51,  1.40s/it, training loss=0.3463]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 683/1835 [15:54<26:51,  1.40s/it, training loss=0.2501]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 684/1835 [15:54<26:47,  1.40s/it, training loss=0.2501]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 684/1835 [15:55<26:47,  1.40s/it, training loss=0.1418]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 685/1835 [15:55<26:48,  1.40s/it, training loss=0.1418]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 685/1835 [15:57<26:48,  1.40s/it, training loss=0.1978]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 686/1835 [15:57<26:43,  1.40s/it, training loss=0.1978]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 686/1835 [15:58<26:43,  1.40s/it, training loss=0.2044]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 687/1835 [15:58<26:42,  1.40s/it, training loss=0.2044]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 687/1835 [15:59<26:42,  1.40s/it, training loss=0.2023]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 688/1835 [15:59<26:40,  1.40s/it, training loss=0.2023]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 688/1835 [16:01<26:40,  1.40s/it, training loss=0.1166]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 689/1835 [16:01<26:40,  1.40s/it, training loss=0.1166]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 689/1835 [16:02<26:40,  1.40s/it, training loss=0.2357]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 690/1835 [16:02<26:37,  1.40s/it, training loss=0.2357]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 690/1835 [16:04<26:37,  1.40s/it, training loss=0.0864]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 691/1835 [16:04<26:39,  1.40s/it, training loss=0.0864]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 691/1835 [16:05<26:39,  1.40s/it, training loss=0.2311]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 692/1835 [16:05<26:38,  1.40s/it, training loss=0.2311]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 692/1835 [16:06<26:38,  1.40s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 693/1835 [16:06<26:36,  1.40s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 693/1835 [16:08<26:36,  1.40s/it, training loss=0.1855]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 694/1835 [16:08<26:34,  1.40s/it, training loss=0.1855]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 694/1835 [16:09<26:34,  1.40s/it, training loss=0.1618]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 695/1835 [16:09<26:32,  1.40s/it, training loss=0.1618]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 695/1835 [16:11<26:32,  1.40s/it, training loss=0.2184]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 696/1835 [16:11<26:28,  1.39s/it, training loss=0.2184]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 696/1835 [16:12<26:28,  1.39s/it, training loss=0.1283]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 697/1835 [16:12<26:28,  1.40s/it, training loss=0.1283]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 697/1835 [16:13<26:28,  1.40s/it, training loss=0.1526]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 698/1835 [16:13<26:27,  1.40s/it, training loss=0.1526]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 698/1835 [16:15<26:27,  1.40s/it, training loss=0.2161]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 699/1835 [16:15<26:25,  1.40s/it, training loss=0.2161]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 699/1835 [16:16<26:25,  1.40s/it, training loss=0.1110]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 700/1835 [16:16<26:25,  1.40s/it, training loss=0.1110]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 700/1835 [16:17<26:25,  1.40s/it, training loss=0.1043]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 701/1835 [16:18<26:23,  1.40s/it, training loss=0.1043]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 701/1835 [16:19<26:23,  1.40s/it, training loss=0.2789]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 702/1835 [16:19<26:23,  1.40s/it, training loss=0.2789]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 702/1835 [16:20<26:23,  1.40s/it, training loss=0.2042]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 703/1835 [16:20<26:23,  1.40s/it, training loss=0.2042]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 703/1835 [16:22<26:23,  1.40s/it, training loss=0.1617]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 704/1835 [16:22<26:22,  1.40s/it, training loss=0.1617]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 704/1835 [16:23<26:22,  1.40s/it, training loss=0.1457]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 705/1835 [16:23<26:23,  1.40s/it, training loss=0.1457]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 705/1835 [16:24<26:23,  1.40s/it, training loss=0.1997]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 706/1835 [16:25<26:18,  1.40s/it, training loss=0.1997]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 706/1835 [16:26<26:18,  1.40s/it, training loss=0.2640]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 707/1835 [16:26<26:19,  1.40s/it, training loss=0.2640]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 707/1835 [16:27<26:19,  1.40s/it, training loss=0.2634]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 708/1835 [16:27<26:15,  1.40s/it, training loss=0.2634]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 708/1835 [16:29<26:15,  1.40s/it, training loss=0.2050]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 709/1835 [16:29<26:12,  1.40s/it, training loss=0.2050]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 709/1835 [16:30<26:12,  1.40s/it, training loss=0.2664]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 710/1835 [16:30<26:14,  1.40s/it, training loss=0.2664]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 710/1835 [16:31<26:14,  1.40s/it, training loss=0.1680]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 711/1835 [16:32<26:14,  1.40s/it, training loss=0.1680]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 711/1835 [16:33<26:14,  1.40s/it, training loss=0.2817]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 712/1835 [16:33<26:13,  1.40s/it, training loss=0.2817]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 712/1835 [16:34<26:13,  1.40s/it, training loss=0.2282]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 713/1835 [16:34<26:11,  1.40s/it, training loss=0.2282]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 713/1835 [16:36<26:11,  1.40s/it, training loss=0.2040]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 714/1835 [16:36<26:10,  1.40s/it, training loss=0.2040]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 714/1835 [16:37<26:10,  1.40s/it, training loss=0.1688]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 715/1835 [16:37<26:08,  1.40s/it, training loss=0.1688]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 715/1835 [16:39<26:08,  1.40s/it, training loss=0.2654]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 716/1835 [16:39<26:09,  1.40s/it, training loss=0.2654]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 716/1835 [16:40<26:09,  1.40s/it, training loss=0.4032]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 717/1835 [16:40<26:05,  1.40s/it, training loss=0.4032]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 717/1835 [16:41<26:05,  1.40s/it, training loss=0.1903]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 718/1835 [16:41<26:06,  1.40s/it, training loss=0.1903]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 718/1835 [16:43<26:06,  1.40s/it, training loss=0.1753]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 719/1835 [16:43<26:05,  1.40s/it, training loss=0.1753]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 719/1835 [16:44<26:05,  1.40s/it, training loss=0.1632]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 720/1835 [16:44<26:02,  1.40s/it, training loss=0.1632]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 720/1835 [16:46<26:02,  1.40s/it, training loss=0.1182]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 721/1835 [16:46<25:59,  1.40s/it, training loss=0.1182]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 721/1835 [16:47<25:59,  1.40s/it, training loss=0.2231]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 722/1835 [16:47<25:58,  1.40s/it, training loss=0.2231]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 722/1835 [16:48<25:58,  1.40s/it, training loss=0.1674]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 723/1835 [16:48<25:57,  1.40s/it, training loss=0.1674]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 723/1835 [16:50<25:57,  1.40s/it, training loss=0.1159]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 724/1835 [16:50<25:55,  1.40s/it, training loss=0.1159]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 724/1835 [16:51<25:55,  1.40s/it, training loss=0.2150]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 725/1835 [16:51<25:52,  1.40s/it, training loss=0.2150]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 725/1835 [16:53<25:52,  1.40s/it, training loss=0.1426]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 726/1835 [16:53<25:54,  1.40s/it, training loss=0.1426]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 726/1835 [16:54<25:54,  1.40s/it, training loss=0.1894]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 727/1835 [16:54<25:53,  1.40s/it, training loss=0.1894]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 727/1835 [16:55<25:53,  1.40s/it, training loss=0.0758]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 728/1835 [16:55<25:48,  1.40s/it, training loss=0.0758]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 728/1835 [16:57<25:48,  1.40s/it, training loss=0.1248]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 729/1835 [16:57<25:49,  1.40s/it, training loss=0.1248]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 729/1835 [16:58<25:49,  1.40s/it, training loss=0.1812]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 730/1835 [16:58<25:51,  1.40s/it, training loss=0.1812]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 730/1835 [17:00<25:51,  1.40s/it, training loss=0.1978]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 731/1835 [17:00<26:02,  1.42s/it, training loss=0.1978]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 731/1835 [17:01<26:02,  1.42s/it, training loss=0.2401]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 732/1835 [17:01<26:19,  1.43s/it, training loss=0.2401]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 732/1835 [17:02<26:19,  1.43s/it, training loss=0.1334]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 733/1835 [17:03<26:27,  1.44s/it, training loss=0.1334]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 733/1835 [17:04<26:27,  1.44s/it, training loss=0.1332]\u001b[A\n",
            "Epoch 1:  40%|████      | 734/1835 [17:04<26:27,  1.44s/it, training loss=0.1332]\u001b[A\n",
            "Epoch 1:  40%|████      | 734/1835 [17:05<26:27,  1.44s/it, training loss=0.1433]\u001b[A\n",
            "Epoch 1:  40%|████      | 735/1835 [17:05<26:23,  1.44s/it, training loss=0.1433]\u001b[A\n",
            "Epoch 1:  40%|████      | 735/1835 [17:07<26:23,  1.44s/it, training loss=0.1973]\u001b[A\n",
            "Epoch 1:  40%|████      | 736/1835 [17:07<26:16,  1.43s/it, training loss=0.1973]\u001b[A\n",
            "Epoch 1:  40%|████      | 736/1835 [17:08<26:16,  1.43s/it, training loss=0.1832]\u001b[A\n",
            "Epoch 1:  40%|████      | 737/1835 [17:08<26:12,  1.43s/it, training loss=0.1832]\u001b[A\n",
            "Epoch 1:  40%|████      | 737/1835 [17:10<26:12,  1.43s/it, training loss=0.1931]\u001b[A\n",
            "Epoch 1:  40%|████      | 738/1835 [17:10<26:10,  1.43s/it, training loss=0.1931]\u001b[A\n",
            "Epoch 1:  40%|████      | 738/1835 [17:11<26:10,  1.43s/it, training loss=0.0996]\u001b[A\n",
            "Epoch 1:  40%|████      | 739/1835 [17:11<26:23,  1.45s/it, training loss=0.0996]\u001b[A\n",
            "Epoch 1:  40%|████      | 739/1835 [17:13<26:23,  1.45s/it, training loss=0.1831]\u001b[A\n",
            "Epoch 1:  40%|████      | 740/1835 [17:13<26:08,  1.43s/it, training loss=0.1831]\u001b[A\n",
            "Epoch 1:  40%|████      | 740/1835 [17:14<26:08,  1.43s/it, training loss=0.2634]\u001b[A\n",
            "Epoch 1:  40%|████      | 741/1835 [17:14<26:00,  1.43s/it, training loss=0.2634]\u001b[A\n",
            "Epoch 1:  40%|████      | 741/1835 [17:15<26:00,  1.43s/it, training loss=0.1420]\u001b[A\n",
            "Epoch 1:  40%|████      | 742/1835 [17:15<26:04,  1.43s/it, training loss=0.1420]\u001b[A\n",
            "Epoch 1:  40%|████      | 742/1835 [17:17<26:04,  1.43s/it, training loss=0.1970]\u001b[A\n",
            "Epoch 1:  40%|████      | 743/1835 [17:17<26:01,  1.43s/it, training loss=0.1970]\u001b[A\n",
            "Epoch 1:  40%|████      | 743/1835 [17:18<26:01,  1.43s/it, training loss=0.2569]\u001b[A\n",
            "Epoch 1:  41%|████      | 744/1835 [17:18<25:57,  1.43s/it, training loss=0.2569]\u001b[A\n",
            "Epoch 1:  41%|████      | 744/1835 [17:20<25:57,  1.43s/it, training loss=0.2771]\u001b[A\n",
            "Epoch 1:  41%|████      | 745/1835 [17:20<25:57,  1.43s/it, training loss=0.2771]\u001b[A\n",
            "Epoch 1:  41%|████      | 745/1835 [17:21<25:57,  1.43s/it, training loss=0.1851]\u001b[A\n",
            "Epoch 1:  41%|████      | 746/1835 [17:21<25:57,  1.43s/it, training loss=0.1851]\u001b[A\n",
            "Epoch 1:  41%|████      | 746/1835 [17:22<25:57,  1.43s/it, training loss=0.3146]\u001b[A\n",
            "Epoch 1:  41%|████      | 747/1835 [17:23<25:43,  1.42s/it, training loss=0.3146]\u001b[A\n",
            "Epoch 1:  41%|████      | 747/1835 [17:24<25:43,  1.42s/it, training loss=0.1953]\u001b[A\n",
            "Epoch 1:  41%|████      | 748/1835 [17:24<25:32,  1.41s/it, training loss=0.1953]\u001b[A\n",
            "Epoch 1:  41%|████      | 748/1835 [17:25<25:32,  1.41s/it, training loss=0.2457]\u001b[A\n",
            "Epoch 1:  41%|████      | 749/1835 [17:25<25:28,  1.41s/it, training loss=0.2457]\u001b[A\n",
            "Epoch 1:  41%|████      | 749/1835 [17:27<25:28,  1.41s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 1:  41%|████      | 750/1835 [17:27<25:25,  1.41s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 1:  41%|████      | 750/1835 [17:28<25:25,  1.41s/it, training loss=0.3073]\u001b[A\n",
            "Epoch 1:  41%|████      | 751/1835 [17:28<25:18,  1.40s/it, training loss=0.3073]\u001b[A\n",
            "Epoch 1:  41%|████      | 751/1835 [17:29<25:18,  1.40s/it, training loss=0.2510]\u001b[A\n",
            "Epoch 1:  41%|████      | 752/1835 [17:29<25:15,  1.40s/it, training loss=0.2510]\u001b[A\n",
            "Epoch 1:  41%|████      | 752/1835 [17:31<25:15,  1.40s/it, training loss=0.3099]\u001b[A\n",
            "Epoch 1:  41%|████      | 753/1835 [17:31<25:14,  1.40s/it, training loss=0.3099]\u001b[A\n",
            "Epoch 1:  41%|████      | 753/1835 [17:32<25:14,  1.40s/it, training loss=0.2207]\u001b[A\n",
            "Epoch 1:  41%|████      | 754/1835 [17:32<25:21,  1.41s/it, training loss=0.2207]\u001b[A\n",
            "Epoch 1:  41%|████      | 754/1835 [17:34<25:21,  1.41s/it, training loss=0.1951]\u001b[A\n",
            "Epoch 1:  41%|████      | 755/1835 [17:34<25:16,  1.40s/it, training loss=0.1951]\u001b[A\n",
            "Epoch 1:  41%|████      | 755/1835 [17:35<25:16,  1.40s/it, training loss=0.2177]\u001b[A\n",
            "Epoch 1:  41%|████      | 756/1835 [17:35<25:16,  1.41s/it, training loss=0.2177]\u001b[A\n",
            "Epoch 1:  41%|████      | 756/1835 [17:37<25:16,  1.41s/it, training loss=0.2309]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 757/1835 [17:37<25:17,  1.41s/it, training loss=0.2309]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 757/1835 [17:38<25:17,  1.41s/it, training loss=0.2921]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 758/1835 [17:38<25:15,  1.41s/it, training loss=0.2921]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 758/1835 [17:39<25:15,  1.41s/it, training loss=0.1541]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 759/1835 [17:39<25:14,  1.41s/it, training loss=0.1541]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 759/1835 [17:41<25:14,  1.41s/it, training loss=0.1924]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 760/1835 [17:41<25:08,  1.40s/it, training loss=0.1924]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 760/1835 [17:42<25:08,  1.40s/it, training loss=0.1454]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 761/1835 [17:42<25:10,  1.41s/it, training loss=0.1454]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 761/1835 [17:44<25:10,  1.41s/it, training loss=0.2724]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 762/1835 [17:44<25:15,  1.41s/it, training loss=0.2724]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 762/1835 [17:45<25:15,  1.41s/it, training loss=0.2468]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 763/1835 [17:45<25:16,  1.41s/it, training loss=0.2468]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 763/1835 [17:46<25:16,  1.41s/it, training loss=0.2114]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 764/1835 [17:46<25:14,  1.41s/it, training loss=0.2114]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 764/1835 [17:48<25:14,  1.41s/it, training loss=0.2840]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 765/1835 [17:48<25:13,  1.41s/it, training loss=0.2840]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 765/1835 [17:49<25:13,  1.41s/it, training loss=0.1588]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 766/1835 [17:49<25:10,  1.41s/it, training loss=0.1588]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 766/1835 [17:51<25:10,  1.41s/it, training loss=0.2903]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 767/1835 [17:51<25:05,  1.41s/it, training loss=0.2903]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 767/1835 [17:52<25:05,  1.41s/it, training loss=0.2244]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 768/1835 [17:52<25:06,  1.41s/it, training loss=0.2244]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 768/1835 [17:53<25:06,  1.41s/it, training loss=0.1641]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 769/1835 [17:53<24:59,  1.41s/it, training loss=0.1641]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 769/1835 [17:55<24:59,  1.41s/it, training loss=0.1798]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 770/1835 [17:55<24:55,  1.40s/it, training loss=0.1798]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 770/1835 [17:56<24:55,  1.40s/it, training loss=0.1742]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 771/1835 [17:56<24:54,  1.40s/it, training loss=0.1742]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 771/1835 [17:58<24:54,  1.40s/it, training loss=0.0754]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 772/1835 [17:58<24:57,  1.41s/it, training loss=0.0754]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 772/1835 [17:59<24:57,  1.41s/it, training loss=0.1626]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 773/1835 [17:59<25:14,  1.43s/it, training loss=0.1626]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 773/1835 [18:01<25:14,  1.43s/it, training loss=0.3499]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 774/1835 [18:01<25:17,  1.43s/it, training loss=0.3499]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 774/1835 [18:02<25:17,  1.43s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 775/1835 [18:02<25:09,  1.42s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 775/1835 [18:03<25:09,  1.42s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 776/1835 [18:03<24:57,  1.41s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 776/1835 [18:05<24:57,  1.41s/it, training loss=0.2139]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 777/1835 [18:05<24:52,  1.41s/it, training loss=0.2139]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 777/1835 [18:06<24:52,  1.41s/it, training loss=0.2082]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 778/1835 [18:06<24:49,  1.41s/it, training loss=0.2082]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 778/1835 [18:08<24:49,  1.41s/it, training loss=0.2505]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 779/1835 [18:08<24:46,  1.41s/it, training loss=0.2505]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 779/1835 [18:09<24:46,  1.41s/it, training loss=0.2267]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 780/1835 [18:09<24:40,  1.40s/it, training loss=0.2267]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 780/1835 [18:10<24:40,  1.40s/it, training loss=0.2947]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 781/1835 [18:10<24:40,  1.40s/it, training loss=0.2947]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 781/1835 [18:12<24:40,  1.40s/it, training loss=0.1941]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 782/1835 [18:12<24:44,  1.41s/it, training loss=0.1941]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 782/1835 [18:13<24:44,  1.41s/it, training loss=0.0836]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 783/1835 [18:13<24:47,  1.41s/it, training loss=0.0836]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 783/1835 [18:15<24:47,  1.41s/it, training loss=0.2880]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 784/1835 [18:15<24:47,  1.42s/it, training loss=0.2880]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 784/1835 [18:16<24:47,  1.42s/it, training loss=0.2642]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 785/1835 [18:16<24:44,  1.41s/it, training loss=0.2642]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 785/1835 [18:17<24:44,  1.41s/it, training loss=0.1915]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 786/1835 [18:17<24:38,  1.41s/it, training loss=0.1915]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 786/1835 [18:19<24:38,  1.41s/it, training loss=0.3051]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 787/1835 [18:19<24:31,  1.40s/it, training loss=0.3051]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 787/1835 [18:20<24:31,  1.40s/it, training loss=0.1846]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 788/1835 [18:20<24:27,  1.40s/it, training loss=0.1846]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 788/1835 [18:22<24:27,  1.40s/it, training loss=0.2363]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 789/1835 [18:22<24:24,  1.40s/it, training loss=0.2363]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 789/1835 [18:23<24:24,  1.40s/it, training loss=0.1755]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 790/1835 [18:23<24:24,  1.40s/it, training loss=0.1755]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 790/1835 [18:24<24:24,  1.40s/it, training loss=0.0964]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 791/1835 [18:24<24:34,  1.41s/it, training loss=0.0964]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 791/1835 [18:26<24:34,  1.41s/it, training loss=0.1673]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 792/1835 [18:26<24:28,  1.41s/it, training loss=0.1673]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 792/1835 [18:27<24:28,  1.41s/it, training loss=0.0839]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 793/1835 [18:27<24:27,  1.41s/it, training loss=0.0839]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 793/1835 [18:29<24:27,  1.41s/it, training loss=0.1463]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 794/1835 [18:29<24:27,  1.41s/it, training loss=0.1463]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 794/1835 [18:30<24:27,  1.41s/it, training loss=0.1329]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 795/1835 [18:30<24:23,  1.41s/it, training loss=0.1329]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 795/1835 [18:31<24:23,  1.41s/it, training loss=0.2518]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 796/1835 [18:32<24:20,  1.41s/it, training loss=0.2518]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 796/1835 [18:33<24:20,  1.41s/it, training loss=0.1334]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 797/1835 [18:33<24:15,  1.40s/it, training loss=0.1334]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 797/1835 [18:34<24:15,  1.40s/it, training loss=0.1020]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 798/1835 [18:34<24:11,  1.40s/it, training loss=0.1020]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 798/1835 [18:36<24:11,  1.40s/it, training loss=0.2533]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 799/1835 [18:36<24:10,  1.40s/it, training loss=0.2533]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 799/1835 [18:37<24:10,  1.40s/it, training loss=0.1084]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 800/1835 [18:37<24:17,  1.41s/it, training loss=0.1084]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 800/1835 [18:39<24:17,  1.41s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 801/1835 [18:39<24:19,  1.41s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 801/1835 [18:40<24:19,  1.41s/it, training loss=0.0736]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 802/1835 [18:40<24:27,  1.42s/it, training loss=0.0736]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 802/1835 [18:41<24:27,  1.42s/it, training loss=0.2506]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 803/1835 [18:41<24:29,  1.42s/it, training loss=0.2506]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 803/1835 [18:43<24:29,  1.42s/it, training loss=0.3625]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 804/1835 [18:43<24:24,  1.42s/it, training loss=0.3625]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 804/1835 [18:44<24:24,  1.42s/it, training loss=0.2720]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 805/1835 [18:44<24:26,  1.42s/it, training loss=0.2720]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 805/1835 [18:46<24:26,  1.42s/it, training loss=0.1765]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 806/1835 [18:46<24:19,  1.42s/it, training loss=0.1765]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 806/1835 [18:47<24:19,  1.42s/it, training loss=0.1032]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 807/1835 [18:47<24:10,  1.41s/it, training loss=0.1032]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 807/1835 [18:48<24:10,  1.41s/it, training loss=0.2562]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 808/1835 [18:48<24:04,  1.41s/it, training loss=0.2562]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 808/1835 [18:50<24:04,  1.41s/it, training loss=0.1833]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 809/1835 [18:50<24:03,  1.41s/it, training loss=0.1833]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 809/1835 [18:51<24:03,  1.41s/it, training loss=0.2651]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 810/1835 [18:51<24:02,  1.41s/it, training loss=0.2651]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 810/1835 [18:53<24:02,  1.41s/it, training loss=0.1250]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 811/1835 [18:53<24:01,  1.41s/it, training loss=0.1250]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 811/1835 [18:54<24:01,  1.41s/it, training loss=0.2416]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 812/1835 [18:54<24:02,  1.41s/it, training loss=0.2416]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 812/1835 [18:55<24:02,  1.41s/it, training loss=0.1491]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 813/1835 [18:55<23:57,  1.41s/it, training loss=0.1491]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 813/1835 [18:57<23:57,  1.41s/it, training loss=0.1442]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 814/1835 [18:57<23:51,  1.40s/it, training loss=0.1442]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 814/1835 [18:58<23:51,  1.40s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 815/1835 [18:58<23:48,  1.40s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 815/1835 [19:00<23:48,  1.40s/it, training loss=0.0636]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 816/1835 [19:00<23:46,  1.40s/it, training loss=0.0636]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 816/1835 [19:01<23:46,  1.40s/it, training loss=0.1481]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 817/1835 [19:01<23:47,  1.40s/it, training loss=0.1481]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 817/1835 [19:02<23:47,  1.40s/it, training loss=0.3149]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 818/1835 [19:02<23:41,  1.40s/it, training loss=0.3149]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 818/1835 [19:04<23:41,  1.40s/it, training loss=0.1775]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 819/1835 [19:04<23:41,  1.40s/it, training loss=0.1775]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 819/1835 [19:05<23:41,  1.40s/it, training loss=0.2050]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 820/1835 [19:05<23:43,  1.40s/it, training loss=0.2050]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 820/1835 [19:07<23:43,  1.40s/it, training loss=0.2176]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 821/1835 [19:07<23:41,  1.40s/it, training loss=0.2176]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 821/1835 [19:08<23:41,  1.40s/it, training loss=0.2826]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 822/1835 [19:08<23:40,  1.40s/it, training loss=0.2826]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 822/1835 [19:09<23:40,  1.40s/it, training loss=0.2864]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 823/1835 [19:10<23:40,  1.40s/it, training loss=0.2864]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 823/1835 [19:11<23:40,  1.40s/it, training loss=0.1515]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 824/1835 [19:11<23:40,  1.41s/it, training loss=0.1515]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 824/1835 [19:12<23:40,  1.41s/it, training loss=0.2169]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 825/1835 [19:12<23:36,  1.40s/it, training loss=0.2169]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 825/1835 [19:14<23:36,  1.40s/it, training loss=0.0702]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 826/1835 [19:14<23:31,  1.40s/it, training loss=0.0702]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 826/1835 [19:15<23:31,  1.40s/it, training loss=0.0960]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 827/1835 [19:15<23:30,  1.40s/it, training loss=0.0960]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 827/1835 [19:16<23:30,  1.40s/it, training loss=0.1803]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 828/1835 [19:16<23:27,  1.40s/it, training loss=0.1803]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 828/1835 [19:18<23:27,  1.40s/it, training loss=0.2922]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 829/1835 [19:18<23:27,  1.40s/it, training loss=0.2922]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 829/1835 [19:19<23:27,  1.40s/it, training loss=0.2013]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 830/1835 [19:19<23:25,  1.40s/it, training loss=0.2013]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 830/1835 [19:21<23:25,  1.40s/it, training loss=0.2991]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 831/1835 [19:21<23:21,  1.40s/it, training loss=0.2991]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 831/1835 [19:22<23:21,  1.40s/it, training loss=0.1622]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 832/1835 [19:22<23:23,  1.40s/it, training loss=0.1622]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 832/1835 [19:23<23:23,  1.40s/it, training loss=0.3107]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 833/1835 [19:24<23:27,  1.40s/it, training loss=0.3107]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 833/1835 [19:25<23:27,  1.40s/it, training loss=0.1404]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 834/1835 [19:25<23:31,  1.41s/it, training loss=0.1404]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 834/1835 [19:26<23:31,  1.41s/it, training loss=0.3694]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 835/1835 [19:26<23:26,  1.41s/it, training loss=0.3694]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 835/1835 [19:28<23:26,  1.41s/it, training loss=0.3105]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 836/1835 [19:28<23:39,  1.42s/it, training loss=0.3105]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 836/1835 [19:29<23:39,  1.42s/it, training loss=0.1404]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 837/1835 [19:29<23:32,  1.42s/it, training loss=0.1404]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 837/1835 [19:31<23:32,  1.42s/it, training loss=0.1083]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 838/1835 [19:31<23:22,  1.41s/it, training loss=0.1083]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 838/1835 [19:32<23:22,  1.41s/it, training loss=0.1736]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 839/1835 [19:32<23:18,  1.40s/it, training loss=0.1736]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 839/1835 [19:33<23:18,  1.40s/it, training loss=0.2346]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 840/1835 [19:33<23:14,  1.40s/it, training loss=0.2346]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 840/1835 [19:35<23:14,  1.40s/it, training loss=0.2046]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 841/1835 [19:35<23:09,  1.40s/it, training loss=0.2046]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 841/1835 [19:36<23:09,  1.40s/it, training loss=0.1289]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 842/1835 [19:36<23:06,  1.40s/it, training loss=0.1289]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 842/1835 [19:38<23:06,  1.40s/it, training loss=0.1690]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 843/1835 [19:38<23:05,  1.40s/it, training loss=0.1690]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 843/1835 [19:39<23:05,  1.40s/it, training loss=0.1397]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 844/1835 [19:39<23:03,  1.40s/it, training loss=0.1397]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 844/1835 [19:40<23:03,  1.40s/it, training loss=0.1918]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 845/1835 [19:40<23:00,  1.39s/it, training loss=0.1918]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 845/1835 [19:42<23:00,  1.39s/it, training loss=0.2015]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 846/1835 [19:42<23:01,  1.40s/it, training loss=0.2015]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 846/1835 [19:43<23:01,  1.40s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 847/1835 [19:43<22:59,  1.40s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 847/1835 [19:45<22:59,  1.40s/it, training loss=0.1811]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 848/1835 [19:45<22:56,  1.39s/it, training loss=0.1811]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 848/1835 [19:46<22:56,  1.39s/it, training loss=0.2556]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 849/1835 [19:46<22:53,  1.39s/it, training loss=0.2556]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 849/1835 [19:47<22:53,  1.39s/it, training loss=0.1900]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 850/1835 [19:47<22:52,  1.39s/it, training loss=0.1900]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 850/1835 [19:49<22:52,  1.39s/it, training loss=0.2825]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 851/1835 [19:49<22:50,  1.39s/it, training loss=0.2825]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 851/1835 [19:50<22:50,  1.39s/it, training loss=0.2996]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 852/1835 [19:50<22:50,  1.39s/it, training loss=0.2996]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 852/1835 [19:51<22:50,  1.39s/it, training loss=0.2578]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 853/1835 [19:51<22:50,  1.40s/it, training loss=0.2578]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 853/1835 [19:53<22:50,  1.40s/it, training loss=0.2263]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 854/1835 [19:53<22:49,  1.40s/it, training loss=0.2263]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 854/1835 [19:54<22:49,  1.40s/it, training loss=0.1922]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 855/1835 [19:54<22:51,  1.40s/it, training loss=0.1922]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 855/1835 [19:56<22:51,  1.40s/it, training loss=0.2301]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 856/1835 [19:56<22:46,  1.40s/it, training loss=0.2301]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 856/1835 [19:57<22:46,  1.40s/it, training loss=0.1812]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 857/1835 [19:57<22:44,  1.40s/it, training loss=0.1812]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 857/1835 [19:58<22:44,  1.40s/it, training loss=0.0790]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 858/1835 [19:58<22:44,  1.40s/it, training loss=0.0790]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 858/1835 [20:00<22:44,  1.40s/it, training loss=0.1248]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 859/1835 [20:00<22:45,  1.40s/it, training loss=0.1248]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 859/1835 [20:01<22:45,  1.40s/it, training loss=0.2527]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 860/1835 [20:01<22:45,  1.40s/it, training loss=0.2527]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 860/1835 [20:03<22:45,  1.40s/it, training loss=0.1254]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 861/1835 [20:03<22:42,  1.40s/it, training loss=0.1254]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 861/1835 [20:04<22:42,  1.40s/it, training loss=0.2604]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 862/1835 [20:04<22:43,  1.40s/it, training loss=0.2604]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 862/1835 [20:05<22:43,  1.40s/it, training loss=0.2011]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 863/1835 [20:05<22:38,  1.40s/it, training loss=0.2011]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 863/1835 [20:07<22:38,  1.40s/it, training loss=0.2494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 864/1835 [20:07<22:37,  1.40s/it, training loss=0.2494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 864/1835 [20:08<22:37,  1.40s/it, training loss=0.2221]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 865/1835 [20:08<22:34,  1.40s/it, training loss=0.2221]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 865/1835 [20:10<22:34,  1.40s/it, training loss=0.2560]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 866/1835 [20:10<22:35,  1.40s/it, training loss=0.2560]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 866/1835 [20:11<22:35,  1.40s/it, training loss=0.1593]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 867/1835 [20:11<22:33,  1.40s/it, training loss=0.1593]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 867/1835 [20:12<22:33,  1.40s/it, training loss=0.0995]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 868/1835 [20:12<22:31,  1.40s/it, training loss=0.0995]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 868/1835 [20:14<22:31,  1.40s/it, training loss=0.2921]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 869/1835 [20:14<22:29,  1.40s/it, training loss=0.2921]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 869/1835 [20:15<22:29,  1.40s/it, training loss=0.1512]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 870/1835 [20:15<22:27,  1.40s/it, training loss=0.1512]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 870/1835 [20:17<22:27,  1.40s/it, training loss=0.1711]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 871/1835 [20:17<22:28,  1.40s/it, training loss=0.1711]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 871/1835 [20:18<22:28,  1.40s/it, training loss=0.2684]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 872/1835 [20:18<22:26,  1.40s/it, training loss=0.2684]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 872/1835 [20:19<22:26,  1.40s/it, training loss=0.0762]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 873/1835 [20:19<22:24,  1.40s/it, training loss=0.0762]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 873/1835 [20:21<22:24,  1.40s/it, training loss=0.1486]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 874/1835 [20:21<22:23,  1.40s/it, training loss=0.1486]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 874/1835 [20:22<22:23,  1.40s/it, training loss=0.1603]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 875/1835 [20:22<22:21,  1.40s/it, training loss=0.1603]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 875/1835 [20:24<22:21,  1.40s/it, training loss=0.1744]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 876/1835 [20:24<22:20,  1.40s/it, training loss=0.1744]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 876/1835 [20:25<22:20,  1.40s/it, training loss=0.2392]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 877/1835 [20:25<22:18,  1.40s/it, training loss=0.2392]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 877/1835 [20:26<22:18,  1.40s/it, training loss=0.1366]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 878/1835 [20:26<22:18,  1.40s/it, training loss=0.1366]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 878/1835 [20:28<22:18,  1.40s/it, training loss=0.2363]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 879/1835 [20:28<22:17,  1.40s/it, training loss=0.2363]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 879/1835 [20:29<22:17,  1.40s/it, training loss=0.2235]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 880/1835 [20:29<22:15,  1.40s/it, training loss=0.2235]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 880/1835 [20:31<22:15,  1.40s/it, training loss=0.2188]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 881/1835 [20:31<22:13,  1.40s/it, training loss=0.2188]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 881/1835 [20:32<22:13,  1.40s/it, training loss=0.2790]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 882/1835 [20:32<22:10,  1.40s/it, training loss=0.2790]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 882/1835 [20:33<22:10,  1.40s/it, training loss=0.2429]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 883/1835 [20:33<22:06,  1.39s/it, training loss=0.2429]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 883/1835 [20:35<22:06,  1.39s/it, training loss=0.1880]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 884/1835 [20:35<22:07,  1.40s/it, training loss=0.1880]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 884/1835 [20:36<22:07,  1.40s/it, training loss=0.1574]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 885/1835 [20:36<22:07,  1.40s/it, training loss=0.1574]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 885/1835 [20:38<22:07,  1.40s/it, training loss=0.2864]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 886/1835 [20:38<22:06,  1.40s/it, training loss=0.2864]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 886/1835 [20:39<22:06,  1.40s/it, training loss=0.2274]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 887/1835 [20:39<22:02,  1.40s/it, training loss=0.2274]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 887/1835 [20:40<22:02,  1.40s/it, training loss=0.1427]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 888/1835 [20:40<22:03,  1.40s/it, training loss=0.1427]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 888/1835 [20:42<22:03,  1.40s/it, training loss=0.1751]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 889/1835 [20:42<21:59,  1.40s/it, training loss=0.1751]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 889/1835 [20:43<21:59,  1.40s/it, training loss=0.2502]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 890/1835 [20:43<21:59,  1.40s/it, training loss=0.2502]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 890/1835 [20:45<21:59,  1.40s/it, training loss=0.1011]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 891/1835 [20:45<21:57,  1.40s/it, training loss=0.1011]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 891/1835 [20:46<21:57,  1.40s/it, training loss=0.2570]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 892/1835 [20:46<21:56,  1.40s/it, training loss=0.2570]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 892/1835 [20:47<21:56,  1.40s/it, training loss=0.1587]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 893/1835 [20:47<21:54,  1.40s/it, training loss=0.1587]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 893/1835 [20:49<21:54,  1.40s/it, training loss=0.2396]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 894/1835 [20:49<21:53,  1.40s/it, training loss=0.2396]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 894/1835 [20:50<21:53,  1.40s/it, training loss=0.1704]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 895/1835 [20:50<21:50,  1.39s/it, training loss=0.1704]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 895/1835 [20:52<21:50,  1.39s/it, training loss=0.1818]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 896/1835 [20:52<21:48,  1.39s/it, training loss=0.1818]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 896/1835 [20:53<21:48,  1.39s/it, training loss=0.1195]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 897/1835 [20:53<21:47,  1.39s/it, training loss=0.1195]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 897/1835 [20:54<21:47,  1.39s/it, training loss=0.2713]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 898/1835 [20:54<21:48,  1.40s/it, training loss=0.2713]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 898/1835 [20:56<21:48,  1.40s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 899/1835 [20:56<21:46,  1.40s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 899/1835 [20:57<21:46,  1.40s/it, training loss=0.1964]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 900/1835 [20:57<21:53,  1.40s/it, training loss=0.1964]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 900/1835 [20:59<21:53,  1.40s/it, training loss=0.0629]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 901/1835 [20:59<21:52,  1.41s/it, training loss=0.0629]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 901/1835 [21:00<21:52,  1.41s/it, training loss=0.1410]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 902/1835 [21:00<21:48,  1.40s/it, training loss=0.1410]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 902/1835 [21:01<21:48,  1.40s/it, training loss=0.1109]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 903/1835 [21:01<21:45,  1.40s/it, training loss=0.1109]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 903/1835 [21:03<21:45,  1.40s/it, training loss=0.1513]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 904/1835 [21:03<21:39,  1.40s/it, training loss=0.1513]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 904/1835 [21:04<21:39,  1.40s/it, training loss=0.2324]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 905/1835 [21:04<21:38,  1.40s/it, training loss=0.2324]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 905/1835 [21:06<21:38,  1.40s/it, training loss=0.3510]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 906/1835 [21:06<21:36,  1.40s/it, training loss=0.3510]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 906/1835 [21:07<21:36,  1.40s/it, training loss=0.3561]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 907/1835 [21:07<21:37,  1.40s/it, training loss=0.3561]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 907/1835 [21:08<21:37,  1.40s/it, training loss=0.1059]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 908/1835 [21:08<21:35,  1.40s/it, training loss=0.1059]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 908/1835 [21:10<21:35,  1.40s/it, training loss=0.3251]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 909/1835 [21:10<21:33,  1.40s/it, training loss=0.3251]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 909/1835 [21:11<21:33,  1.40s/it, training loss=0.3026]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 910/1835 [21:11<21:32,  1.40s/it, training loss=0.3026]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 910/1835 [21:13<21:32,  1.40s/it, training loss=0.2194]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 911/1835 [21:13<21:28,  1.39s/it, training loss=0.2194]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 911/1835 [21:14<21:28,  1.39s/it, training loss=0.2638]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 912/1835 [21:14<21:29,  1.40s/it, training loss=0.2638]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 912/1835 [21:15<21:29,  1.40s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 913/1835 [21:15<21:27,  1.40s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 913/1835 [21:17<21:27,  1.40s/it, training loss=0.1593]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 914/1835 [21:17<21:26,  1.40s/it, training loss=0.1593]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 914/1835 [21:18<21:26,  1.40s/it, training loss=0.1666]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 915/1835 [21:18<21:23,  1.39s/it, training loss=0.1666]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 915/1835 [21:20<21:23,  1.39s/it, training loss=0.2167]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 916/1835 [21:20<21:21,  1.39s/it, training loss=0.2167]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 916/1835 [21:21<21:21,  1.39s/it, training loss=0.2022]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 917/1835 [21:21<21:20,  1.39s/it, training loss=0.2022]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 917/1835 [21:22<21:20,  1.39s/it, training loss=0.1434]\u001b[A\n",
            "Epoch 1:  50%|█████     | 918/1835 [21:22<21:19,  1.40s/it, training loss=0.1434]\u001b[A\n",
            "Epoch 1:  50%|█████     | 918/1835 [21:24<21:19,  1.40s/it, training loss=0.2218]\u001b[A\n",
            "Epoch 1:  50%|█████     | 919/1835 [21:24<21:16,  1.39s/it, training loss=0.2218]\u001b[A\n",
            "Epoch 1:  50%|█████     | 919/1835 [21:25<21:16,  1.39s/it, training loss=0.1956]\u001b[A\n",
            "Epoch 1:  50%|█████     | 920/1835 [21:25<21:14,  1.39s/it, training loss=0.1956]\u001b[A\n",
            "Epoch 1:  50%|█████     | 920/1835 [21:26<21:14,  1.39s/it, training loss=0.1240]\u001b[A\n",
            "Epoch 1:  50%|█████     | 921/1835 [21:26<21:15,  1.40s/it, training loss=0.1240]\u001b[A\n",
            "Epoch 1:  50%|█████     | 921/1835 [21:28<21:15,  1.40s/it, training loss=0.2876]\u001b[A\n",
            "Epoch 1:  50%|█████     | 922/1835 [21:28<21:13,  1.40s/it, training loss=0.2876]\u001b[A\n",
            "Epoch 1:  50%|█████     | 922/1835 [21:29<21:13,  1.40s/it, training loss=0.1778]\u001b[A\n",
            "Epoch 1:  50%|█████     | 923/1835 [21:29<21:13,  1.40s/it, training loss=0.1778]\u001b[A\n",
            "Epoch 1:  50%|█████     | 923/1835 [21:31<21:13,  1.40s/it, training loss=0.2049]\u001b[A\n",
            "Epoch 1:  50%|█████     | 924/1835 [21:31<21:12,  1.40s/it, training loss=0.2049]\u001b[A\n",
            "Epoch 1:  50%|█████     | 924/1835 [21:32<21:12,  1.40s/it, training loss=0.1891]\u001b[A\n",
            "Epoch 1:  50%|█████     | 925/1835 [21:32<21:09,  1.39s/it, training loss=0.1891]\u001b[A\n",
            "Epoch 1:  50%|█████     | 925/1835 [21:33<21:09,  1.39s/it, training loss=0.1446]\u001b[A\n",
            "Epoch 1:  50%|█████     | 926/1835 [21:33<21:05,  1.39s/it, training loss=0.1446]\u001b[A\n",
            "Epoch 1:  50%|█████     | 926/1835 [21:35<21:05,  1.39s/it, training loss=0.1400]\u001b[A\n",
            "Epoch 1:  51%|█████     | 927/1835 [21:35<21:04,  1.39s/it, training loss=0.1400]\u001b[A\n",
            "Epoch 1:  51%|█████     | 927/1835 [21:36<21:04,  1.39s/it, training loss=0.2495]\u001b[A\n",
            "Epoch 1:  51%|█████     | 928/1835 [21:36<21:01,  1.39s/it, training loss=0.2495]\u001b[A\n",
            "Epoch 1:  51%|█████     | 928/1835 [21:38<21:01,  1.39s/it, training loss=0.1096]\u001b[A\n",
            "Epoch 1:  51%|█████     | 929/1835 [21:38<21:02,  1.39s/it, training loss=0.1096]\u001b[A\n",
            "Epoch 1:  51%|█████     | 929/1835 [21:39<21:02,  1.39s/it, training loss=0.0478]\u001b[A\n",
            "Epoch 1:  51%|█████     | 930/1835 [21:39<21:03,  1.40s/it, training loss=0.0478]\u001b[A\n",
            "Epoch 1:  51%|█████     | 930/1835 [21:40<21:03,  1.40s/it, training loss=0.1746]\u001b[A\n",
            "Epoch 1:  51%|█████     | 931/1835 [21:40<21:01,  1.40s/it, training loss=0.1746]\u001b[A\n",
            "Epoch 1:  51%|█████     | 931/1835 [21:42<21:01,  1.40s/it, training loss=0.3580]\u001b[A\n",
            "Epoch 1:  51%|█████     | 932/1835 [21:42<21:01,  1.40s/it, training loss=0.3580]\u001b[A\n",
            "Epoch 1:  51%|█████     | 932/1835 [21:43<21:01,  1.40s/it, training loss=0.1906]\u001b[A\n",
            "Epoch 1:  51%|█████     | 933/1835 [21:43<20:59,  1.40s/it, training loss=0.1906]\u001b[A\n",
            "Epoch 1:  51%|█████     | 933/1835 [21:45<20:59,  1.40s/it, training loss=0.1642]\u001b[A\n",
            "Epoch 1:  51%|█████     | 934/1835 [21:45<20:57,  1.40s/it, training loss=0.1642]\u001b[A\n",
            "Epoch 1:  51%|█████     | 934/1835 [21:46<20:57,  1.40s/it, training loss=0.1042]\u001b[A\n",
            "Epoch 1:  51%|█████     | 935/1835 [21:46<20:55,  1.40s/it, training loss=0.1042]\u001b[A\n",
            "Epoch 1:  51%|█████     | 935/1835 [21:47<20:55,  1.40s/it, training loss=0.0873]\u001b[A\n",
            "Epoch 1:  51%|█████     | 936/1835 [21:47<20:54,  1.40s/it, training loss=0.0873]\u001b[A\n",
            "Epoch 1:  51%|█████     | 936/1835 [21:49<20:54,  1.40s/it, training loss=0.1645]\u001b[A\n",
            "Epoch 1:  51%|█████     | 937/1835 [21:49<20:50,  1.39s/it, training loss=0.1645]\u001b[A\n",
            "Epoch 1:  51%|█████     | 937/1835 [21:50<20:50,  1.39s/it, training loss=0.2721]\u001b[A\n",
            "Epoch 1:  51%|█████     | 938/1835 [21:50<20:48,  1.39s/it, training loss=0.2721]\u001b[A\n",
            "Epoch 1:  51%|█████     | 938/1835 [21:52<20:48,  1.39s/it, training loss=0.0500]\u001b[A\n",
            "Epoch 1:  51%|█████     | 939/1835 [21:52<20:50,  1.40s/it, training loss=0.0500]\u001b[A\n",
            "Epoch 1:  51%|█████     | 939/1835 [21:53<20:50,  1.40s/it, training loss=0.2131]\u001b[A\n",
            "Epoch 1:  51%|█████     | 940/1835 [21:53<20:46,  1.39s/it, training loss=0.2131]\u001b[A\n",
            "Epoch 1:  51%|█████     | 940/1835 [21:54<20:46,  1.39s/it, training loss=0.1075]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 941/1835 [21:54<20:45,  1.39s/it, training loss=0.1075]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 941/1835 [21:56<20:45,  1.39s/it, training loss=0.2002]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 942/1835 [21:56<20:44,  1.39s/it, training loss=0.2002]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 942/1835 [21:57<20:44,  1.39s/it, training loss=0.2560]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 943/1835 [21:57<20:41,  1.39s/it, training loss=0.2560]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 943/1835 [21:59<20:41,  1.39s/it, training loss=0.1824]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 944/1835 [21:59<20:39,  1.39s/it, training loss=0.1824]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 944/1835 [22:00<20:39,  1.39s/it, training loss=0.2589]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 945/1835 [22:00<20:38,  1.39s/it, training loss=0.2589]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 945/1835 [22:01<20:38,  1.39s/it, training loss=0.1204]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 946/1835 [22:01<20:38,  1.39s/it, training loss=0.1204]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 946/1835 [22:03<20:38,  1.39s/it, training loss=0.1779]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 947/1835 [22:03<20:36,  1.39s/it, training loss=0.1779]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 947/1835 [22:04<20:36,  1.39s/it, training loss=0.1960]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 948/1835 [22:04<20:36,  1.39s/it, training loss=0.1960]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 948/1835 [22:06<20:36,  1.39s/it, training loss=0.2887]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 949/1835 [22:06<20:35,  1.39s/it, training loss=0.2887]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 949/1835 [22:07<20:35,  1.39s/it, training loss=0.1394]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 950/1835 [22:07<20:34,  1.40s/it, training loss=0.1394]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 950/1835 [22:08<20:34,  1.40s/it, training loss=0.0910]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 951/1835 [22:08<20:34,  1.40s/it, training loss=0.0910]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 951/1835 [22:10<20:34,  1.40s/it, training loss=0.0929]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 952/1835 [22:10<20:29,  1.39s/it, training loss=0.0929]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 952/1835 [22:11<20:29,  1.39s/it, training loss=0.1080]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 953/1835 [22:11<20:29,  1.39s/it, training loss=0.1080]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 953/1835 [22:12<20:29,  1.39s/it, training loss=0.2670]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 954/1835 [22:12<20:28,  1.40s/it, training loss=0.2670]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 954/1835 [22:14<20:28,  1.40s/it, training loss=0.2171]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 955/1835 [22:14<20:29,  1.40s/it, training loss=0.2171]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 955/1835 [22:15<20:29,  1.40s/it, training loss=0.1574]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 956/1835 [22:15<20:26,  1.40s/it, training loss=0.1574]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 956/1835 [22:17<20:26,  1.40s/it, training loss=0.2567]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 957/1835 [22:17<20:26,  1.40s/it, training loss=0.2567]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 957/1835 [22:18<20:26,  1.40s/it, training loss=0.3842]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 958/1835 [22:18<20:26,  1.40s/it, training loss=0.3842]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 958/1835 [22:19<20:26,  1.40s/it, training loss=0.1038]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 959/1835 [22:19<20:25,  1.40s/it, training loss=0.1038]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 959/1835 [22:21<20:25,  1.40s/it, training loss=0.1493]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 960/1835 [22:21<20:23,  1.40s/it, training loss=0.1493]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 960/1835 [22:22<20:23,  1.40s/it, training loss=0.2814]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 961/1835 [22:22<20:21,  1.40s/it, training loss=0.2814]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 961/1835 [22:24<20:21,  1.40s/it, training loss=0.2439]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 962/1835 [22:24<20:16,  1.39s/it, training loss=0.2439]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 962/1835 [22:25<20:16,  1.39s/it, training loss=0.2670]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 963/1835 [22:25<20:14,  1.39s/it, training loss=0.2670]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 963/1835 [22:26<20:14,  1.39s/it, training loss=0.1221]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 964/1835 [22:26<20:11,  1.39s/it, training loss=0.1221]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 964/1835 [22:28<20:11,  1.39s/it, training loss=0.1147]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 965/1835 [22:28<20:09,  1.39s/it, training loss=0.1147]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 965/1835 [22:29<20:09,  1.39s/it, training loss=0.1907]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 966/1835 [22:29<20:10,  1.39s/it, training loss=0.1907]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 966/1835 [22:31<20:10,  1.39s/it, training loss=0.2948]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 967/1835 [22:31<20:09,  1.39s/it, training loss=0.2948]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 967/1835 [22:32<20:09,  1.39s/it, training loss=0.2474]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 968/1835 [22:32<20:09,  1.39s/it, training loss=0.2474]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 968/1835 [22:33<20:09,  1.39s/it, training loss=0.1605]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 969/1835 [22:33<20:08,  1.40s/it, training loss=0.1605]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 969/1835 [22:35<20:08,  1.40s/it, training loss=0.1077]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 970/1835 [22:35<20:06,  1.39s/it, training loss=0.1077]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 970/1835 [22:36<20:06,  1.39s/it, training loss=0.1859]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 971/1835 [22:36<20:03,  1.39s/it, training loss=0.1859]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 971/1835 [22:38<20:03,  1.39s/it, training loss=0.2798]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 972/1835 [22:38<20:02,  1.39s/it, training loss=0.2798]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 972/1835 [22:39<20:02,  1.39s/it, training loss=0.1335]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 973/1835 [22:39<20:01,  1.39s/it, training loss=0.1335]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 973/1835 [22:40<20:01,  1.39s/it, training loss=0.1522]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 974/1835 [22:40<19:59,  1.39s/it, training loss=0.1522]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 974/1835 [22:42<19:59,  1.39s/it, training loss=0.1021]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 975/1835 [22:42<20:01,  1.40s/it, training loss=0.1021]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 975/1835 [22:43<20:01,  1.40s/it, training loss=0.1265]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 976/1835 [22:43<19:58,  1.40s/it, training loss=0.1265]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 976/1835 [22:45<19:58,  1.40s/it, training loss=0.2461]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 977/1835 [22:45<19:56,  1.39s/it, training loss=0.2461]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 977/1835 [22:46<19:56,  1.39s/it, training loss=0.2250]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 978/1835 [22:46<19:56,  1.40s/it, training loss=0.2250]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 978/1835 [22:47<19:56,  1.40s/it, training loss=0.0674]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 979/1835 [22:47<19:54,  1.40s/it, training loss=0.0674]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 979/1835 [22:49<19:54,  1.40s/it, training loss=0.1525]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 980/1835 [22:49<19:50,  1.39s/it, training loss=0.1525]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 980/1835 [22:50<19:50,  1.39s/it, training loss=0.1325]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 981/1835 [22:50<19:47,  1.39s/it, training loss=0.1325]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 981/1835 [22:52<19:47,  1.39s/it, training loss=0.1924]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 982/1835 [22:52<19:45,  1.39s/it, training loss=0.1924]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 982/1835 [22:53<19:45,  1.39s/it, training loss=0.2360]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 983/1835 [22:53<19:43,  1.39s/it, training loss=0.2360]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 983/1835 [22:54<19:43,  1.39s/it, training loss=0.1963]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 984/1835 [22:54<19:41,  1.39s/it, training loss=0.1963]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 984/1835 [22:56<19:41,  1.39s/it, training loss=0.0985]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 985/1835 [22:56<19:39,  1.39s/it, training loss=0.0985]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 985/1835 [22:57<19:39,  1.39s/it, training loss=0.1053]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 986/1835 [22:57<19:39,  1.39s/it, training loss=0.1053]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 986/1835 [22:58<19:39,  1.39s/it, training loss=0.1594]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 987/1835 [22:58<19:37,  1.39s/it, training loss=0.1594]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 987/1835 [23:00<19:37,  1.39s/it, training loss=0.2590]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 988/1835 [23:00<19:37,  1.39s/it, training loss=0.2590]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 988/1835 [23:01<19:37,  1.39s/it, training loss=0.1840]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 989/1835 [23:01<19:38,  1.39s/it, training loss=0.1840]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 989/1835 [23:03<19:38,  1.39s/it, training loss=0.1823]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 990/1835 [23:03<19:36,  1.39s/it, training loss=0.1823]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 990/1835 [23:04<19:36,  1.39s/it, training loss=0.1559]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 991/1835 [23:04<19:34,  1.39s/it, training loss=0.1559]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 991/1835 [23:05<19:34,  1.39s/it, training loss=0.1491]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 992/1835 [23:05<19:34,  1.39s/it, training loss=0.1491]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 992/1835 [23:07<19:34,  1.39s/it, training loss=0.1062]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 993/1835 [23:07<19:31,  1.39s/it, training loss=0.1062]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 993/1835 [23:08<19:31,  1.39s/it, training loss=0.3486]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 994/1835 [23:08<19:29,  1.39s/it, training loss=0.3486]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 994/1835 [23:10<19:29,  1.39s/it, training loss=0.2625]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 995/1835 [23:10<19:28,  1.39s/it, training loss=0.2625]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 995/1835 [23:11<19:28,  1.39s/it, training loss=0.2406]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 996/1835 [23:11<19:26,  1.39s/it, training loss=0.2406]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 996/1835 [23:12<19:26,  1.39s/it, training loss=0.4869]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 997/1835 [23:12<19:25,  1.39s/it, training loss=0.4869]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 997/1835 [23:14<19:25,  1.39s/it, training loss=0.0455]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 998/1835 [23:14<19:26,  1.39s/it, training loss=0.0455]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 998/1835 [23:15<19:26,  1.39s/it, training loss=0.1194]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 999/1835 [23:15<19:25,  1.39s/it, training loss=0.1194]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 999/1835 [23:17<19:25,  1.39s/it, training loss=0.0566]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 1000/1835 [23:17<19:23,  1.39s/it, training loss=0.0566]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 1000/1835 [23:18<19:23,  1.39s/it, training loss=0.3468]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1001/1835 [23:18<19:22,  1.39s/it, training loss=0.3468]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1001/1835 [23:19<19:22,  1.39s/it, training loss=0.2950]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1002/1835 [23:19<19:20,  1.39s/it, training loss=0.2950]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1002/1835 [23:21<19:20,  1.39s/it, training loss=0.2698]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1003/1835 [23:21<19:18,  1.39s/it, training loss=0.2698]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1003/1835 [23:22<19:18,  1.39s/it, training loss=0.1124]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1004/1835 [23:22<19:16,  1.39s/it, training loss=0.1124]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1004/1835 [23:24<19:16,  1.39s/it, training loss=0.2594]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1005/1835 [23:24<19:13,  1.39s/it, training loss=0.2594]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1005/1835 [23:25<19:13,  1.39s/it, training loss=0.1194]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1006/1835 [23:25<19:14,  1.39s/it, training loss=0.1194]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1006/1835 [23:26<19:14,  1.39s/it, training loss=0.2671]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1007/1835 [23:26<19:09,  1.39s/it, training loss=0.2671]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1007/1835 [23:28<19:09,  1.39s/it, training loss=0.2445]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1008/1835 [23:28<19:08,  1.39s/it, training loss=0.2445]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1008/1835 [23:29<19:08,  1.39s/it, training loss=0.1356]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1009/1835 [23:29<19:08,  1.39s/it, training loss=0.1356]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 1009/1835 [23:30<19:08,  1.39s/it, training loss=0.0992]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1010/1835 [23:30<19:05,  1.39s/it, training loss=0.0992]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1010/1835 [23:32<19:05,  1.39s/it, training loss=0.3134]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1011/1835 [23:32<19:03,  1.39s/it, training loss=0.3134]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1011/1835 [23:33<19:03,  1.39s/it, training loss=0.1043]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1012/1835 [23:33<19:02,  1.39s/it, training loss=0.1043]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1012/1835 [23:35<19:02,  1.39s/it, training loss=0.2070]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1013/1835 [23:35<19:01,  1.39s/it, training loss=0.2070]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1013/1835 [23:36<19:01,  1.39s/it, training loss=0.0788]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1014/1835 [23:36<19:01,  1.39s/it, training loss=0.0788]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1014/1835 [23:37<19:01,  1.39s/it, training loss=0.2889]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1015/1835 [23:37<19:02,  1.39s/it, training loss=0.2889]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1015/1835 [23:39<19:02,  1.39s/it, training loss=0.0618]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1016/1835 [23:39<19:01,  1.39s/it, training loss=0.0618]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1016/1835 [23:40<19:01,  1.39s/it, training loss=0.1632]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1017/1835 [23:40<19:01,  1.40s/it, training loss=0.1632]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1017/1835 [23:42<19:01,  1.40s/it, training loss=0.1157]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1018/1835 [23:42<18:59,  1.39s/it, training loss=0.1157]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 1018/1835 [23:43<18:59,  1.39s/it, training loss=0.3053]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1019/1835 [23:43<18:57,  1.39s/it, training loss=0.3053]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1019/1835 [23:44<18:57,  1.39s/it, training loss=0.1125]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1020/1835 [23:44<18:54,  1.39s/it, training loss=0.1125]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1020/1835 [23:46<18:54,  1.39s/it, training loss=0.1941]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1021/1835 [23:46<18:53,  1.39s/it, training loss=0.1941]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1021/1835 [23:47<18:53,  1.39s/it, training loss=0.2698]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1022/1835 [23:47<18:53,  1.39s/it, training loss=0.2698]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1022/1835 [23:49<18:53,  1.39s/it, training loss=0.1447]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1023/1835 [23:49<18:51,  1.39s/it, training loss=0.1447]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1023/1835 [23:50<18:51,  1.39s/it, training loss=0.4130]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1024/1835 [23:50<18:51,  1.40s/it, training loss=0.4130]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1024/1835 [23:51<18:51,  1.40s/it, training loss=0.3912]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1025/1835 [23:51<18:51,  1.40s/it, training loss=0.3912]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1025/1835 [23:53<18:51,  1.40s/it, training loss=0.1927]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1026/1835 [23:53<18:48,  1.39s/it, training loss=0.1927]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1026/1835 [23:54<18:48,  1.39s/it, training loss=0.1042]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1027/1835 [23:54<18:46,  1.39s/it, training loss=0.1042]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1027/1835 [23:56<18:46,  1.39s/it, training loss=0.1557]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1028/1835 [23:56<18:45,  1.39s/it, training loss=0.1557]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1028/1835 [23:57<18:45,  1.39s/it, training loss=0.0814]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1029/1835 [23:57<18:44,  1.40s/it, training loss=0.0814]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1029/1835 [23:58<18:44,  1.40s/it, training loss=0.1241]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1030/1835 [23:58<18:41,  1.39s/it, training loss=0.1241]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1030/1835 [24:00<18:41,  1.39s/it, training loss=0.2428]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1031/1835 [24:00<18:38,  1.39s/it, training loss=0.2428]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1031/1835 [24:01<18:38,  1.39s/it, training loss=0.2481]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1032/1835 [24:01<18:36,  1.39s/it, training loss=0.2481]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 1032/1835 [24:03<18:36,  1.39s/it, training loss=0.2440]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 1033/1835 [24:03<18:36,  1.39s/it, training loss=0.2440]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 1033/1835 [24:04<18:36,  1.39s/it, training loss=0.1219]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 1034/1835 [24:04<18:33,  1.39s/it, training loss=0.1219]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 1034/1835 [24:05<18:33,  1.39s/it, training loss=0.1104]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 1035/1835 [24:05<18:32,  1.39s/it, training loss=0.1104]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 1035/1835 [24:07<18:32,  1.39s/it, training loss=0.0957]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 1036/1835 [24:07<18:30,  1.39s/it, training loss=0.0957]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 1036/1835 [24:08<18:30,  1.39s/it, training loss=0.1372]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1037/1835 [24:08<18:29,  1.39s/it, training loss=0.1372]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1037/1835 [24:09<18:29,  1.39s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1038/1835 [24:09<18:29,  1.39s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1038/1835 [24:11<18:29,  1.39s/it, training loss=0.0939]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1039/1835 [24:11<18:30,  1.39s/it, training loss=0.0939]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1039/1835 [24:12<18:30,  1.39s/it, training loss=0.1786]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1040/1835 [24:12<18:29,  1.40s/it, training loss=0.1786]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1040/1835 [24:14<18:29,  1.40s/it, training loss=0.1208]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1041/1835 [24:14<18:26,  1.39s/it, training loss=0.1208]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1041/1835 [24:15<18:26,  1.39s/it, training loss=0.1954]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1042/1835 [24:15<18:24,  1.39s/it, training loss=0.1954]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1042/1835 [24:16<18:24,  1.39s/it, training loss=0.1416]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1043/1835 [24:16<18:25,  1.40s/it, training loss=0.1416]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1043/1835 [24:18<18:25,  1.40s/it, training loss=0.1543]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1044/1835 [24:18<18:23,  1.40s/it, training loss=0.1543]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1044/1835 [24:19<18:23,  1.40s/it, training loss=0.2692]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1045/1835 [24:19<18:24,  1.40s/it, training loss=0.2692]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1045/1835 [24:21<18:24,  1.40s/it, training loss=0.1890]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1046/1835 [24:21<18:19,  1.39s/it, training loss=0.1890]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1046/1835 [24:22<18:19,  1.39s/it, training loss=0.2021]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1047/1835 [24:22<18:18,  1.39s/it, training loss=0.2021]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1047/1835 [24:23<18:18,  1.39s/it, training loss=0.2612]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1048/1835 [24:23<18:16,  1.39s/it, training loss=0.2612]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1048/1835 [24:25<18:16,  1.39s/it, training loss=0.3147]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1049/1835 [24:25<18:14,  1.39s/it, training loss=0.3147]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1049/1835 [24:26<18:14,  1.39s/it, training loss=0.1466]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1050/1835 [24:26<18:12,  1.39s/it, training loss=0.1466]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1050/1835 [24:28<18:12,  1.39s/it, training loss=0.3221]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1051/1835 [24:28<18:11,  1.39s/it, training loss=0.3221]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1051/1835 [24:29<18:11,  1.39s/it, training loss=0.0821]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1052/1835 [24:29<18:12,  1.40s/it, training loss=0.0821]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1052/1835 [24:30<18:12,  1.40s/it, training loss=0.2541]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1053/1835 [24:30<18:09,  1.39s/it, training loss=0.2541]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1053/1835 [24:32<18:09,  1.39s/it, training loss=0.1334]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1054/1835 [24:32<18:10,  1.40s/it, training loss=0.1334]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1054/1835 [24:33<18:10,  1.40s/it, training loss=0.0947]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1055/1835 [24:33<18:10,  1.40s/it, training loss=0.0947]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 1055/1835 [24:35<18:10,  1.40s/it, training loss=0.1425]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1056/1835 [24:35<18:08,  1.40s/it, training loss=0.1425]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1056/1835 [24:36<18:08,  1.40s/it, training loss=0.2215]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1057/1835 [24:36<18:06,  1.40s/it, training loss=0.2215]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1057/1835 [24:37<18:06,  1.40s/it, training loss=0.2098]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1058/1835 [24:37<18:04,  1.40s/it, training loss=0.2098]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1058/1835 [24:39<18:04,  1.40s/it, training loss=0.1636]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1059/1835 [24:39<18:01,  1.39s/it, training loss=0.1636]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1059/1835 [24:40<18:01,  1.39s/it, training loss=0.1009]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1060/1835 [24:40<18:00,  1.39s/it, training loss=0.1009]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1060/1835 [24:42<18:00,  1.39s/it, training loss=0.1411]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1061/1835 [24:42<18:00,  1.40s/it, training loss=0.1411]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1061/1835 [24:43<18:00,  1.40s/it, training loss=0.2581]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1062/1835 [24:43<17:59,  1.40s/it, training loss=0.2581]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1062/1835 [24:44<17:59,  1.40s/it, training loss=0.1707]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1063/1835 [24:44<18:00,  1.40s/it, training loss=0.1707]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1063/1835 [24:46<18:00,  1.40s/it, training loss=0.1154]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1064/1835 [24:46<17:58,  1.40s/it, training loss=0.1154]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1064/1835 [24:47<17:58,  1.40s/it, training loss=0.1360]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1065/1835 [24:47<17:55,  1.40s/it, training loss=0.1360]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1065/1835 [24:49<17:55,  1.40s/it, training loss=0.1898]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1066/1835 [24:49<17:55,  1.40s/it, training loss=0.1898]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1066/1835 [24:50<17:55,  1.40s/it, training loss=0.0657]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1067/1835 [24:50<17:54,  1.40s/it, training loss=0.0657]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1067/1835 [24:51<17:54,  1.40s/it, training loss=0.1267]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1068/1835 [24:51<17:53,  1.40s/it, training loss=0.1267]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1068/1835 [24:53<17:53,  1.40s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1069/1835 [24:53<17:52,  1.40s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1069/1835 [24:54<17:52,  1.40s/it, training loss=0.1640]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1070/1835 [24:54<17:49,  1.40s/it, training loss=0.1640]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1070/1835 [24:56<17:49,  1.40s/it, training loss=0.1910]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1071/1835 [24:56<17:47,  1.40s/it, training loss=0.1910]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1071/1835 [24:57<17:47,  1.40s/it, training loss=0.1633]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1072/1835 [24:57<17:44,  1.39s/it, training loss=0.1633]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1072/1835 [24:58<17:44,  1.39s/it, training loss=0.0780]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1073/1835 [24:58<17:42,  1.39s/it, training loss=0.0780]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 1073/1835 [25:00<17:42,  1.39s/it, training loss=0.2516]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 1074/1835 [25:00<17:39,  1.39s/it, training loss=0.2516]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 1074/1835 [25:01<17:39,  1.39s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 1075/1835 [25:01<17:39,  1.39s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 1075/1835 [25:03<17:39,  1.39s/it, training loss=0.3151]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 1076/1835 [25:03<17:38,  1.39s/it, training loss=0.3151]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 1076/1835 [25:04<17:38,  1.39s/it, training loss=0.2978]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 1077/1835 [25:04<17:37,  1.39s/it, training loss=0.2978]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 1077/1835 [25:05<17:37,  1.39s/it, training loss=0.1657]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 1078/1835 [25:05<17:37,  1.40s/it, training loss=0.1657]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 1078/1835 [25:07<17:37,  1.40s/it, training loss=0.3155]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1079/1835 [25:07<17:37,  1.40s/it, training loss=0.3155]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1079/1835 [25:08<17:37,  1.40s/it, training loss=0.2713]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1080/1835 [25:08<17:34,  1.40s/it, training loss=0.2713]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1080/1835 [25:09<17:34,  1.40s/it, training loss=0.1708]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1081/1835 [25:09<17:32,  1.40s/it, training loss=0.1708]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1081/1835 [25:11<17:32,  1.40s/it, training loss=0.1319]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1082/1835 [25:11<17:30,  1.40s/it, training loss=0.1319]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1082/1835 [25:12<17:30,  1.40s/it, training loss=0.1742]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1083/1835 [25:12<17:30,  1.40s/it, training loss=0.1742]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1083/1835 [25:14<17:30,  1.40s/it, training loss=0.2666]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1084/1835 [25:14<17:29,  1.40s/it, training loss=0.2666]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1084/1835 [25:15<17:29,  1.40s/it, training loss=0.0808]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1085/1835 [25:15<17:28,  1.40s/it, training loss=0.0808]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1085/1835 [25:16<17:28,  1.40s/it, training loss=0.1593]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1086/1835 [25:16<17:26,  1.40s/it, training loss=0.1593]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1086/1835 [25:18<17:26,  1.40s/it, training loss=0.1687]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1087/1835 [25:18<17:24,  1.40s/it, training loss=0.1687]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1087/1835 [25:19<17:24,  1.40s/it, training loss=0.2535]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1088/1835 [25:19<17:24,  1.40s/it, training loss=0.2535]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1088/1835 [25:21<17:24,  1.40s/it, training loss=0.1322]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1089/1835 [25:21<17:22,  1.40s/it, training loss=0.1322]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1089/1835 [25:22<17:22,  1.40s/it, training loss=0.3198]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1090/1835 [25:22<17:20,  1.40s/it, training loss=0.3198]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1090/1835 [25:23<17:20,  1.40s/it, training loss=0.2034]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1091/1835 [25:23<17:19,  1.40s/it, training loss=0.2034]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 1091/1835 [25:25<17:19,  1.40s/it, training loss=0.2697]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1092/1835 [25:25<17:18,  1.40s/it, training loss=0.2697]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1092/1835 [25:26<17:18,  1.40s/it, training loss=0.1803]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1093/1835 [25:26<17:15,  1.40s/it, training loss=0.1803]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1093/1835 [25:28<17:15,  1.40s/it, training loss=0.2113]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1094/1835 [25:28<17:14,  1.40s/it, training loss=0.2113]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1094/1835 [25:29<17:14,  1.40s/it, training loss=0.1273]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1095/1835 [25:29<17:12,  1.40s/it, training loss=0.1273]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1095/1835 [25:30<17:12,  1.40s/it, training loss=0.1945]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1096/1835 [25:30<17:12,  1.40s/it, training loss=0.1945]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1096/1835 [25:32<17:12,  1.40s/it, training loss=0.1643]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1097/1835 [25:32<17:11,  1.40s/it, training loss=0.1643]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1097/1835 [25:33<17:11,  1.40s/it, training loss=0.1220]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1098/1835 [25:33<17:08,  1.40s/it, training loss=0.1220]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1098/1835 [25:35<17:08,  1.40s/it, training loss=0.2064]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1099/1835 [25:35<17:07,  1.40s/it, training loss=0.2064]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1099/1835 [25:36<17:07,  1.40s/it, training loss=0.1406]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1100/1835 [25:36<17:08,  1.40s/it, training loss=0.1406]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1100/1835 [25:37<17:08,  1.40s/it, training loss=0.2094]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1101/1835 [25:37<17:03,  1.39s/it, training loss=0.2094]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1101/1835 [25:39<17:03,  1.39s/it, training loss=0.2501]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1102/1835 [25:39<17:05,  1.40s/it, training loss=0.2501]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1102/1835 [25:40<17:05,  1.40s/it, training loss=0.1002]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1103/1835 [25:40<17:03,  1.40s/it, training loss=0.1002]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1103/1835 [25:42<17:03,  1.40s/it, training loss=0.2911]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1104/1835 [25:42<17:02,  1.40s/it, training loss=0.2911]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1104/1835 [25:43<17:02,  1.40s/it, training loss=0.0506]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1105/1835 [25:43<16:59,  1.40s/it, training loss=0.0506]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1105/1835 [25:44<16:59,  1.40s/it, training loss=0.1574]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1106/1835 [25:44<16:57,  1.40s/it, training loss=0.1574]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1106/1835 [25:46<16:57,  1.40s/it, training loss=0.1667]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1107/1835 [25:46<16:55,  1.40s/it, training loss=0.1667]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1107/1835 [25:47<16:55,  1.40s/it, training loss=0.2054]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1108/1835 [25:47<16:53,  1.39s/it, training loss=0.2054]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1108/1835 [25:49<16:53,  1.39s/it, training loss=0.1320]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1109/1835 [25:49<16:52,  1.39s/it, training loss=0.1320]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1109/1835 [25:50<16:52,  1.39s/it, training loss=0.1522]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1110/1835 [25:50<16:53,  1.40s/it, training loss=0.1522]\u001b[A\n",
            "Epoch 1:  60%|██████    | 1110/1835 [25:51<16:53,  1.40s/it, training loss=0.3672]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1111/1835 [25:51<16:52,  1.40s/it, training loss=0.3672]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1111/1835 [25:53<16:52,  1.40s/it, training loss=0.1005]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1112/1835 [25:53<16:50,  1.40s/it, training loss=0.1005]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1112/1835 [25:54<16:50,  1.40s/it, training loss=0.2727]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1113/1835 [25:54<16:49,  1.40s/it, training loss=0.2727]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1113/1835 [25:56<16:49,  1.40s/it, training loss=0.1781]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1114/1835 [25:56<16:48,  1.40s/it, training loss=0.1781]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1114/1835 [25:57<16:48,  1.40s/it, training loss=0.1239]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1115/1835 [25:57<16:46,  1.40s/it, training loss=0.1239]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1115/1835 [25:58<16:46,  1.40s/it, training loss=0.1101]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1116/1835 [25:58<16:44,  1.40s/it, training loss=0.1101]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1116/1835 [26:00<16:44,  1.40s/it, training loss=0.1266]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1117/1835 [26:00<16:42,  1.40s/it, training loss=0.1266]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1117/1835 [26:01<16:42,  1.40s/it, training loss=0.2644]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1118/1835 [26:01<16:42,  1.40s/it, training loss=0.2644]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1118/1835 [26:03<16:42,  1.40s/it, training loss=0.2278]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1119/1835 [26:03<16:40,  1.40s/it, training loss=0.2278]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1119/1835 [26:04<16:40,  1.40s/it, training loss=0.1524]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1120/1835 [26:04<16:38,  1.40s/it, training loss=0.1524]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1120/1835 [26:05<16:38,  1.40s/it, training loss=0.2157]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1121/1835 [26:05<16:37,  1.40s/it, training loss=0.2157]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1121/1835 [26:07<16:37,  1.40s/it, training loss=0.1267]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1122/1835 [26:07<16:35,  1.40s/it, training loss=0.1267]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1122/1835 [26:08<16:35,  1.40s/it, training loss=0.3162]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1123/1835 [26:08<16:34,  1.40s/it, training loss=0.3162]\u001b[A\n",
            "Epoch 1:  61%|██████    | 1123/1835 [26:10<16:34,  1.40s/it, training loss=0.1362]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 1124/1835 [26:10<16:32,  1.40s/it, training loss=0.1362]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 1124/1835 [26:11<16:32,  1.40s/it, training loss=0.3146]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 1125/1835 [26:11<16:31,  1.40s/it, training loss=0.3146]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 1125/1835 [26:12<16:31,  1.40s/it, training loss=0.2075]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 1126/1835 [26:12<16:30,  1.40s/it, training loss=0.2075]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 1126/1835 [26:14<16:30,  1.40s/it, training loss=0.1292]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 1127/1835 [26:14<16:28,  1.40s/it, training loss=0.1292]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 1127/1835 [26:15<16:28,  1.40s/it, training loss=0.2260]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 1128/1835 [26:15<16:27,  1.40s/it, training loss=0.2260]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 1128/1835 [26:17<16:27,  1.40s/it, training loss=0.2014]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1129/1835 [26:17<16:26,  1.40s/it, training loss=0.2014]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1129/1835 [26:18<16:26,  1.40s/it, training loss=0.2297]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1130/1835 [26:18<16:25,  1.40s/it, training loss=0.2297]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1130/1835 [26:19<16:25,  1.40s/it, training loss=0.3614]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1131/1835 [26:19<16:24,  1.40s/it, training loss=0.3614]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1131/1835 [26:21<16:24,  1.40s/it, training loss=0.2818]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1132/1835 [26:21<16:20,  1.40s/it, training loss=0.2818]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1132/1835 [26:22<16:20,  1.40s/it, training loss=0.1275]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1133/1835 [26:22<16:19,  1.40s/it, training loss=0.1275]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1133/1835 [26:24<16:19,  1.40s/it, training loss=0.0616]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1134/1835 [26:24<16:18,  1.40s/it, training loss=0.0616]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1134/1835 [26:25<16:18,  1.40s/it, training loss=0.2695]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1135/1835 [26:25<16:16,  1.40s/it, training loss=0.2695]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1135/1835 [26:26<16:16,  1.40s/it, training loss=0.2975]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1136/1835 [26:26<16:18,  1.40s/it, training loss=0.2975]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1136/1835 [26:28<16:18,  1.40s/it, training loss=0.1195]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1137/1835 [26:28<16:15,  1.40s/it, training loss=0.1195]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1137/1835 [26:29<16:15,  1.40s/it, training loss=0.1409]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1138/1835 [26:29<16:14,  1.40s/it, training loss=0.1409]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1138/1835 [26:31<16:14,  1.40s/it, training loss=0.2284]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1139/1835 [26:31<16:12,  1.40s/it, training loss=0.2284]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1139/1835 [26:32<16:12,  1.40s/it, training loss=0.1320]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1140/1835 [26:32<16:10,  1.40s/it, training loss=0.1320]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1140/1835 [26:33<16:10,  1.40s/it, training loss=0.2214]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1141/1835 [26:33<16:10,  1.40s/it, training loss=0.2214]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1141/1835 [26:35<16:10,  1.40s/it, training loss=0.2147]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1142/1835 [26:35<16:07,  1.40s/it, training loss=0.2147]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1142/1835 [26:36<16:07,  1.40s/it, training loss=0.2488]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1143/1835 [26:36<16:05,  1.40s/it, training loss=0.2488]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1143/1835 [26:37<16:05,  1.40s/it, training loss=0.0968]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1144/1835 [26:37<16:04,  1.40s/it, training loss=0.0968]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1144/1835 [26:39<16:04,  1.40s/it, training loss=0.2455]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1145/1835 [26:39<16:04,  1.40s/it, training loss=0.2455]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1145/1835 [26:40<16:04,  1.40s/it, training loss=0.1352]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1146/1835 [26:40<16:02,  1.40s/it, training loss=0.1352]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 1146/1835 [26:42<16:02,  1.40s/it, training loss=0.2775]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1147/1835 [26:42<16:01,  1.40s/it, training loss=0.2775]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1147/1835 [26:43<16:01,  1.40s/it, training loss=0.2004]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1148/1835 [26:43<15:59,  1.40s/it, training loss=0.2004]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1148/1835 [26:44<15:59,  1.40s/it, training loss=0.1454]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1149/1835 [26:44<16:00,  1.40s/it, training loss=0.1454]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1149/1835 [26:46<16:00,  1.40s/it, training loss=0.2995]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1150/1835 [26:46<15:57,  1.40s/it, training loss=0.2995]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1150/1835 [26:47<15:57,  1.40s/it, training loss=0.1939]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1151/1835 [26:47<15:55,  1.40s/it, training loss=0.1939]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1151/1835 [26:49<15:55,  1.40s/it, training loss=0.1597]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1152/1835 [26:49<15:53,  1.40s/it, training loss=0.1597]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1152/1835 [26:50<15:53,  1.40s/it, training loss=0.1178]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1153/1835 [26:50<15:53,  1.40s/it, training loss=0.1178]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1153/1835 [26:51<15:53,  1.40s/it, training loss=0.0898]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1154/1835 [26:51<15:51,  1.40s/it, training loss=0.0898]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1154/1835 [26:53<15:51,  1.40s/it, training loss=0.1395]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1155/1835 [26:53<15:50,  1.40s/it, training loss=0.1395]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1155/1835 [26:54<15:50,  1.40s/it, training loss=0.2555]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1156/1835 [26:54<15:49,  1.40s/it, training loss=0.2555]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1156/1835 [26:56<15:49,  1.40s/it, training loss=0.1963]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1157/1835 [26:56<15:48,  1.40s/it, training loss=0.1963]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1157/1835 [26:57<15:48,  1.40s/it, training loss=0.2902]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1158/1835 [26:57<15:47,  1.40s/it, training loss=0.2902]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1158/1835 [26:58<15:47,  1.40s/it, training loss=0.3068]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1159/1835 [26:58<15:45,  1.40s/it, training loss=0.3068]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1159/1835 [27:00<15:45,  1.40s/it, training loss=0.0853]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1160/1835 [27:00<15:43,  1.40s/it, training loss=0.0853]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1160/1835 [27:01<15:43,  1.40s/it, training loss=0.2007]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1161/1835 [27:01<15:41,  1.40s/it, training loss=0.2007]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1161/1835 [27:03<15:41,  1.40s/it, training loss=0.3037]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1162/1835 [27:03<15:40,  1.40s/it, training loss=0.3037]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1162/1835 [27:04<15:40,  1.40s/it, training loss=0.1746]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1163/1835 [27:04<15:38,  1.40s/it, training loss=0.1746]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1163/1835 [27:05<15:38,  1.40s/it, training loss=0.3075]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1164/1835 [27:05<15:37,  1.40s/it, training loss=0.3075]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1164/1835 [27:07<15:37,  1.40s/it, training loss=0.2400]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1165/1835 [27:07<15:34,  1.40s/it, training loss=0.2400]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 1165/1835 [27:08<15:34,  1.40s/it, training loss=0.2131]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 1166/1835 [27:08<15:34,  1.40s/it, training loss=0.2131]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 1166/1835 [27:10<15:34,  1.40s/it, training loss=0.1429]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 1167/1835 [27:10<15:34,  1.40s/it, training loss=0.1429]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 1167/1835 [27:11<15:34,  1.40s/it, training loss=0.1206]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 1168/1835 [27:11<15:32,  1.40s/it, training loss=0.1206]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 1168/1835 [27:12<15:32,  1.40s/it, training loss=0.2227]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 1169/1835 [27:12<15:31,  1.40s/it, training loss=0.2227]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 1169/1835 [27:14<15:31,  1.40s/it, training loss=0.1596]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1170/1835 [27:14<15:29,  1.40s/it, training loss=0.1596]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1170/1835 [27:15<15:29,  1.40s/it, training loss=0.1497]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1171/1835 [27:15<15:26,  1.40s/it, training loss=0.1497]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1171/1835 [27:17<15:26,  1.40s/it, training loss=0.2293]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1172/1835 [27:17<15:25,  1.40s/it, training loss=0.2293]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1172/1835 [27:18<15:25,  1.40s/it, training loss=0.2027]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1173/1835 [27:18<15:24,  1.40s/it, training loss=0.2027]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1173/1835 [27:19<15:24,  1.40s/it, training loss=0.2436]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1174/1835 [27:19<15:23,  1.40s/it, training loss=0.2436]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1174/1835 [27:21<15:23,  1.40s/it, training loss=0.1824]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1175/1835 [27:21<15:22,  1.40s/it, training loss=0.1824]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1175/1835 [27:22<15:22,  1.40s/it, training loss=0.2308]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1176/1835 [27:22<15:21,  1.40s/it, training loss=0.2308]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1176/1835 [27:24<15:21,  1.40s/it, training loss=0.1353]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1177/1835 [27:24<15:19,  1.40s/it, training loss=0.1353]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1177/1835 [27:25<15:19,  1.40s/it, training loss=0.1108]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1178/1835 [27:25<15:18,  1.40s/it, training loss=0.1108]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1178/1835 [27:26<15:18,  1.40s/it, training loss=0.1315]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1179/1835 [27:26<15:15,  1.40s/it, training loss=0.1315]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1179/1835 [27:28<15:15,  1.40s/it, training loss=0.1861]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1180/1835 [27:28<15:14,  1.40s/it, training loss=0.1861]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1180/1835 [27:29<15:14,  1.40s/it, training loss=0.1688]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1181/1835 [27:29<15:13,  1.40s/it, training loss=0.1688]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1181/1835 [27:31<15:13,  1.40s/it, training loss=0.1655]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1182/1835 [27:31<15:12,  1.40s/it, training loss=0.1655]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1182/1835 [27:32<15:12,  1.40s/it, training loss=0.2471]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1183/1835 [27:32<15:10,  1.40s/it, training loss=0.2471]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 1183/1835 [27:33<15:10,  1.40s/it, training loss=0.2316]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1184/1835 [27:33<15:08,  1.40s/it, training loss=0.2316]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1184/1835 [27:35<15:08,  1.40s/it, training loss=0.2048]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1185/1835 [27:35<15:07,  1.40s/it, training loss=0.2048]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1185/1835 [27:36<15:07,  1.40s/it, training loss=0.1835]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1186/1835 [27:36<15:06,  1.40s/it, training loss=0.1835]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1186/1835 [27:38<15:06,  1.40s/it, training loss=0.1330]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1187/1835 [27:38<15:05,  1.40s/it, training loss=0.1330]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1187/1835 [27:39<15:05,  1.40s/it, training loss=0.1156]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1188/1835 [27:39<15:03,  1.40s/it, training loss=0.1156]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1188/1835 [27:40<15:03,  1.40s/it, training loss=0.1376]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1189/1835 [27:40<15:02,  1.40s/it, training loss=0.1376]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1189/1835 [27:42<15:02,  1.40s/it, training loss=0.2678]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1190/1835 [27:42<14:59,  1.40s/it, training loss=0.2678]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1190/1835 [27:43<14:59,  1.40s/it, training loss=0.2163]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1191/1835 [27:43<14:59,  1.40s/it, training loss=0.2163]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1191/1835 [27:45<14:59,  1.40s/it, training loss=0.1152]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1192/1835 [27:45<14:58,  1.40s/it, training loss=0.1152]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 1192/1835 [27:46<14:58,  1.40s/it, training loss=0.1905]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1193/1835 [27:46<14:56,  1.40s/it, training loss=0.1905]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1193/1835 [27:47<14:56,  1.40s/it, training loss=0.1633]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1194/1835 [27:47<14:56,  1.40s/it, training loss=0.1633]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1194/1835 [27:49<14:56,  1.40s/it, training loss=0.0959]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1195/1835 [27:49<14:55,  1.40s/it, training loss=0.0959]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1195/1835 [27:50<14:55,  1.40s/it, training loss=0.1778]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1196/1835 [27:50<14:55,  1.40s/it, training loss=0.1778]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1196/1835 [27:52<14:55,  1.40s/it, training loss=0.1393]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1197/1835 [27:52<14:53,  1.40s/it, training loss=0.1393]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1197/1835 [27:53<14:53,  1.40s/it, training loss=0.1068]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1198/1835 [27:53<14:53,  1.40s/it, training loss=0.1068]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1198/1835 [27:54<14:53,  1.40s/it, training loss=0.2301]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1199/1835 [27:54<14:51,  1.40s/it, training loss=0.2301]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1199/1835 [27:56<14:51,  1.40s/it, training loss=0.1025]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1200/1835 [27:56<14:51,  1.40s/it, training loss=0.1025]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1200/1835 [27:57<14:51,  1.40s/it, training loss=0.2079]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1201/1835 [27:57<14:49,  1.40s/it, training loss=0.2079]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 1201/1835 [27:59<14:49,  1.40s/it, training loss=0.1196]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1202/1835 [27:59<14:47,  1.40s/it, training loss=0.1196]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1202/1835 [28:00<14:47,  1.40s/it, training loss=0.2078]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1203/1835 [28:00<14:44,  1.40s/it, training loss=0.2078]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1203/1835 [28:01<14:44,  1.40s/it, training loss=0.3804]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1204/1835 [28:01<14:43,  1.40s/it, training loss=0.3804]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1204/1835 [28:03<14:43,  1.40s/it, training loss=0.2755]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1205/1835 [28:03<14:41,  1.40s/it, training loss=0.2755]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1205/1835 [28:04<14:41,  1.40s/it, training loss=0.1399]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1206/1835 [28:04<14:40,  1.40s/it, training loss=0.1399]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1206/1835 [28:06<14:40,  1.40s/it, training loss=0.1117]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1207/1835 [28:06<14:36,  1.40s/it, training loss=0.1117]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1207/1835 [28:07<14:36,  1.40s/it, training loss=0.2628]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1208/1835 [28:07<14:35,  1.40s/it, training loss=0.2628]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1208/1835 [28:08<14:35,  1.40s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1209/1835 [28:08<14:34,  1.40s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1209/1835 [28:10<14:34,  1.40s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1210/1835 [28:10<14:32,  1.40s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1210/1835 [28:11<14:32,  1.40s/it, training loss=0.1341]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1211/1835 [28:11<14:31,  1.40s/it, training loss=0.1341]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1211/1835 [28:13<14:31,  1.40s/it, training loss=0.1695]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1212/1835 [28:13<14:28,  1.39s/it, training loss=0.1695]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1212/1835 [28:14<14:28,  1.39s/it, training loss=0.0704]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1213/1835 [28:14<14:27,  1.39s/it, training loss=0.0704]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1213/1835 [28:15<14:27,  1.39s/it, training loss=0.2060]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1214/1835 [28:15<14:23,  1.39s/it, training loss=0.2060]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1214/1835 [28:17<14:23,  1.39s/it, training loss=0.0458]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1215/1835 [28:17<14:23,  1.39s/it, training loss=0.0458]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 1215/1835 [28:18<14:23,  1.39s/it, training loss=0.1097]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 1216/1835 [28:18<14:22,  1.39s/it, training loss=0.1097]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 1216/1835 [28:19<14:22,  1.39s/it, training loss=0.2962]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 1217/1835 [28:20<14:21,  1.39s/it, training loss=0.2962]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 1217/1835 [28:21<14:21,  1.39s/it, training loss=0.1885]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 1218/1835 [28:21<14:18,  1.39s/it, training loss=0.1885]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 1218/1835 [28:22<14:18,  1.39s/it, training loss=0.2110]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 1219/1835 [28:22<14:17,  1.39s/it, training loss=0.2110]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 1219/1835 [28:24<14:17,  1.39s/it, training loss=0.1440]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 1220/1835 [28:24<14:18,  1.40s/it, training loss=0.1440]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 1220/1835 [28:25<14:18,  1.40s/it, training loss=0.3529]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1221/1835 [28:25<14:16,  1.39s/it, training loss=0.3529]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1221/1835 [28:27<14:16,  1.39s/it, training loss=0.3610]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1222/1835 [28:27<14:26,  1.41s/it, training loss=0.3610]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1222/1835 [28:28<14:26,  1.41s/it, training loss=0.1116]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1223/1835 [28:28<14:17,  1.40s/it, training loss=0.1116]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1223/1835 [28:29<14:17,  1.40s/it, training loss=0.1373]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1224/1835 [28:29<14:14,  1.40s/it, training loss=0.1373]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1224/1835 [28:31<14:14,  1.40s/it, training loss=0.2001]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1225/1835 [28:31<14:21,  1.41s/it, training loss=0.2001]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1225/1835 [28:32<14:21,  1.41s/it, training loss=0.3684]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1226/1835 [28:32<14:18,  1.41s/it, training loss=0.3684]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1226/1835 [28:34<14:18,  1.41s/it, training loss=0.2260]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1227/1835 [28:34<14:21,  1.42s/it, training loss=0.2260]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1227/1835 [28:35<14:21,  1.42s/it, training loss=0.1321]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1228/1835 [28:35<14:15,  1.41s/it, training loss=0.1321]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1228/1835 [28:36<14:15,  1.41s/it, training loss=0.2067]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1229/1835 [28:36<14:13,  1.41s/it, training loss=0.2067]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1229/1835 [28:38<14:13,  1.41s/it, training loss=0.1697]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1230/1835 [28:38<14:14,  1.41s/it, training loss=0.1697]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1230/1835 [28:39<14:14,  1.41s/it, training loss=0.1829]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1231/1835 [28:39<14:16,  1.42s/it, training loss=0.1829]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1231/1835 [28:41<14:16,  1.42s/it, training loss=0.1928]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1232/1835 [28:41<14:11,  1.41s/it, training loss=0.1928]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1232/1835 [28:42<14:11,  1.41s/it, training loss=0.2378]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1233/1835 [28:42<14:09,  1.41s/it, training loss=0.2378]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1233/1835 [28:43<14:09,  1.41s/it, training loss=0.1380]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1234/1835 [28:43<14:05,  1.41s/it, training loss=0.1380]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1234/1835 [28:45<14:05,  1.41s/it, training loss=0.1204]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1235/1835 [28:45<14:03,  1.41s/it, training loss=0.1204]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1235/1835 [28:46<14:03,  1.41s/it, training loss=0.3430]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1236/1835 [28:46<14:00,  1.40s/it, training loss=0.3430]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1236/1835 [28:48<14:00,  1.40s/it, training loss=0.2452]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1237/1835 [28:48<13:57,  1.40s/it, training loss=0.2452]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1237/1835 [28:49<13:57,  1.40s/it, training loss=0.2437]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1238/1835 [28:49<13:58,  1.40s/it, training loss=0.2437]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 1238/1835 [28:50<13:58,  1.40s/it, training loss=0.1948]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1239/1835 [28:50<13:55,  1.40s/it, training loss=0.1948]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1239/1835 [28:52<13:55,  1.40s/it, training loss=0.1292]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1240/1835 [28:52<13:52,  1.40s/it, training loss=0.1292]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1240/1835 [28:53<13:52,  1.40s/it, training loss=0.2085]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1241/1835 [28:53<13:52,  1.40s/it, training loss=0.2085]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1241/1835 [28:55<13:52,  1.40s/it, training loss=0.1418]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1242/1835 [28:55<13:50,  1.40s/it, training loss=0.1418]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1242/1835 [28:56<13:50,  1.40s/it, training loss=0.2588]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1243/1835 [28:56<13:47,  1.40s/it, training loss=0.2588]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1243/1835 [28:57<13:47,  1.40s/it, training loss=0.2383]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1244/1835 [28:57<13:45,  1.40s/it, training loss=0.2383]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1244/1835 [28:59<13:45,  1.40s/it, training loss=0.3344]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1245/1835 [28:59<13:43,  1.40s/it, training loss=0.3344]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1245/1835 [29:00<13:43,  1.40s/it, training loss=0.2108]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1246/1835 [29:00<13:40,  1.39s/it, training loss=0.2108]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1246/1835 [29:02<13:40,  1.39s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1247/1835 [29:02<13:40,  1.40s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1247/1835 [29:03<13:40,  1.40s/it, training loss=0.1844]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1248/1835 [29:03<13:41,  1.40s/it, training loss=0.1844]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1248/1835 [29:04<13:41,  1.40s/it, training loss=0.1481]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1249/1835 [29:04<13:41,  1.40s/it, training loss=0.1481]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1249/1835 [29:06<13:41,  1.40s/it, training loss=0.1246]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1250/1835 [29:06<13:41,  1.41s/it, training loss=0.1246]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1250/1835 [29:07<13:41,  1.41s/it, training loss=0.1363]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1251/1835 [29:07<13:40,  1.41s/it, training loss=0.1363]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1251/1835 [29:09<13:40,  1.41s/it, training loss=0.1563]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1252/1835 [29:09<13:38,  1.40s/it, training loss=0.1563]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1252/1835 [29:10<13:38,  1.40s/it, training loss=0.2213]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1253/1835 [29:10<13:36,  1.40s/it, training loss=0.2213]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1253/1835 [29:11<13:36,  1.40s/it, training loss=0.1925]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1254/1835 [29:11<13:37,  1.41s/it, training loss=0.1925]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1254/1835 [29:13<13:37,  1.41s/it, training loss=0.2127]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1255/1835 [29:13<13:44,  1.42s/it, training loss=0.2127]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1255/1835 [29:14<13:44,  1.42s/it, training loss=0.1497]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1256/1835 [29:14<13:39,  1.42s/it, training loss=0.1497]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 1256/1835 [29:16<13:39,  1.42s/it, training loss=0.2018]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 1257/1835 [29:16<13:33,  1.41s/it, training loss=0.2018]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 1257/1835 [29:17<13:33,  1.41s/it, training loss=0.2167]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 1258/1835 [29:17<13:33,  1.41s/it, training loss=0.2167]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 1258/1835 [29:19<13:33,  1.41s/it, training loss=0.2135]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 1259/1835 [29:19<13:35,  1.42s/it, training loss=0.2135]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 1259/1835 [29:20<13:35,  1.42s/it, training loss=0.1954]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 1260/1835 [29:20<13:31,  1.41s/it, training loss=0.1954]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 1260/1835 [29:21<13:31,  1.41s/it, training loss=0.1541]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 1261/1835 [29:21<13:27,  1.41s/it, training loss=0.1541]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 1261/1835 [29:23<13:27,  1.41s/it, training loss=0.2008]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1262/1835 [29:23<13:24,  1.40s/it, training loss=0.2008]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1262/1835 [29:24<13:24,  1.40s/it, training loss=0.2226]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1263/1835 [29:24<13:21,  1.40s/it, training loss=0.2226]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1263/1835 [29:26<13:21,  1.40s/it, training loss=0.2060]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1264/1835 [29:26<13:20,  1.40s/it, training loss=0.2060]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1264/1835 [29:27<13:20,  1.40s/it, training loss=0.0941]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1265/1835 [29:27<13:19,  1.40s/it, training loss=0.0941]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1265/1835 [29:28<13:19,  1.40s/it, training loss=0.1189]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1266/1835 [29:28<13:16,  1.40s/it, training loss=0.1189]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1266/1835 [29:30<13:16,  1.40s/it, training loss=0.2102]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1267/1835 [29:30<13:17,  1.40s/it, training loss=0.2102]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1267/1835 [29:31<13:17,  1.40s/it, training loss=0.1693]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1268/1835 [29:31<13:15,  1.40s/it, training loss=0.1693]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1268/1835 [29:33<13:15,  1.40s/it, training loss=0.1063]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1269/1835 [29:33<13:13,  1.40s/it, training loss=0.1063]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1269/1835 [29:34<13:13,  1.40s/it, training loss=0.1769]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1270/1835 [29:34<13:10,  1.40s/it, training loss=0.1769]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1270/1835 [29:35<13:10,  1.40s/it, training loss=0.1907]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1271/1835 [29:35<13:09,  1.40s/it, training loss=0.1907]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1271/1835 [29:37<13:09,  1.40s/it, training loss=0.1286]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1272/1835 [29:37<13:07,  1.40s/it, training loss=0.1286]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1272/1835 [29:38<13:07,  1.40s/it, training loss=0.1666]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1273/1835 [29:38<13:06,  1.40s/it, training loss=0.1666]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1273/1835 [29:40<13:06,  1.40s/it, training loss=0.2692]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1274/1835 [29:40<13:05,  1.40s/it, training loss=0.2692]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1274/1835 [29:41<13:05,  1.40s/it, training loss=0.1085]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1275/1835 [29:41<13:05,  1.40s/it, training loss=0.1085]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 1275/1835 [29:42<13:05,  1.40s/it, training loss=0.3389]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1276/1835 [29:42<13:04,  1.40s/it, training loss=0.3389]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1276/1835 [29:44<13:04,  1.40s/it, training loss=0.3538]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1277/1835 [29:44<13:02,  1.40s/it, training loss=0.3538]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1277/1835 [29:45<13:02,  1.40s/it, training loss=0.1170]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1278/1835 [29:45<12:59,  1.40s/it, training loss=0.1170]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1278/1835 [29:47<12:59,  1.40s/it, training loss=0.2591]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1279/1835 [29:47<12:58,  1.40s/it, training loss=0.2591]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1279/1835 [29:48<12:58,  1.40s/it, training loss=0.1572]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1280/1835 [29:48<12:56,  1.40s/it, training loss=0.1572]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1280/1835 [29:49<12:56,  1.40s/it, training loss=0.1860]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1281/1835 [29:49<12:55,  1.40s/it, training loss=0.1860]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1281/1835 [29:51<12:55,  1.40s/it, training loss=0.1941]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1282/1835 [29:51<12:54,  1.40s/it, training loss=0.1941]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1282/1835 [29:52<12:54,  1.40s/it, training loss=0.4009]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1283/1835 [29:52<12:56,  1.41s/it, training loss=0.4009]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1283/1835 [29:54<12:56,  1.41s/it, training loss=0.1415]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1284/1835 [29:54<12:54,  1.41s/it, training loss=0.1415]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1284/1835 [29:55<12:54,  1.41s/it, training loss=0.2176]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1285/1835 [29:55<12:52,  1.40s/it, training loss=0.2176]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1285/1835 [29:56<12:52,  1.40s/it, training loss=0.2978]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1286/1835 [29:56<12:49,  1.40s/it, training loss=0.2978]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1286/1835 [29:58<12:49,  1.40s/it, training loss=0.1272]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1287/1835 [29:58<12:46,  1.40s/it, training loss=0.1272]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1287/1835 [29:59<12:46,  1.40s/it, training loss=0.1405]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1288/1835 [29:59<12:43,  1.40s/it, training loss=0.1405]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1288/1835 [30:01<12:43,  1.40s/it, training loss=0.1674]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1289/1835 [30:01<12:43,  1.40s/it, training loss=0.1674]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1289/1835 [30:02<12:43,  1.40s/it, training loss=0.2573]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1290/1835 [30:02<12:40,  1.40s/it, training loss=0.2573]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1290/1835 [30:03<12:40,  1.40s/it, training loss=0.1802]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1291/1835 [30:03<12:39,  1.40s/it, training loss=0.1802]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1291/1835 [30:05<12:39,  1.40s/it, training loss=0.2352]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1292/1835 [30:05<12:38,  1.40s/it, training loss=0.2352]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1292/1835 [30:06<12:38,  1.40s/it, training loss=0.1539]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1293/1835 [30:06<12:36,  1.40s/it, training loss=0.1539]\u001b[A\n",
            "Epoch 1:  70%|███████   | 1293/1835 [30:08<12:36,  1.40s/it, training loss=0.1585]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1294/1835 [30:08<12:35,  1.40s/it, training loss=0.1585]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1294/1835 [30:09<12:35,  1.40s/it, training loss=0.1362]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1295/1835 [30:09<12:31,  1.39s/it, training loss=0.1362]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1295/1835 [30:10<12:31,  1.39s/it, training loss=0.1482]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1296/1835 [30:10<12:31,  1.39s/it, training loss=0.1482]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1296/1835 [30:12<12:31,  1.39s/it, training loss=0.1155]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1297/1835 [30:12<12:29,  1.39s/it, training loss=0.1155]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1297/1835 [30:13<12:29,  1.39s/it, training loss=0.2278]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1298/1835 [30:13<12:27,  1.39s/it, training loss=0.2278]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1298/1835 [30:14<12:27,  1.39s/it, training loss=0.2020]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1299/1835 [30:14<12:27,  1.39s/it, training loss=0.2020]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1299/1835 [30:16<12:27,  1.39s/it, training loss=0.1540]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1300/1835 [30:16<12:27,  1.40s/it, training loss=0.1540]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1300/1835 [30:17<12:27,  1.40s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1301/1835 [30:17<12:25,  1.40s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1301/1835 [30:19<12:25,  1.40s/it, training loss=0.1130]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1302/1835 [30:19<12:24,  1.40s/it, training loss=0.1130]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1302/1835 [30:20<12:24,  1.40s/it, training loss=0.2030]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1303/1835 [30:20<12:22,  1.40s/it, training loss=0.2030]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1303/1835 [30:21<12:22,  1.40s/it, training loss=0.1980]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1304/1835 [30:21<12:22,  1.40s/it, training loss=0.1980]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1304/1835 [30:23<12:22,  1.40s/it, training loss=0.0446]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1305/1835 [30:23<12:21,  1.40s/it, training loss=0.0446]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1305/1835 [30:24<12:21,  1.40s/it, training loss=0.1781]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1306/1835 [30:24<12:19,  1.40s/it, training loss=0.1781]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1306/1835 [30:26<12:19,  1.40s/it, training loss=0.2026]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1307/1835 [30:26<12:17,  1.40s/it, training loss=0.2026]\u001b[A\n",
            "Epoch 1:  71%|███████   | 1307/1835 [30:27<12:17,  1.40s/it, training loss=0.1478]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 1308/1835 [30:27<12:15,  1.40s/it, training loss=0.1478]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 1308/1835 [30:28<12:15,  1.40s/it, training loss=0.2147]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 1309/1835 [30:28<12:15,  1.40s/it, training loss=0.2147]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 1309/1835 [30:30<12:15,  1.40s/it, training loss=0.1703]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 1310/1835 [30:30<12:14,  1.40s/it, training loss=0.1703]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 1310/1835 [30:31<12:14,  1.40s/it, training loss=0.1067]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 1311/1835 [30:31<12:13,  1.40s/it, training loss=0.1067]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 1311/1835 [30:33<12:13,  1.40s/it, training loss=0.0467]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 1312/1835 [30:33<12:11,  1.40s/it, training loss=0.0467]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 1312/1835 [30:34<12:11,  1.40s/it, training loss=0.1838]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1313/1835 [30:34<12:08,  1.40s/it, training loss=0.1838]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1313/1835 [30:35<12:08,  1.40s/it, training loss=0.3398]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1314/1835 [30:35<12:07,  1.40s/it, training loss=0.3398]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1314/1835 [30:37<12:07,  1.40s/it, training loss=0.0603]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1315/1835 [30:37<12:06,  1.40s/it, training loss=0.0603]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1315/1835 [30:38<12:06,  1.40s/it, training loss=0.2844]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1316/1835 [30:38<12:04,  1.40s/it, training loss=0.2844]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1316/1835 [30:40<12:04,  1.40s/it, training loss=0.2459]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1317/1835 [30:40<12:02,  1.39s/it, training loss=0.2459]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1317/1835 [30:41<12:02,  1.39s/it, training loss=0.1330]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1318/1835 [30:41<12:01,  1.40s/it, training loss=0.1330]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1318/1835 [30:42<12:01,  1.40s/it, training loss=0.1441]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1319/1835 [30:42<11:59,  1.39s/it, training loss=0.1441]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1319/1835 [30:44<11:59,  1.39s/it, training loss=0.2221]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1320/1835 [30:44<11:58,  1.40s/it, training loss=0.2221]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1320/1835 [30:45<11:58,  1.40s/it, training loss=0.1740]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1321/1835 [30:45<11:57,  1.40s/it, training loss=0.1740]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1321/1835 [30:47<11:57,  1.40s/it, training loss=0.1326]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1322/1835 [30:47<11:55,  1.39s/it, training loss=0.1326]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1322/1835 [30:48<11:55,  1.39s/it, training loss=0.2027]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1323/1835 [30:48<11:53,  1.39s/it, training loss=0.2027]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1323/1835 [30:49<11:53,  1.39s/it, training loss=0.3554]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1324/1835 [30:49<11:51,  1.39s/it, training loss=0.3554]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1324/1835 [30:51<11:51,  1.39s/it, training loss=0.0621]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1325/1835 [30:51<11:50,  1.39s/it, training loss=0.0621]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1325/1835 [30:52<11:50,  1.39s/it, training loss=0.2604]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1326/1835 [30:52<11:49,  1.39s/it, training loss=0.2604]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1326/1835 [30:54<11:49,  1.39s/it, training loss=0.2939]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1327/1835 [30:54<11:47,  1.39s/it, training loss=0.2939]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1327/1835 [30:55<11:47,  1.39s/it, training loss=0.1528]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1328/1835 [30:55<11:47,  1.39s/it, training loss=0.1528]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1328/1835 [30:56<11:47,  1.39s/it, training loss=0.0697]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1329/1835 [30:56<11:45,  1.39s/it, training loss=0.0697]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1329/1835 [30:58<11:45,  1.39s/it, training loss=0.2380]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1330/1835 [30:58<11:43,  1.39s/it, training loss=0.2380]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 1330/1835 [30:59<11:43,  1.39s/it, training loss=0.1074]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1331/1835 [30:59<11:41,  1.39s/it, training loss=0.1074]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1331/1835 [31:01<11:41,  1.39s/it, training loss=0.2673]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1332/1835 [31:01<11:41,  1.39s/it, training loss=0.2673]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1332/1835 [31:02<11:41,  1.39s/it, training loss=0.2433]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1333/1835 [31:02<11:40,  1.39s/it, training loss=0.2433]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1333/1835 [31:03<11:40,  1.39s/it, training loss=0.2681]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1334/1835 [31:03<11:39,  1.40s/it, training loss=0.2681]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1334/1835 [31:05<11:39,  1.40s/it, training loss=0.2648]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1335/1835 [31:05<11:38,  1.40s/it, training loss=0.2648]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1335/1835 [31:06<11:38,  1.40s/it, training loss=0.2250]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1336/1835 [31:06<11:38,  1.40s/it, training loss=0.2250]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1336/1835 [31:08<11:38,  1.40s/it, training loss=0.2098]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1337/1835 [31:08<11:35,  1.40s/it, training loss=0.2098]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1337/1835 [31:09<11:35,  1.40s/it, training loss=0.2028]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1338/1835 [31:09<11:34,  1.40s/it, training loss=0.2028]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1338/1835 [31:10<11:34,  1.40s/it, training loss=0.1131]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1339/1835 [31:10<11:33,  1.40s/it, training loss=0.1131]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1339/1835 [31:12<11:33,  1.40s/it, training loss=0.1475]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1340/1835 [31:12<11:31,  1.40s/it, training loss=0.1475]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1340/1835 [31:13<11:31,  1.40s/it, training loss=0.1361]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1341/1835 [31:13<11:30,  1.40s/it, training loss=0.1361]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1341/1835 [31:15<11:30,  1.40s/it, training loss=0.1495]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1342/1835 [31:15<11:29,  1.40s/it, training loss=0.1495]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1342/1835 [31:16<11:29,  1.40s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1343/1835 [31:16<11:27,  1.40s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1343/1835 [31:17<11:27,  1.40s/it, training loss=0.1042]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1344/1835 [31:17<11:25,  1.40s/it, training loss=0.1042]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1344/1835 [31:19<11:25,  1.40s/it, training loss=0.1748]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1345/1835 [31:19<11:24,  1.40s/it, training loss=0.1748]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1345/1835 [31:20<11:24,  1.40s/it, training loss=0.0818]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1346/1835 [31:20<11:22,  1.40s/it, training loss=0.0818]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1346/1835 [31:22<11:22,  1.40s/it, training loss=0.2324]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1347/1835 [31:22<11:22,  1.40s/it, training loss=0.2324]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1347/1835 [31:23<11:22,  1.40s/it, training loss=0.2877]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1348/1835 [31:23<11:20,  1.40s/it, training loss=0.2877]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 1348/1835 [31:24<11:20,  1.40s/it, training loss=0.0605]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 1349/1835 [31:24<11:19,  1.40s/it, training loss=0.0605]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 1349/1835 [31:26<11:19,  1.40s/it, training loss=0.1574]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 1350/1835 [31:26<11:18,  1.40s/it, training loss=0.1574]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 1350/1835 [31:27<11:18,  1.40s/it, training loss=0.2108]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 1351/1835 [31:27<11:16,  1.40s/it, training loss=0.2108]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 1351/1835 [31:28<11:16,  1.40s/it, training loss=0.2863]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 1352/1835 [31:29<11:15,  1.40s/it, training loss=0.2863]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 1352/1835 [31:30<11:15,  1.40s/it, training loss=0.1985]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 1353/1835 [31:30<11:14,  1.40s/it, training loss=0.1985]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 1353/1835 [31:31<11:14,  1.40s/it, training loss=0.1582]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1354/1835 [31:31<11:12,  1.40s/it, training loss=0.1582]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1354/1835 [31:33<11:12,  1.40s/it, training loss=0.1755]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1355/1835 [31:33<11:10,  1.40s/it, training loss=0.1755]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1355/1835 [31:34<11:10,  1.40s/it, training loss=0.1493]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1356/1835 [31:34<11:08,  1.40s/it, training loss=0.1493]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1356/1835 [31:35<11:08,  1.40s/it, training loss=0.2438]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1357/1835 [31:35<11:08,  1.40s/it, training loss=0.2438]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1357/1835 [31:37<11:08,  1.40s/it, training loss=0.1478]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1358/1835 [31:37<11:07,  1.40s/it, training loss=0.1478]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1358/1835 [31:38<11:07,  1.40s/it, training loss=0.2155]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1359/1835 [31:38<11:05,  1.40s/it, training loss=0.2155]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1359/1835 [31:40<11:05,  1.40s/it, training loss=0.1077]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1360/1835 [31:40<11:03,  1.40s/it, training loss=0.1077]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1360/1835 [31:41<11:03,  1.40s/it, training loss=0.2102]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1361/1835 [31:41<11:01,  1.40s/it, training loss=0.2102]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1361/1835 [31:42<11:01,  1.40s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1362/1835 [31:42<11:00,  1.40s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1362/1835 [31:44<11:00,  1.40s/it, training loss=0.2694]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1363/1835 [31:44<10:59,  1.40s/it, training loss=0.2694]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1363/1835 [31:45<10:59,  1.40s/it, training loss=0.2332]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1364/1835 [31:45<10:58,  1.40s/it, training loss=0.2332]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1364/1835 [31:47<10:58,  1.40s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1365/1835 [31:47<10:56,  1.40s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1365/1835 [31:48<10:56,  1.40s/it, training loss=0.2481]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1366/1835 [31:48<10:54,  1.40s/it, training loss=0.2481]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1366/1835 [31:49<10:54,  1.40s/it, training loss=0.1820]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1367/1835 [31:49<10:53,  1.40s/it, training loss=0.1820]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 1367/1835 [31:51<10:53,  1.40s/it, training loss=0.2264]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1368/1835 [31:51<10:52,  1.40s/it, training loss=0.2264]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1368/1835 [31:52<10:52,  1.40s/it, training loss=0.1845]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1369/1835 [31:52<10:51,  1.40s/it, training loss=0.1845]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1369/1835 [31:54<10:51,  1.40s/it, training loss=0.1861]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1370/1835 [31:54<10:49,  1.40s/it, training loss=0.1861]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1370/1835 [31:55<10:49,  1.40s/it, training loss=0.1260]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1371/1835 [31:55<10:46,  1.39s/it, training loss=0.1260]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1371/1835 [31:56<10:46,  1.39s/it, training loss=0.3039]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1372/1835 [31:56<10:46,  1.40s/it, training loss=0.3039]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1372/1835 [31:58<10:46,  1.40s/it, training loss=0.1769]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1373/1835 [31:58<10:45,  1.40s/it, training loss=0.1769]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1373/1835 [31:59<10:45,  1.40s/it, training loss=0.2025]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1374/1835 [31:59<10:44,  1.40s/it, training loss=0.2025]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1374/1835 [32:01<10:44,  1.40s/it, training loss=0.1991]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1375/1835 [32:01<10:42,  1.40s/it, training loss=0.1991]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1375/1835 [32:02<10:42,  1.40s/it, training loss=0.2121]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1376/1835 [32:02<10:41,  1.40s/it, training loss=0.2121]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 1376/1835 [32:03<10:41,  1.40s/it, training loss=0.2694]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1377/1835 [32:03<10:40,  1.40s/it, training loss=0.2694]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1377/1835 [32:05<10:40,  1.40s/it, training loss=0.1548]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1378/1835 [32:05<10:38,  1.40s/it, training loss=0.1548]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1378/1835 [32:06<10:38,  1.40s/it, training loss=0.1734]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1379/1835 [32:06<10:37,  1.40s/it, training loss=0.1734]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1379/1835 [32:08<10:37,  1.40s/it, training loss=0.1208]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1380/1835 [32:08<10:35,  1.40s/it, training loss=0.1208]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1380/1835 [32:09<10:35,  1.40s/it, training loss=0.1840]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1381/1835 [32:09<10:34,  1.40s/it, training loss=0.1840]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1381/1835 [32:10<10:34,  1.40s/it, training loss=0.2343]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1382/1835 [32:10<10:33,  1.40s/it, training loss=0.2343]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1382/1835 [32:12<10:33,  1.40s/it, training loss=0.1355]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1383/1835 [32:12<10:31,  1.40s/it, training loss=0.1355]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1383/1835 [32:13<10:31,  1.40s/it, training loss=0.3218]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1384/1835 [32:13<10:29,  1.40s/it, training loss=0.3218]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1384/1835 [32:15<10:29,  1.40s/it, training loss=0.2933]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1385/1835 [32:15<10:28,  1.40s/it, training loss=0.2933]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 1385/1835 [32:16<10:28,  1.40s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1386/1835 [32:16<10:27,  1.40s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1386/1835 [32:17<10:27,  1.40s/it, training loss=0.1184]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1387/1835 [32:17<10:26,  1.40s/it, training loss=0.1184]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1387/1835 [32:19<10:26,  1.40s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1388/1835 [32:19<10:25,  1.40s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1388/1835 [32:20<10:25,  1.40s/it, training loss=0.1893]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1389/1835 [32:20<10:23,  1.40s/it, training loss=0.1893]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1389/1835 [32:22<10:23,  1.40s/it, training loss=0.1700]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1390/1835 [32:22<10:20,  1.40s/it, training loss=0.1700]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1390/1835 [32:23<10:20,  1.40s/it, training loss=0.2491]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1391/1835 [32:23<10:18,  1.39s/it, training loss=0.2491]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1391/1835 [32:24<10:18,  1.39s/it, training loss=0.2264]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1392/1835 [32:24<10:17,  1.39s/it, training loss=0.2264]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1392/1835 [32:26<10:17,  1.39s/it, training loss=0.2710]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1393/1835 [32:26<10:17,  1.40s/it, training loss=0.2710]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1393/1835 [32:27<10:17,  1.40s/it, training loss=0.1297]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1394/1835 [32:27<10:15,  1.40s/it, training loss=0.1297]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1394/1835 [32:29<10:15,  1.40s/it, training loss=0.2896]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1395/1835 [32:29<10:12,  1.39s/it, training loss=0.2896]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1395/1835 [32:30<10:12,  1.39s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1396/1835 [32:30<10:10,  1.39s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1396/1835 [32:31<10:10,  1.39s/it, training loss=0.1836]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1397/1835 [32:31<10:10,  1.39s/it, training loss=0.1836]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1397/1835 [32:33<10:10,  1.39s/it, training loss=0.2401]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1398/1835 [32:33<10:10,  1.40s/it, training loss=0.2401]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1398/1835 [32:34<10:10,  1.40s/it, training loss=0.1756]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1399/1835 [32:34<10:09,  1.40s/it, training loss=0.1756]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 1399/1835 [32:36<10:09,  1.40s/it, training loss=0.2264]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 1400/1835 [32:36<10:08,  1.40s/it, training loss=0.2264]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 1400/1835 [32:37<10:08,  1.40s/it, training loss=0.1166]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 1401/1835 [32:37<10:06,  1.40s/it, training loss=0.1166]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 1401/1835 [32:38<10:06,  1.40s/it, training loss=0.1775]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 1402/1835 [32:38<10:03,  1.39s/it, training loss=0.1775]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 1402/1835 [32:40<10:03,  1.39s/it, training loss=0.2371]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 1403/1835 [32:40<10:02,  1.39s/it, training loss=0.2371]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 1403/1835 [32:41<10:02,  1.39s/it, training loss=0.1122]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1404/1835 [32:41<10:00,  1.39s/it, training loss=0.1122]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1404/1835 [32:43<10:00,  1.39s/it, training loss=0.2010]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1405/1835 [32:43<09:59,  1.39s/it, training loss=0.2010]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1405/1835 [32:44<09:59,  1.39s/it, training loss=0.1302]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1406/1835 [32:44<09:58,  1.40s/it, training loss=0.1302]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1406/1835 [32:45<09:58,  1.40s/it, training loss=0.0854]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1407/1835 [32:45<09:57,  1.40s/it, training loss=0.0854]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1407/1835 [32:47<09:57,  1.40s/it, training loss=0.2152]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1408/1835 [32:47<09:56,  1.40s/it, training loss=0.2152]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1408/1835 [32:48<09:56,  1.40s/it, training loss=0.1427]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1409/1835 [32:48<09:55,  1.40s/it, training loss=0.1427]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1409/1835 [32:50<09:55,  1.40s/it, training loss=0.1756]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1410/1835 [32:50<09:53,  1.40s/it, training loss=0.1756]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1410/1835 [32:51<09:53,  1.40s/it, training loss=0.3157]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1411/1835 [32:51<09:52,  1.40s/it, training loss=0.3157]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1411/1835 [32:52<09:52,  1.40s/it, training loss=0.1756]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1412/1835 [32:52<09:50,  1.40s/it, training loss=0.1756]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1412/1835 [32:54<09:50,  1.40s/it, training loss=0.1080]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1413/1835 [32:54<09:49,  1.40s/it, training loss=0.1080]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1413/1835 [32:55<09:49,  1.40s/it, training loss=0.0864]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1414/1835 [32:55<09:47,  1.39s/it, training loss=0.0864]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1414/1835 [32:56<09:47,  1.39s/it, training loss=0.1876]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1415/1835 [32:56<09:45,  1.39s/it, training loss=0.1876]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1415/1835 [32:58<09:45,  1.39s/it, training loss=0.0941]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1416/1835 [32:58<09:44,  1.40s/it, training loss=0.0941]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1416/1835 [32:59<09:44,  1.40s/it, training loss=0.0811]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1417/1835 [32:59<09:42,  1.39s/it, training loss=0.0811]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1417/1835 [33:01<09:42,  1.39s/it, training loss=0.2167]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1418/1835 [33:01<09:42,  1.40s/it, training loss=0.2167]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1418/1835 [33:02<09:42,  1.40s/it, training loss=0.2332]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1419/1835 [33:02<09:41,  1.40s/it, training loss=0.2332]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1419/1835 [33:03<09:41,  1.40s/it, training loss=0.0904]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1420/1835 [33:03<09:39,  1.40s/it, training loss=0.0904]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1420/1835 [33:05<09:39,  1.40s/it, training loss=0.3482]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1421/1835 [33:05<09:38,  1.40s/it, training loss=0.3482]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1421/1835 [33:06<09:38,  1.40s/it, training loss=0.2433]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1422/1835 [33:06<09:36,  1.40s/it, training loss=0.2433]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 1422/1835 [33:08<09:36,  1.40s/it, training loss=0.1819]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1423/1835 [33:08<09:35,  1.40s/it, training loss=0.1819]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1423/1835 [33:09<09:35,  1.40s/it, training loss=0.0848]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1424/1835 [33:09<09:33,  1.40s/it, training loss=0.0848]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1424/1835 [33:10<09:33,  1.40s/it, training loss=0.2031]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1425/1835 [33:10<09:31,  1.39s/it, training loss=0.2031]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1425/1835 [33:12<09:31,  1.39s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1426/1835 [33:12<09:31,  1.40s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1426/1835 [33:13<09:31,  1.40s/it, training loss=0.1222]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1427/1835 [33:13<09:30,  1.40s/it, training loss=0.1222]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1427/1835 [33:15<09:30,  1.40s/it, training loss=0.1239]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1428/1835 [33:15<09:28,  1.40s/it, training loss=0.1239]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1428/1835 [33:16<09:28,  1.40s/it, training loss=0.0994]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1429/1835 [33:16<09:26,  1.40s/it, training loss=0.0994]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1429/1835 [33:17<09:26,  1.40s/it, training loss=0.2049]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1430/1835 [33:17<09:24,  1.39s/it, training loss=0.2049]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1430/1835 [33:19<09:24,  1.39s/it, training loss=0.2345]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1431/1835 [33:19<09:22,  1.39s/it, training loss=0.2345]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1431/1835 [33:20<09:22,  1.39s/it, training loss=0.0254]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1432/1835 [33:20<09:21,  1.39s/it, training loss=0.0254]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1432/1835 [33:22<09:21,  1.39s/it, training loss=0.1053]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1433/1835 [33:22<09:21,  1.40s/it, training loss=0.1053]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1433/1835 [33:23<09:21,  1.40s/it, training loss=0.2031]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1434/1835 [33:23<09:19,  1.40s/it, training loss=0.2031]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1434/1835 [33:24<09:19,  1.40s/it, training loss=0.2022]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1435/1835 [33:24<09:18,  1.40s/it, training loss=0.2022]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1435/1835 [33:26<09:18,  1.40s/it, training loss=0.1246]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1436/1835 [33:26<09:16,  1.40s/it, training loss=0.1246]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1436/1835 [33:27<09:16,  1.40s/it, training loss=0.1648]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1437/1835 [33:27<09:15,  1.40s/it, training loss=0.1648]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1437/1835 [33:29<09:15,  1.40s/it, training loss=0.1336]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1438/1835 [33:29<09:13,  1.40s/it, training loss=0.1336]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1438/1835 [33:30<09:13,  1.40s/it, training loss=0.1650]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1439/1835 [33:30<09:13,  1.40s/it, training loss=0.1650]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1439/1835 [33:31<09:13,  1.40s/it, training loss=0.1747]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1440/1835 [33:31<09:11,  1.40s/it, training loss=0.1747]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 1440/1835 [33:33<09:11,  1.40s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 1441/1835 [33:33<09:10,  1.40s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 1441/1835 [33:34<09:10,  1.40s/it, training loss=0.2116]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 1442/1835 [33:34<09:08,  1.40s/it, training loss=0.2116]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 1442/1835 [33:36<09:08,  1.40s/it, training loss=0.1145]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 1443/1835 [33:36<09:06,  1.39s/it, training loss=0.1145]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 1443/1835 [33:37<09:06,  1.39s/it, training loss=0.1220]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 1444/1835 [33:37<09:05,  1.39s/it, training loss=0.1220]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 1444/1835 [33:38<09:05,  1.39s/it, training loss=0.1477]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 1445/1835 [33:38<09:04,  1.40s/it, training loss=0.1477]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 1445/1835 [33:40<09:04,  1.40s/it, training loss=0.2287]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1446/1835 [33:40<09:02,  1.40s/it, training loss=0.2287]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1446/1835 [33:41<09:02,  1.40s/it, training loss=0.1611]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1447/1835 [33:41<09:01,  1.40s/it, training loss=0.1611]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1447/1835 [33:43<09:01,  1.40s/it, training loss=0.0980]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1448/1835 [33:43<08:59,  1.39s/it, training loss=0.0980]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1448/1835 [33:44<08:59,  1.39s/it, training loss=0.2239]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1449/1835 [33:44<08:57,  1.39s/it, training loss=0.2239]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1449/1835 [33:45<08:57,  1.39s/it, training loss=0.2153]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1450/1835 [33:45<08:56,  1.39s/it, training loss=0.2153]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1450/1835 [33:47<08:56,  1.39s/it, training loss=0.1666]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1451/1835 [33:47<08:55,  1.40s/it, training loss=0.1666]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1451/1835 [33:48<08:55,  1.40s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1452/1835 [33:48<08:53,  1.39s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1452/1835 [33:49<08:53,  1.39s/it, training loss=0.0976]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1453/1835 [33:50<08:52,  1.39s/it, training loss=0.0976]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1453/1835 [33:51<08:52,  1.39s/it, training loss=0.2012]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1454/1835 [33:51<08:51,  1.39s/it, training loss=0.2012]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1454/1835 [33:52<08:51,  1.39s/it, training loss=0.2622]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1455/1835 [33:52<08:49,  1.39s/it, training loss=0.2622]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1455/1835 [33:54<08:49,  1.39s/it, training loss=0.2368]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1456/1835 [33:54<08:47,  1.39s/it, training loss=0.2368]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1456/1835 [33:55<08:47,  1.39s/it, training loss=0.3761]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1457/1835 [33:55<08:46,  1.39s/it, training loss=0.3761]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1457/1835 [33:56<08:46,  1.39s/it, training loss=0.1516]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1458/1835 [33:56<08:46,  1.40s/it, training loss=0.1516]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 1458/1835 [33:58<08:46,  1.40s/it, training loss=0.2045]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1459/1835 [33:58<08:44,  1.40s/it, training loss=0.2045]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1459/1835 [33:59<08:44,  1.40s/it, training loss=0.2432]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1460/1835 [33:59<08:44,  1.40s/it, training loss=0.2432]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1460/1835 [34:01<08:44,  1.40s/it, training loss=0.1066]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1461/1835 [34:01<08:42,  1.40s/it, training loss=0.1066]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1461/1835 [34:02<08:42,  1.40s/it, training loss=0.2178]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1462/1835 [34:02<08:40,  1.40s/it, training loss=0.2178]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1462/1835 [34:03<08:40,  1.40s/it, training loss=0.1853]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1463/1835 [34:03<08:38,  1.39s/it, training loss=0.1853]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1463/1835 [34:05<08:38,  1.39s/it, training loss=0.2685]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1464/1835 [34:05<08:37,  1.39s/it, training loss=0.2685]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1464/1835 [34:06<08:37,  1.39s/it, training loss=0.2575]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1465/1835 [34:06<08:35,  1.39s/it, training loss=0.2575]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1465/1835 [34:08<08:35,  1.39s/it, training loss=0.1917]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1466/1835 [34:08<08:34,  1.39s/it, training loss=0.1917]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1466/1835 [34:09<08:34,  1.39s/it, training loss=0.2586]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1467/1835 [34:09<08:32,  1.39s/it, training loss=0.2586]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1467/1835 [34:10<08:32,  1.39s/it, training loss=0.1884]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1468/1835 [34:10<08:31,  1.39s/it, training loss=0.1884]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1468/1835 [34:12<08:31,  1.39s/it, training loss=0.2912]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1469/1835 [34:12<08:29,  1.39s/it, training loss=0.2912]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1469/1835 [34:13<08:29,  1.39s/it, training loss=0.2024]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1470/1835 [34:13<08:28,  1.39s/it, training loss=0.2024]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1470/1835 [34:15<08:28,  1.39s/it, training loss=0.1504]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1471/1835 [34:15<08:26,  1.39s/it, training loss=0.1504]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1471/1835 [34:16<08:26,  1.39s/it, training loss=0.1676]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1472/1835 [34:16<08:25,  1.39s/it, training loss=0.1676]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1472/1835 [34:17<08:25,  1.39s/it, training loss=0.2861]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1473/1835 [34:17<08:23,  1.39s/it, training loss=0.2861]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1473/1835 [34:19<08:23,  1.39s/it, training loss=0.2918]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1474/1835 [34:19<08:22,  1.39s/it, training loss=0.2918]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1474/1835 [34:20<08:22,  1.39s/it, training loss=0.1916]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1475/1835 [34:20<08:20,  1.39s/it, training loss=0.1916]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1475/1835 [34:22<08:20,  1.39s/it, training loss=0.1517]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1476/1835 [34:22<08:19,  1.39s/it, training loss=0.1517]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1476/1835 [34:23<08:19,  1.39s/it, training loss=0.1932]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1477/1835 [34:23<08:18,  1.39s/it, training loss=0.1932]\u001b[A\n",
            "Epoch 1:  80%|████████  | 1477/1835 [34:24<08:18,  1.39s/it, training loss=0.2308]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1478/1835 [34:24<08:16,  1.39s/it, training loss=0.2308]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1478/1835 [34:26<08:16,  1.39s/it, training loss=0.1371]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1479/1835 [34:26<08:15,  1.39s/it, training loss=0.1371]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1479/1835 [34:27<08:15,  1.39s/it, training loss=0.2214]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1480/1835 [34:27<08:15,  1.39s/it, training loss=0.2214]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1480/1835 [34:29<08:15,  1.39s/it, training loss=0.1426]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1481/1835 [34:29<08:14,  1.40s/it, training loss=0.1426]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1481/1835 [34:30<08:14,  1.40s/it, training loss=0.2250]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1482/1835 [34:30<08:13,  1.40s/it, training loss=0.2250]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1482/1835 [34:31<08:13,  1.40s/it, training loss=0.1600]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1483/1835 [34:31<08:11,  1.40s/it, training loss=0.1600]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1483/1835 [34:33<08:11,  1.40s/it, training loss=0.1589]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1484/1835 [34:33<08:09,  1.39s/it, training loss=0.1589]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1484/1835 [34:34<08:09,  1.39s/it, training loss=0.1395]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1485/1835 [34:34<08:08,  1.39s/it, training loss=0.1395]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1485/1835 [34:35<08:08,  1.39s/it, training loss=0.0845]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1486/1835 [34:36<08:06,  1.40s/it, training loss=0.0845]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1486/1835 [34:37<08:06,  1.40s/it, training loss=0.1424]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1487/1835 [34:37<08:05,  1.39s/it, training loss=0.1424]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1487/1835 [34:38<08:05,  1.39s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1488/1835 [34:38<08:04,  1.39s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1488/1835 [34:40<08:04,  1.39s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1489/1835 [34:40<08:03,  1.40s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1489/1835 [34:41<08:03,  1.40s/it, training loss=0.2686]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1490/1835 [34:41<08:12,  1.43s/it, training loss=0.2686]\u001b[A\n",
            "Epoch 1:  81%|████████  | 1490/1835 [34:43<08:12,  1.43s/it, training loss=0.1526]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 1491/1835 [34:43<08:11,  1.43s/it, training loss=0.1526]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 1491/1835 [34:44<08:11,  1.43s/it, training loss=0.0782]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 1492/1835 [34:44<08:07,  1.42s/it, training loss=0.0782]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 1492/1835 [34:45<08:07,  1.42s/it, training loss=0.1527]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 1493/1835 [34:45<08:03,  1.41s/it, training loss=0.1527]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 1493/1835 [34:47<08:03,  1.41s/it, training loss=0.1413]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 1494/1835 [34:47<07:59,  1.41s/it, training loss=0.1413]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 1494/1835 [34:48<07:59,  1.41s/it, training loss=0.2098]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 1495/1835 [34:48<07:56,  1.40s/it, training loss=0.2098]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 1495/1835 [34:50<07:56,  1.40s/it, training loss=0.2532]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1496/1835 [34:50<07:54,  1.40s/it, training loss=0.2532]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1496/1835 [34:51<07:54,  1.40s/it, training loss=0.2320]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1497/1835 [34:51<07:53,  1.40s/it, training loss=0.2320]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1497/1835 [34:52<07:53,  1.40s/it, training loss=0.3057]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1498/1835 [34:52<07:51,  1.40s/it, training loss=0.3057]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1498/1835 [34:54<07:51,  1.40s/it, training loss=0.2308]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1499/1835 [34:54<07:50,  1.40s/it, training loss=0.2308]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1499/1835 [34:55<07:50,  1.40s/it, training loss=0.2523]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1500/1835 [34:55<07:48,  1.40s/it, training loss=0.2523]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1500/1835 [34:57<07:48,  1.40s/it, training loss=0.1341]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1501/1835 [34:57<07:47,  1.40s/it, training loss=0.1341]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1501/1835 [34:58<07:47,  1.40s/it, training loss=0.1644]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1502/1835 [34:58<07:46,  1.40s/it, training loss=0.1644]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1502/1835 [34:59<07:46,  1.40s/it, training loss=0.1134]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1503/1835 [34:59<07:44,  1.40s/it, training loss=0.1134]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1503/1835 [35:01<07:44,  1.40s/it, training loss=0.2385]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1504/1835 [35:01<07:42,  1.40s/it, training loss=0.2385]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1504/1835 [35:02<07:42,  1.40s/it, training loss=0.0696]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1505/1835 [35:02<07:42,  1.40s/it, training loss=0.0696]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1505/1835 [35:04<07:42,  1.40s/it, training loss=0.2539]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1506/1835 [35:04<07:41,  1.40s/it, training loss=0.2539]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1506/1835 [35:05<07:41,  1.40s/it, training loss=0.2709]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1507/1835 [35:05<07:39,  1.40s/it, training loss=0.2709]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1507/1835 [35:06<07:39,  1.40s/it, training loss=0.3292]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1508/1835 [35:06<07:38,  1.40s/it, training loss=0.3292]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1508/1835 [35:08<07:38,  1.40s/it, training loss=0.2968]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1509/1835 [35:08<07:38,  1.41s/it, training loss=0.2968]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1509/1835 [35:09<07:38,  1.41s/it, training loss=0.2249]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1510/1835 [35:09<07:36,  1.40s/it, training loss=0.2249]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1510/1835 [35:11<07:36,  1.40s/it, training loss=0.1254]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1511/1835 [35:11<07:34,  1.40s/it, training loss=0.1254]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1511/1835 [35:12<07:34,  1.40s/it, training loss=0.1106]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1512/1835 [35:12<07:32,  1.40s/it, training loss=0.1106]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1512/1835 [35:13<07:32,  1.40s/it, training loss=0.1806]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1513/1835 [35:13<07:30,  1.40s/it, training loss=0.1806]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 1513/1835 [35:15<07:30,  1.40s/it, training loss=0.2344]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1514/1835 [35:15<07:29,  1.40s/it, training loss=0.2344]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1514/1835 [35:16<07:29,  1.40s/it, training loss=0.3255]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1515/1835 [35:16<07:27,  1.40s/it, training loss=0.3255]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1515/1835 [35:18<07:27,  1.40s/it, training loss=0.2598]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1516/1835 [35:18<07:26,  1.40s/it, training loss=0.2598]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1516/1835 [35:19<07:26,  1.40s/it, training loss=0.0822]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1517/1835 [35:19<07:24,  1.40s/it, training loss=0.0822]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1517/1835 [35:20<07:24,  1.40s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1518/1835 [35:20<07:23,  1.40s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1518/1835 [35:22<07:23,  1.40s/it, training loss=0.1062]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1519/1835 [35:22<07:22,  1.40s/it, training loss=0.1062]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1519/1835 [35:23<07:22,  1.40s/it, training loss=0.2222]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1520/1835 [35:23<07:20,  1.40s/it, training loss=0.2222]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1520/1835 [35:25<07:20,  1.40s/it, training loss=0.0686]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1521/1835 [35:25<07:18,  1.40s/it, training loss=0.0686]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1521/1835 [35:26<07:18,  1.40s/it, training loss=0.1247]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1522/1835 [35:26<07:17,  1.40s/it, training loss=0.1247]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1522/1835 [35:27<07:17,  1.40s/it, training loss=0.1631]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1523/1835 [35:27<07:16,  1.40s/it, training loss=0.1631]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1523/1835 [35:29<07:16,  1.40s/it, training loss=0.2867]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1524/1835 [35:29<07:14,  1.40s/it, training loss=0.2867]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1524/1835 [35:30<07:14,  1.40s/it, training loss=0.3043]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1525/1835 [35:30<07:13,  1.40s/it, training loss=0.3043]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1525/1835 [35:32<07:13,  1.40s/it, training loss=0.2531]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1526/1835 [35:32<07:11,  1.40s/it, training loss=0.2531]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1526/1835 [35:33<07:11,  1.40s/it, training loss=0.2059]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1527/1835 [35:33<07:10,  1.40s/it, training loss=0.2059]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1527/1835 [35:34<07:10,  1.40s/it, training loss=0.3413]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1528/1835 [35:34<07:08,  1.40s/it, training loss=0.3413]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1528/1835 [35:36<07:08,  1.40s/it, training loss=0.2145]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1529/1835 [35:36<07:07,  1.40s/it, training loss=0.2145]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1529/1835 [35:37<07:07,  1.40s/it, training loss=0.1989]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1530/1835 [35:37<07:05,  1.40s/it, training loss=0.1989]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1530/1835 [35:39<07:05,  1.40s/it, training loss=0.1817]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1531/1835 [35:39<07:04,  1.40s/it, training loss=0.1817]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1531/1835 [35:40<07:04,  1.40s/it, training loss=0.0973]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1532/1835 [35:40<07:02,  1.39s/it, training loss=0.0973]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 1532/1835 [35:41<07:02,  1.39s/it, training loss=0.1189]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 1533/1835 [35:41<07:01,  1.39s/it, training loss=0.1189]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 1533/1835 [35:43<07:01,  1.39s/it, training loss=0.1698]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 1534/1835 [35:43<06:59,  1.39s/it, training loss=0.1698]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 1534/1835 [35:44<06:59,  1.39s/it, training loss=0.1355]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 1535/1835 [35:44<06:58,  1.40s/it, training loss=0.1355]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 1535/1835 [35:46<06:58,  1.40s/it, training loss=0.2440]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 1536/1835 [35:46<06:56,  1.39s/it, training loss=0.2440]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 1536/1835 [35:47<06:56,  1.39s/it, training loss=0.2410]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1537/1835 [35:47<06:55,  1.39s/it, training loss=0.2410]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1537/1835 [35:48<06:55,  1.39s/it, training loss=0.1200]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1538/1835 [35:48<06:54,  1.39s/it, training loss=0.1200]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1538/1835 [35:50<06:54,  1.39s/it, training loss=0.1730]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1539/1835 [35:50<06:52,  1.39s/it, training loss=0.1730]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1539/1835 [35:51<06:52,  1.39s/it, training loss=0.1788]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1540/1835 [35:51<06:51,  1.40s/it, training loss=0.1788]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1540/1835 [35:53<06:51,  1.40s/it, training loss=0.1690]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1541/1835 [35:53<06:51,  1.40s/it, training loss=0.1690]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1541/1835 [35:54<06:51,  1.40s/it, training loss=0.1360]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1542/1835 [35:54<06:49,  1.40s/it, training loss=0.1360]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1542/1835 [35:55<06:49,  1.40s/it, training loss=0.1155]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1543/1835 [35:55<06:49,  1.40s/it, training loss=0.1155]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1543/1835 [35:57<06:49,  1.40s/it, training loss=0.2711]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1544/1835 [35:57<06:48,  1.40s/it, training loss=0.2711]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1544/1835 [35:58<06:48,  1.40s/it, training loss=0.2151]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1545/1835 [35:58<06:46,  1.40s/it, training loss=0.2151]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1545/1835 [36:00<06:46,  1.40s/it, training loss=0.2175]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1546/1835 [36:00<06:45,  1.40s/it, training loss=0.2175]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1546/1835 [36:01<06:45,  1.40s/it, training loss=0.1454]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1547/1835 [36:01<06:44,  1.41s/it, training loss=0.1454]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1547/1835 [36:02<06:44,  1.41s/it, training loss=0.2994]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1548/1835 [36:02<06:43,  1.40s/it, training loss=0.2994]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1548/1835 [36:04<06:43,  1.40s/it, training loss=0.1962]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1549/1835 [36:04<06:41,  1.40s/it, training loss=0.1962]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1549/1835 [36:05<06:41,  1.40s/it, training loss=0.1662]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1550/1835 [36:05<06:41,  1.41s/it, training loss=0.1662]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 1550/1835 [36:07<06:41,  1.41s/it, training loss=0.1306]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1551/1835 [36:07<06:41,  1.41s/it, training loss=0.1306]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1551/1835 [36:08<06:41,  1.41s/it, training loss=0.2398]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1552/1835 [36:08<06:39,  1.41s/it, training loss=0.2398]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1552/1835 [36:09<06:39,  1.41s/it, training loss=0.1737]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1553/1835 [36:09<06:39,  1.42s/it, training loss=0.1737]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1553/1835 [36:11<06:39,  1.42s/it, training loss=0.1782]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1554/1835 [36:11<06:37,  1.41s/it, training loss=0.1782]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1554/1835 [36:12<06:37,  1.41s/it, training loss=0.2157]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1555/1835 [36:12<06:34,  1.41s/it, training loss=0.2157]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1555/1835 [36:14<06:34,  1.41s/it, training loss=0.1471]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1556/1835 [36:14<06:33,  1.41s/it, training loss=0.1471]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1556/1835 [36:15<06:33,  1.41s/it, training loss=0.1185]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1557/1835 [36:15<06:32,  1.41s/it, training loss=0.1185]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1557/1835 [36:16<06:32,  1.41s/it, training loss=0.0964]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1558/1835 [36:16<06:30,  1.41s/it, training loss=0.0964]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1558/1835 [36:18<06:30,  1.41s/it, training loss=0.3003]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1559/1835 [36:18<06:27,  1.40s/it, training loss=0.3003]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 1559/1835 [36:19<06:27,  1.40s/it, training loss=0.1091]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1560/1835 [36:19<06:26,  1.40s/it, training loss=0.1091]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1560/1835 [36:21<06:26,  1.40s/it, training loss=0.1629]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1561/1835 [36:21<06:25,  1.41s/it, training loss=0.1629]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1561/1835 [36:22<06:25,  1.41s/it, training loss=0.1741]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1562/1835 [36:22<06:24,  1.41s/it, training loss=0.1741]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1562/1835 [36:23<06:24,  1.41s/it, training loss=0.1478]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1563/1835 [36:23<06:22,  1.41s/it, training loss=0.1478]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1563/1835 [36:25<06:22,  1.41s/it, training loss=0.1851]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1564/1835 [36:25<06:21,  1.41s/it, training loss=0.1851]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1564/1835 [36:26<06:21,  1.41s/it, training loss=0.2299]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1565/1835 [36:26<06:20,  1.41s/it, training loss=0.2299]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1565/1835 [36:28<06:20,  1.41s/it, training loss=0.1576]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1566/1835 [36:28<06:17,  1.40s/it, training loss=0.1576]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1566/1835 [36:29<06:17,  1.40s/it, training loss=0.2194]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1567/1835 [36:29<06:15,  1.40s/it, training loss=0.2194]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1567/1835 [36:31<06:15,  1.40s/it, training loss=0.2044]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1568/1835 [36:31<06:14,  1.40s/it, training loss=0.2044]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 1568/1835 [36:32<06:14,  1.40s/it, training loss=0.1243]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1569/1835 [36:32<06:12,  1.40s/it, training loss=0.1243]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1569/1835 [36:33<06:12,  1.40s/it, training loss=0.1687]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1570/1835 [36:33<06:11,  1.40s/it, training loss=0.1687]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1570/1835 [36:35<06:11,  1.40s/it, training loss=0.1796]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1571/1835 [36:35<06:11,  1.41s/it, training loss=0.1796]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1571/1835 [36:36<06:11,  1.41s/it, training loss=0.1467]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1572/1835 [36:36<06:12,  1.41s/it, training loss=0.1467]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1572/1835 [36:38<06:12,  1.41s/it, training loss=0.2354]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1573/1835 [36:38<06:10,  1.41s/it, training loss=0.2354]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1573/1835 [36:39<06:10,  1.41s/it, training loss=0.3008]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1574/1835 [36:39<06:08,  1.41s/it, training loss=0.3008]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1574/1835 [36:40<06:08,  1.41s/it, training loss=0.2402]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1575/1835 [36:40<06:08,  1.42s/it, training loss=0.2402]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1575/1835 [36:42<06:08,  1.42s/it, training loss=0.2837]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1576/1835 [36:42<06:06,  1.41s/it, training loss=0.2837]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1576/1835 [36:43<06:06,  1.41s/it, training loss=0.1862]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1577/1835 [36:43<06:03,  1.41s/it, training loss=0.1862]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1577/1835 [36:45<06:03,  1.41s/it, training loss=0.1368]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1578/1835 [36:45<06:01,  1.41s/it, training loss=0.1368]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1578/1835 [36:46<06:01,  1.41s/it, training loss=0.2354]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1579/1835 [36:46<05:59,  1.40s/it, training loss=0.2354]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1579/1835 [36:47<05:59,  1.40s/it, training loss=0.1170]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1580/1835 [36:47<05:58,  1.41s/it, training loss=0.1170]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1580/1835 [36:49<05:58,  1.41s/it, training loss=0.1652]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1581/1835 [36:49<05:56,  1.40s/it, training loss=0.1652]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1581/1835 [36:50<05:56,  1.40s/it, training loss=0.3363]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1582/1835 [36:50<05:59,  1.42s/it, training loss=0.3363]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 1582/1835 [36:52<05:59,  1.42s/it, training loss=0.2422]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1583/1835 [36:52<06:06,  1.45s/it, training loss=0.2422]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1583/1835 [36:53<06:06,  1.45s/it, training loss=0.2191]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1584/1835 [36:53<06:01,  1.44s/it, training loss=0.2191]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1584/1835 [36:55<06:01,  1.44s/it, training loss=0.2544]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1585/1835 [36:55<05:57,  1.43s/it, training loss=0.2544]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1585/1835 [36:56<05:57,  1.43s/it, training loss=0.2001]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1586/1835 [36:56<05:53,  1.42s/it, training loss=0.2001]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1586/1835 [36:57<05:53,  1.42s/it, training loss=0.1158]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1587/1835 [36:57<05:51,  1.42s/it, training loss=0.1158]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 1587/1835 [36:59<05:51,  1.42s/it, training loss=0.1395]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1588/1835 [36:59<05:48,  1.41s/it, training loss=0.1395]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1588/1835 [37:00<05:48,  1.41s/it, training loss=0.2842]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1589/1835 [37:00<05:46,  1.41s/it, training loss=0.2842]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1589/1835 [37:02<05:46,  1.41s/it, training loss=0.3318]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1590/1835 [37:02<05:44,  1.41s/it, training loss=0.3318]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1590/1835 [37:03<05:44,  1.41s/it, training loss=0.1214]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1591/1835 [37:03<05:43,  1.41s/it, training loss=0.1214]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1591/1835 [37:04<05:43,  1.41s/it, training loss=0.1349]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1592/1835 [37:04<05:41,  1.40s/it, training loss=0.1349]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1592/1835 [37:06<05:41,  1.40s/it, training loss=0.2142]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1593/1835 [37:06<05:40,  1.41s/it, training loss=0.2142]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1593/1835 [37:07<05:40,  1.41s/it, training loss=0.0850]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1594/1835 [37:07<05:40,  1.41s/it, training loss=0.0850]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1594/1835 [37:09<05:40,  1.41s/it, training loss=0.2095]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1595/1835 [37:09<05:39,  1.41s/it, training loss=0.2095]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1595/1835 [37:10<05:39,  1.41s/it, training loss=0.2205]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1596/1835 [37:10<05:40,  1.43s/it, training loss=0.2205]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1596/1835 [37:12<05:40,  1.43s/it, training loss=0.2133]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1597/1835 [37:12<05:38,  1.42s/it, training loss=0.2133]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1597/1835 [37:13<05:38,  1.42s/it, training loss=0.1655]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1598/1835 [37:13<05:36,  1.42s/it, training loss=0.1655]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1598/1835 [37:14<05:36,  1.42s/it, training loss=0.1772]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1599/1835 [37:14<05:34,  1.42s/it, training loss=0.1772]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1599/1835 [37:16<05:34,  1.42s/it, training loss=0.2485]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1600/1835 [37:16<05:32,  1.41s/it, training loss=0.2485]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1600/1835 [37:17<05:32,  1.41s/it, training loss=0.1108]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1601/1835 [37:17<05:29,  1.41s/it, training loss=0.1108]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1601/1835 [37:19<05:29,  1.41s/it, training loss=0.0548]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1602/1835 [37:19<05:30,  1.42s/it, training loss=0.0548]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1602/1835 [37:20<05:30,  1.42s/it, training loss=0.2299]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1603/1835 [37:20<05:27,  1.41s/it, training loss=0.2299]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1603/1835 [37:21<05:27,  1.41s/it, training loss=0.1831]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1604/1835 [37:21<05:25,  1.41s/it, training loss=0.1831]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1604/1835 [37:23<05:25,  1.41s/it, training loss=0.1586]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1605/1835 [37:23<05:23,  1.41s/it, training loss=0.1586]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 1605/1835 [37:24<05:23,  1.41s/it, training loss=0.1850]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1606/1835 [37:24<05:21,  1.41s/it, training loss=0.1850]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1606/1835 [37:26<05:21,  1.41s/it, training loss=0.2489]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1607/1835 [37:26<05:19,  1.40s/it, training loss=0.2489]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1607/1835 [37:27<05:19,  1.40s/it, training loss=0.0774]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1608/1835 [37:27<05:17,  1.40s/it, training loss=0.0774]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1608/1835 [37:28<05:17,  1.40s/it, training loss=0.1319]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1609/1835 [37:28<05:16,  1.40s/it, training loss=0.1319]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1609/1835 [37:30<05:16,  1.40s/it, training loss=0.2289]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1610/1835 [37:30<05:14,  1.40s/it, training loss=0.2289]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1610/1835 [37:31<05:14,  1.40s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1611/1835 [37:31<05:13,  1.40s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1611/1835 [37:33<05:13,  1.40s/it, training loss=0.0990]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1612/1835 [37:33<05:11,  1.40s/it, training loss=0.0990]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1612/1835 [37:34<05:11,  1.40s/it, training loss=0.1141]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1613/1835 [37:34<05:10,  1.40s/it, training loss=0.1141]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1613/1835 [37:35<05:10,  1.40s/it, training loss=0.0594]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1614/1835 [37:35<05:08,  1.40s/it, training loss=0.0594]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1614/1835 [37:37<05:08,  1.40s/it, training loss=0.2048]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1615/1835 [37:37<05:07,  1.40s/it, training loss=0.2048]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1615/1835 [37:38<05:07,  1.40s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1616/1835 [37:38<05:06,  1.40s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1616/1835 [37:40<05:06,  1.40s/it, training loss=0.1467]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1617/1835 [37:40<05:04,  1.40s/it, training loss=0.1467]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1617/1835 [37:41<05:04,  1.40s/it, training loss=0.2954]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1618/1835 [37:41<05:02,  1.40s/it, training loss=0.2954]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1618/1835 [37:42<05:02,  1.40s/it, training loss=0.2151]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1619/1835 [37:42<05:02,  1.40s/it, training loss=0.2151]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1619/1835 [37:44<05:02,  1.40s/it, training loss=0.1349]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1620/1835 [37:44<05:00,  1.40s/it, training loss=0.1349]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1620/1835 [37:45<05:00,  1.40s/it, training loss=0.2324]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1621/1835 [37:45<04:59,  1.40s/it, training loss=0.2324]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1621/1835 [37:47<04:59,  1.40s/it, training loss=0.1728]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1622/1835 [37:47<04:58,  1.40s/it, training loss=0.1728]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1622/1835 [37:48<04:58,  1.40s/it, training loss=0.2766]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1623/1835 [37:48<04:57,  1.40s/it, training loss=0.2766]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 1623/1835 [37:49<04:57,  1.40s/it, training loss=0.2126]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1624/1835 [37:49<04:57,  1.41s/it, training loss=0.2126]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1624/1835 [37:51<04:57,  1.41s/it, training loss=0.2364]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1625/1835 [37:51<04:55,  1.41s/it, training loss=0.2364]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1625/1835 [37:52<04:55,  1.41s/it, training loss=0.1831]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1626/1835 [37:52<04:53,  1.41s/it, training loss=0.1831]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1626/1835 [37:54<04:53,  1.41s/it, training loss=0.1472]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1627/1835 [37:54<04:51,  1.40s/it, training loss=0.1472]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1627/1835 [37:55<04:51,  1.40s/it, training loss=0.1724]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1628/1835 [37:55<04:50,  1.40s/it, training loss=0.1724]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 1628/1835 [37:56<04:50,  1.40s/it, training loss=0.1427]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1629/1835 [37:56<04:48,  1.40s/it, training loss=0.1427]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1629/1835 [37:58<04:48,  1.40s/it, training loss=0.1242]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1630/1835 [37:58<04:46,  1.40s/it, training loss=0.1242]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1630/1835 [37:59<04:46,  1.40s/it, training loss=0.3085]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1631/1835 [37:59<04:45,  1.40s/it, training loss=0.3085]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1631/1835 [38:01<04:45,  1.40s/it, training loss=0.1616]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1632/1835 [38:01<04:45,  1.40s/it, training loss=0.1616]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1632/1835 [38:02<04:45,  1.40s/it, training loss=0.0907]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1633/1835 [38:02<04:42,  1.40s/it, training loss=0.0907]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1633/1835 [38:03<04:42,  1.40s/it, training loss=0.2445]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1634/1835 [38:03<04:42,  1.40s/it, training loss=0.2445]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1634/1835 [38:05<04:42,  1.40s/it, training loss=0.1357]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1635/1835 [38:05<04:40,  1.40s/it, training loss=0.1357]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1635/1835 [38:06<04:40,  1.40s/it, training loss=0.2817]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1636/1835 [38:06<04:39,  1.40s/it, training loss=0.2817]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1636/1835 [38:08<04:39,  1.40s/it, training loss=0.1559]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1637/1835 [38:08<04:38,  1.40s/it, training loss=0.1559]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1637/1835 [38:09<04:38,  1.40s/it, training loss=0.2971]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1638/1835 [38:09<04:36,  1.40s/it, training loss=0.2971]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1638/1835 [38:10<04:36,  1.40s/it, training loss=0.1718]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1639/1835 [38:10<04:34,  1.40s/it, training loss=0.1718]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1639/1835 [38:12<04:34,  1.40s/it, training loss=0.2305]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1640/1835 [38:12<04:33,  1.40s/it, training loss=0.2305]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1640/1835 [38:13<04:33,  1.40s/it, training loss=0.1717]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1641/1835 [38:13<04:31,  1.40s/it, training loss=0.1717]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1641/1835 [38:15<04:31,  1.40s/it, training loss=0.1662]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1642/1835 [38:15<04:29,  1.40s/it, training loss=0.1662]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 1642/1835 [38:16<04:29,  1.40s/it, training loss=0.1147]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1643/1835 [38:16<04:27,  1.40s/it, training loss=0.1147]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1643/1835 [38:17<04:27,  1.40s/it, training loss=0.2012]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1644/1835 [38:17<04:26,  1.40s/it, training loss=0.2012]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1644/1835 [38:19<04:26,  1.40s/it, training loss=0.1928]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1645/1835 [38:19<04:25,  1.40s/it, training loss=0.1928]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1645/1835 [38:20<04:25,  1.40s/it, training loss=0.2629]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1646/1835 [38:20<04:23,  1.40s/it, training loss=0.2629]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1646/1835 [38:22<04:23,  1.40s/it, training loss=0.2285]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1647/1835 [38:22<04:22,  1.40s/it, training loss=0.2285]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1647/1835 [38:23<04:22,  1.40s/it, training loss=0.3192]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1648/1835 [38:23<04:21,  1.40s/it, training loss=0.3192]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1648/1835 [38:24<04:21,  1.40s/it, training loss=0.1857]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1649/1835 [38:24<04:19,  1.40s/it, training loss=0.1857]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1649/1835 [38:26<04:19,  1.40s/it, training loss=0.3604]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1650/1835 [38:26<04:19,  1.40s/it, training loss=0.3604]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1650/1835 [38:27<04:19,  1.40s/it, training loss=0.2254]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1651/1835 [38:27<04:18,  1.41s/it, training loss=0.2254]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1651/1835 [38:29<04:18,  1.41s/it, training loss=0.0932]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1652/1835 [38:29<04:17,  1.41s/it, training loss=0.0932]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1652/1835 [38:30<04:17,  1.41s/it, training loss=0.1466]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1653/1835 [38:30<04:15,  1.40s/it, training loss=0.1466]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1653/1835 [38:31<04:15,  1.40s/it, training loss=0.1704]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1654/1835 [38:31<04:13,  1.40s/it, training loss=0.1704]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1654/1835 [38:33<04:13,  1.40s/it, training loss=0.1739]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1655/1835 [38:33<04:11,  1.40s/it, training loss=0.1739]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1655/1835 [38:34<04:11,  1.40s/it, training loss=0.2782]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1656/1835 [38:34<04:10,  1.40s/it, training loss=0.2782]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1656/1835 [38:36<04:10,  1.40s/it, training loss=0.2577]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1657/1835 [38:36<04:08,  1.40s/it, training loss=0.2577]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1657/1835 [38:37<04:08,  1.40s/it, training loss=0.2200]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1658/1835 [38:37<04:07,  1.40s/it, training loss=0.2200]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1658/1835 [38:38<04:07,  1.40s/it, training loss=0.1983]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1659/1835 [38:38<04:06,  1.40s/it, training loss=0.1983]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1659/1835 [38:40<04:06,  1.40s/it, training loss=0.1651]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1660/1835 [38:40<04:04,  1.40s/it, training loss=0.1651]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 1660/1835 [38:41<04:04,  1.40s/it, training loss=0.2499]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1661/1835 [38:41<04:05,  1.41s/it, training loss=0.2499]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1661/1835 [38:43<04:05,  1.41s/it, training loss=0.2340]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1662/1835 [38:43<04:04,  1.41s/it, training loss=0.2340]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1662/1835 [38:44<04:04,  1.41s/it, training loss=0.1504]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1663/1835 [38:44<04:02,  1.41s/it, training loss=0.1504]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1663/1835 [38:46<04:02,  1.41s/it, training loss=0.1631]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1664/1835 [38:46<04:01,  1.41s/it, training loss=0.1631]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1664/1835 [38:47<04:01,  1.41s/it, training loss=0.2153]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1665/1835 [38:47<04:02,  1.43s/it, training loss=0.2153]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1665/1835 [38:48<04:02,  1.43s/it, training loss=0.1953]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1666/1835 [38:48<04:05,  1.45s/it, training loss=0.1953]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1666/1835 [38:50<04:05,  1.45s/it, training loss=0.1485]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1667/1835 [38:50<04:00,  1.43s/it, training loss=0.1485]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1667/1835 [38:51<04:00,  1.43s/it, training loss=0.1340]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1668/1835 [38:51<03:57,  1.42s/it, training loss=0.1340]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1668/1835 [38:53<03:57,  1.42s/it, training loss=0.1972]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1669/1835 [38:53<03:54,  1.41s/it, training loss=0.1972]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1669/1835 [38:54<03:54,  1.41s/it, training loss=0.1102]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1670/1835 [38:54<03:52,  1.41s/it, training loss=0.1102]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1670/1835 [38:55<03:52,  1.41s/it, training loss=0.2155]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1671/1835 [38:55<03:50,  1.41s/it, training loss=0.2155]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1671/1835 [38:57<03:50,  1.41s/it, training loss=0.0930]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1672/1835 [38:57<03:48,  1.40s/it, training loss=0.0930]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1672/1835 [38:58<03:48,  1.40s/it, training loss=0.2092]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1673/1835 [38:58<03:47,  1.40s/it, training loss=0.2092]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1673/1835 [39:00<03:47,  1.40s/it, training loss=0.1225]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1674/1835 [39:00<03:45,  1.40s/it, training loss=0.1225]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 1674/1835 [39:01<03:45,  1.40s/it, training loss=0.1530]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1675/1835 [39:01<03:44,  1.40s/it, training loss=0.1530]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1675/1835 [39:02<03:44,  1.40s/it, training loss=0.1110]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1676/1835 [39:02<03:42,  1.40s/it, training loss=0.1110]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1676/1835 [39:04<03:42,  1.40s/it, training loss=0.0849]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1677/1835 [39:04<03:41,  1.40s/it, training loss=0.0849]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1677/1835 [39:05<03:41,  1.40s/it, training loss=0.1586]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1678/1835 [39:05<03:41,  1.41s/it, training loss=0.1586]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1678/1835 [39:07<03:41,  1.41s/it, training loss=0.3161]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1679/1835 [39:07<03:39,  1.41s/it, training loss=0.3161]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 1679/1835 [39:08<03:39,  1.41s/it, training loss=0.1739]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1680/1835 [39:08<03:38,  1.41s/it, training loss=0.1739]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1680/1835 [39:10<03:38,  1.41s/it, training loss=0.2655]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1681/1835 [39:10<03:37,  1.41s/it, training loss=0.2655]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1681/1835 [39:11<03:37,  1.41s/it, training loss=0.2127]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1682/1835 [39:11<03:35,  1.41s/it, training loss=0.2127]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1682/1835 [39:12<03:35,  1.41s/it, training loss=0.1628]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1683/1835 [39:12<03:33,  1.40s/it, training loss=0.1628]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1683/1835 [39:14<03:33,  1.40s/it, training loss=0.2241]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1684/1835 [39:14<03:31,  1.40s/it, training loss=0.2241]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1684/1835 [39:15<03:31,  1.40s/it, training loss=0.1679]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1685/1835 [39:15<03:30,  1.40s/it, training loss=0.1679]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1685/1835 [39:17<03:30,  1.40s/it, training loss=0.2232]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1686/1835 [39:17<03:28,  1.40s/it, training loss=0.2232]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1686/1835 [39:18<03:28,  1.40s/it, training loss=0.2918]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1687/1835 [39:18<03:27,  1.40s/it, training loss=0.2918]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1687/1835 [39:19<03:27,  1.40s/it, training loss=0.1450]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1688/1835 [39:19<03:25,  1.40s/it, training loss=0.1450]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1688/1835 [39:21<03:25,  1.40s/it, training loss=0.1211]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1689/1835 [39:21<03:24,  1.40s/it, training loss=0.1211]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1689/1835 [39:22<03:24,  1.40s/it, training loss=0.0829]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1690/1835 [39:22<03:22,  1.40s/it, training loss=0.0829]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1690/1835 [39:23<03:22,  1.40s/it, training loss=0.1297]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1691/1835 [39:23<03:20,  1.39s/it, training loss=0.1297]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1691/1835 [39:25<03:20,  1.39s/it, training loss=0.2221]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1692/1835 [39:25<03:19,  1.39s/it, training loss=0.2221]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1692/1835 [39:26<03:19,  1.39s/it, training loss=0.0889]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1693/1835 [39:26<03:17,  1.39s/it, training loss=0.0889]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1693/1835 [39:28<03:17,  1.39s/it, training loss=0.1553]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1694/1835 [39:28<03:16,  1.39s/it, training loss=0.1553]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1694/1835 [39:29<03:16,  1.39s/it, training loss=0.2745]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1695/1835 [39:29<03:15,  1.39s/it, training loss=0.2745]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1695/1835 [39:30<03:15,  1.39s/it, training loss=0.1144]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1696/1835 [39:30<03:13,  1.39s/it, training loss=0.1144]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1696/1835 [39:32<03:13,  1.39s/it, training loss=0.1569]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1697/1835 [39:32<03:12,  1.39s/it, training loss=0.1569]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 1697/1835 [39:33<03:12,  1.39s/it, training loss=0.3183]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1698/1835 [39:33<03:11,  1.40s/it, training loss=0.3183]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1698/1835 [39:35<03:11,  1.40s/it, training loss=0.1382]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1699/1835 [39:35<03:09,  1.40s/it, training loss=0.1382]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1699/1835 [39:36<03:09,  1.40s/it, training loss=0.1432]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1700/1835 [39:36<03:08,  1.40s/it, training loss=0.1432]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1700/1835 [39:37<03:08,  1.40s/it, training loss=0.2114]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1701/1835 [39:37<03:06,  1.40s/it, training loss=0.2114]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1701/1835 [39:39<03:06,  1.40s/it, training loss=0.1279]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1702/1835 [39:39<03:05,  1.39s/it, training loss=0.1279]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1702/1835 [39:40<03:05,  1.39s/it, training loss=0.1267]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1703/1835 [39:40<03:03,  1.39s/it, training loss=0.1267]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1703/1835 [39:42<03:03,  1.39s/it, training loss=0.2039]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1704/1835 [39:42<03:02,  1.39s/it, training loss=0.2039]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1704/1835 [39:43<03:02,  1.39s/it, training loss=0.1958]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1705/1835 [39:43<03:01,  1.39s/it, training loss=0.1958]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1705/1835 [39:44<03:01,  1.39s/it, training loss=0.1413]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1706/1835 [39:44<02:59,  1.39s/it, training loss=0.1413]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1706/1835 [39:46<02:59,  1.39s/it, training loss=0.1483]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1707/1835 [39:46<02:58,  1.39s/it, training loss=0.1483]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1707/1835 [39:47<02:58,  1.39s/it, training loss=0.0831]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1708/1835 [39:47<02:57,  1.39s/it, training loss=0.0831]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1708/1835 [39:49<02:57,  1.39s/it, training loss=0.1138]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1709/1835 [39:49<02:55,  1.39s/it, training loss=0.1138]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1709/1835 [39:50<02:55,  1.39s/it, training loss=0.2057]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1710/1835 [39:50<02:54,  1.39s/it, training loss=0.2057]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1710/1835 [39:51<02:54,  1.39s/it, training loss=0.1680]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1711/1835 [39:51<02:52,  1.39s/it, training loss=0.1680]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1711/1835 [39:53<02:52,  1.39s/it, training loss=0.2488]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1712/1835 [39:53<02:51,  1.39s/it, training loss=0.2488]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1712/1835 [39:54<02:51,  1.39s/it, training loss=0.1115]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1713/1835 [39:54<02:49,  1.39s/it, training loss=0.1115]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1713/1835 [39:56<02:49,  1.39s/it, training loss=0.1944]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1714/1835 [39:56<02:48,  1.39s/it, training loss=0.1944]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1714/1835 [39:57<02:48,  1.39s/it, training loss=0.2536]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1715/1835 [39:57<02:47,  1.39s/it, training loss=0.2536]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 1715/1835 [39:58<02:47,  1.39s/it, training loss=0.1450]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1716/1835 [39:58<02:46,  1.40s/it, training loss=0.1450]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1716/1835 [40:00<02:46,  1.40s/it, training loss=0.1682]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1717/1835 [40:00<02:44,  1.40s/it, training loss=0.1682]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1717/1835 [40:01<02:44,  1.40s/it, training loss=0.0978]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1718/1835 [40:01<02:43,  1.40s/it, training loss=0.0978]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1718/1835 [40:03<02:43,  1.40s/it, training loss=0.2220]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1719/1835 [40:03<02:41,  1.40s/it, training loss=0.2220]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1719/1835 [40:04<02:41,  1.40s/it, training loss=0.1030]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1720/1835 [40:04<02:40,  1.40s/it, training loss=0.1030]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 1720/1835 [40:05<02:40,  1.40s/it, training loss=0.1267]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1721/1835 [40:05<02:39,  1.40s/it, training loss=0.1267]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1721/1835 [40:07<02:39,  1.40s/it, training loss=0.1482]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1722/1835 [40:07<02:37,  1.40s/it, training loss=0.1482]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1722/1835 [40:08<02:37,  1.40s/it, training loss=0.1402]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1723/1835 [40:08<02:36,  1.40s/it, training loss=0.1402]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1723/1835 [40:10<02:36,  1.40s/it, training loss=0.1725]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1724/1835 [40:10<02:34,  1.40s/it, training loss=0.1725]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1724/1835 [40:11<02:34,  1.40s/it, training loss=0.2942]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1725/1835 [40:11<02:33,  1.39s/it, training loss=0.2942]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1725/1835 [40:12<02:33,  1.39s/it, training loss=0.1665]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1726/1835 [40:12<02:32,  1.39s/it, training loss=0.1665]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1726/1835 [40:14<02:32,  1.39s/it, training loss=0.2450]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1727/1835 [40:14<02:30,  1.40s/it, training loss=0.2450]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1727/1835 [40:15<02:30,  1.40s/it, training loss=0.4241]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1728/1835 [40:15<02:29,  1.40s/it, training loss=0.4241]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1728/1835 [40:16<02:29,  1.40s/it, training loss=0.0461]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1729/1835 [40:16<02:27,  1.39s/it, training loss=0.0461]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1729/1835 [40:18<02:27,  1.39s/it, training loss=0.2868]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1730/1835 [40:18<02:26,  1.39s/it, training loss=0.2868]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1730/1835 [40:19<02:26,  1.39s/it, training loss=0.3389]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1731/1835 [40:19<02:24,  1.39s/it, training loss=0.3389]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1731/1835 [40:21<02:24,  1.39s/it, training loss=0.0923]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1732/1835 [40:21<02:23,  1.39s/it, training loss=0.0923]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1732/1835 [40:22<02:23,  1.39s/it, training loss=0.2810]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1733/1835 [40:22<02:22,  1.39s/it, training loss=0.2810]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1733/1835 [40:23<02:22,  1.39s/it, training loss=0.0751]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1734/1835 [40:23<02:20,  1.40s/it, training loss=0.0751]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 1734/1835 [40:25<02:20,  1.40s/it, training loss=0.1483]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1735/1835 [40:25<02:19,  1.39s/it, training loss=0.1483]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1735/1835 [40:26<02:19,  1.39s/it, training loss=0.1540]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1736/1835 [40:26<02:18,  1.39s/it, training loss=0.1540]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1736/1835 [40:28<02:18,  1.39s/it, training loss=0.1105]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1737/1835 [40:28<02:16,  1.39s/it, training loss=0.1105]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1737/1835 [40:29<02:16,  1.39s/it, training loss=0.0683]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1738/1835 [40:29<02:15,  1.40s/it, training loss=0.0683]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1738/1835 [40:30<02:15,  1.40s/it, training loss=0.2679]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1739/1835 [40:30<02:13,  1.40s/it, training loss=0.2679]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1739/1835 [40:32<02:13,  1.40s/it, training loss=0.1245]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1740/1835 [40:32<02:12,  1.40s/it, training loss=0.1245]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1740/1835 [40:33<02:12,  1.40s/it, training loss=0.3302]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1741/1835 [40:33<02:11,  1.40s/it, training loss=0.3302]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1741/1835 [40:35<02:11,  1.40s/it, training loss=0.2858]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1742/1835 [40:35<02:09,  1.40s/it, training loss=0.2858]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1742/1835 [40:36<02:09,  1.40s/it, training loss=0.1948]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1743/1835 [40:36<02:08,  1.40s/it, training loss=0.1948]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 1743/1835 [40:37<02:08,  1.40s/it, training loss=0.1506]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1744/1835 [40:37<02:06,  1.39s/it, training loss=0.1506]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1744/1835 [40:39<02:06,  1.39s/it, training loss=0.2548]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1745/1835 [40:39<02:05,  1.39s/it, training loss=0.2548]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1745/1835 [40:40<02:05,  1.39s/it, training loss=0.1416]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1746/1835 [40:40<02:04,  1.40s/it, training loss=0.1416]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1746/1835 [40:42<02:04,  1.40s/it, training loss=0.3019]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1747/1835 [40:42<02:02,  1.40s/it, training loss=0.3019]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1747/1835 [40:43<02:02,  1.40s/it, training loss=0.1224]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1748/1835 [40:43<02:01,  1.40s/it, training loss=0.1224]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1748/1835 [40:44<02:01,  1.40s/it, training loss=0.3034]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1749/1835 [40:44<02:00,  1.40s/it, training loss=0.3034]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1749/1835 [40:46<02:00,  1.40s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1750/1835 [40:46<01:58,  1.40s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1750/1835 [40:47<01:58,  1.40s/it, training loss=0.1862]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1751/1835 [40:47<01:57,  1.40s/it, training loss=0.1862]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1751/1835 [40:49<01:57,  1.40s/it, training loss=0.1739]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1752/1835 [40:49<01:55,  1.40s/it, training loss=0.1739]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 1752/1835 [40:50<01:55,  1.40s/it, training loss=0.3037]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1753/1835 [40:50<01:54,  1.40s/it, training loss=0.3037]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1753/1835 [40:51<01:54,  1.40s/it, training loss=0.1480]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1754/1835 [40:51<01:53,  1.40s/it, training loss=0.1480]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1754/1835 [40:53<01:53,  1.40s/it, training loss=0.1133]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1755/1835 [40:53<01:51,  1.40s/it, training loss=0.1133]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1755/1835 [40:54<01:51,  1.40s/it, training loss=0.2372]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1756/1835 [40:54<01:50,  1.39s/it, training loss=0.2372]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1756/1835 [40:56<01:50,  1.39s/it, training loss=0.1557]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1757/1835 [40:56<01:48,  1.39s/it, training loss=0.1557]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1757/1835 [40:57<01:48,  1.39s/it, training loss=0.2258]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1758/1835 [40:57<01:49,  1.42s/it, training loss=0.2258]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1758/1835 [40:58<01:49,  1.42s/it, training loss=0.2341]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1759/1835 [40:58<01:47,  1.41s/it, training loss=0.2341]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1759/1835 [41:00<01:47,  1.41s/it, training loss=0.2331]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1760/1835 [41:00<01:45,  1.40s/it, training loss=0.2331]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1760/1835 [41:01<01:45,  1.40s/it, training loss=0.0967]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1761/1835 [41:01<01:43,  1.40s/it, training loss=0.0967]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1761/1835 [41:03<01:43,  1.40s/it, training loss=0.2292]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1762/1835 [41:03<01:42,  1.40s/it, training loss=0.2292]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1762/1835 [41:04<01:42,  1.40s/it, training loss=0.2974]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1763/1835 [41:04<01:40,  1.40s/it, training loss=0.2974]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1763/1835 [41:05<01:40,  1.40s/it, training loss=0.2632]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1764/1835 [41:05<01:39,  1.40s/it, training loss=0.2632]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1764/1835 [41:07<01:39,  1.40s/it, training loss=0.4028]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1765/1835 [41:07<01:37,  1.40s/it, training loss=0.4028]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1765/1835 [41:08<01:37,  1.40s/it, training loss=0.1908]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1766/1835 [41:08<01:36,  1.40s/it, training loss=0.1908]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 1766/1835 [41:10<01:36,  1.40s/it, training loss=0.2090]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1767/1835 [41:10<01:34,  1.40s/it, training loss=0.2090]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1767/1835 [41:11<01:34,  1.40s/it, training loss=0.2394]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1768/1835 [41:11<01:33,  1.40s/it, training loss=0.2394]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1768/1835 [41:12<01:33,  1.40s/it, training loss=0.2041]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1769/1835 [41:12<01:32,  1.40s/it, training loss=0.2041]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1769/1835 [41:14<01:32,  1.40s/it, training loss=0.1470]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1770/1835 [41:14<01:30,  1.40s/it, training loss=0.1470]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 1770/1835 [41:15<01:30,  1.40s/it, training loss=0.2164]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1771/1835 [41:15<01:29,  1.40s/it, training loss=0.2164]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1771/1835 [41:17<01:29,  1.40s/it, training loss=0.1401]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1772/1835 [41:17<01:27,  1.40s/it, training loss=0.1401]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1772/1835 [41:18<01:27,  1.40s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1773/1835 [41:18<01:26,  1.40s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1773/1835 [41:19<01:26,  1.40s/it, training loss=0.1353]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1774/1835 [41:19<01:25,  1.40s/it, training loss=0.1353]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1774/1835 [41:21<01:25,  1.40s/it, training loss=0.1532]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1775/1835 [41:21<01:23,  1.40s/it, training loss=0.1532]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1775/1835 [41:22<01:23,  1.40s/it, training loss=0.2188]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1776/1835 [41:22<01:22,  1.40s/it, training loss=0.2188]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1776/1835 [41:24<01:22,  1.40s/it, training loss=0.1871]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1777/1835 [41:24<01:20,  1.39s/it, training loss=0.1871]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1777/1835 [41:25<01:20,  1.39s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1778/1835 [41:25<01:19,  1.40s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1778/1835 [41:26<01:19,  1.40s/it, training loss=0.1368]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1779/1835 [41:26<01:18,  1.39s/it, training loss=0.1368]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1779/1835 [41:28<01:18,  1.39s/it, training loss=0.1379]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1780/1835 [41:28<01:16,  1.39s/it, training loss=0.1379]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1780/1835 [41:29<01:16,  1.39s/it, training loss=0.0915]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1781/1835 [41:29<01:15,  1.39s/it, training loss=0.0915]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1781/1835 [41:30<01:15,  1.39s/it, training loss=0.1907]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1782/1835 [41:31<01:13,  1.39s/it, training loss=0.1907]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1782/1835 [41:32<01:13,  1.39s/it, training loss=0.2860]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1783/1835 [41:32<01:12,  1.39s/it, training loss=0.2860]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1783/1835 [41:33<01:12,  1.39s/it, training loss=0.2647]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1784/1835 [41:33<01:11,  1.39s/it, training loss=0.2647]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1784/1835 [41:35<01:11,  1.39s/it, training loss=0.1316]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1785/1835 [41:35<01:09,  1.39s/it, training loss=0.1316]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1785/1835 [41:36<01:09,  1.39s/it, training loss=0.1823]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1786/1835 [41:36<01:08,  1.39s/it, training loss=0.1823]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1786/1835 [41:37<01:08,  1.39s/it, training loss=0.1128]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1787/1835 [41:37<01:06,  1.39s/it, training loss=0.1128]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1787/1835 [41:39<01:06,  1.39s/it, training loss=0.2132]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1788/1835 [41:39<01:05,  1.39s/it, training loss=0.2132]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1788/1835 [41:40<01:05,  1.39s/it, training loss=0.1614]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1789/1835 [41:40<01:03,  1.39s/it, training loss=0.1614]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 1789/1835 [41:42<01:03,  1.39s/it, training loss=0.2119]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1790/1835 [41:42<01:02,  1.39s/it, training loss=0.2119]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1790/1835 [41:43<01:02,  1.39s/it, training loss=0.0766]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1791/1835 [41:43<01:01,  1.39s/it, training loss=0.0766]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1791/1835 [41:44<01:01,  1.39s/it, training loss=0.0861]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1792/1835 [41:44<00:59,  1.40s/it, training loss=0.0861]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1792/1835 [41:46<00:59,  1.40s/it, training loss=0.2104]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1793/1835 [41:46<00:58,  1.39s/it, training loss=0.2104]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1793/1835 [41:47<00:58,  1.39s/it, training loss=0.2465]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1794/1835 [41:47<00:57,  1.39s/it, training loss=0.2465]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1794/1835 [41:49<00:57,  1.39s/it, training loss=0.1607]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1795/1835 [41:49<00:55,  1.39s/it, training loss=0.1607]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1795/1835 [41:50<00:55,  1.39s/it, training loss=0.0297]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1796/1835 [41:50<00:54,  1.39s/it, training loss=0.0297]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1796/1835 [41:51<00:54,  1.39s/it, training loss=0.1250]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1797/1835 [41:51<00:52,  1.39s/it, training loss=0.1250]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1797/1835 [41:53<00:52,  1.39s/it, training loss=0.3621]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1798/1835 [41:53<00:51,  1.39s/it, training loss=0.3621]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1798/1835 [41:54<00:51,  1.39s/it, training loss=0.4283]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1799/1835 [41:54<00:50,  1.40s/it, training loss=0.4283]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1799/1835 [41:56<00:50,  1.40s/it, training loss=0.2098]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1800/1835 [41:56<00:48,  1.39s/it, training loss=0.2098]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1800/1835 [41:57<00:48,  1.39s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1801/1835 [41:57<00:47,  1.39s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1801/1835 [41:58<00:47,  1.39s/it, training loss=0.1118]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1802/1835 [41:58<00:46,  1.39s/it, training loss=0.1118]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1802/1835 [42:00<00:46,  1.39s/it, training loss=0.1952]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1803/1835 [42:00<00:44,  1.39s/it, training loss=0.1952]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1803/1835 [42:01<00:44,  1.39s/it, training loss=0.1769]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1804/1835 [42:01<00:43,  1.39s/it, training loss=0.1769]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1804/1835 [42:03<00:43,  1.39s/it, training loss=0.1908]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1805/1835 [42:03<00:41,  1.39s/it, training loss=0.1908]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1805/1835 [42:04<00:41,  1.39s/it, training loss=0.2614]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1806/1835 [42:04<00:40,  1.39s/it, training loss=0.2614]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1806/1835 [42:05<00:40,  1.39s/it, training loss=0.1423]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1807/1835 [42:05<00:39,  1.40s/it, training loss=0.1423]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 1807/1835 [42:07<00:39,  1.40s/it, training loss=0.1704]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1808/1835 [42:07<00:37,  1.39s/it, training loss=0.1704]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1808/1835 [42:08<00:37,  1.39s/it, training loss=0.1853]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1809/1835 [42:08<00:36,  1.40s/it, training loss=0.1853]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1809/1835 [42:10<00:36,  1.40s/it, training loss=0.2051]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1810/1835 [42:10<00:34,  1.40s/it, training loss=0.2051]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1810/1835 [42:11<00:34,  1.40s/it, training loss=0.2466]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1811/1835 [42:11<00:33,  1.39s/it, training loss=0.2466]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1811/1835 [42:12<00:33,  1.39s/it, training loss=0.2137]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1812/1835 [42:12<00:32,  1.39s/it, training loss=0.2137]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 1812/1835 [42:14<00:32,  1.39s/it, training loss=0.0751]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1813/1835 [42:14<00:30,  1.39s/it, training loss=0.0751]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1813/1835 [42:15<00:30,  1.39s/it, training loss=0.1210]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1814/1835 [42:15<00:29,  1.39s/it, training loss=0.1210]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1814/1835 [42:16<00:29,  1.39s/it, training loss=0.3247]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1815/1835 [42:16<00:27,  1.39s/it, training loss=0.3247]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1815/1835 [42:18<00:27,  1.39s/it, training loss=0.2177]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1816/1835 [42:18<00:26,  1.39s/it, training loss=0.2177]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1816/1835 [42:19<00:26,  1.39s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1817/1835 [42:19<00:25,  1.39s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1817/1835 [42:21<00:25,  1.39s/it, training loss=0.1547]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1818/1835 [42:21<00:23,  1.39s/it, training loss=0.1547]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1818/1835 [42:22<00:23,  1.39s/it, training loss=0.0702]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1819/1835 [42:22<00:22,  1.39s/it, training loss=0.0702]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1819/1835 [42:23<00:22,  1.39s/it, training loss=0.1330]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1820/1835 [42:23<00:20,  1.39s/it, training loss=0.1330]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1820/1835 [42:25<00:20,  1.39s/it, training loss=0.2177]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1821/1835 [42:25<00:19,  1.39s/it, training loss=0.2177]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1821/1835 [42:26<00:19,  1.39s/it, training loss=0.3777]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1822/1835 [42:26<00:18,  1.39s/it, training loss=0.3777]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1822/1835 [42:28<00:18,  1.39s/it, training loss=0.2248]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1823/1835 [42:28<00:16,  1.39s/it, training loss=0.2248]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1823/1835 [42:29<00:16,  1.39s/it, training loss=0.2262]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1824/1835 [42:29<00:15,  1.40s/it, training loss=0.2262]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1824/1835 [42:30<00:15,  1.40s/it, training loss=0.2879]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1825/1835 [42:30<00:13,  1.40s/it, training loss=0.2879]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 1825/1835 [42:32<00:13,  1.40s/it, training loss=0.2779]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1826/1835 [42:32<00:12,  1.40s/it, training loss=0.2779]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1826/1835 [42:33<00:12,  1.40s/it, training loss=0.2019]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1827/1835 [42:33<00:11,  1.40s/it, training loss=0.2019]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1827/1835 [42:35<00:11,  1.40s/it, training loss=0.0832]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1828/1835 [42:35<00:09,  1.40s/it, training loss=0.0832]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1828/1835 [42:36<00:09,  1.40s/it, training loss=0.0882]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1829/1835 [42:36<00:08,  1.40s/it, training loss=0.0882]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1829/1835 [42:37<00:08,  1.40s/it, training loss=0.2273]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1830/1835 [42:37<00:06,  1.40s/it, training loss=0.2273]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1830/1835 [42:39<00:06,  1.40s/it, training loss=0.2399]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1831/1835 [42:39<00:05,  1.40s/it, training loss=0.2399]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1831/1835 [42:40<00:05,  1.40s/it, training loss=0.2162]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1832/1835 [42:40<00:04,  1.40s/it, training loss=0.2162]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1832/1835 [42:42<00:04,  1.40s/it, training loss=0.0840]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1833/1835 [42:42<00:02,  1.40s/it, training loss=0.0840]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1833/1835 [42:43<00:02,  1.40s/it, training loss=0.2018]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1834/1835 [42:43<00:01,  1.39s/it, training loss=0.2018]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1834/1835 [42:44<00:01,  1.39s/it, training loss=0.2093]\u001b[A\n",
            "Epoch 1: 100%|██████████| 1835/1835 [42:44<00:00,  1.24s/it, training loss=0.2093]\u001b[A\n",
            "  0%|          | 0/3 [42:44<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch {epoch}\n",
            "Training loss: 0.6048201410460212\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 1/3 [44:28<1:28:57, 2668.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5457044273030525\n",
            "F1 Score (weighted): 0.7739689104849554\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2:   0%|          | 0/1835 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:   0%|          | 0/1835 [00:01<?, ?it/s, training loss=0.2152]\u001b[A\n",
            "Epoch 2:   0%|          | 1/1835 [00:01<42:15,  1.38s/it, training loss=0.2152]\u001b[A\n",
            "Epoch 2:   0%|          | 1/1835 [00:02<42:15,  1.38s/it, training loss=0.3509]\u001b[A\n",
            "Epoch 2:   0%|          | 2/1835 [00:02<42:22,  1.39s/it, training loss=0.3509]\u001b[A\n",
            "Epoch 2:   0%|          | 2/1835 [00:04<42:22,  1.39s/it, training loss=0.1771]\u001b[A\n",
            "Epoch 2:   0%|          | 3/1835 [00:04<42:29,  1.39s/it, training loss=0.1771]\u001b[A\n",
            "Epoch 2:   0%|          | 3/1835 [00:05<42:29,  1.39s/it, training loss=0.1995]\u001b[A\n",
            "Epoch 2:   0%|          | 4/1835 [00:05<42:26,  1.39s/it, training loss=0.1995]\u001b[A\n",
            "Epoch 2:   0%|          | 4/1835 [00:06<42:26,  1.39s/it, training loss=0.0911]\u001b[A\n",
            "Epoch 2:   0%|          | 5/1835 [00:06<42:23,  1.39s/it, training loss=0.0911]\u001b[A\n",
            "Epoch 2:   0%|          | 5/1835 [00:08<42:23,  1.39s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 2:   0%|          | 6/1835 [00:08<42:29,  1.39s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 2:   0%|          | 6/1835 [00:09<42:29,  1.39s/it, training loss=0.1657]\u001b[A\n",
            "Epoch 2:   0%|          | 7/1835 [00:09<42:25,  1.39s/it, training loss=0.1657]\u001b[A\n",
            "Epoch 2:   0%|          | 7/1835 [00:11<42:25,  1.39s/it, training loss=0.1868]\u001b[A\n",
            "Epoch 2:   0%|          | 8/1835 [00:11<42:26,  1.39s/it, training loss=0.1868]\u001b[A\n",
            "Epoch 2:   0%|          | 8/1835 [00:12<42:26,  1.39s/it, training loss=0.1309]\u001b[A\n",
            "Epoch 2:   0%|          | 9/1835 [00:12<42:25,  1.39s/it, training loss=0.1309]\u001b[A\n",
            "Epoch 2:   0%|          | 9/1835 [00:13<42:25,  1.39s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 2:   1%|          | 10/1835 [00:13<42:23,  1.39s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 2:   1%|          | 10/1835 [00:15<42:23,  1.39s/it, training loss=0.1559]\u001b[A\n",
            "Epoch 2:   1%|          | 11/1835 [00:15<42:21,  1.39s/it, training loss=0.1559]\u001b[A\n",
            "Epoch 2:   1%|          | 11/1835 [00:16<42:21,  1.39s/it, training loss=0.1262]\u001b[A\n",
            "Epoch 2:   1%|          | 12/1835 [00:16<42:21,  1.39s/it, training loss=0.1262]\u001b[A\n",
            "Epoch 2:   1%|          | 12/1835 [00:18<42:21,  1.39s/it, training loss=0.2221]\u001b[A\n",
            "Epoch 2:   1%|          | 13/1835 [00:18<42:21,  1.39s/it, training loss=0.2221]\u001b[A\n",
            "Epoch 2:   1%|          | 13/1835 [00:19<42:21,  1.39s/it, training loss=0.1880]\u001b[A\n",
            "Epoch 2:   1%|          | 14/1835 [00:19<42:21,  1.40s/it, training loss=0.1880]\u001b[A\n",
            "Epoch 2:   1%|          | 14/1835 [00:20<42:21,  1.40s/it, training loss=0.1247]\u001b[A\n",
            "Epoch 2:   1%|          | 15/1835 [00:20<42:20,  1.40s/it, training loss=0.1247]\u001b[A\n",
            "Epoch 2:   1%|          | 15/1835 [00:22<42:20,  1.40s/it, training loss=0.1361]\u001b[A\n",
            "Epoch 2:   1%|          | 16/1835 [00:22<42:36,  1.41s/it, training loss=0.1361]\u001b[A\n",
            "Epoch 2:   1%|          | 16/1835 [00:23<42:36,  1.41s/it, training loss=0.1102]\u001b[A\n",
            "Epoch 2:   1%|          | 17/1835 [00:23<42:33,  1.40s/it, training loss=0.1102]\u001b[A\n",
            "Epoch 2:   1%|          | 17/1835 [00:25<42:33,  1.40s/it, training loss=0.0771]\u001b[A\n",
            "Epoch 2:   1%|          | 18/1835 [00:25<42:24,  1.40s/it, training loss=0.0771]\u001b[A\n",
            "Epoch 2:   1%|          | 18/1835 [00:26<42:24,  1.40s/it, training loss=0.1500]\u001b[A\n",
            "Epoch 2:   1%|          | 19/1835 [00:26<42:19,  1.40s/it, training loss=0.1500]\u001b[A\n",
            "Epoch 2:   1%|          | 19/1835 [00:27<42:19,  1.40s/it, training loss=0.1091]\u001b[A\n",
            "Epoch 2:   1%|          | 20/1835 [00:27<42:20,  1.40s/it, training loss=0.1091]\u001b[A\n",
            "Epoch 2:   1%|          | 20/1835 [00:29<42:20,  1.40s/it, training loss=0.2212]\u001b[A\n",
            "Epoch 2:   1%|          | 21/1835 [00:29<42:14,  1.40s/it, training loss=0.2212]\u001b[A\n",
            "Epoch 2:   1%|          | 21/1835 [00:30<42:14,  1.40s/it, training loss=0.2155]\u001b[A\n",
            "Epoch 2:   1%|          | 22/1835 [00:30<42:11,  1.40s/it, training loss=0.2155]\u001b[A\n",
            "Epoch 2:   1%|          | 22/1835 [00:32<42:11,  1.40s/it, training loss=0.0695]\u001b[A\n",
            "Epoch 2:   1%|▏         | 23/1835 [00:32<42:10,  1.40s/it, training loss=0.0695]\u001b[A\n",
            "Epoch 2:   1%|▏         | 23/1835 [00:33<42:10,  1.40s/it, training loss=0.1445]\u001b[A\n",
            "Epoch 2:   1%|▏         | 24/1835 [00:33<42:08,  1.40s/it, training loss=0.1445]\u001b[A\n",
            "Epoch 2:   1%|▏         | 24/1835 [00:34<42:08,  1.40s/it, training loss=0.1268]\u001b[A\n",
            "Epoch 2:   1%|▏         | 25/1835 [00:34<42:10,  1.40s/it, training loss=0.1268]\u001b[A\n",
            "Epoch 2:   1%|▏         | 25/1835 [00:36<42:10,  1.40s/it, training loss=0.1340]\u001b[A\n",
            "Epoch 2:   1%|▏         | 26/1835 [00:36<42:04,  1.40s/it, training loss=0.1340]\u001b[A\n",
            "Epoch 2:   1%|▏         | 26/1835 [00:37<42:04,  1.40s/it, training loss=0.0585]\u001b[A\n",
            "Epoch 2:   1%|▏         | 27/1835 [00:37<42:02,  1.40s/it, training loss=0.0585]\u001b[A\n",
            "Epoch 2:   1%|▏         | 27/1835 [00:39<42:02,  1.40s/it, training loss=0.0623]\u001b[A\n",
            "Epoch 2:   2%|▏         | 28/1835 [00:39<41:58,  1.39s/it, training loss=0.0623]\u001b[A\n",
            "Epoch 2:   2%|▏         | 28/1835 [00:40<41:58,  1.39s/it, training loss=0.1239]\u001b[A\n",
            "Epoch 2:   2%|▏         | 29/1835 [00:40<42:01,  1.40s/it, training loss=0.1239]\u001b[A\n",
            "Epoch 2:   2%|▏         | 29/1835 [00:41<42:01,  1.40s/it, training loss=0.1387]\u001b[A\n",
            "Epoch 2:   2%|▏         | 30/1835 [00:41<42:01,  1.40s/it, training loss=0.1387]\u001b[A\n",
            "Epoch 2:   2%|▏         | 30/1835 [00:43<42:01,  1.40s/it, training loss=0.1919]\u001b[A\n",
            "Epoch 2:   2%|▏         | 31/1835 [00:43<41:57,  1.40s/it, training loss=0.1919]\u001b[A\n",
            "Epoch 2:   2%|▏         | 31/1835 [00:44<41:57,  1.40s/it, training loss=0.2538]\u001b[A\n",
            "Epoch 2:   2%|▏         | 32/1835 [00:44<41:55,  1.40s/it, training loss=0.2538]\u001b[A\n",
            "Epoch 2:   2%|▏         | 32/1835 [00:46<41:55,  1.40s/it, training loss=0.0938]\u001b[A\n",
            "Epoch 2:   2%|▏         | 33/1835 [00:46<41:54,  1.40s/it, training loss=0.0938]\u001b[A\n",
            "Epoch 2:   2%|▏         | 33/1835 [00:47<41:54,  1.40s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 2:   2%|▏         | 34/1835 [00:47<41:48,  1.39s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 2:   2%|▏         | 34/1835 [00:48<41:48,  1.39s/it, training loss=0.1339]\u001b[A\n",
            "Epoch 2:   2%|▏         | 35/1835 [00:48<41:44,  1.39s/it, training loss=0.1339]\u001b[A\n",
            "Epoch 2:   2%|▏         | 35/1835 [00:50<41:44,  1.39s/it, training loss=0.0870]\u001b[A\n",
            "Epoch 2:   2%|▏         | 36/1835 [00:50<41:45,  1.39s/it, training loss=0.0870]\u001b[A\n",
            "Epoch 2:   2%|▏         | 36/1835 [00:51<41:45,  1.39s/it, training loss=0.2433]\u001b[A\n",
            "Epoch 2:   2%|▏         | 37/1835 [00:51<41:40,  1.39s/it, training loss=0.2433]\u001b[A\n",
            "Epoch 2:   2%|▏         | 37/1835 [00:53<41:40,  1.39s/it, training loss=0.1155]\u001b[A\n",
            "Epoch 2:   2%|▏         | 38/1835 [00:53<41:40,  1.39s/it, training loss=0.1155]\u001b[A\n",
            "Epoch 2:   2%|▏         | 38/1835 [00:54<41:40,  1.39s/it, training loss=0.1012]\u001b[A\n",
            "Epoch 2:   2%|▏         | 39/1835 [00:54<41:43,  1.39s/it, training loss=0.1012]\u001b[A\n",
            "Epoch 2:   2%|▏         | 39/1835 [00:55<41:43,  1.39s/it, training loss=0.1589]\u001b[A\n",
            "Epoch 2:   2%|▏         | 40/1835 [00:55<41:44,  1.40s/it, training loss=0.1589]\u001b[A\n",
            "Epoch 2:   2%|▏         | 40/1835 [00:57<41:44,  1.40s/it, training loss=0.0726]\u001b[A\n",
            "Epoch 2:   2%|▏         | 41/1835 [00:57<41:41,  1.39s/it, training loss=0.0726]\u001b[A\n",
            "Epoch 2:   2%|▏         | 41/1835 [00:58<41:41,  1.39s/it, training loss=0.1443]\u001b[A\n",
            "Epoch 2:   2%|▏         | 42/1835 [00:58<41:44,  1.40s/it, training loss=0.1443]\u001b[A\n",
            "Epoch 2:   2%|▏         | 42/1835 [00:59<41:44,  1.40s/it, training loss=0.0905]\u001b[A\n",
            "Epoch 2:   2%|▏         | 43/1835 [00:59<41:40,  1.40s/it, training loss=0.0905]\u001b[A\n",
            "Epoch 2:   2%|▏         | 43/1835 [01:01<41:40,  1.40s/it, training loss=0.4797]\u001b[A\n",
            "Epoch 2:   2%|▏         | 44/1835 [01:01<41:41,  1.40s/it, training loss=0.4797]\u001b[A\n",
            "Epoch 2:   2%|▏         | 44/1835 [01:02<41:41,  1.40s/it, training loss=0.0943]\u001b[A\n",
            "Epoch 2:   2%|▏         | 45/1835 [01:02<41:36,  1.39s/it, training loss=0.0943]\u001b[A\n",
            "Epoch 2:   2%|▏         | 45/1835 [01:04<41:36,  1.39s/it, training loss=0.0977]\u001b[A\n",
            "Epoch 2:   3%|▎         | 46/1835 [01:04<41:37,  1.40s/it, training loss=0.0977]\u001b[A\n",
            "Epoch 2:   3%|▎         | 46/1835 [01:05<41:37,  1.40s/it, training loss=0.1367]\u001b[A\n",
            "Epoch 2:   3%|▎         | 47/1835 [01:05<41:38,  1.40s/it, training loss=0.1367]\u001b[A\n",
            "Epoch 2:   3%|▎         | 47/1835 [01:06<41:38,  1.40s/it, training loss=0.3594]\u001b[A\n",
            "Epoch 2:   3%|▎         | 48/1835 [01:06<41:40,  1.40s/it, training loss=0.3594]\u001b[A\n",
            "Epoch 2:   3%|▎         | 48/1835 [01:08<41:40,  1.40s/it, training loss=0.1385]\u001b[A\n",
            "Epoch 2:   3%|▎         | 49/1835 [01:08<41:36,  1.40s/it, training loss=0.1385]\u001b[A\n",
            "Epoch 2:   3%|▎         | 49/1835 [01:09<41:36,  1.40s/it, training loss=0.2472]\u001b[A\n",
            "Epoch 2:   3%|▎         | 50/1835 [01:09<41:32,  1.40s/it, training loss=0.2472]\u001b[A\n",
            "Epoch 2:   3%|▎         | 50/1835 [01:11<41:32,  1.40s/it, training loss=0.0569]\u001b[A\n",
            "Epoch 2:   3%|▎         | 51/1835 [01:11<41:32,  1.40s/it, training loss=0.0569]\u001b[A\n",
            "Epoch 2:   3%|▎         | 51/1835 [01:12<41:32,  1.40s/it, training loss=0.1023]\u001b[A\n",
            "Epoch 2:   3%|▎         | 52/1835 [01:12<41:31,  1.40s/it, training loss=0.1023]\u001b[A\n",
            "Epoch 2:   3%|▎         | 52/1835 [01:13<41:31,  1.40s/it, training loss=0.2361]\u001b[A\n",
            "Epoch 2:   3%|▎         | 53/1835 [01:13<41:24,  1.39s/it, training loss=0.2361]\u001b[A\n",
            "Epoch 2:   3%|▎         | 53/1835 [01:15<41:24,  1.39s/it, training loss=0.0401]\u001b[A\n",
            "Epoch 2:   3%|▎         | 54/1835 [01:15<41:23,  1.39s/it, training loss=0.0401]\u001b[A\n",
            "Epoch 2:   3%|▎         | 54/1835 [01:16<41:23,  1.39s/it, training loss=0.1384]\u001b[A\n",
            "Epoch 2:   3%|▎         | 55/1835 [01:16<41:22,  1.39s/it, training loss=0.1384]\u001b[A\n",
            "Epoch 2:   3%|▎         | 55/1835 [01:18<41:22,  1.39s/it, training loss=0.2264]\u001b[A\n",
            "Epoch 2:   3%|▎         | 56/1835 [01:18<41:20,  1.39s/it, training loss=0.2264]\u001b[A\n",
            "Epoch 2:   3%|▎         | 56/1835 [01:19<41:20,  1.39s/it, training loss=0.2297]\u001b[A\n",
            "Epoch 2:   3%|▎         | 57/1835 [01:19<41:17,  1.39s/it, training loss=0.2297]\u001b[A\n",
            "Epoch 2:   3%|▎         | 57/1835 [01:20<41:17,  1.39s/it, training loss=0.0803]\u001b[A\n",
            "Epoch 2:   3%|▎         | 58/1835 [01:20<41:48,  1.41s/it, training loss=0.0803]\u001b[A\n",
            "Epoch 2:   3%|▎         | 58/1835 [01:22<41:48,  1.41s/it, training loss=0.1279]\u001b[A\n",
            "Epoch 2:   3%|▎         | 59/1835 [01:22<42:03,  1.42s/it, training loss=0.1279]\u001b[A\n",
            "Epoch 2:   3%|▎         | 59/1835 [01:23<42:03,  1.42s/it, training loss=0.1216]\u001b[A\n",
            "Epoch 2:   3%|▎         | 60/1835 [01:23<42:34,  1.44s/it, training loss=0.1216]\u001b[A\n",
            "Epoch 2:   3%|▎         | 60/1835 [01:25<42:34,  1.44s/it, training loss=0.0877]\u001b[A\n",
            "Epoch 2:   3%|▎         | 61/1835 [01:25<42:08,  1.43s/it, training loss=0.0877]\u001b[A\n",
            "Epoch 2:   3%|▎         | 61/1835 [01:26<42:08,  1.43s/it, training loss=0.1916]\u001b[A\n",
            "Epoch 2:   3%|▎         | 62/1835 [01:26<41:47,  1.41s/it, training loss=0.1916]\u001b[A\n",
            "Epoch 2:   3%|▎         | 62/1835 [01:28<41:47,  1.41s/it, training loss=0.0822]\u001b[A\n",
            "Epoch 2:   3%|▎         | 63/1835 [01:28<41:33,  1.41s/it, training loss=0.0822]\u001b[A\n",
            "Epoch 2:   3%|▎         | 63/1835 [01:29<41:33,  1.41s/it, training loss=0.0562]\u001b[A\n",
            "Epoch 2:   3%|▎         | 64/1835 [01:29<41:25,  1.40s/it, training loss=0.0562]\u001b[A\n",
            "Epoch 2:   3%|▎         | 64/1835 [01:30<41:25,  1.40s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 2:   4%|▎         | 65/1835 [01:30<41:16,  1.40s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 2:   4%|▎         | 65/1835 [01:32<41:16,  1.40s/it, training loss=0.3277]\u001b[A\n",
            "Epoch 2:   4%|▎         | 66/1835 [01:32<41:12,  1.40s/it, training loss=0.3277]\u001b[A\n",
            "Epoch 2:   4%|▎         | 66/1835 [01:33<41:12,  1.40s/it, training loss=0.1050]\u001b[A\n",
            "Epoch 2:   4%|▎         | 67/1835 [01:33<41:13,  1.40s/it, training loss=0.1050]\u001b[A\n",
            "Epoch 2:   4%|▎         | 67/1835 [01:35<41:13,  1.40s/it, training loss=0.2559]\u001b[A\n",
            "Epoch 2:   4%|▎         | 68/1835 [01:35<41:06,  1.40s/it, training loss=0.2559]\u001b[A\n",
            "Epoch 2:   4%|▎         | 68/1835 [01:36<41:06,  1.40s/it, training loss=0.0372]\u001b[A\n",
            "Epoch 2:   4%|▍         | 69/1835 [01:36<41:02,  1.39s/it, training loss=0.0372]\u001b[A\n",
            "Epoch 2:   4%|▍         | 69/1835 [01:37<41:02,  1.39s/it, training loss=0.1458]\u001b[A\n",
            "Epoch 2:   4%|▍         | 70/1835 [01:37<41:03,  1.40s/it, training loss=0.1458]\u001b[A\n",
            "Epoch 2:   4%|▍         | 70/1835 [01:39<41:03,  1.40s/it, training loss=0.1254]\u001b[A\n",
            "Epoch 2:   4%|▍         | 71/1835 [01:39<41:01,  1.40s/it, training loss=0.1254]\u001b[A\n",
            "Epoch 2:   4%|▍         | 71/1835 [01:40<41:01,  1.40s/it, training loss=0.1935]\u001b[A\n",
            "Epoch 2:   4%|▍         | 72/1835 [01:40<40:59,  1.40s/it, training loss=0.1935]\u001b[A\n",
            "Epoch 2:   4%|▍         | 72/1835 [01:42<40:59,  1.40s/it, training loss=0.0797]\u001b[A\n",
            "Epoch 2:   4%|▍         | 73/1835 [01:42<40:58,  1.40s/it, training loss=0.0797]\u001b[A\n",
            "Epoch 2:   4%|▍         | 73/1835 [01:43<40:58,  1.40s/it, training loss=0.1726]\u001b[A\n",
            "Epoch 2:   4%|▍         | 74/1835 [01:43<40:54,  1.39s/it, training loss=0.1726]\u001b[A\n",
            "Epoch 2:   4%|▍         | 74/1835 [01:44<40:54,  1.39s/it, training loss=0.1222]\u001b[A\n",
            "Epoch 2:   4%|▍         | 75/1835 [01:44<40:54,  1.39s/it, training loss=0.1222]\u001b[A\n",
            "Epoch 2:   4%|▍         | 75/1835 [01:46<40:54,  1.39s/it, training loss=0.0697]\u001b[A\n",
            "Epoch 2:   4%|▍         | 76/1835 [01:46<40:53,  1.39s/it, training loss=0.0697]\u001b[A\n",
            "Epoch 2:   4%|▍         | 76/1835 [01:47<40:53,  1.39s/it, training loss=0.1841]\u001b[A\n",
            "Epoch 2:   4%|▍         | 77/1835 [01:47<40:54,  1.40s/it, training loss=0.1841]\u001b[A\n",
            "Epoch 2:   4%|▍         | 77/1835 [01:49<40:54,  1.40s/it, training loss=0.0347]\u001b[A\n",
            "Epoch 2:   4%|▍         | 78/1835 [01:49<40:54,  1.40s/it, training loss=0.0347]\u001b[A\n",
            "Epoch 2:   4%|▍         | 78/1835 [01:50<40:54,  1.40s/it, training loss=0.3373]\u001b[A\n",
            "Epoch 2:   4%|▍         | 79/1835 [01:50<40:53,  1.40s/it, training loss=0.3373]\u001b[A\n",
            "Epoch 2:   4%|▍         | 79/1835 [01:51<40:53,  1.40s/it, training loss=0.1651]\u001b[A\n",
            "Epoch 2:   4%|▍         | 80/1835 [01:51<40:52,  1.40s/it, training loss=0.1651]\u001b[A\n",
            "Epoch 2:   4%|▍         | 80/1835 [01:53<40:52,  1.40s/it, training loss=0.0616]\u001b[A\n",
            "Epoch 2:   4%|▍         | 81/1835 [01:53<40:48,  1.40s/it, training loss=0.0616]\u001b[A\n",
            "Epoch 2:   4%|▍         | 81/1835 [01:54<40:48,  1.40s/it, training loss=0.1057]\u001b[A\n",
            "Epoch 2:   4%|▍         | 82/1835 [01:54<40:46,  1.40s/it, training loss=0.1057]\u001b[A\n",
            "Epoch 2:   4%|▍         | 82/1835 [01:55<40:46,  1.40s/it, training loss=0.2279]\u001b[A\n",
            "Epoch 2:   5%|▍         | 83/1835 [01:55<40:39,  1.39s/it, training loss=0.2279]\u001b[A\n",
            "Epoch 2:   5%|▍         | 83/1835 [01:57<40:39,  1.39s/it, training loss=0.0975]\u001b[A\n",
            "Epoch 2:   5%|▍         | 84/1835 [01:57<40:34,  1.39s/it, training loss=0.0975]\u001b[A\n",
            "Epoch 2:   5%|▍         | 84/1835 [01:58<40:34,  1.39s/it, training loss=0.0438]\u001b[A\n",
            "Epoch 2:   5%|▍         | 85/1835 [01:58<40:32,  1.39s/it, training loss=0.0438]\u001b[A\n",
            "Epoch 2:   5%|▍         | 85/1835 [02:00<40:32,  1.39s/it, training loss=0.1300]\u001b[A\n",
            "Epoch 2:   5%|▍         | 86/1835 [02:00<40:29,  1.39s/it, training loss=0.1300]\u001b[A\n",
            "Epoch 2:   5%|▍         | 86/1835 [02:01<40:29,  1.39s/it, training loss=0.2687]\u001b[A\n",
            "Epoch 2:   5%|▍         | 87/1835 [02:01<40:31,  1.39s/it, training loss=0.2687]\u001b[A\n",
            "Epoch 2:   5%|▍         | 87/1835 [02:02<40:31,  1.39s/it, training loss=0.1197]\u001b[A\n",
            "Epoch 2:   5%|▍         | 88/1835 [02:02<40:35,  1.39s/it, training loss=0.1197]\u001b[A\n",
            "Epoch 2:   5%|▍         | 88/1835 [02:04<40:35,  1.39s/it, training loss=0.1843]\u001b[A\n",
            "Epoch 2:   5%|▍         | 89/1835 [02:04<40:38,  1.40s/it, training loss=0.1843]\u001b[A\n",
            "Epoch 2:   5%|▍         | 89/1835 [02:05<40:38,  1.40s/it, training loss=0.0703]\u001b[A\n",
            "Epoch 2:   5%|▍         | 90/1835 [02:05<40:32,  1.39s/it, training loss=0.0703]\u001b[A\n",
            "Epoch 2:   5%|▍         | 90/1835 [02:07<40:32,  1.39s/it, training loss=0.2047]\u001b[A\n",
            "Epoch 2:   5%|▍         | 91/1835 [02:07<40:34,  1.40s/it, training loss=0.2047]\u001b[A\n",
            "Epoch 2:   5%|▍         | 91/1835 [02:08<40:34,  1.40s/it, training loss=0.1455]\u001b[A\n",
            "Epoch 2:   5%|▌         | 92/1835 [02:08<40:29,  1.39s/it, training loss=0.1455]\u001b[A\n",
            "Epoch 2:   5%|▌         | 92/1835 [02:09<40:29,  1.39s/it, training loss=0.1231]\u001b[A\n",
            "Epoch 2:   5%|▌         | 93/1835 [02:09<40:27,  1.39s/it, training loss=0.1231]\u001b[A\n",
            "Epoch 2:   5%|▌         | 93/1835 [02:11<40:27,  1.39s/it, training loss=0.0894]\u001b[A\n",
            "Epoch 2:   5%|▌         | 94/1835 [02:11<40:25,  1.39s/it, training loss=0.0894]\u001b[A\n",
            "Epoch 2:   5%|▌         | 94/1835 [02:12<40:25,  1.39s/it, training loss=0.1095]\u001b[A\n",
            "Epoch 2:   5%|▌         | 95/1835 [02:12<40:20,  1.39s/it, training loss=0.1095]\u001b[A\n",
            "Epoch 2:   5%|▌         | 95/1835 [02:14<40:20,  1.39s/it, training loss=0.1629]\u001b[A\n",
            "Epoch 2:   5%|▌         | 96/1835 [02:14<40:26,  1.40s/it, training loss=0.1629]\u001b[A\n",
            "Epoch 2:   5%|▌         | 96/1835 [02:15<40:26,  1.40s/it, training loss=0.2600]\u001b[A\n",
            "Epoch 2:   5%|▌         | 97/1835 [02:15<40:27,  1.40s/it, training loss=0.2600]\u001b[A\n",
            "Epoch 2:   5%|▌         | 97/1835 [02:16<40:27,  1.40s/it, training loss=0.0684]\u001b[A\n",
            "Epoch 2:   5%|▌         | 98/1835 [02:16<40:24,  1.40s/it, training loss=0.0684]\u001b[A\n",
            "Epoch 2:   5%|▌         | 98/1835 [02:18<40:24,  1.40s/it, training loss=0.1083]\u001b[A\n",
            "Epoch 2:   5%|▌         | 99/1835 [02:18<40:25,  1.40s/it, training loss=0.1083]\u001b[A\n",
            "Epoch 2:   5%|▌         | 99/1835 [02:19<40:25,  1.40s/it, training loss=0.1763]\u001b[A\n",
            "Epoch 2:   5%|▌         | 100/1835 [02:19<40:23,  1.40s/it, training loss=0.1763]\u001b[A\n",
            "Epoch 2:   5%|▌         | 100/1835 [02:21<40:23,  1.40s/it, training loss=0.1570]\u001b[A\n",
            "Epoch 2:   6%|▌         | 101/1835 [02:21<40:18,  1.39s/it, training loss=0.1570]\u001b[A\n",
            "Epoch 2:   6%|▌         | 101/1835 [02:22<40:18,  1.39s/it, training loss=0.2351]\u001b[A\n",
            "Epoch 2:   6%|▌         | 102/1835 [02:22<40:19,  1.40s/it, training loss=0.2351]\u001b[A\n",
            "Epoch 2:   6%|▌         | 102/1835 [02:23<40:19,  1.40s/it, training loss=0.2834]\u001b[A\n",
            "Epoch 2:   6%|▌         | 103/1835 [02:23<40:21,  1.40s/it, training loss=0.2834]\u001b[A\n",
            "Epoch 2:   6%|▌         | 103/1835 [02:25<40:21,  1.40s/it, training loss=0.2189]\u001b[A\n",
            "Epoch 2:   6%|▌         | 104/1835 [02:25<40:18,  1.40s/it, training loss=0.2189]\u001b[A\n",
            "Epoch 2:   6%|▌         | 104/1835 [02:26<40:18,  1.40s/it, training loss=0.0434]\u001b[A\n",
            "Epoch 2:   6%|▌         | 105/1835 [02:26<40:14,  1.40s/it, training loss=0.0434]\u001b[A\n",
            "Epoch 2:   6%|▌         | 105/1835 [02:28<40:14,  1.40s/it, training loss=0.1087]\u001b[A\n",
            "Epoch 2:   6%|▌         | 106/1835 [02:28<40:11,  1.39s/it, training loss=0.1087]\u001b[A\n",
            "Epoch 2:   6%|▌         | 106/1835 [02:29<40:11,  1.39s/it, training loss=0.1852]\u001b[A\n",
            "Epoch 2:   6%|▌         | 107/1835 [02:29<40:07,  1.39s/it, training loss=0.1852]\u001b[A\n",
            "Epoch 2:   6%|▌         | 107/1835 [02:30<40:07,  1.39s/it, training loss=0.2805]\u001b[A\n",
            "Epoch 2:   6%|▌         | 108/1835 [02:30<40:06,  1.39s/it, training loss=0.2805]\u001b[A\n",
            "Epoch 2:   6%|▌         | 108/1835 [02:32<40:06,  1.39s/it, training loss=0.2271]\u001b[A\n",
            "Epoch 2:   6%|▌         | 109/1835 [02:32<40:02,  1.39s/it, training loss=0.2271]\u001b[A\n",
            "Epoch 2:   6%|▌         | 109/1835 [02:33<40:02,  1.39s/it, training loss=0.2026]\u001b[A\n",
            "Epoch 2:   6%|▌         | 110/1835 [02:33<40:03,  1.39s/it, training loss=0.2026]\u001b[A\n",
            "Epoch 2:   6%|▌         | 110/1835 [02:35<40:03,  1.39s/it, training loss=0.0690]\u001b[A\n",
            "Epoch 2:   6%|▌         | 111/1835 [02:35<40:03,  1.39s/it, training loss=0.0690]\u001b[A\n",
            "Epoch 2:   6%|▌         | 111/1835 [02:36<40:03,  1.39s/it, training loss=0.0817]\u001b[A\n",
            "Epoch 2:   6%|▌         | 112/1835 [02:36<39:59,  1.39s/it, training loss=0.0817]\u001b[A\n",
            "Epoch 2:   6%|▌         | 112/1835 [02:37<39:59,  1.39s/it, training loss=0.0612]\u001b[A\n",
            "Epoch 2:   6%|▌         | 113/1835 [02:37<40:01,  1.39s/it, training loss=0.0612]\u001b[A\n",
            "Epoch 2:   6%|▌         | 113/1835 [02:39<40:01,  1.39s/it, training loss=0.1628]\u001b[A\n",
            "Epoch 2:   6%|▌         | 114/1835 [02:39<40:00,  1.39s/it, training loss=0.1628]\u001b[A\n",
            "Epoch 2:   6%|▌         | 114/1835 [02:40<40:00,  1.39s/it, training loss=0.1073]\u001b[A\n",
            "Epoch 2:   6%|▋         | 115/1835 [02:40<39:54,  1.39s/it, training loss=0.1073]\u001b[A\n",
            "Epoch 2:   6%|▋         | 115/1835 [02:41<39:54,  1.39s/it, training loss=0.1622]\u001b[A\n",
            "Epoch 2:   6%|▋         | 116/1835 [02:41<39:50,  1.39s/it, training loss=0.1622]\u001b[A\n",
            "Epoch 2:   6%|▋         | 116/1835 [02:43<39:50,  1.39s/it, training loss=0.1304]\u001b[A\n",
            "Epoch 2:   6%|▋         | 117/1835 [02:43<39:52,  1.39s/it, training loss=0.1304]\u001b[A\n",
            "Epoch 2:   6%|▋         | 117/1835 [02:44<39:52,  1.39s/it, training loss=0.0704]\u001b[A\n",
            "Epoch 2:   6%|▋         | 118/1835 [02:44<39:56,  1.40s/it, training loss=0.0704]\u001b[A\n",
            "Epoch 2:   6%|▋         | 118/1835 [02:46<39:56,  1.40s/it, training loss=0.1622]\u001b[A\n",
            "Epoch 2:   6%|▋         | 119/1835 [02:46<39:54,  1.40s/it, training loss=0.1622]\u001b[A\n",
            "Epoch 2:   6%|▋         | 119/1835 [02:47<39:54,  1.40s/it, training loss=0.1161]\u001b[A\n",
            "Epoch 2:   7%|▋         | 120/1835 [02:47<39:56,  1.40s/it, training loss=0.1161]\u001b[A\n",
            "Epoch 2:   7%|▋         | 120/1835 [02:48<39:56,  1.40s/it, training loss=0.1474]\u001b[A\n",
            "Epoch 2:   7%|▋         | 121/1835 [02:48<39:55,  1.40s/it, training loss=0.1474]\u001b[A\n",
            "Epoch 2:   7%|▋         | 121/1835 [02:50<39:55,  1.40s/it, training loss=0.1803]\u001b[A\n",
            "Epoch 2:   7%|▋         | 122/1835 [02:50<39:53,  1.40s/it, training loss=0.1803]\u001b[A\n",
            "Epoch 2:   7%|▋         | 122/1835 [02:51<39:53,  1.40s/it, training loss=0.1362]\u001b[A\n",
            "Epoch 2:   7%|▋         | 123/1835 [02:51<39:47,  1.39s/it, training loss=0.1362]\u001b[A\n",
            "Epoch 2:   7%|▋         | 123/1835 [02:53<39:47,  1.39s/it, training loss=0.1185]\u001b[A\n",
            "Epoch 2:   7%|▋         | 124/1835 [02:53<39:50,  1.40s/it, training loss=0.1185]\u001b[A\n",
            "Epoch 2:   7%|▋         | 124/1835 [02:54<39:50,  1.40s/it, training loss=0.1283]\u001b[A\n",
            "Epoch 2:   7%|▋         | 125/1835 [02:54<39:46,  1.40s/it, training loss=0.1283]\u001b[A\n",
            "Epoch 2:   7%|▋         | 125/1835 [02:55<39:46,  1.40s/it, training loss=0.1582]\u001b[A\n",
            "Epoch 2:   7%|▋         | 126/1835 [02:55<39:39,  1.39s/it, training loss=0.1582]\u001b[A\n",
            "Epoch 2:   7%|▋         | 126/1835 [02:57<39:39,  1.39s/it, training loss=0.2080]\u001b[A\n",
            "Epoch 2:   7%|▋         | 127/1835 [02:57<39:39,  1.39s/it, training loss=0.2080]\u001b[A\n",
            "Epoch 2:   7%|▋         | 127/1835 [02:58<39:39,  1.39s/it, training loss=0.1960]\u001b[A\n",
            "Epoch 2:   7%|▋         | 128/1835 [02:58<39:40,  1.39s/it, training loss=0.1960]\u001b[A\n",
            "Epoch 2:   7%|▋         | 128/1835 [03:00<39:40,  1.39s/it, training loss=0.2126]\u001b[A\n",
            "Epoch 2:   7%|▋         | 129/1835 [03:00<39:39,  1.39s/it, training loss=0.2126]\u001b[A\n",
            "Epoch 2:   7%|▋         | 129/1835 [03:01<39:39,  1.39s/it, training loss=0.1198]\u001b[A\n",
            "Epoch 2:   7%|▋         | 130/1835 [03:01<39:36,  1.39s/it, training loss=0.1198]\u001b[A\n",
            "Epoch 2:   7%|▋         | 130/1835 [03:02<39:36,  1.39s/it, training loss=0.0652]\u001b[A\n",
            "Epoch 2:   7%|▋         | 131/1835 [03:02<39:38,  1.40s/it, training loss=0.0652]\u001b[A\n",
            "Epoch 2:   7%|▋         | 131/1835 [03:04<39:38,  1.40s/it, training loss=0.2621]\u001b[A\n",
            "Epoch 2:   7%|▋         | 132/1835 [03:04<39:36,  1.40s/it, training loss=0.2621]\u001b[A\n",
            "Epoch 2:   7%|▋         | 132/1835 [03:05<39:36,  1.40s/it, training loss=0.0941]\u001b[A\n",
            "Epoch 2:   7%|▋         | 133/1835 [03:05<39:34,  1.39s/it, training loss=0.0941]\u001b[A\n",
            "Epoch 2:   7%|▋         | 133/1835 [03:07<39:34,  1.39s/it, training loss=0.0962]\u001b[A\n",
            "Epoch 2:   7%|▋         | 134/1835 [03:07<39:35,  1.40s/it, training loss=0.0962]\u001b[A\n",
            "Epoch 2:   7%|▋         | 134/1835 [03:08<39:35,  1.40s/it, training loss=0.1226]\u001b[A\n",
            "Epoch 2:   7%|▋         | 135/1835 [03:08<39:33,  1.40s/it, training loss=0.1226]\u001b[A\n",
            "Epoch 2:   7%|▋         | 135/1835 [03:09<39:33,  1.40s/it, training loss=0.1057]\u001b[A\n",
            "Epoch 2:   7%|▋         | 136/1835 [03:09<39:33,  1.40s/it, training loss=0.1057]\u001b[A\n",
            "Epoch 2:   7%|▋         | 136/1835 [03:11<39:33,  1.40s/it, training loss=0.0394]\u001b[A\n",
            "Epoch 2:   7%|▋         | 137/1835 [03:11<39:31,  1.40s/it, training loss=0.0394]\u001b[A\n",
            "Epoch 2:   7%|▋         | 137/1835 [03:12<39:31,  1.40s/it, training loss=0.1884]\u001b[A\n",
            "Epoch 2:   8%|▊         | 138/1835 [03:12<39:30,  1.40s/it, training loss=0.1884]\u001b[A\n",
            "Epoch 2:   8%|▊         | 138/1835 [03:14<39:30,  1.40s/it, training loss=0.1030]\u001b[A\n",
            "Epoch 2:   8%|▊         | 139/1835 [03:14<39:26,  1.40s/it, training loss=0.1030]\u001b[A\n",
            "Epoch 2:   8%|▊         | 139/1835 [03:15<39:26,  1.40s/it, training loss=0.0650]\u001b[A\n",
            "Epoch 2:   8%|▊         | 140/1835 [03:15<39:27,  1.40s/it, training loss=0.0650]\u001b[A\n",
            "Epoch 2:   8%|▊         | 140/1835 [03:16<39:27,  1.40s/it, training loss=0.0821]\u001b[A\n",
            "Epoch 2:   8%|▊         | 141/1835 [03:16<39:25,  1.40s/it, training loss=0.0821]\u001b[A\n",
            "Epoch 2:   8%|▊         | 141/1835 [03:18<39:25,  1.40s/it, training loss=0.0972]\u001b[A\n",
            "Epoch 2:   8%|▊         | 142/1835 [03:18<39:19,  1.39s/it, training loss=0.0972]\u001b[A\n",
            "Epoch 2:   8%|▊         | 142/1835 [03:19<39:19,  1.39s/it, training loss=0.1473]\u001b[A\n",
            "Epoch 2:   8%|▊         | 143/1835 [03:19<39:17,  1.39s/it, training loss=0.1473]\u001b[A\n",
            "Epoch 2:   8%|▊         | 143/1835 [03:21<39:17,  1.39s/it, training loss=0.2467]\u001b[A\n",
            "Epoch 2:   8%|▊         | 144/1835 [03:21<39:15,  1.39s/it, training loss=0.2467]\u001b[A\n",
            "Epoch 2:   8%|▊         | 144/1835 [03:22<39:15,  1.39s/it, training loss=0.2032]\u001b[A\n",
            "Epoch 2:   8%|▊         | 145/1835 [03:22<39:13,  1.39s/it, training loss=0.2032]\u001b[A\n",
            "Epoch 2:   8%|▊         | 145/1835 [03:23<39:13,  1.39s/it, training loss=0.0688]\u001b[A\n",
            "Epoch 2:   8%|▊         | 146/1835 [03:23<39:16,  1.40s/it, training loss=0.0688]\u001b[A\n",
            "Epoch 2:   8%|▊         | 146/1835 [03:25<39:16,  1.40s/it, training loss=0.1702]\u001b[A\n",
            "Epoch 2:   8%|▊         | 147/1835 [03:25<39:15,  1.40s/it, training loss=0.1702]\u001b[A\n",
            "Epoch 2:   8%|▊         | 147/1835 [03:26<39:15,  1.40s/it, training loss=0.1328]\u001b[A\n",
            "Epoch 2:   8%|▊         | 148/1835 [03:26<39:12,  1.39s/it, training loss=0.1328]\u001b[A\n",
            "Epoch 2:   8%|▊         | 148/1835 [03:28<39:12,  1.39s/it, training loss=0.0608]\u001b[A\n",
            "Epoch 2:   8%|▊         | 149/1835 [03:28<39:08,  1.39s/it, training loss=0.0608]\u001b[A\n",
            "Epoch 2:   8%|▊         | 149/1835 [03:29<39:08,  1.39s/it, training loss=0.1570]\u001b[A\n",
            "Epoch 2:   8%|▊         | 150/1835 [03:29<39:11,  1.40s/it, training loss=0.1570]\u001b[A\n",
            "Epoch 2:   8%|▊         | 150/1835 [03:30<39:11,  1.40s/it, training loss=0.1858]\u001b[A\n",
            "Epoch 2:   8%|▊         | 151/1835 [03:30<39:09,  1.40s/it, training loss=0.1858]\u001b[A\n",
            "Epoch 2:   8%|▊         | 151/1835 [03:32<39:09,  1.40s/it, training loss=0.1382]\u001b[A\n",
            "Epoch 2:   8%|▊         | 152/1835 [03:32<39:12,  1.40s/it, training loss=0.1382]\u001b[A\n",
            "Epoch 2:   8%|▊         | 152/1835 [03:33<39:12,  1.40s/it, training loss=0.1576]\u001b[A\n",
            "Epoch 2:   8%|▊         | 153/1835 [03:33<39:09,  1.40s/it, training loss=0.1576]\u001b[A\n",
            "Epoch 2:   8%|▊         | 153/1835 [03:35<39:09,  1.40s/it, training loss=0.0741]\u001b[A\n",
            "Epoch 2:   8%|▊         | 154/1835 [03:35<39:06,  1.40s/it, training loss=0.0741]\u001b[A\n",
            "Epoch 2:   8%|▊         | 154/1835 [03:36<39:06,  1.40s/it, training loss=0.1634]\u001b[A\n",
            "Epoch 2:   8%|▊         | 155/1835 [03:36<39:05,  1.40s/it, training loss=0.1634]\u001b[A\n",
            "Epoch 2:   8%|▊         | 155/1835 [03:37<39:05,  1.40s/it, training loss=0.2385]\u001b[A\n",
            "Epoch 2:   9%|▊         | 156/1835 [03:37<39:03,  1.40s/it, training loss=0.2385]\u001b[A\n",
            "Epoch 2:   9%|▊         | 156/1835 [03:39<39:03,  1.40s/it, training loss=0.2790]\u001b[A\n",
            "Epoch 2:   9%|▊         | 157/1835 [03:39<39:02,  1.40s/it, training loss=0.2790]\u001b[A\n",
            "Epoch 2:   9%|▊         | 157/1835 [03:40<39:02,  1.40s/it, training loss=0.3855]\u001b[A\n",
            "Epoch 2:   9%|▊         | 158/1835 [03:40<39:04,  1.40s/it, training loss=0.3855]\u001b[A\n",
            "Epoch 2:   9%|▊         | 158/1835 [03:41<39:04,  1.40s/it, training loss=0.0899]\u001b[A\n",
            "Epoch 2:   9%|▊         | 159/1835 [03:41<39:02,  1.40s/it, training loss=0.0899]\u001b[A\n",
            "Epoch 2:   9%|▊         | 159/1835 [03:43<39:02,  1.40s/it, training loss=0.1936]\u001b[A\n",
            "Epoch 2:   9%|▊         | 160/1835 [03:43<38:58,  1.40s/it, training loss=0.1936]\u001b[A\n",
            "Epoch 2:   9%|▊         | 160/1835 [03:44<38:58,  1.40s/it, training loss=0.1009]\u001b[A\n",
            "Epoch 2:   9%|▉         | 161/1835 [03:44<38:54,  1.39s/it, training loss=0.1009]\u001b[A\n",
            "Epoch 2:   9%|▉         | 161/1835 [03:46<38:54,  1.39s/it, training loss=0.1021]\u001b[A\n",
            "Epoch 2:   9%|▉         | 162/1835 [03:46<38:51,  1.39s/it, training loss=0.1021]\u001b[A\n",
            "Epoch 2:   9%|▉         | 162/1835 [03:47<38:51,  1.39s/it, training loss=0.1108]\u001b[A\n",
            "Epoch 2:   9%|▉         | 163/1835 [03:47<38:45,  1.39s/it, training loss=0.1108]\u001b[A\n",
            "Epoch 2:   9%|▉         | 163/1835 [03:48<38:45,  1.39s/it, training loss=0.1904]\u001b[A\n",
            "Epoch 2:   9%|▉         | 164/1835 [03:48<38:45,  1.39s/it, training loss=0.1904]\u001b[A\n",
            "Epoch 2:   9%|▉         | 164/1835 [03:50<38:45,  1.39s/it, training loss=0.1506]\u001b[A\n",
            "Epoch 2:   9%|▉         | 165/1835 [03:50<38:45,  1.39s/it, training loss=0.1506]\u001b[A\n",
            "Epoch 2:   9%|▉         | 165/1835 [03:51<38:45,  1.39s/it, training loss=0.0613]\u001b[A\n",
            "Epoch 2:   9%|▉         | 166/1835 [03:51<38:41,  1.39s/it, training loss=0.0613]\u001b[A\n",
            "Epoch 2:   9%|▉         | 166/1835 [03:53<38:41,  1.39s/it, training loss=0.0990]\u001b[A\n",
            "Epoch 2:   9%|▉         | 167/1835 [03:53<38:41,  1.39s/it, training loss=0.0990]\u001b[A\n",
            "Epoch 2:   9%|▉         | 167/1835 [03:54<38:41,  1.39s/it, training loss=0.1390]\u001b[A\n",
            "Epoch 2:   9%|▉         | 168/1835 [03:54<38:36,  1.39s/it, training loss=0.1390]\u001b[A\n",
            "Epoch 2:   9%|▉         | 168/1835 [03:55<38:36,  1.39s/it, training loss=0.0432]\u001b[A\n",
            "Epoch 2:   9%|▉         | 169/1835 [03:55<38:34,  1.39s/it, training loss=0.0432]\u001b[A\n",
            "Epoch 2:   9%|▉         | 169/1835 [03:57<38:34,  1.39s/it, training loss=0.1159]\u001b[A\n",
            "Epoch 2:   9%|▉         | 170/1835 [03:57<38:35,  1.39s/it, training loss=0.1159]\u001b[A\n",
            "Epoch 2:   9%|▉         | 170/1835 [03:58<38:35,  1.39s/it, training loss=0.1614]\u001b[A\n",
            "Epoch 2:   9%|▉         | 171/1835 [03:58<38:35,  1.39s/it, training loss=0.1614]\u001b[A\n",
            "Epoch 2:   9%|▉         | 171/1835 [04:00<38:35,  1.39s/it, training loss=0.1299]\u001b[A\n",
            "Epoch 2:   9%|▉         | 172/1835 [04:00<38:34,  1.39s/it, training loss=0.1299]\u001b[A\n",
            "Epoch 2:   9%|▉         | 172/1835 [04:01<38:34,  1.39s/it, training loss=0.1570]\u001b[A\n",
            "Epoch 2:   9%|▉         | 173/1835 [04:01<38:35,  1.39s/it, training loss=0.1570]\u001b[A\n",
            "Epoch 2:   9%|▉         | 173/1835 [04:02<38:35,  1.39s/it, training loss=0.1500]\u001b[A\n",
            "Epoch 2:   9%|▉         | 174/1835 [04:02<38:40,  1.40s/it, training loss=0.1500]\u001b[A\n",
            "Epoch 2:   9%|▉         | 174/1835 [04:04<38:40,  1.40s/it, training loss=0.0737]\u001b[A\n",
            "Epoch 2:  10%|▉         | 175/1835 [04:04<38:41,  1.40s/it, training loss=0.0737]\u001b[A\n",
            "Epoch 2:  10%|▉         | 175/1835 [04:05<38:41,  1.40s/it, training loss=0.1797]\u001b[A\n",
            "Epoch 2:  10%|▉         | 176/1835 [04:05<38:39,  1.40s/it, training loss=0.1797]\u001b[A\n",
            "Epoch 2:  10%|▉         | 176/1835 [04:07<38:39,  1.40s/it, training loss=0.1771]\u001b[A\n",
            "Epoch 2:  10%|▉         | 177/1835 [04:07<38:41,  1.40s/it, training loss=0.1771]\u001b[A\n",
            "Epoch 2:  10%|▉         | 177/1835 [04:08<38:41,  1.40s/it, training loss=0.1144]\u001b[A\n",
            "Epoch 2:  10%|▉         | 178/1835 [04:08<38:35,  1.40s/it, training loss=0.1144]\u001b[A\n",
            "Epoch 2:  10%|▉         | 178/1835 [04:09<38:35,  1.40s/it, training loss=0.1130]\u001b[A\n",
            "Epoch 2:  10%|▉         | 179/1835 [04:09<38:32,  1.40s/it, training loss=0.1130]\u001b[A\n",
            "Epoch 2:  10%|▉         | 179/1835 [04:11<38:32,  1.40s/it, training loss=0.0323]\u001b[A\n",
            "Epoch 2:  10%|▉         | 180/1835 [04:11<38:35,  1.40s/it, training loss=0.0323]\u001b[A\n",
            "Epoch 2:  10%|▉         | 180/1835 [04:12<38:35,  1.40s/it, training loss=0.0610]\u001b[A\n",
            "Epoch 2:  10%|▉         | 181/1835 [04:12<38:31,  1.40s/it, training loss=0.0610]\u001b[A\n",
            "Epoch 2:  10%|▉         | 181/1835 [04:14<38:31,  1.40s/it, training loss=0.3913]\u001b[A\n",
            "Epoch 2:  10%|▉         | 182/1835 [04:14<38:27,  1.40s/it, training loss=0.3913]\u001b[A\n",
            "Epoch 2:  10%|▉         | 182/1835 [04:15<38:27,  1.40s/it, training loss=0.0270]\u001b[A\n",
            "Epoch 2:  10%|▉         | 183/1835 [04:15<38:28,  1.40s/it, training loss=0.0270]\u001b[A\n",
            "Epoch 2:  10%|▉         | 183/1835 [04:16<38:28,  1.40s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 2:  10%|█         | 184/1835 [04:16<38:25,  1.40s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 2:  10%|█         | 184/1835 [04:18<38:25,  1.40s/it, training loss=0.1083]\u001b[A\n",
            "Epoch 2:  10%|█         | 185/1835 [04:18<38:21,  1.39s/it, training loss=0.1083]\u001b[A\n",
            "Epoch 2:  10%|█         | 185/1835 [04:19<38:21,  1.39s/it, training loss=0.1757]\u001b[A\n",
            "Epoch 2:  10%|█         | 186/1835 [04:19<38:19,  1.39s/it, training loss=0.1757]\u001b[A\n",
            "Epoch 2:  10%|█         | 186/1835 [04:21<38:19,  1.39s/it, training loss=0.1167]\u001b[A\n",
            "Epoch 2:  10%|█         | 187/1835 [04:21<38:16,  1.39s/it, training loss=0.1167]\u001b[A\n",
            "Epoch 2:  10%|█         | 187/1835 [04:22<38:16,  1.39s/it, training loss=0.0573]\u001b[A\n",
            "Epoch 2:  10%|█         | 188/1835 [04:22<38:17,  1.39s/it, training loss=0.0573]\u001b[A\n",
            "Epoch 2:  10%|█         | 188/1835 [04:23<38:17,  1.39s/it, training loss=0.1671]\u001b[A\n",
            "Epoch 2:  10%|█         | 189/1835 [04:23<38:16,  1.40s/it, training loss=0.1671]\u001b[A\n",
            "Epoch 2:  10%|█         | 189/1835 [04:25<38:16,  1.40s/it, training loss=0.1993]\u001b[A\n",
            "Epoch 2:  10%|█         | 190/1835 [04:25<38:13,  1.39s/it, training loss=0.1993]\u001b[A\n",
            "Epoch 2:  10%|█         | 190/1835 [04:26<38:13,  1.39s/it, training loss=0.1810]\u001b[A\n",
            "Epoch 2:  10%|█         | 191/1835 [04:26<38:13,  1.40s/it, training loss=0.1810]\u001b[A\n",
            "Epoch 2:  10%|█         | 191/1835 [04:28<38:13,  1.40s/it, training loss=0.2071]\u001b[A\n",
            "Epoch 2:  10%|█         | 192/1835 [04:28<38:14,  1.40s/it, training loss=0.2071]\u001b[A\n",
            "Epoch 2:  10%|█         | 192/1835 [04:29<38:14,  1.40s/it, training loss=0.0845]\u001b[A\n",
            "Epoch 2:  11%|█         | 193/1835 [04:29<38:10,  1.39s/it, training loss=0.0845]\u001b[A\n",
            "Epoch 2:  11%|█         | 193/1835 [04:30<38:10,  1.39s/it, training loss=0.0544]\u001b[A\n",
            "Epoch 2:  11%|█         | 194/1835 [04:30<38:07,  1.39s/it, training loss=0.0544]\u001b[A\n",
            "Epoch 2:  11%|█         | 194/1835 [04:32<38:07,  1.39s/it, training loss=0.1161]\u001b[A\n",
            "Epoch 2:  11%|█         | 195/1835 [04:32<38:10,  1.40s/it, training loss=0.1161]\u001b[A\n",
            "Epoch 2:  11%|█         | 195/1835 [04:33<38:10,  1.40s/it, training loss=0.3029]\u001b[A\n",
            "Epoch 2:  11%|█         | 196/1835 [04:33<38:11,  1.40s/it, training loss=0.3029]\u001b[A\n",
            "Epoch 2:  11%|█         | 196/1835 [04:34<38:11,  1.40s/it, training loss=0.0974]\u001b[A\n",
            "Epoch 2:  11%|█         | 197/1835 [04:34<38:06,  1.40s/it, training loss=0.0974]\u001b[A\n",
            "Epoch 2:  11%|█         | 197/1835 [04:36<38:06,  1.40s/it, training loss=0.0532]\u001b[A\n",
            "Epoch 2:  11%|█         | 198/1835 [04:36<38:09,  1.40s/it, training loss=0.0532]\u001b[A\n",
            "Epoch 2:  11%|█         | 198/1835 [04:37<38:09,  1.40s/it, training loss=0.1144]\u001b[A\n",
            "Epoch 2:  11%|█         | 199/1835 [04:37<38:07,  1.40s/it, training loss=0.1144]\u001b[A\n",
            "Epoch 2:  11%|█         | 199/1835 [04:39<38:07,  1.40s/it, training loss=0.0834]\u001b[A\n",
            "Epoch 2:  11%|█         | 200/1835 [04:39<38:04,  1.40s/it, training loss=0.0834]\u001b[A\n",
            "Epoch 2:  11%|█         | 200/1835 [04:40<38:04,  1.40s/it, training loss=0.1369]\u001b[A\n",
            "Epoch 2:  11%|█         | 201/1835 [04:40<38:03,  1.40s/it, training loss=0.1369]\u001b[A\n",
            "Epoch 2:  11%|█         | 201/1835 [04:41<38:03,  1.40s/it, training loss=0.2055]\u001b[A\n",
            "Epoch 2:  11%|█         | 202/1835 [04:41<38:02,  1.40s/it, training loss=0.2055]\u001b[A\n",
            "Epoch 2:  11%|█         | 202/1835 [04:43<38:02,  1.40s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 2:  11%|█         | 203/1835 [04:43<38:02,  1.40s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 2:  11%|█         | 203/1835 [04:44<38:02,  1.40s/it, training loss=0.2917]\u001b[A\n",
            "Epoch 2:  11%|█         | 204/1835 [04:44<37:58,  1.40s/it, training loss=0.2917]\u001b[A\n",
            "Epoch 2:  11%|█         | 204/1835 [04:46<37:58,  1.40s/it, training loss=0.1057]\u001b[A\n",
            "Epoch 2:  11%|█         | 205/1835 [04:46<37:55,  1.40s/it, training loss=0.1057]\u001b[A\n",
            "Epoch 2:  11%|█         | 205/1835 [04:47<37:55,  1.40s/it, training loss=0.2464]\u001b[A\n",
            "Epoch 2:  11%|█         | 206/1835 [04:47<37:52,  1.39s/it, training loss=0.2464]\u001b[A\n",
            "Epoch 2:  11%|█         | 206/1835 [04:48<37:52,  1.39s/it, training loss=0.2564]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 207/1835 [04:48<37:53,  1.40s/it, training loss=0.2564]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 207/1835 [04:50<37:53,  1.40s/it, training loss=0.2430]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 208/1835 [04:50<37:54,  1.40s/it, training loss=0.2430]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 208/1835 [04:51<37:54,  1.40s/it, training loss=0.0359]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 209/1835 [04:51<37:52,  1.40s/it, training loss=0.0359]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 209/1835 [04:53<37:52,  1.40s/it, training loss=0.3431]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 210/1835 [04:53<37:50,  1.40s/it, training loss=0.3431]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 210/1835 [04:54<37:50,  1.40s/it, training loss=0.2522]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 211/1835 [04:54<37:48,  1.40s/it, training loss=0.2522]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 211/1835 [04:55<37:48,  1.40s/it, training loss=0.1368]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 212/1835 [04:55<37:43,  1.39s/it, training loss=0.1368]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 212/1835 [04:57<37:43,  1.39s/it, training loss=0.2597]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 213/1835 [04:57<37:43,  1.40s/it, training loss=0.2597]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 213/1835 [04:58<37:43,  1.40s/it, training loss=0.1257]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 214/1835 [04:58<37:43,  1.40s/it, training loss=0.1257]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 214/1835 [05:00<37:43,  1.40s/it, training loss=0.1176]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 215/1835 [05:00<37:38,  1.39s/it, training loss=0.1176]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 215/1835 [05:01<37:38,  1.39s/it, training loss=0.3149]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 216/1835 [05:01<37:39,  1.40s/it, training loss=0.3149]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 216/1835 [05:02<37:39,  1.40s/it, training loss=0.1476]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 217/1835 [05:02<37:37,  1.40s/it, training loss=0.1476]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 217/1835 [05:04<37:37,  1.40s/it, training loss=0.1517]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 218/1835 [05:04<37:34,  1.39s/it, training loss=0.1517]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 218/1835 [05:05<37:34,  1.39s/it, training loss=0.0986]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 219/1835 [05:05<37:33,  1.39s/it, training loss=0.0986]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 219/1835 [05:07<37:33,  1.39s/it, training loss=0.1215]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 220/1835 [05:07<37:29,  1.39s/it, training loss=0.1215]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 220/1835 [05:08<37:29,  1.39s/it, training loss=0.1864]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 221/1835 [05:08<37:24,  1.39s/it, training loss=0.1864]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 221/1835 [05:09<37:24,  1.39s/it, training loss=0.1736]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 222/1835 [05:09<37:24,  1.39s/it, training loss=0.1736]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 222/1835 [05:11<37:24,  1.39s/it, training loss=0.1562]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 223/1835 [05:11<37:24,  1.39s/it, training loss=0.1562]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 223/1835 [05:12<37:24,  1.39s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 224/1835 [05:12<37:25,  1.39s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 224/1835 [05:14<37:25,  1.39s/it, training loss=0.1443]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 225/1835 [05:14<37:24,  1.39s/it, training loss=0.1443]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 225/1835 [05:15<37:24,  1.39s/it, training loss=0.0880]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 226/1835 [05:15<37:25,  1.40s/it, training loss=0.0880]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 226/1835 [05:16<37:25,  1.40s/it, training loss=0.0987]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 227/1835 [05:16<37:23,  1.40s/it, training loss=0.0987]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 227/1835 [05:18<37:23,  1.40s/it, training loss=0.1086]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 228/1835 [05:18<37:22,  1.40s/it, training loss=0.1086]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 228/1835 [05:19<37:22,  1.40s/it, training loss=0.1634]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 229/1835 [05:19<37:21,  1.40s/it, training loss=0.1634]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 229/1835 [05:21<37:21,  1.40s/it, training loss=0.2563]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 230/1835 [05:21<37:22,  1.40s/it, training loss=0.2563]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 230/1835 [05:22<37:22,  1.40s/it, training loss=0.3488]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 231/1835 [05:22<37:19,  1.40s/it, training loss=0.3488]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 231/1835 [05:23<37:19,  1.40s/it, training loss=0.1142]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 232/1835 [05:23<37:15,  1.39s/it, training loss=0.1142]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 232/1835 [05:25<37:15,  1.39s/it, training loss=0.0343]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 233/1835 [05:25<37:15,  1.40s/it, training loss=0.0343]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 233/1835 [05:26<37:15,  1.40s/it, training loss=0.1806]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 234/1835 [05:26<37:14,  1.40s/it, training loss=0.1806]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 234/1835 [05:28<37:14,  1.40s/it, training loss=0.1003]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 235/1835 [05:28<37:14,  1.40s/it, training loss=0.1003]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 235/1835 [05:29<37:14,  1.40s/it, training loss=0.1683]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 236/1835 [05:29<37:10,  1.39s/it, training loss=0.1683]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 236/1835 [05:30<37:10,  1.39s/it, training loss=0.0786]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 237/1835 [05:30<37:04,  1.39s/it, training loss=0.0786]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 237/1835 [05:32<37:04,  1.39s/it, training loss=0.0637]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 238/1835 [05:32<37:06,  1.39s/it, training loss=0.0637]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 238/1835 [05:33<37:06,  1.39s/it, training loss=0.2362]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 239/1835 [05:33<37:06,  1.40s/it, training loss=0.2362]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 239/1835 [05:34<37:06,  1.40s/it, training loss=0.3364]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 240/1835 [05:35<37:07,  1.40s/it, training loss=0.3364]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 240/1835 [05:36<37:07,  1.40s/it, training loss=0.0633]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 241/1835 [05:36<37:09,  1.40s/it, training loss=0.0633]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 241/1835 [05:37<37:09,  1.40s/it, training loss=0.0504]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 242/1835 [05:37<37:01,  1.39s/it, training loss=0.0504]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 242/1835 [05:39<37:01,  1.39s/it, training loss=0.1056]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 243/1835 [05:39<36:58,  1.39s/it, training loss=0.1056]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 243/1835 [05:40<36:58,  1.39s/it, training loss=0.1195]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 244/1835 [05:40<36:54,  1.39s/it, training loss=0.1195]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 244/1835 [05:41<36:54,  1.39s/it, training loss=0.2100]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 245/1835 [05:41<36:53,  1.39s/it, training loss=0.2100]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 245/1835 [05:43<36:53,  1.39s/it, training loss=0.3152]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 246/1835 [05:43<36:55,  1.39s/it, training loss=0.3152]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 246/1835 [05:44<36:55,  1.39s/it, training loss=0.1165]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 247/1835 [05:44<36:51,  1.39s/it, training loss=0.1165]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 247/1835 [05:46<36:51,  1.39s/it, training loss=0.1316]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 248/1835 [05:46<36:51,  1.39s/it, training loss=0.1316]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 248/1835 [05:47<36:51,  1.39s/it, training loss=0.1066]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 249/1835 [05:47<36:52,  1.40s/it, training loss=0.1066]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 249/1835 [05:48<36:52,  1.40s/it, training loss=0.2083]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 250/1835 [05:48<36:53,  1.40s/it, training loss=0.2083]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 250/1835 [05:50<36:53,  1.40s/it, training loss=0.2070]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 251/1835 [05:50<36:52,  1.40s/it, training loss=0.2070]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 251/1835 [05:51<36:52,  1.40s/it, training loss=0.1478]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 252/1835 [05:51<36:48,  1.39s/it, training loss=0.1478]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 252/1835 [05:53<36:48,  1.39s/it, training loss=0.1282]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 253/1835 [05:53<36:49,  1.40s/it, training loss=0.1282]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 253/1835 [05:54<36:49,  1.40s/it, training loss=0.3647]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 254/1835 [05:54<36:47,  1.40s/it, training loss=0.3647]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 254/1835 [05:55<36:47,  1.40s/it, training loss=0.2028]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 255/1835 [05:55<36:44,  1.40s/it, training loss=0.2028]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 255/1835 [05:57<36:44,  1.40s/it, training loss=0.0791]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 256/1835 [05:57<36:43,  1.40s/it, training loss=0.0791]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 256/1835 [05:58<36:43,  1.40s/it, training loss=0.1613]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 257/1835 [05:58<36:42,  1.40s/it, training loss=0.1613]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 257/1835 [06:00<36:42,  1.40s/it, training loss=0.0380]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 258/1835 [06:00<36:43,  1.40s/it, training loss=0.0380]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 258/1835 [06:01<36:43,  1.40s/it, training loss=0.3336]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 259/1835 [06:01<36:40,  1.40s/it, training loss=0.3336]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 259/1835 [06:02<36:40,  1.40s/it, training loss=0.2106]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 260/1835 [06:02<36:38,  1.40s/it, training loss=0.2106]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 260/1835 [06:04<36:38,  1.40s/it, training loss=0.3037]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 261/1835 [06:04<36:33,  1.39s/it, training loss=0.3037]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 261/1835 [06:05<36:33,  1.39s/it, training loss=0.0718]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 262/1835 [06:05<36:30,  1.39s/it, training loss=0.0718]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 262/1835 [06:07<36:30,  1.39s/it, training loss=0.1487]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 263/1835 [06:07<36:33,  1.40s/it, training loss=0.1487]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 263/1835 [06:08<36:33,  1.40s/it, training loss=0.1491]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 264/1835 [06:08<36:31,  1.39s/it, training loss=0.1491]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 264/1835 [06:09<36:31,  1.39s/it, training loss=0.1831]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 265/1835 [06:09<36:27,  1.39s/it, training loss=0.1831]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 265/1835 [06:11<36:27,  1.39s/it, training loss=0.2378]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 266/1835 [06:11<36:27,  1.39s/it, training loss=0.2378]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 266/1835 [06:12<36:27,  1.39s/it, training loss=0.1487]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 267/1835 [06:12<36:25,  1.39s/it, training loss=0.1487]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 267/1835 [06:14<36:25,  1.39s/it, training loss=0.1404]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 268/1835 [06:14<36:23,  1.39s/it, training loss=0.1404]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 268/1835 [06:15<36:23,  1.39s/it, training loss=0.1555]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 269/1835 [06:15<36:24,  1.39s/it, training loss=0.1555]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 269/1835 [06:16<36:24,  1.39s/it, training loss=0.2042]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 270/1835 [06:16<36:18,  1.39s/it, training loss=0.2042]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 270/1835 [06:18<36:18,  1.39s/it, training loss=0.1737]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 271/1835 [06:18<36:16,  1.39s/it, training loss=0.1737]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 271/1835 [06:19<36:16,  1.39s/it, training loss=0.1715]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 272/1835 [06:19<36:17,  1.39s/it, training loss=0.1715]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 272/1835 [06:21<36:17,  1.39s/it, training loss=0.1540]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 273/1835 [06:21<36:14,  1.39s/it, training loss=0.1540]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 273/1835 [06:22<36:14,  1.39s/it, training loss=0.0748]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 274/1835 [06:22<36:14,  1.39s/it, training loss=0.0748]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 274/1835 [06:23<36:14,  1.39s/it, training loss=0.1956]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 275/1835 [06:23<36:16,  1.40s/it, training loss=0.1956]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 275/1835 [06:25<36:16,  1.40s/it, training loss=0.3453]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 276/1835 [06:25<36:17,  1.40s/it, training loss=0.3453]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 276/1835 [06:26<36:17,  1.40s/it, training loss=0.1543]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 277/1835 [06:26<36:15,  1.40s/it, training loss=0.1543]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 277/1835 [06:28<36:15,  1.40s/it, training loss=0.1008]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 278/1835 [06:28<36:16,  1.40s/it, training loss=0.1008]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 278/1835 [06:29<36:16,  1.40s/it, training loss=0.0669]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 279/1835 [06:29<36:14,  1.40s/it, training loss=0.0669]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 279/1835 [06:30<36:14,  1.40s/it, training loss=0.1143]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 280/1835 [06:30<36:10,  1.40s/it, training loss=0.1143]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 280/1835 [06:32<36:10,  1.40s/it, training loss=0.1263]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 281/1835 [06:32<36:11,  1.40s/it, training loss=0.1263]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 281/1835 [06:33<36:11,  1.40s/it, training loss=0.0530]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 282/1835 [06:33<36:12,  1.40s/it, training loss=0.0530]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 282/1835 [06:34<36:12,  1.40s/it, training loss=0.1060]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 283/1835 [06:35<36:11,  1.40s/it, training loss=0.1060]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 283/1835 [06:36<36:11,  1.40s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 284/1835 [06:36<36:10,  1.40s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 284/1835 [06:37<36:10,  1.40s/it, training loss=0.0805]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 285/1835 [06:37<36:10,  1.40s/it, training loss=0.0805]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 285/1835 [06:39<36:10,  1.40s/it, training loss=0.1473]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 286/1835 [06:39<36:05,  1.40s/it, training loss=0.1473]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 286/1835 [06:40<36:05,  1.40s/it, training loss=0.2025]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 287/1835 [06:40<36:05,  1.40s/it, training loss=0.2025]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 287/1835 [06:41<36:05,  1.40s/it, training loss=0.1838]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 288/1835 [06:41<36:01,  1.40s/it, training loss=0.1838]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 288/1835 [06:43<36:01,  1.40s/it, training loss=0.1486]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 289/1835 [06:43<36:03,  1.40s/it, training loss=0.1486]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 289/1835 [06:44<36:03,  1.40s/it, training loss=0.1712]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 290/1835 [06:44<36:01,  1.40s/it, training loss=0.1712]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 290/1835 [06:46<36:01,  1.40s/it, training loss=0.1374]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 291/1835 [06:46<35:55,  1.40s/it, training loss=0.1374]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 291/1835 [06:47<35:55,  1.40s/it, training loss=0.1444]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 292/1835 [06:47<35:53,  1.40s/it, training loss=0.1444]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 292/1835 [06:48<35:53,  1.40s/it, training loss=0.1790]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 293/1835 [06:48<35:52,  1.40s/it, training loss=0.1790]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 293/1835 [06:50<35:52,  1.40s/it, training loss=0.2709]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 294/1835 [06:50<35:50,  1.40s/it, training loss=0.2709]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 294/1835 [06:51<35:50,  1.40s/it, training loss=0.3176]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 295/1835 [06:51<35:49,  1.40s/it, training loss=0.3176]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 295/1835 [06:53<35:49,  1.40s/it, training loss=0.2103]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 296/1835 [06:53<35:47,  1.40s/it, training loss=0.2103]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 296/1835 [06:54<35:47,  1.40s/it, training loss=0.1302]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 297/1835 [06:54<35:48,  1.40s/it, training loss=0.1302]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 297/1835 [06:55<35:48,  1.40s/it, training loss=0.2028]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 298/1835 [06:55<35:47,  1.40s/it, training loss=0.2028]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 298/1835 [06:57<35:47,  1.40s/it, training loss=0.2046]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 299/1835 [06:57<35:47,  1.40s/it, training loss=0.2046]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 299/1835 [06:58<35:47,  1.40s/it, training loss=0.1249]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 300/1835 [06:58<35:48,  1.40s/it, training loss=0.1249]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 300/1835 [07:00<35:48,  1.40s/it, training loss=0.1999]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 301/1835 [07:00<35:50,  1.40s/it, training loss=0.1999]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 301/1835 [07:01<35:50,  1.40s/it, training loss=0.2102]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 302/1835 [07:01<35:46,  1.40s/it, training loss=0.2102]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 302/1835 [07:02<35:46,  1.40s/it, training loss=0.1652]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 303/1835 [07:02<35:44,  1.40s/it, training loss=0.1652]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 303/1835 [07:04<35:44,  1.40s/it, training loss=0.1481]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 304/1835 [07:04<35:43,  1.40s/it, training loss=0.1481]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 304/1835 [07:05<35:43,  1.40s/it, training loss=0.2973]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 305/1835 [07:05<35:40,  1.40s/it, training loss=0.2973]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 305/1835 [07:07<35:40,  1.40s/it, training loss=0.1127]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 306/1835 [07:07<35:39,  1.40s/it, training loss=0.1127]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 306/1835 [07:08<35:39,  1.40s/it, training loss=0.2992]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 307/1835 [07:08<35:36,  1.40s/it, training loss=0.2992]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 307/1835 [07:09<35:36,  1.40s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 308/1835 [07:09<35:33,  1.40s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 308/1835 [07:11<35:33,  1.40s/it, training loss=0.1920]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 309/1835 [07:11<35:28,  1.39s/it, training loss=0.1920]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 309/1835 [07:12<35:28,  1.39s/it, training loss=0.2923]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 310/1835 [07:12<35:28,  1.40s/it, training loss=0.2923]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 310/1835 [07:14<35:28,  1.40s/it, training loss=0.1850]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 311/1835 [07:14<35:24,  1.39s/it, training loss=0.1850]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 311/1835 [07:15<35:24,  1.39s/it, training loss=0.1539]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 312/1835 [07:15<35:23,  1.39s/it, training loss=0.1539]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 312/1835 [07:16<35:23,  1.39s/it, training loss=0.0708]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 313/1835 [07:16<35:19,  1.39s/it, training loss=0.0708]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 313/1835 [07:18<35:19,  1.39s/it, training loss=0.2774]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 314/1835 [07:18<35:18,  1.39s/it, training loss=0.2774]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 314/1835 [07:19<35:18,  1.39s/it, training loss=0.1139]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 315/1835 [07:19<35:19,  1.39s/it, training loss=0.1139]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 315/1835 [07:21<35:19,  1.39s/it, training loss=0.1525]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 316/1835 [07:21<35:17,  1.39s/it, training loss=0.1525]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 316/1835 [07:22<35:17,  1.39s/it, training loss=0.1769]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 317/1835 [07:22<35:16,  1.39s/it, training loss=0.1769]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 317/1835 [07:23<35:16,  1.39s/it, training loss=0.1804]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 318/1835 [07:23<35:14,  1.39s/it, training loss=0.1804]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 318/1835 [07:25<35:14,  1.39s/it, training loss=0.2037]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 319/1835 [07:25<35:15,  1.40s/it, training loss=0.2037]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 319/1835 [07:26<35:15,  1.40s/it, training loss=0.1166]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 320/1835 [07:26<35:11,  1.39s/it, training loss=0.1166]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 320/1835 [07:28<35:11,  1.39s/it, training loss=0.3716]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 321/1835 [07:28<35:11,  1.39s/it, training loss=0.3716]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 321/1835 [07:29<35:11,  1.39s/it, training loss=0.1458]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 322/1835 [07:29<35:08,  1.39s/it, training loss=0.1458]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 322/1835 [07:30<35:08,  1.39s/it, training loss=0.2676]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 323/1835 [07:30<35:10,  1.40s/it, training loss=0.2676]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 323/1835 [07:32<35:10,  1.40s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 324/1835 [07:32<35:07,  1.40s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 324/1835 [07:33<35:07,  1.40s/it, training loss=0.1023]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 325/1835 [07:33<35:04,  1.39s/it, training loss=0.1023]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 325/1835 [07:35<35:04,  1.39s/it, training loss=0.0687]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 326/1835 [07:35<35:03,  1.39s/it, training loss=0.0687]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 326/1835 [07:36<35:03,  1.39s/it, training loss=0.2052]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 327/1835 [07:36<35:02,  1.39s/it, training loss=0.2052]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 327/1835 [07:37<35:02,  1.39s/it, training loss=0.1555]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 328/1835 [07:37<35:02,  1.40s/it, training loss=0.1555]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 328/1835 [07:39<35:02,  1.40s/it, training loss=0.1840]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 329/1835 [07:39<35:04,  1.40s/it, training loss=0.1840]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 329/1835 [07:40<35:04,  1.40s/it, training loss=0.2518]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 330/1835 [07:40<35:01,  1.40s/it, training loss=0.2518]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 330/1835 [07:42<35:01,  1.40s/it, training loss=0.3790]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 331/1835 [07:42<34:57,  1.39s/it, training loss=0.3790]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 331/1835 [07:43<34:57,  1.39s/it, training loss=0.3018]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 332/1835 [07:43<34:57,  1.40s/it, training loss=0.3018]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 332/1835 [07:44<34:57,  1.40s/it, training loss=0.2872]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 333/1835 [07:44<34:56,  1.40s/it, training loss=0.2872]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 333/1835 [07:46<34:56,  1.40s/it, training loss=0.1618]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 334/1835 [07:46<34:54,  1.40s/it, training loss=0.1618]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 334/1835 [07:47<34:54,  1.40s/it, training loss=0.0583]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 335/1835 [07:47<34:52,  1.39s/it, training loss=0.0583]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 335/1835 [07:48<34:52,  1.39s/it, training loss=0.2290]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 336/1835 [07:48<34:52,  1.40s/it, training loss=0.2290]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 336/1835 [07:50<34:52,  1.40s/it, training loss=0.1878]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 337/1835 [07:50<34:54,  1.40s/it, training loss=0.1878]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 337/1835 [07:51<34:54,  1.40s/it, training loss=0.2560]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 338/1835 [07:51<34:48,  1.40s/it, training loss=0.2560]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 338/1835 [07:53<34:48,  1.40s/it, training loss=0.1818]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 339/1835 [07:53<34:49,  1.40s/it, training loss=0.1818]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 339/1835 [07:54<34:49,  1.40s/it, training loss=0.3462]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 340/1835 [07:54<34:49,  1.40s/it, training loss=0.3462]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 340/1835 [07:55<34:49,  1.40s/it, training loss=0.1030]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 341/1835 [07:55<34:46,  1.40s/it, training loss=0.1030]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 341/1835 [07:57<34:46,  1.40s/it, training loss=0.0899]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 342/1835 [07:57<34:41,  1.39s/it, training loss=0.0899]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 342/1835 [07:58<34:41,  1.39s/it, training loss=0.0851]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 343/1835 [07:58<34:42,  1.40s/it, training loss=0.0851]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 343/1835 [08:00<34:42,  1.40s/it, training loss=0.1727]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 344/1835 [08:00<34:42,  1.40s/it, training loss=0.1727]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 344/1835 [08:01<34:42,  1.40s/it, training loss=0.2101]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 345/1835 [08:01<34:38,  1.39s/it, training loss=0.2101]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 345/1835 [08:02<34:38,  1.39s/it, training loss=0.1331]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 346/1835 [08:02<34:36,  1.39s/it, training loss=0.1331]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 346/1835 [08:04<34:36,  1.39s/it, training loss=0.1414]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 347/1835 [08:04<34:34,  1.39s/it, training loss=0.1414]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 347/1835 [08:05<34:34,  1.39s/it, training loss=0.0931]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 348/1835 [08:05<34:33,  1.39s/it, training loss=0.0931]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 348/1835 [08:07<34:33,  1.39s/it, training loss=0.1276]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 349/1835 [08:07<34:30,  1.39s/it, training loss=0.1276]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 349/1835 [08:08<34:30,  1.39s/it, training loss=0.1828]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 350/1835 [08:08<34:27,  1.39s/it, training loss=0.1828]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 350/1835 [08:09<34:27,  1.39s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 351/1835 [08:09<34:27,  1.39s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 351/1835 [08:11<34:27,  1.39s/it, training loss=0.1718]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 352/1835 [08:11<34:30,  1.40s/it, training loss=0.1718]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 352/1835 [08:12<34:30,  1.40s/it, training loss=0.2070]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 353/1835 [08:12<34:30,  1.40s/it, training loss=0.2070]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 353/1835 [08:14<34:30,  1.40s/it, training loss=0.1686]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 354/1835 [08:14<34:29,  1.40s/it, training loss=0.1686]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 354/1835 [08:15<34:29,  1.40s/it, training loss=0.0954]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 355/1835 [08:15<34:25,  1.40s/it, training loss=0.0954]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 355/1835 [08:16<34:25,  1.40s/it, training loss=0.1354]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 356/1835 [08:16<34:26,  1.40s/it, training loss=0.1354]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 356/1835 [08:18<34:26,  1.40s/it, training loss=0.2109]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 357/1835 [08:18<34:21,  1.40s/it, training loss=0.2109]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 357/1835 [08:19<34:21,  1.40s/it, training loss=0.1560]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 358/1835 [08:19<34:23,  1.40s/it, training loss=0.1560]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 358/1835 [08:21<34:23,  1.40s/it, training loss=0.1145]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 359/1835 [08:21<34:21,  1.40s/it, training loss=0.1145]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 359/1835 [08:22<34:21,  1.40s/it, training loss=0.1547]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 360/1835 [08:22<34:18,  1.40s/it, training loss=0.1547]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 360/1835 [08:23<34:18,  1.40s/it, training loss=0.1073]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 361/1835 [08:23<34:17,  1.40s/it, training loss=0.1073]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 361/1835 [08:25<34:17,  1.40s/it, training loss=0.1206]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 362/1835 [08:25<34:18,  1.40s/it, training loss=0.1206]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 362/1835 [08:26<34:18,  1.40s/it, training loss=0.1536]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 363/1835 [08:26<34:14,  1.40s/it, training loss=0.1536]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 363/1835 [08:28<34:14,  1.40s/it, training loss=0.1181]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 364/1835 [08:28<34:10,  1.39s/it, training loss=0.1181]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 364/1835 [08:29<34:10,  1.39s/it, training loss=0.2419]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 365/1835 [08:29<34:06,  1.39s/it, training loss=0.2419]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 365/1835 [08:30<34:06,  1.39s/it, training loss=0.0758]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 366/1835 [08:30<34:05,  1.39s/it, training loss=0.0758]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 366/1835 [08:32<34:05,  1.39s/it, training loss=0.1825]\u001b[A\n",
            "Epoch 2:  20%|██        | 367/1835 [08:32<34:05,  1.39s/it, training loss=0.1825]\u001b[A\n",
            "Epoch 2:  20%|██        | 367/1835 [08:33<34:05,  1.39s/it, training loss=0.1450]\u001b[A\n",
            "Epoch 2:  20%|██        | 368/1835 [08:33<34:03,  1.39s/it, training loss=0.1450]\u001b[A\n",
            "Epoch 2:  20%|██        | 368/1835 [08:35<34:03,  1.39s/it, training loss=0.0331]\u001b[A\n",
            "Epoch 2:  20%|██        | 369/1835 [08:35<34:01,  1.39s/it, training loss=0.0331]\u001b[A\n",
            "Epoch 2:  20%|██        | 369/1835 [08:36<34:01,  1.39s/it, training loss=0.1221]\u001b[A\n",
            "Epoch 2:  20%|██        | 370/1835 [08:36<34:00,  1.39s/it, training loss=0.1221]\u001b[A\n",
            "Epoch 2:  20%|██        | 370/1835 [08:37<34:00,  1.39s/it, training loss=0.1248]\u001b[A\n",
            "Epoch 2:  20%|██        | 371/1835 [08:37<34:03,  1.40s/it, training loss=0.1248]\u001b[A\n",
            "Epoch 2:  20%|██        | 371/1835 [08:39<34:03,  1.40s/it, training loss=0.0759]\u001b[A\n",
            "Epoch 2:  20%|██        | 372/1835 [08:39<33:58,  1.39s/it, training loss=0.0759]\u001b[A\n",
            "Epoch 2:  20%|██        | 372/1835 [08:40<33:58,  1.39s/it, training loss=0.1183]\u001b[A\n",
            "Epoch 2:  20%|██        | 373/1835 [08:40<33:58,  1.39s/it, training loss=0.1183]\u001b[A\n",
            "Epoch 2:  20%|██        | 373/1835 [08:42<33:58,  1.39s/it, training loss=0.1706]\u001b[A\n",
            "Epoch 2:  20%|██        | 374/1835 [08:42<34:00,  1.40s/it, training loss=0.1706]\u001b[A\n",
            "Epoch 2:  20%|██        | 374/1835 [08:43<34:00,  1.40s/it, training loss=0.3784]\u001b[A\n",
            "Epoch 2:  20%|██        | 375/1835 [08:43<33:57,  1.40s/it, training loss=0.3784]\u001b[A\n",
            "Epoch 2:  20%|██        | 375/1835 [08:44<33:57,  1.40s/it, training loss=0.1523]\u001b[A\n",
            "Epoch 2:  20%|██        | 376/1835 [08:44<33:55,  1.40s/it, training loss=0.1523]\u001b[A\n",
            "Epoch 2:  20%|██        | 376/1835 [08:46<33:55,  1.40s/it, training loss=0.2411]\u001b[A\n",
            "Epoch 2:  21%|██        | 377/1835 [08:46<33:52,  1.39s/it, training loss=0.2411]\u001b[A\n",
            "Epoch 2:  21%|██        | 377/1835 [08:47<33:52,  1.39s/it, training loss=0.0894]\u001b[A\n",
            "Epoch 2:  21%|██        | 378/1835 [08:47<33:53,  1.40s/it, training loss=0.0894]\u001b[A\n",
            "Epoch 2:  21%|██        | 378/1835 [08:48<33:53,  1.40s/it, training loss=0.3254]\u001b[A\n",
            "Epoch 2:  21%|██        | 379/1835 [08:48<33:53,  1.40s/it, training loss=0.3254]\u001b[A\n",
            "Epoch 2:  21%|██        | 379/1835 [08:50<33:53,  1.40s/it, training loss=0.1262]\u001b[A\n",
            "Epoch 2:  21%|██        | 380/1835 [08:50<33:54,  1.40s/it, training loss=0.1262]\u001b[A\n",
            "Epoch 2:  21%|██        | 380/1835 [08:51<33:54,  1.40s/it, training loss=0.1442]\u001b[A\n",
            "Epoch 2:  21%|██        | 381/1835 [08:51<33:51,  1.40s/it, training loss=0.1442]\u001b[A\n",
            "Epoch 2:  21%|██        | 381/1835 [08:53<33:51,  1.40s/it, training loss=0.0690]\u001b[A\n",
            "Epoch 2:  21%|██        | 382/1835 [08:53<33:48,  1.40s/it, training loss=0.0690]\u001b[A\n",
            "Epoch 2:  21%|██        | 382/1835 [08:54<33:48,  1.40s/it, training loss=0.1571]\u001b[A\n",
            "Epoch 2:  21%|██        | 383/1835 [08:54<33:47,  1.40s/it, training loss=0.1571]\u001b[A\n",
            "Epoch 2:  21%|██        | 383/1835 [08:55<33:47,  1.40s/it, training loss=0.1970]\u001b[A\n",
            "Epoch 2:  21%|██        | 384/1835 [08:55<33:50,  1.40s/it, training loss=0.1970]\u001b[A\n",
            "Epoch 2:  21%|██        | 384/1835 [08:57<33:50,  1.40s/it, training loss=0.1087]\u001b[A\n",
            "Epoch 2:  21%|██        | 385/1835 [08:57<33:46,  1.40s/it, training loss=0.1087]\u001b[A\n",
            "Epoch 2:  21%|██        | 385/1835 [08:58<33:46,  1.40s/it, training loss=0.1834]\u001b[A\n",
            "Epoch 2:  21%|██        | 386/1835 [08:58<33:46,  1.40s/it, training loss=0.1834]\u001b[A\n",
            "Epoch 2:  21%|██        | 386/1835 [09:00<33:46,  1.40s/it, training loss=0.2076]\u001b[A\n",
            "Epoch 2:  21%|██        | 387/1835 [09:00<33:43,  1.40s/it, training loss=0.2076]\u001b[A\n",
            "Epoch 2:  21%|██        | 387/1835 [09:01<33:43,  1.40s/it, training loss=0.0434]\u001b[A\n",
            "Epoch 2:  21%|██        | 388/1835 [09:01<33:40,  1.40s/it, training loss=0.0434]\u001b[A\n",
            "Epoch 2:  21%|██        | 388/1835 [09:02<33:40,  1.40s/it, training loss=0.1728]\u001b[A\n",
            "Epoch 2:  21%|██        | 389/1835 [09:02<33:41,  1.40s/it, training loss=0.1728]\u001b[A\n",
            "Epoch 2:  21%|██        | 389/1835 [09:04<33:41,  1.40s/it, training loss=0.1602]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 390/1835 [09:04<33:37,  1.40s/it, training loss=0.1602]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 390/1835 [09:05<33:37,  1.40s/it, training loss=0.1753]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 391/1835 [09:05<33:36,  1.40s/it, training loss=0.1753]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 391/1835 [09:07<33:36,  1.40s/it, training loss=0.0409]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 392/1835 [09:07<33:35,  1.40s/it, training loss=0.0409]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 392/1835 [09:08<33:35,  1.40s/it, training loss=0.0546]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 393/1835 [09:08<33:31,  1.40s/it, training loss=0.0546]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 393/1835 [09:09<33:31,  1.40s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 394/1835 [09:09<33:30,  1.40s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 394/1835 [09:11<33:30,  1.40s/it, training loss=0.1984]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 395/1835 [09:11<33:28,  1.39s/it, training loss=0.1984]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 395/1835 [09:12<33:28,  1.39s/it, training loss=0.0448]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 396/1835 [09:12<33:27,  1.40s/it, training loss=0.0448]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 396/1835 [09:14<33:27,  1.40s/it, training loss=0.1140]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 397/1835 [09:14<33:26,  1.40s/it, training loss=0.1140]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 397/1835 [09:15<33:26,  1.40s/it, training loss=0.0995]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 398/1835 [09:15<33:24,  1.39s/it, training loss=0.0995]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 398/1835 [09:16<33:24,  1.39s/it, training loss=0.2695]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 399/1835 [09:16<33:26,  1.40s/it, training loss=0.2695]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 399/1835 [09:18<33:26,  1.40s/it, training loss=0.1894]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 400/1835 [09:18<33:27,  1.40s/it, training loss=0.1894]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 400/1835 [09:19<33:27,  1.40s/it, training loss=0.1384]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 401/1835 [09:19<33:26,  1.40s/it, training loss=0.1384]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 401/1835 [09:21<33:26,  1.40s/it, training loss=0.0790]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 402/1835 [09:21<33:28,  1.40s/it, training loss=0.0790]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 402/1835 [09:22<33:28,  1.40s/it, training loss=0.2217]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 403/1835 [09:22<33:24,  1.40s/it, training loss=0.2217]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 403/1835 [09:23<33:24,  1.40s/it, training loss=0.0163]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 404/1835 [09:23<33:21,  1.40s/it, training loss=0.0163]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 404/1835 [09:25<33:21,  1.40s/it, training loss=0.1860]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 405/1835 [09:25<33:20,  1.40s/it, training loss=0.1860]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 405/1835 [09:26<33:20,  1.40s/it, training loss=0.1416]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 406/1835 [09:26<33:15,  1.40s/it, training loss=0.1416]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 406/1835 [09:28<33:15,  1.40s/it, training loss=0.0790]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 407/1835 [09:28<33:14,  1.40s/it, training loss=0.0790]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 407/1835 [09:29<33:14,  1.40s/it, training loss=0.0831]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 408/1835 [09:29<33:15,  1.40s/it, training loss=0.0831]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 408/1835 [09:30<33:15,  1.40s/it, training loss=0.2080]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 409/1835 [09:30<33:13,  1.40s/it, training loss=0.2080]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 409/1835 [09:32<33:13,  1.40s/it, training loss=0.2188]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 410/1835 [09:32<33:13,  1.40s/it, training loss=0.2188]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 410/1835 [09:33<33:13,  1.40s/it, training loss=0.1764]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 411/1835 [09:33<33:12,  1.40s/it, training loss=0.1764]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 411/1835 [09:35<33:12,  1.40s/it, training loss=0.2687]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 412/1835 [09:35<33:10,  1.40s/it, training loss=0.2687]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 412/1835 [09:36<33:10,  1.40s/it, training loss=0.3154]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 413/1835 [09:36<33:06,  1.40s/it, training loss=0.3154]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 413/1835 [09:37<33:06,  1.40s/it, training loss=0.1659]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 414/1835 [09:37<33:06,  1.40s/it, training loss=0.1659]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 414/1835 [09:39<33:06,  1.40s/it, training loss=0.1126]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 415/1835 [09:39<33:01,  1.40s/it, training loss=0.1126]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 415/1835 [09:40<33:01,  1.40s/it, training loss=0.1514]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 416/1835 [09:40<32:57,  1.39s/it, training loss=0.1514]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 416/1835 [09:42<32:57,  1.39s/it, training loss=0.0975]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 417/1835 [09:42<33:00,  1.40s/it, training loss=0.0975]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 417/1835 [09:43<33:00,  1.40s/it, training loss=0.2591]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 418/1835 [09:43<33:00,  1.40s/it, training loss=0.2591]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 418/1835 [09:44<33:00,  1.40s/it, training loss=0.1502]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 419/1835 [09:44<32:58,  1.40s/it, training loss=0.1502]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 419/1835 [09:46<32:58,  1.40s/it, training loss=0.1048]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 420/1835 [09:46<32:57,  1.40s/it, training loss=0.1048]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 420/1835 [09:47<32:57,  1.40s/it, training loss=0.2120]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 421/1835 [09:47<32:55,  1.40s/it, training loss=0.2120]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 421/1835 [09:49<32:55,  1.40s/it, training loss=0.0451]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 422/1835 [09:49<32:54,  1.40s/it, training loss=0.0451]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 422/1835 [09:50<32:54,  1.40s/it, training loss=0.1656]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 423/1835 [09:50<32:50,  1.40s/it, training loss=0.1656]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 423/1835 [09:51<32:50,  1.40s/it, training loss=0.2289]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 424/1835 [09:51<32:46,  1.39s/it, training loss=0.2289]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 424/1835 [09:53<32:46,  1.39s/it, training loss=0.1705]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 425/1835 [09:53<32:43,  1.39s/it, training loss=0.1705]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 425/1835 [09:54<32:43,  1.39s/it, training loss=0.0784]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 426/1835 [09:54<32:42,  1.39s/it, training loss=0.0784]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 426/1835 [09:56<32:42,  1.39s/it, training loss=0.2021]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 427/1835 [09:56<32:44,  1.40s/it, training loss=0.2021]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 427/1835 [09:57<32:44,  1.40s/it, training loss=0.0836]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 428/1835 [09:57<32:43,  1.40s/it, training loss=0.0836]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 428/1835 [09:58<32:43,  1.40s/it, training loss=0.1623]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 429/1835 [09:58<32:42,  1.40s/it, training loss=0.1623]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 429/1835 [10:00<32:42,  1.40s/it, training loss=0.1244]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 430/1835 [10:00<32:39,  1.39s/it, training loss=0.1244]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 430/1835 [10:01<32:39,  1.39s/it, training loss=0.0423]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 431/1835 [10:01<32:38,  1.39s/it, training loss=0.0423]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 431/1835 [10:03<32:38,  1.39s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 432/1835 [10:03<32:39,  1.40s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 432/1835 [10:04<32:39,  1.40s/it, training loss=0.2959]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 433/1835 [10:04<32:37,  1.40s/it, training loss=0.2959]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 433/1835 [10:05<32:37,  1.40s/it, training loss=0.1405]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 434/1835 [10:05<32:38,  1.40s/it, training loss=0.1405]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 434/1835 [10:07<32:38,  1.40s/it, training loss=0.1138]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 435/1835 [10:07<32:40,  1.40s/it, training loss=0.1138]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 435/1835 [10:08<32:40,  1.40s/it, training loss=0.2208]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 436/1835 [10:08<32:37,  1.40s/it, training loss=0.2208]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 436/1835 [10:10<32:37,  1.40s/it, training loss=0.0673]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 437/1835 [10:10<32:36,  1.40s/it, training loss=0.0673]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 437/1835 [10:11<32:36,  1.40s/it, training loss=0.2431]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 438/1835 [10:11<32:35,  1.40s/it, training loss=0.2431]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 438/1835 [10:12<32:35,  1.40s/it, training loss=0.1500]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 439/1835 [10:12<32:30,  1.40s/it, training loss=0.1500]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 439/1835 [10:14<32:30,  1.40s/it, training loss=0.0657]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 440/1835 [10:14<32:29,  1.40s/it, training loss=0.0657]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 440/1835 [10:15<32:29,  1.40s/it, training loss=0.0658]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 441/1835 [10:15<32:26,  1.40s/it, training loss=0.0658]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 441/1835 [10:16<32:26,  1.40s/it, training loss=0.0606]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 442/1835 [10:17<32:25,  1.40s/it, training loss=0.0606]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 442/1835 [10:18<32:25,  1.40s/it, training loss=0.1336]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 443/1835 [10:18<32:23,  1.40s/it, training loss=0.1336]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 443/1835 [10:19<32:23,  1.40s/it, training loss=0.0870]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 444/1835 [10:19<32:19,  1.39s/it, training loss=0.0870]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 444/1835 [10:21<32:19,  1.39s/it, training loss=0.2086]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 445/1835 [10:21<32:20,  1.40s/it, training loss=0.2086]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 445/1835 [10:22<32:20,  1.40s/it, training loss=0.2014]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 446/1835 [10:22<32:17,  1.40s/it, training loss=0.2014]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 446/1835 [10:23<32:17,  1.40s/it, training loss=0.1521]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 447/1835 [10:23<32:17,  1.40s/it, training loss=0.1521]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 447/1835 [10:25<32:17,  1.40s/it, training loss=0.0518]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 448/1835 [10:25<32:18,  1.40s/it, training loss=0.0518]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 448/1835 [10:26<32:18,  1.40s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 449/1835 [10:26<32:19,  1.40s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 449/1835 [10:28<32:19,  1.40s/it, training loss=0.1974]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 450/1835 [10:28<32:18,  1.40s/it, training loss=0.1974]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 450/1835 [10:29<32:18,  1.40s/it, training loss=0.0818]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 451/1835 [10:29<32:15,  1.40s/it, training loss=0.0818]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 451/1835 [10:30<32:15,  1.40s/it, training loss=0.1566]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 452/1835 [10:30<32:16,  1.40s/it, training loss=0.1566]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 452/1835 [10:32<32:16,  1.40s/it, training loss=0.0748]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 453/1835 [10:32<32:13,  1.40s/it, training loss=0.0748]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 453/1835 [10:33<32:13,  1.40s/it, training loss=0.1057]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 454/1835 [10:33<32:08,  1.40s/it, training loss=0.1057]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 454/1835 [10:35<32:08,  1.40s/it, training loss=0.3411]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 455/1835 [10:35<32:04,  1.39s/it, training loss=0.3411]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 455/1835 [10:36<32:04,  1.39s/it, training loss=0.2032]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 456/1835 [10:36<32:07,  1.40s/it, training loss=0.2032]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 456/1835 [10:37<32:07,  1.40s/it, training loss=0.2413]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 457/1835 [10:37<32:06,  1.40s/it, training loss=0.2413]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 457/1835 [10:39<32:06,  1.40s/it, training loss=0.2346]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 458/1835 [10:39<32:04,  1.40s/it, training loss=0.2346]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 458/1835 [10:40<32:04,  1.40s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 459/1835 [10:40<32:02,  1.40s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 459/1835 [10:42<32:02,  1.40s/it, training loss=0.0388]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 460/1835 [10:42<32:02,  1.40s/it, training loss=0.0388]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 460/1835 [10:43<32:02,  1.40s/it, training loss=0.1280]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 461/1835 [10:43<31:58,  1.40s/it, training loss=0.1280]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 461/1835 [10:44<31:58,  1.40s/it, training loss=0.0845]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 462/1835 [10:44<31:56,  1.40s/it, training loss=0.0845]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 462/1835 [10:46<31:56,  1.40s/it, training loss=0.1814]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 463/1835 [10:46<31:56,  1.40s/it, training loss=0.1814]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 463/1835 [10:47<31:56,  1.40s/it, training loss=0.2987]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 464/1835 [10:47<31:53,  1.40s/it, training loss=0.2987]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 464/1835 [10:49<31:53,  1.40s/it, training loss=0.1459]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 465/1835 [10:49<31:52,  1.40s/it, training loss=0.1459]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 465/1835 [10:50<31:52,  1.40s/it, training loss=0.2019]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 466/1835 [10:50<31:54,  1.40s/it, training loss=0.2019]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 466/1835 [10:51<31:54,  1.40s/it, training loss=0.1950]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 467/1835 [10:51<31:51,  1.40s/it, training loss=0.1950]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 467/1835 [10:53<31:51,  1.40s/it, training loss=0.0449]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 468/1835 [10:53<31:51,  1.40s/it, training loss=0.0449]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 468/1835 [10:54<31:51,  1.40s/it, training loss=0.1822]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 469/1835 [10:54<31:50,  1.40s/it, training loss=0.1822]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 469/1835 [10:56<31:50,  1.40s/it, training loss=0.2433]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 470/1835 [10:56<31:49,  1.40s/it, training loss=0.2433]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 470/1835 [10:57<31:49,  1.40s/it, training loss=0.0771]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 471/1835 [10:57<31:44,  1.40s/it, training loss=0.0771]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 471/1835 [10:58<31:44,  1.40s/it, training loss=0.2231]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 472/1835 [10:58<31:43,  1.40s/it, training loss=0.2231]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 472/1835 [11:00<31:43,  1.40s/it, training loss=0.0638]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 473/1835 [11:00<31:42,  1.40s/it, training loss=0.0638]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 473/1835 [11:01<31:42,  1.40s/it, training loss=0.1087]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 474/1835 [11:01<31:38,  1.39s/it, training loss=0.1087]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 474/1835 [11:03<31:38,  1.39s/it, training loss=0.1387]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 475/1835 [11:03<31:38,  1.40s/it, training loss=0.1387]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 475/1835 [11:04<31:38,  1.40s/it, training loss=0.1741]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 476/1835 [11:04<31:37,  1.40s/it, training loss=0.1741]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 476/1835 [11:05<31:37,  1.40s/it, training loss=0.0974]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 477/1835 [11:05<31:37,  1.40s/it, training loss=0.0974]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 477/1835 [11:07<31:37,  1.40s/it, training loss=0.0597]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 478/1835 [11:07<31:33,  1.40s/it, training loss=0.0597]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 478/1835 [11:08<31:33,  1.40s/it, training loss=0.1280]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 479/1835 [11:08<31:40,  1.40s/it, training loss=0.1280]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 479/1835 [11:10<31:40,  1.40s/it, training loss=0.1241]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 480/1835 [11:10<31:42,  1.40s/it, training loss=0.1241]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 480/1835 [11:11<31:42,  1.40s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 481/1835 [11:11<31:43,  1.41s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 481/1835 [11:12<31:43,  1.41s/it, training loss=0.0229]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 482/1835 [11:12<31:46,  1.41s/it, training loss=0.0229]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 482/1835 [11:14<31:46,  1.41s/it, training loss=0.0945]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 483/1835 [11:14<31:43,  1.41s/it, training loss=0.0945]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 483/1835 [11:15<31:43,  1.41s/it, training loss=0.1217]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 484/1835 [11:15<31:42,  1.41s/it, training loss=0.1217]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 484/1835 [11:17<31:42,  1.41s/it, training loss=0.0723]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 485/1835 [11:17<31:45,  1.41s/it, training loss=0.0723]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 485/1835 [11:18<31:45,  1.41s/it, training loss=0.1264]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 486/1835 [11:18<31:38,  1.41s/it, training loss=0.1264]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 486/1835 [11:19<31:38,  1.41s/it, training loss=0.1351]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 487/1835 [11:19<31:36,  1.41s/it, training loss=0.1351]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 487/1835 [11:21<31:36,  1.41s/it, training loss=0.2162]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 488/1835 [11:21<31:35,  1.41s/it, training loss=0.2162]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 488/1835 [11:22<31:35,  1.41s/it, training loss=0.2219]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 489/1835 [11:22<31:41,  1.41s/it, training loss=0.2219]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 489/1835 [11:24<31:41,  1.41s/it, training loss=0.2072]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 490/1835 [11:24<31:39,  1.41s/it, training loss=0.2072]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 490/1835 [11:25<31:39,  1.41s/it, training loss=0.0615]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 491/1835 [11:25<31:43,  1.42s/it, training loss=0.0615]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 491/1835 [11:27<31:43,  1.42s/it, training loss=0.1789]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 492/1835 [11:27<31:36,  1.41s/it, training loss=0.1789]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 492/1835 [11:28<31:36,  1.41s/it, training loss=0.1076]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 493/1835 [11:28<31:27,  1.41s/it, training loss=0.1076]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 493/1835 [11:29<31:27,  1.41s/it, training loss=0.0697]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 494/1835 [11:29<31:27,  1.41s/it, training loss=0.0697]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 494/1835 [11:31<31:27,  1.41s/it, training loss=0.1430]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 495/1835 [11:31<31:20,  1.40s/it, training loss=0.1430]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 495/1835 [11:32<31:20,  1.40s/it, training loss=0.0449]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 496/1835 [11:32<31:16,  1.40s/it, training loss=0.0449]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 496/1835 [11:34<31:16,  1.40s/it, training loss=0.1133]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 497/1835 [11:34<31:16,  1.40s/it, training loss=0.1133]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 497/1835 [11:35<31:16,  1.40s/it, training loss=0.3627]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 498/1835 [11:35<31:16,  1.40s/it, training loss=0.3627]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 498/1835 [11:36<31:16,  1.40s/it, training loss=0.2396]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 499/1835 [11:36<31:17,  1.41s/it, training loss=0.2396]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 499/1835 [11:38<31:17,  1.41s/it, training loss=0.0847]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 500/1835 [11:38<31:18,  1.41s/it, training loss=0.0847]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 500/1835 [11:39<31:18,  1.41s/it, training loss=0.1417]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 501/1835 [11:39<31:14,  1.40s/it, training loss=0.1417]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 501/1835 [11:41<31:14,  1.40s/it, training loss=0.1245]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 502/1835 [11:41<31:24,  1.41s/it, training loss=0.1245]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 502/1835 [11:42<31:24,  1.41s/it, training loss=0.0289]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 503/1835 [11:42<31:21,  1.41s/it, training loss=0.0289]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 503/1835 [11:43<31:21,  1.41s/it, training loss=0.1021]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 504/1835 [11:43<31:15,  1.41s/it, training loss=0.1021]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 504/1835 [11:45<31:15,  1.41s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 505/1835 [11:45<31:14,  1.41s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 505/1835 [11:46<31:14,  1.41s/it, training loss=0.1172]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 506/1835 [11:46<31:15,  1.41s/it, training loss=0.1172]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 506/1835 [11:48<31:15,  1.41s/it, training loss=0.1892]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 507/1835 [11:48<31:22,  1.42s/it, training loss=0.1892]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 507/1835 [11:49<31:22,  1.42s/it, training loss=0.2246]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 508/1835 [11:49<31:13,  1.41s/it, training loss=0.2246]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 508/1835 [11:50<31:13,  1.41s/it, training loss=0.0532]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 509/1835 [11:50<31:08,  1.41s/it, training loss=0.0532]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 509/1835 [11:52<31:08,  1.41s/it, training loss=0.4038]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 510/1835 [11:52<31:20,  1.42s/it, training loss=0.4038]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 510/1835 [11:53<31:20,  1.42s/it, training loss=0.3030]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 511/1835 [11:53<31:24,  1.42s/it, training loss=0.3030]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 511/1835 [11:55<31:24,  1.42s/it, training loss=0.0577]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 512/1835 [11:55<31:31,  1.43s/it, training loss=0.0577]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 512/1835 [11:56<31:31,  1.43s/it, training loss=0.0692]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 513/1835 [11:56<31:16,  1.42s/it, training loss=0.0692]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 513/1835 [11:58<31:16,  1.42s/it, training loss=0.1495]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 514/1835 [11:58<31:26,  1.43s/it, training loss=0.1495]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 514/1835 [11:59<31:26,  1.43s/it, training loss=0.1019]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 515/1835 [11:59<31:15,  1.42s/it, training loss=0.1019]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 515/1835 [12:00<31:15,  1.42s/it, training loss=0.0773]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 516/1835 [12:00<31:14,  1.42s/it, training loss=0.0773]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 516/1835 [12:02<31:14,  1.42s/it, training loss=0.3013]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 517/1835 [12:02<31:06,  1.42s/it, training loss=0.3013]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 517/1835 [12:03<31:06,  1.42s/it, training loss=0.0963]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 518/1835 [12:03<31:03,  1.42s/it, training loss=0.0963]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 518/1835 [12:05<31:03,  1.42s/it, training loss=0.0690]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 519/1835 [12:05<31:05,  1.42s/it, training loss=0.0690]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 519/1835 [12:06<31:05,  1.42s/it, training loss=0.1820]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 520/1835 [12:06<31:24,  1.43s/it, training loss=0.1820]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 520/1835 [12:08<31:24,  1.43s/it, training loss=0.1749]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 521/1835 [12:08<31:27,  1.44s/it, training loss=0.1749]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 521/1835 [12:09<31:27,  1.44s/it, training loss=0.1351]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 522/1835 [12:09<31:19,  1.43s/it, training loss=0.1351]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 522/1835 [12:10<31:19,  1.43s/it, training loss=0.2635]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 523/1835 [12:10<31:04,  1.42s/it, training loss=0.2635]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 523/1835 [12:12<31:04,  1.42s/it, training loss=0.2741]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 524/1835 [12:12<30:54,  1.41s/it, training loss=0.2741]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 524/1835 [12:13<30:54,  1.41s/it, training loss=0.1399]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 525/1835 [12:13<30:44,  1.41s/it, training loss=0.1399]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 525/1835 [12:15<30:44,  1.41s/it, training loss=0.0930]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 526/1835 [12:15<30:32,  1.40s/it, training loss=0.0930]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 526/1835 [12:16<30:32,  1.40s/it, training loss=0.1211]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 527/1835 [12:16<30:27,  1.40s/it, training loss=0.1211]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 527/1835 [12:17<30:27,  1.40s/it, training loss=0.1861]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 528/1835 [12:17<30:24,  1.40s/it, training loss=0.1861]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 528/1835 [12:19<30:24,  1.40s/it, training loss=0.1167]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 529/1835 [12:19<30:24,  1.40s/it, training loss=0.1167]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 529/1835 [12:20<30:24,  1.40s/it, training loss=0.2136]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 530/1835 [12:20<30:19,  1.39s/it, training loss=0.2136]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 530/1835 [12:22<30:19,  1.39s/it, training loss=0.0813]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 531/1835 [12:22<30:20,  1.40s/it, training loss=0.0813]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 531/1835 [12:23<30:20,  1.40s/it, training loss=0.1270]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 532/1835 [12:23<30:18,  1.40s/it, training loss=0.1270]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 532/1835 [12:24<30:18,  1.40s/it, training loss=0.1072]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 533/1835 [12:24<30:16,  1.40s/it, training loss=0.1072]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 533/1835 [12:26<30:16,  1.40s/it, training loss=0.1305]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 534/1835 [12:26<30:12,  1.39s/it, training loss=0.1305]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 534/1835 [12:27<30:12,  1.39s/it, training loss=0.0999]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 535/1835 [12:27<30:14,  1.40s/it, training loss=0.0999]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 535/1835 [12:29<30:14,  1.40s/it, training loss=0.1236]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 536/1835 [12:29<30:13,  1.40s/it, training loss=0.1236]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 536/1835 [12:30<30:13,  1.40s/it, training loss=0.1065]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 537/1835 [12:30<30:09,  1.39s/it, training loss=0.1065]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 537/1835 [12:31<30:09,  1.39s/it, training loss=0.3340]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 538/1835 [12:31<30:09,  1.40s/it, training loss=0.3340]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 538/1835 [12:33<30:09,  1.40s/it, training loss=0.1731]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 539/1835 [12:33<30:10,  1.40s/it, training loss=0.1731]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 539/1835 [12:34<30:10,  1.40s/it, training loss=0.1501]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 540/1835 [12:34<30:08,  1.40s/it, training loss=0.1501]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 540/1835 [12:36<30:08,  1.40s/it, training loss=0.1679]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 541/1835 [12:36<30:08,  1.40s/it, training loss=0.1679]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 541/1835 [12:37<30:08,  1.40s/it, training loss=0.1293]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 542/1835 [12:37<30:06,  1.40s/it, training loss=0.1293]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 542/1835 [12:38<30:06,  1.40s/it, training loss=0.2926]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 543/1835 [12:38<30:06,  1.40s/it, training loss=0.2926]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 543/1835 [12:40<30:06,  1.40s/it, training loss=0.0833]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 544/1835 [12:40<30:05,  1.40s/it, training loss=0.0833]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 544/1835 [12:41<30:05,  1.40s/it, training loss=0.2338]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 545/1835 [12:41<30:02,  1.40s/it, training loss=0.2338]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 545/1835 [12:43<30:02,  1.40s/it, training loss=0.1513]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 546/1835 [12:43<30:02,  1.40s/it, training loss=0.1513]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 546/1835 [12:44<30:02,  1.40s/it, training loss=0.1379]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 547/1835 [12:44<29:57,  1.40s/it, training loss=0.1379]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 547/1835 [12:45<29:57,  1.40s/it, training loss=0.2187]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 548/1835 [12:45<29:57,  1.40s/it, training loss=0.2187]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 548/1835 [12:47<29:57,  1.40s/it, training loss=0.1540]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 549/1835 [12:47<29:58,  1.40s/it, training loss=0.1540]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 549/1835 [12:48<29:58,  1.40s/it, training loss=0.2625]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 550/1835 [12:48<29:57,  1.40s/it, training loss=0.2625]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 550/1835 [12:50<29:57,  1.40s/it, training loss=0.0787]\u001b[A\n",
            "Epoch 2:  30%|███       | 551/1835 [12:50<29:57,  1.40s/it, training loss=0.0787]\u001b[A\n",
            "Epoch 2:  30%|███       | 551/1835 [12:51<29:57,  1.40s/it, training loss=0.0769]\u001b[A\n",
            "Epoch 2:  30%|███       | 552/1835 [12:51<29:55,  1.40s/it, training loss=0.0769]\u001b[A\n",
            "Epoch 2:  30%|███       | 552/1835 [12:52<29:55,  1.40s/it, training loss=0.1562]\u001b[A\n",
            "Epoch 2:  30%|███       | 553/1835 [12:52<29:53,  1.40s/it, training loss=0.1562]\u001b[A\n",
            "Epoch 2:  30%|███       | 553/1835 [12:54<29:53,  1.40s/it, training loss=0.2104]\u001b[A\n",
            "Epoch 2:  30%|███       | 554/1835 [12:54<29:52,  1.40s/it, training loss=0.2104]\u001b[A\n",
            "Epoch 2:  30%|███       | 554/1835 [12:55<29:52,  1.40s/it, training loss=0.1431]\u001b[A\n",
            "Epoch 2:  30%|███       | 555/1835 [12:55<29:50,  1.40s/it, training loss=0.1431]\u001b[A\n",
            "Epoch 2:  30%|███       | 555/1835 [12:57<29:50,  1.40s/it, training loss=0.2456]\u001b[A\n",
            "Epoch 2:  30%|███       | 556/1835 [12:57<29:46,  1.40s/it, training loss=0.2456]\u001b[A\n",
            "Epoch 2:  30%|███       | 556/1835 [12:58<29:46,  1.40s/it, training loss=0.0457]\u001b[A\n",
            "Epoch 2:  30%|███       | 557/1835 [12:58<29:46,  1.40s/it, training loss=0.0457]\u001b[A\n",
            "Epoch 2:  30%|███       | 557/1835 [12:59<29:46,  1.40s/it, training loss=0.1944]\u001b[A\n",
            "Epoch 2:  30%|███       | 558/1835 [12:59<29:45,  1.40s/it, training loss=0.1944]\u001b[A\n",
            "Epoch 2:  30%|███       | 558/1835 [13:01<29:45,  1.40s/it, training loss=0.2323]\u001b[A\n",
            "Epoch 2:  30%|███       | 559/1835 [13:01<29:44,  1.40s/it, training loss=0.2323]\u001b[A\n",
            "Epoch 2:  30%|███       | 559/1835 [13:02<29:44,  1.40s/it, training loss=0.1082]\u001b[A\n",
            "Epoch 2:  31%|███       | 560/1835 [13:02<29:42,  1.40s/it, training loss=0.1082]\u001b[A\n",
            "Epoch 2:  31%|███       | 560/1835 [13:04<29:42,  1.40s/it, training loss=0.1402]\u001b[A\n",
            "Epoch 2:  31%|███       | 561/1835 [13:04<29:46,  1.40s/it, training loss=0.1402]\u001b[A\n",
            "Epoch 2:  31%|███       | 561/1835 [13:05<29:46,  1.40s/it, training loss=0.0766]\u001b[A\n",
            "Epoch 2:  31%|███       | 562/1835 [13:05<29:45,  1.40s/it, training loss=0.0766]\u001b[A\n",
            "Epoch 2:  31%|███       | 562/1835 [13:06<29:45,  1.40s/it, training loss=0.0367]\u001b[A\n",
            "Epoch 2:  31%|███       | 563/1835 [13:06<29:42,  1.40s/it, training loss=0.0367]\u001b[A\n",
            "Epoch 2:  31%|███       | 563/1835 [13:08<29:42,  1.40s/it, training loss=0.0956]\u001b[A\n",
            "Epoch 2:  31%|███       | 564/1835 [13:08<29:41,  1.40s/it, training loss=0.0956]\u001b[A\n",
            "Epoch 2:  31%|███       | 564/1835 [13:09<29:41,  1.40s/it, training loss=0.3223]\u001b[A\n",
            "Epoch 2:  31%|███       | 565/1835 [13:09<29:40,  1.40s/it, training loss=0.3223]\u001b[A\n",
            "Epoch 2:  31%|███       | 565/1835 [13:11<29:40,  1.40s/it, training loss=0.4581]\u001b[A\n",
            "Epoch 2:  31%|███       | 566/1835 [13:11<29:36,  1.40s/it, training loss=0.4581]\u001b[A\n",
            "Epoch 2:  31%|███       | 566/1835 [13:12<29:36,  1.40s/it, training loss=0.0357]\u001b[A\n",
            "Epoch 2:  31%|███       | 567/1835 [13:12<29:35,  1.40s/it, training loss=0.0357]\u001b[A\n",
            "Epoch 2:  31%|███       | 567/1835 [13:13<29:35,  1.40s/it, training loss=0.2280]\u001b[A\n",
            "Epoch 2:  31%|███       | 568/1835 [13:13<29:33,  1.40s/it, training loss=0.2280]\u001b[A\n",
            "Epoch 2:  31%|███       | 568/1835 [13:15<29:33,  1.40s/it, training loss=0.2014]\u001b[A\n",
            "Epoch 2:  31%|███       | 569/1835 [13:15<29:32,  1.40s/it, training loss=0.2014]\u001b[A\n",
            "Epoch 2:  31%|███       | 569/1835 [13:16<29:32,  1.40s/it, training loss=0.3110]\u001b[A\n",
            "Epoch 2:  31%|███       | 570/1835 [13:16<29:31,  1.40s/it, training loss=0.3110]\u001b[A\n",
            "Epoch 2:  31%|███       | 570/1835 [13:18<29:31,  1.40s/it, training loss=0.1306]\u001b[A\n",
            "Epoch 2:  31%|███       | 571/1835 [13:18<29:29,  1.40s/it, training loss=0.1306]\u001b[A\n",
            "Epoch 2:  31%|███       | 571/1835 [13:19<29:29,  1.40s/it, training loss=0.1495]\u001b[A\n",
            "Epoch 2:  31%|███       | 572/1835 [13:19<29:27,  1.40s/it, training loss=0.1495]\u001b[A\n",
            "Epoch 2:  31%|███       | 572/1835 [13:20<29:27,  1.40s/it, training loss=0.2344]\u001b[A\n",
            "Epoch 2:  31%|███       | 573/1835 [13:20<29:25,  1.40s/it, training loss=0.2344]\u001b[A\n",
            "Epoch 2:  31%|███       | 573/1835 [13:22<29:25,  1.40s/it, training loss=0.1112]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 574/1835 [13:22<29:22,  1.40s/it, training loss=0.1112]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 574/1835 [13:23<29:22,  1.40s/it, training loss=0.1370]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 575/1835 [13:23<29:21,  1.40s/it, training loss=0.1370]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 575/1835 [13:25<29:21,  1.40s/it, training loss=0.1652]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 576/1835 [13:25<29:17,  1.40s/it, training loss=0.1652]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 576/1835 [13:26<29:17,  1.40s/it, training loss=0.0898]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 577/1835 [13:26<29:14,  1.39s/it, training loss=0.0898]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 577/1835 [13:27<29:14,  1.39s/it, training loss=0.3001]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 578/1835 [13:27<29:12,  1.39s/it, training loss=0.3001]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 578/1835 [13:29<29:12,  1.39s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 579/1835 [13:29<29:09,  1.39s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 579/1835 [13:30<29:09,  1.39s/it, training loss=0.1919]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 580/1835 [13:30<29:11,  1.40s/it, training loss=0.1919]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 580/1835 [13:31<29:11,  1.40s/it, training loss=0.2112]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 581/1835 [13:31<29:07,  1.39s/it, training loss=0.2112]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 581/1835 [13:33<29:07,  1.39s/it, training loss=0.1805]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 582/1835 [13:33<29:04,  1.39s/it, training loss=0.1805]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 582/1835 [13:34<29:04,  1.39s/it, training loss=0.0608]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 583/1835 [13:34<29:04,  1.39s/it, training loss=0.0608]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 583/1835 [13:36<29:04,  1.39s/it, training loss=0.1217]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 584/1835 [13:36<29:00,  1.39s/it, training loss=0.1217]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 584/1835 [13:37<29:00,  1.39s/it, training loss=0.0764]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 585/1835 [13:37<28:59,  1.39s/it, training loss=0.0764]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 585/1835 [13:38<28:59,  1.39s/it, training loss=0.2356]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 586/1835 [13:38<28:59,  1.39s/it, training loss=0.2356]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 586/1835 [13:40<28:59,  1.39s/it, training loss=0.1355]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 587/1835 [13:40<28:58,  1.39s/it, training loss=0.1355]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 587/1835 [13:41<28:58,  1.39s/it, training loss=0.0460]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 588/1835 [13:41<28:57,  1.39s/it, training loss=0.0460]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 588/1835 [13:43<28:57,  1.39s/it, training loss=0.1161]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 589/1835 [13:43<28:53,  1.39s/it, training loss=0.1161]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 589/1835 [13:44<28:53,  1.39s/it, training loss=0.2229]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 590/1835 [13:44<28:52,  1.39s/it, training loss=0.2229]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 590/1835 [13:45<28:52,  1.39s/it, training loss=0.1310]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 591/1835 [13:45<28:52,  1.39s/it, training loss=0.1310]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 591/1835 [13:47<28:52,  1.39s/it, training loss=0.1236]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 592/1835 [13:47<28:49,  1.39s/it, training loss=0.1236]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 592/1835 [13:48<28:49,  1.39s/it, training loss=0.2151]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 593/1835 [13:48<28:52,  1.39s/it, training loss=0.2151]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 593/1835 [13:50<28:52,  1.39s/it, training loss=0.1689]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 594/1835 [13:50<28:48,  1.39s/it, training loss=0.1689]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 594/1835 [13:51<28:48,  1.39s/it, training loss=0.1569]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 595/1835 [13:51<28:50,  1.40s/it, training loss=0.1569]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 595/1835 [13:52<28:50,  1.40s/it, training loss=0.1340]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 596/1835 [13:52<28:50,  1.40s/it, training loss=0.1340]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 596/1835 [13:54<28:50,  1.40s/it, training loss=0.2709]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 597/1835 [13:54<28:48,  1.40s/it, training loss=0.2709]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 597/1835 [13:55<28:48,  1.40s/it, training loss=0.1186]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 598/1835 [13:55<28:44,  1.39s/it, training loss=0.1186]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 598/1835 [13:57<28:44,  1.39s/it, training loss=0.1762]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 599/1835 [13:57<28:44,  1.40s/it, training loss=0.1762]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 599/1835 [13:58<28:44,  1.40s/it, training loss=0.1301]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 600/1835 [13:58<28:40,  1.39s/it, training loss=0.1301]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 600/1835 [13:59<28:40,  1.39s/it, training loss=0.1729]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 601/1835 [13:59<28:36,  1.39s/it, training loss=0.1729]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 601/1835 [14:01<28:36,  1.39s/it, training loss=0.0747]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 602/1835 [14:01<28:36,  1.39s/it, training loss=0.0747]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 602/1835 [14:02<28:36,  1.39s/it, training loss=0.1279]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 603/1835 [14:02<28:32,  1.39s/it, training loss=0.1279]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 603/1835 [14:04<28:32,  1.39s/it, training loss=0.1218]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 604/1835 [14:04<28:31,  1.39s/it, training loss=0.1218]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 604/1835 [14:05<28:31,  1.39s/it, training loss=0.2624]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 605/1835 [14:05<28:34,  1.39s/it, training loss=0.2624]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 605/1835 [14:06<28:34,  1.39s/it, training loss=0.1218]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 606/1835 [14:06<28:31,  1.39s/it, training loss=0.1218]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 606/1835 [14:08<28:31,  1.39s/it, training loss=0.1549]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 607/1835 [14:08<28:27,  1.39s/it, training loss=0.1549]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 607/1835 [14:09<28:27,  1.39s/it, training loss=0.1084]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 608/1835 [14:09<28:26,  1.39s/it, training loss=0.1084]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 608/1835 [14:11<28:26,  1.39s/it, training loss=0.1661]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 609/1835 [14:11<28:40,  1.40s/it, training loss=0.1661]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 609/1835 [14:12<28:40,  1.40s/it, training loss=0.1191]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 610/1835 [14:12<28:33,  1.40s/it, training loss=0.1191]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 610/1835 [14:13<28:33,  1.40s/it, training loss=0.1285]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 611/1835 [14:13<28:31,  1.40s/it, training loss=0.1285]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 611/1835 [14:15<28:31,  1.40s/it, training loss=0.2525]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 612/1835 [14:15<28:30,  1.40s/it, training loss=0.2525]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 612/1835 [14:16<28:30,  1.40s/it, training loss=0.0902]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 613/1835 [14:16<28:27,  1.40s/it, training loss=0.0902]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 613/1835 [14:17<28:27,  1.40s/it, training loss=0.0893]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 614/1835 [14:17<28:24,  1.40s/it, training loss=0.0893]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 614/1835 [14:19<28:24,  1.40s/it, training loss=0.1233]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 615/1835 [14:19<28:21,  1.39s/it, training loss=0.1233]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 615/1835 [14:20<28:21,  1.39s/it, training loss=0.0342]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 616/1835 [14:20<28:21,  1.40s/it, training loss=0.0342]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 616/1835 [14:22<28:21,  1.40s/it, training loss=0.2717]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 617/1835 [14:22<28:21,  1.40s/it, training loss=0.2717]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 617/1835 [14:23<28:21,  1.40s/it, training loss=0.0567]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 618/1835 [14:23<28:16,  1.39s/it, training loss=0.0567]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 618/1835 [14:24<28:16,  1.39s/it, training loss=0.1838]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 619/1835 [14:24<28:13,  1.39s/it, training loss=0.1838]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 619/1835 [14:26<28:13,  1.39s/it, training loss=0.0538]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 620/1835 [14:26<28:13,  1.39s/it, training loss=0.0538]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 620/1835 [14:27<28:13,  1.39s/it, training loss=0.2151]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 621/1835 [14:27<28:12,  1.39s/it, training loss=0.2151]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 621/1835 [14:29<28:12,  1.39s/it, training loss=0.2246]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 622/1835 [14:29<28:09,  1.39s/it, training loss=0.2246]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 622/1835 [14:30<28:09,  1.39s/it, training loss=0.1174]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 623/1835 [14:30<28:06,  1.39s/it, training loss=0.1174]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 623/1835 [14:31<28:06,  1.39s/it, training loss=0.2305]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 624/1835 [14:31<28:08,  1.39s/it, training loss=0.2305]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 624/1835 [14:33<28:08,  1.39s/it, training loss=0.1857]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 625/1835 [14:33<28:05,  1.39s/it, training loss=0.1857]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 625/1835 [14:34<28:05,  1.39s/it, training loss=0.1148]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 626/1835 [14:34<28:04,  1.39s/it, training loss=0.1148]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 626/1835 [14:36<28:04,  1.39s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 627/1835 [14:36<28:02,  1.39s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 627/1835 [14:37<28:02,  1.39s/it, training loss=0.2298]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 628/1835 [14:37<27:59,  1.39s/it, training loss=0.2298]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 628/1835 [14:38<27:59,  1.39s/it, training loss=0.0911]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 629/1835 [14:38<27:59,  1.39s/it, training loss=0.0911]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 629/1835 [14:40<27:59,  1.39s/it, training loss=0.1167]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 630/1835 [14:40<27:59,  1.39s/it, training loss=0.1167]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 630/1835 [14:41<27:59,  1.39s/it, training loss=0.2163]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 631/1835 [14:41<27:58,  1.39s/it, training loss=0.2163]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 631/1835 [14:43<27:58,  1.39s/it, training loss=0.0567]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 632/1835 [14:43<27:57,  1.39s/it, training loss=0.0567]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 632/1835 [14:44<27:57,  1.39s/it, training loss=0.2594]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 633/1835 [14:44<27:54,  1.39s/it, training loss=0.2594]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 633/1835 [14:45<27:54,  1.39s/it, training loss=0.1547]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 634/1835 [14:45<27:53,  1.39s/it, training loss=0.1547]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 634/1835 [14:47<27:53,  1.39s/it, training loss=0.1927]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 635/1835 [14:47<27:50,  1.39s/it, training loss=0.1927]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 635/1835 [14:48<27:50,  1.39s/it, training loss=0.4156]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 636/1835 [14:48<27:52,  1.39s/it, training loss=0.4156]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 636/1835 [14:50<27:52,  1.39s/it, training loss=0.1845]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 637/1835 [14:50<27:51,  1.40s/it, training loss=0.1845]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 637/1835 [14:51<27:51,  1.40s/it, training loss=0.1214]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 638/1835 [14:51<27:51,  1.40s/it, training loss=0.1214]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 638/1835 [14:52<27:51,  1.40s/it, training loss=0.1737]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 639/1835 [14:52<27:52,  1.40s/it, training loss=0.1737]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 639/1835 [14:54<27:52,  1.40s/it, training loss=0.1167]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 640/1835 [14:54<27:53,  1.40s/it, training loss=0.1167]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 640/1835 [14:55<27:53,  1.40s/it, training loss=0.1323]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 641/1835 [14:55<27:52,  1.40s/it, training loss=0.1323]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 641/1835 [14:57<27:52,  1.40s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 642/1835 [14:57<27:51,  1.40s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 642/1835 [14:58<27:51,  1.40s/it, training loss=0.1228]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 643/1835 [14:58<27:50,  1.40s/it, training loss=0.1228]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 643/1835 [14:59<27:50,  1.40s/it, training loss=0.2272]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 644/1835 [14:59<27:50,  1.40s/it, training loss=0.2272]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 644/1835 [15:01<27:50,  1.40s/it, training loss=0.3893]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 645/1835 [15:01<27:49,  1.40s/it, training loss=0.3893]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 645/1835 [15:02<27:49,  1.40s/it, training loss=0.2611]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 646/1835 [15:02<27:48,  1.40s/it, training loss=0.2611]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 646/1835 [15:04<27:48,  1.40s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 647/1835 [15:04<27:46,  1.40s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 647/1835 [15:05<27:46,  1.40s/it, training loss=0.3524]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 648/1835 [15:05<27:45,  1.40s/it, training loss=0.3524]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 648/1835 [15:06<27:45,  1.40s/it, training loss=0.1078]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 649/1835 [15:06<27:43,  1.40s/it, training loss=0.1078]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 649/1835 [15:08<27:43,  1.40s/it, training loss=0.1269]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 650/1835 [15:08<27:38,  1.40s/it, training loss=0.1269]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 650/1835 [15:09<27:38,  1.40s/it, training loss=0.1523]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 651/1835 [15:09<27:38,  1.40s/it, training loss=0.1523]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 651/1835 [15:11<27:38,  1.40s/it, training loss=0.1002]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 652/1835 [15:11<27:34,  1.40s/it, training loss=0.1002]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 652/1835 [15:12<27:34,  1.40s/it, training loss=0.1612]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 653/1835 [15:12<27:32,  1.40s/it, training loss=0.1612]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 653/1835 [15:13<27:32,  1.40s/it, training loss=0.1405]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 654/1835 [15:13<27:28,  1.40s/it, training loss=0.1405]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 654/1835 [15:15<27:28,  1.40s/it, training loss=0.2366]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 655/1835 [15:15<27:29,  1.40s/it, training loss=0.2366]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 655/1835 [15:16<27:29,  1.40s/it, training loss=0.1764]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 656/1835 [15:16<27:26,  1.40s/it, training loss=0.1764]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 656/1835 [15:18<27:26,  1.40s/it, training loss=0.0747]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 657/1835 [15:18<27:22,  1.39s/it, training loss=0.0747]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 657/1835 [15:19<27:22,  1.39s/it, training loss=0.1271]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 658/1835 [15:19<27:20,  1.39s/it, training loss=0.1271]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 658/1835 [15:20<27:20,  1.39s/it, training loss=0.1150]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 659/1835 [15:20<27:21,  1.40s/it, training loss=0.1150]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 659/1835 [15:22<27:21,  1.40s/it, training loss=0.2377]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 660/1835 [15:22<27:18,  1.39s/it, training loss=0.2377]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 660/1835 [15:23<27:18,  1.39s/it, training loss=0.0914]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 661/1835 [15:23<27:18,  1.40s/it, training loss=0.0914]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 661/1835 [15:25<27:18,  1.40s/it, training loss=0.1071]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 662/1835 [15:25<27:15,  1.39s/it, training loss=0.1071]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 662/1835 [15:26<27:15,  1.39s/it, training loss=0.2661]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 663/1835 [15:26<27:15,  1.40s/it, training loss=0.2661]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 663/1835 [15:27<27:15,  1.40s/it, training loss=0.1091]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 664/1835 [15:27<27:15,  1.40s/it, training loss=0.1091]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 664/1835 [15:29<27:15,  1.40s/it, training loss=0.1588]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 665/1835 [15:29<27:11,  1.39s/it, training loss=0.1588]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 665/1835 [15:30<27:11,  1.39s/it, training loss=0.0359]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 666/1835 [15:30<27:10,  1.39s/it, training loss=0.0359]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 666/1835 [15:31<27:10,  1.39s/it, training loss=0.2618]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 667/1835 [15:31<27:10,  1.40s/it, training loss=0.2618]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 667/1835 [15:33<27:10,  1.40s/it, training loss=0.1290]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 668/1835 [15:33<27:09,  1.40s/it, training loss=0.1290]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 668/1835 [15:34<27:09,  1.40s/it, training loss=0.3091]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 669/1835 [15:34<27:06,  1.39s/it, training loss=0.3091]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 669/1835 [15:36<27:06,  1.39s/it, training loss=0.1632]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 670/1835 [15:36<27:08,  1.40s/it, training loss=0.1632]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 670/1835 [15:37<27:08,  1.40s/it, training loss=0.1146]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 671/1835 [15:37<27:06,  1.40s/it, training loss=0.1146]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 671/1835 [15:38<27:06,  1.40s/it, training loss=0.1649]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 672/1835 [15:38<27:03,  1.40s/it, training loss=0.1649]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 672/1835 [15:40<27:03,  1.40s/it, training loss=0.2444]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 673/1835 [15:40<27:02,  1.40s/it, training loss=0.2444]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 673/1835 [15:41<27:02,  1.40s/it, training loss=0.2625]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 674/1835 [15:41<27:01,  1.40s/it, training loss=0.2625]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 674/1835 [15:43<27:01,  1.40s/it, training loss=0.1063]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 675/1835 [15:43<26:58,  1.39s/it, training loss=0.1063]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 675/1835 [15:44<26:58,  1.39s/it, training loss=0.1819]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 676/1835 [15:44<26:57,  1.40s/it, training loss=0.1819]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 676/1835 [15:45<26:57,  1.40s/it, training loss=0.3039]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 677/1835 [15:45<26:53,  1.39s/it, training loss=0.3039]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 677/1835 [15:47<26:53,  1.39s/it, training loss=0.0871]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 678/1835 [15:47<26:51,  1.39s/it, training loss=0.0871]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 678/1835 [15:48<26:51,  1.39s/it, training loss=0.1859]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 679/1835 [15:48<26:49,  1.39s/it, training loss=0.1859]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 679/1835 [15:50<26:49,  1.39s/it, training loss=0.0945]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 680/1835 [15:50<26:49,  1.39s/it, training loss=0.0945]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 680/1835 [15:51<26:49,  1.39s/it, training loss=0.1462]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 681/1835 [15:51<26:46,  1.39s/it, training loss=0.1462]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 681/1835 [15:52<26:46,  1.39s/it, training loss=0.2367]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 682/1835 [15:52<26:45,  1.39s/it, training loss=0.2367]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 682/1835 [15:54<26:45,  1.39s/it, training loss=0.2304]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 683/1835 [15:54<26:42,  1.39s/it, training loss=0.2304]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 683/1835 [15:55<26:42,  1.39s/it, training loss=0.1517]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 684/1835 [15:55<26:43,  1.39s/it, training loss=0.1517]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 684/1835 [15:57<26:43,  1.39s/it, training loss=0.1633]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 685/1835 [15:57<26:43,  1.39s/it, training loss=0.1633]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 685/1835 [15:58<26:43,  1.39s/it, training loss=0.1982]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 686/1835 [15:58<26:41,  1.39s/it, training loss=0.1982]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 686/1835 [15:59<26:41,  1.39s/it, training loss=0.1817]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 687/1835 [15:59<26:38,  1.39s/it, training loss=0.1817]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 687/1835 [16:01<26:38,  1.39s/it, training loss=0.1617]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 688/1835 [16:01<26:38,  1.39s/it, training loss=0.1617]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 688/1835 [16:02<26:38,  1.39s/it, training loss=0.1247]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 689/1835 [16:02<26:37,  1.39s/it, training loss=0.1247]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 689/1835 [16:04<26:37,  1.39s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 690/1835 [16:04<26:35,  1.39s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 690/1835 [16:05<26:35,  1.39s/it, training loss=0.2470]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 691/1835 [16:05<26:37,  1.40s/it, training loss=0.2470]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 691/1835 [16:06<26:37,  1.40s/it, training loss=0.2107]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 692/1835 [16:06<26:35,  1.40s/it, training loss=0.2107]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 692/1835 [16:08<26:35,  1.40s/it, training loss=0.1105]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 693/1835 [16:08<26:34,  1.40s/it, training loss=0.1105]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 693/1835 [16:09<26:34,  1.40s/it, training loss=0.2781]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 694/1835 [16:09<26:34,  1.40s/it, training loss=0.2781]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 694/1835 [16:11<26:34,  1.40s/it, training loss=0.1247]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 695/1835 [16:11<26:33,  1.40s/it, training loss=0.1247]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 695/1835 [16:12<26:33,  1.40s/it, training loss=0.1922]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 696/1835 [16:12<26:28,  1.39s/it, training loss=0.1922]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 696/1835 [16:13<26:28,  1.39s/it, training loss=0.1805]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 697/1835 [16:13<26:28,  1.40s/it, training loss=0.1805]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 697/1835 [16:15<26:28,  1.40s/it, training loss=0.2292]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 698/1835 [16:15<26:27,  1.40s/it, training loss=0.2292]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 698/1835 [16:16<26:27,  1.40s/it, training loss=0.1164]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 699/1835 [16:16<26:26,  1.40s/it, training loss=0.1164]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 699/1835 [16:18<26:26,  1.40s/it, training loss=0.2162]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 700/1835 [16:18<26:25,  1.40s/it, training loss=0.2162]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 700/1835 [16:19<26:25,  1.40s/it, training loss=0.2362]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 701/1835 [16:19<26:24,  1.40s/it, training loss=0.2362]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 701/1835 [16:20<26:24,  1.40s/it, training loss=0.0928]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 702/1835 [16:20<26:21,  1.40s/it, training loss=0.0928]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 702/1835 [16:22<26:21,  1.40s/it, training loss=0.1098]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 703/1835 [16:22<26:18,  1.39s/it, training loss=0.1098]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 703/1835 [16:23<26:18,  1.39s/it, training loss=0.1355]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 704/1835 [16:23<26:17,  1.39s/it, training loss=0.1355]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 704/1835 [16:24<26:17,  1.39s/it, training loss=0.1045]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 705/1835 [16:24<26:16,  1.39s/it, training loss=0.1045]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 705/1835 [16:26<26:16,  1.39s/it, training loss=0.1582]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 706/1835 [16:26<26:16,  1.40s/it, training loss=0.1582]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 706/1835 [16:27<26:16,  1.40s/it, training loss=0.2034]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 707/1835 [16:27<26:13,  1.39s/it, training loss=0.2034]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 707/1835 [16:29<26:13,  1.39s/it, training loss=0.1740]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 708/1835 [16:29<26:11,  1.39s/it, training loss=0.1740]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 708/1835 [16:30<26:11,  1.39s/it, training loss=0.1228]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 709/1835 [16:30<26:11,  1.40s/it, training loss=0.1228]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 709/1835 [16:31<26:11,  1.40s/it, training loss=0.0760]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 710/1835 [16:31<26:10,  1.40s/it, training loss=0.0760]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 710/1835 [16:33<26:10,  1.40s/it, training loss=0.1142]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 711/1835 [16:33<26:09,  1.40s/it, training loss=0.1142]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 711/1835 [16:34<26:09,  1.40s/it, training loss=0.1269]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 712/1835 [16:34<26:07,  1.40s/it, training loss=0.1269]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 712/1835 [16:36<26:07,  1.40s/it, training loss=0.0684]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 713/1835 [16:36<26:07,  1.40s/it, training loss=0.0684]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 713/1835 [16:37<26:07,  1.40s/it, training loss=0.1071]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 714/1835 [16:37<26:07,  1.40s/it, training loss=0.1071]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 714/1835 [16:38<26:07,  1.40s/it, training loss=0.0557]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 715/1835 [16:38<26:03,  1.40s/it, training loss=0.0557]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 715/1835 [16:40<26:03,  1.40s/it, training loss=0.0681]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 716/1835 [16:40<26:02,  1.40s/it, training loss=0.0681]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 716/1835 [16:41<26:02,  1.40s/it, training loss=0.1288]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 717/1835 [16:41<26:02,  1.40s/it, training loss=0.1288]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 717/1835 [16:43<26:02,  1.40s/it, training loss=0.1540]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 718/1835 [16:43<26:01,  1.40s/it, training loss=0.1540]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 718/1835 [16:44<26:01,  1.40s/it, training loss=0.1283]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 719/1835 [16:44<25:59,  1.40s/it, training loss=0.1283]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 719/1835 [16:45<25:59,  1.40s/it, training loss=0.2043]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 720/1835 [16:45<25:56,  1.40s/it, training loss=0.2043]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 720/1835 [16:47<25:56,  1.40s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 721/1835 [16:47<25:54,  1.40s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 721/1835 [16:48<25:54,  1.40s/it, training loss=0.2476]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 722/1835 [16:48<25:51,  1.39s/it, training loss=0.2476]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 722/1835 [16:50<25:51,  1.39s/it, training loss=0.1494]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 723/1835 [16:50<25:49,  1.39s/it, training loss=0.1494]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 723/1835 [16:51<25:49,  1.39s/it, training loss=0.1211]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 724/1835 [16:51<25:46,  1.39s/it, training loss=0.1211]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 724/1835 [16:52<25:46,  1.39s/it, training loss=0.0577]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 725/1835 [16:52<25:46,  1.39s/it, training loss=0.0577]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 725/1835 [16:54<25:46,  1.39s/it, training loss=0.1751]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 726/1835 [16:54<25:46,  1.39s/it, training loss=0.1751]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 726/1835 [16:55<25:46,  1.39s/it, training loss=0.1645]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 727/1835 [16:55<25:47,  1.40s/it, training loss=0.1645]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 727/1835 [16:57<25:47,  1.40s/it, training loss=0.1126]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 728/1835 [16:57<25:43,  1.39s/it, training loss=0.1126]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 728/1835 [16:58<25:43,  1.39s/it, training loss=0.1216]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 729/1835 [16:58<25:44,  1.40s/it, training loss=0.1216]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 729/1835 [16:59<25:44,  1.40s/it, training loss=0.2261]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 730/1835 [16:59<25:42,  1.40s/it, training loss=0.2261]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 730/1835 [17:01<25:42,  1.40s/it, training loss=0.0752]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 731/1835 [17:01<25:39,  1.39s/it, training loss=0.0752]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 731/1835 [17:02<25:39,  1.39s/it, training loss=0.0886]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 732/1835 [17:02<25:37,  1.39s/it, training loss=0.0886]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 732/1835 [17:04<25:37,  1.39s/it, training loss=0.0931]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 733/1835 [17:04<25:34,  1.39s/it, training loss=0.0931]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 733/1835 [17:05<25:34,  1.39s/it, training loss=0.1232]\u001b[A\n",
            "Epoch 2:  40%|████      | 734/1835 [17:05<25:33,  1.39s/it, training loss=0.1232]\u001b[A\n",
            "Epoch 2:  40%|████      | 734/1835 [17:06<25:33,  1.39s/it, training loss=0.2259]\u001b[A\n",
            "Epoch 2:  40%|████      | 735/1835 [17:06<25:32,  1.39s/it, training loss=0.2259]\u001b[A\n",
            "Epoch 2:  40%|████      | 735/1835 [17:08<25:32,  1.39s/it, training loss=0.2349]\u001b[A\n",
            "Epoch 2:  40%|████      | 736/1835 [17:08<25:31,  1.39s/it, training loss=0.2349]\u001b[A\n",
            "Epoch 2:  40%|████      | 736/1835 [17:09<25:31,  1.39s/it, training loss=0.2127]\u001b[A\n",
            "Epoch 2:  40%|████      | 737/1835 [17:09<25:29,  1.39s/it, training loss=0.2127]\u001b[A\n",
            "Epoch 2:  40%|████      | 737/1835 [17:11<25:29,  1.39s/it, training loss=0.1200]\u001b[A\n",
            "Epoch 2:  40%|████      | 738/1835 [17:11<25:29,  1.39s/it, training loss=0.1200]\u001b[A\n",
            "Epoch 2:  40%|████      | 738/1835 [17:12<25:29,  1.39s/it, training loss=0.1223]\u001b[A\n",
            "Epoch 2:  40%|████      | 739/1835 [17:12<25:28,  1.39s/it, training loss=0.1223]\u001b[A\n",
            "Epoch 2:  40%|████      | 739/1835 [17:13<25:28,  1.39s/it, training loss=0.1582]\u001b[A\n",
            "Epoch 2:  40%|████      | 740/1835 [17:13<25:27,  1.39s/it, training loss=0.1582]\u001b[A\n",
            "Epoch 2:  40%|████      | 740/1835 [17:15<25:27,  1.39s/it, training loss=0.1843]\u001b[A\n",
            "Epoch 2:  40%|████      | 741/1835 [17:15<25:27,  1.40s/it, training loss=0.1843]\u001b[A\n",
            "Epoch 2:  40%|████      | 741/1835 [17:16<25:27,  1.40s/it, training loss=0.2107]\u001b[A\n",
            "Epoch 2:  40%|████      | 742/1835 [17:16<25:25,  1.40s/it, training loss=0.2107]\u001b[A\n",
            "Epoch 2:  40%|████      | 742/1835 [17:17<25:25,  1.40s/it, training loss=0.0521]\u001b[A\n",
            "Epoch 2:  40%|████      | 743/1835 [17:18<25:22,  1.39s/it, training loss=0.0521]\u001b[A\n",
            "Epoch 2:  40%|████      | 743/1835 [17:19<25:22,  1.39s/it, training loss=0.1842]\u001b[A\n",
            "Epoch 2:  41%|████      | 744/1835 [17:19<25:19,  1.39s/it, training loss=0.1842]\u001b[A\n",
            "Epoch 2:  41%|████      | 744/1835 [17:20<25:19,  1.39s/it, training loss=0.2992]\u001b[A\n",
            "Epoch 2:  41%|████      | 745/1835 [17:20<25:17,  1.39s/it, training loss=0.2992]\u001b[A\n",
            "Epoch 2:  41%|████      | 745/1835 [17:22<25:17,  1.39s/it, training loss=0.0875]\u001b[A\n",
            "Epoch 2:  41%|████      | 746/1835 [17:22<25:17,  1.39s/it, training loss=0.0875]\u001b[A\n",
            "Epoch 2:  41%|████      | 746/1835 [17:23<25:17,  1.39s/it, training loss=0.1151]\u001b[A\n",
            "Epoch 2:  41%|████      | 747/1835 [17:23<25:20,  1.40s/it, training loss=0.1151]\u001b[A\n",
            "Epoch 2:  41%|████      | 747/1835 [17:24<25:20,  1.40s/it, training loss=0.0448]\u001b[A\n",
            "Epoch 2:  41%|████      | 748/1835 [17:24<25:19,  1.40s/it, training loss=0.0448]\u001b[A\n",
            "Epoch 2:  41%|████      | 748/1835 [17:26<25:19,  1.40s/it, training loss=0.1712]\u001b[A\n",
            "Epoch 2:  41%|████      | 749/1835 [17:26<25:19,  1.40s/it, training loss=0.1712]\u001b[A\n",
            "Epoch 2:  41%|████      | 749/1835 [17:27<25:19,  1.40s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 2:  41%|████      | 750/1835 [17:27<25:14,  1.40s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 2:  41%|████      | 750/1835 [17:29<25:14,  1.40s/it, training loss=0.0507]\u001b[A\n",
            "Epoch 2:  41%|████      | 751/1835 [17:29<25:14,  1.40s/it, training loss=0.0507]\u001b[A\n",
            "Epoch 2:  41%|████      | 751/1835 [17:30<25:14,  1.40s/it, training loss=0.1649]\u001b[A\n",
            "Epoch 2:  41%|████      | 752/1835 [17:30<25:13,  1.40s/it, training loss=0.1649]\u001b[A\n",
            "Epoch 2:  41%|████      | 752/1835 [17:31<25:13,  1.40s/it, training loss=0.1028]\u001b[A\n",
            "Epoch 2:  41%|████      | 753/1835 [17:31<25:11,  1.40s/it, training loss=0.1028]\u001b[A\n",
            "Epoch 2:  41%|████      | 753/1835 [17:33<25:11,  1.40s/it, training loss=0.0535]\u001b[A\n",
            "Epoch 2:  41%|████      | 754/1835 [17:33<25:09,  1.40s/it, training loss=0.0535]\u001b[A\n",
            "Epoch 2:  41%|████      | 754/1835 [17:34<25:09,  1.40s/it, training loss=0.1520]\u001b[A\n",
            "Epoch 2:  41%|████      | 755/1835 [17:34<25:07,  1.40s/it, training loss=0.1520]\u001b[A\n",
            "Epoch 2:  41%|████      | 755/1835 [17:36<25:07,  1.40s/it, training loss=0.1169]\u001b[A\n",
            "Epoch 2:  41%|████      | 756/1835 [17:36<25:03,  1.39s/it, training loss=0.1169]\u001b[A\n",
            "Epoch 2:  41%|████      | 756/1835 [17:37<25:03,  1.39s/it, training loss=0.2337]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 757/1835 [17:37<25:00,  1.39s/it, training loss=0.2337]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 757/1835 [17:38<25:00,  1.39s/it, training loss=0.1666]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 758/1835 [17:38<24:59,  1.39s/it, training loss=0.1666]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 758/1835 [17:40<24:59,  1.39s/it, training loss=0.1613]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 759/1835 [17:40<25:00,  1.39s/it, training loss=0.1613]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 759/1835 [17:41<25:00,  1.39s/it, training loss=0.1659]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 760/1835 [17:41<24:58,  1.39s/it, training loss=0.1659]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 760/1835 [17:43<24:58,  1.39s/it, training loss=0.0528]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 761/1835 [17:43<24:57,  1.39s/it, training loss=0.0528]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 761/1835 [17:44<24:57,  1.39s/it, training loss=0.1980]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 762/1835 [17:44<24:57,  1.40s/it, training loss=0.1980]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 762/1835 [17:45<24:57,  1.40s/it, training loss=0.2034]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 763/1835 [17:45<24:55,  1.40s/it, training loss=0.2034]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 763/1835 [17:47<24:55,  1.40s/it, training loss=0.1184]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 764/1835 [17:47<24:53,  1.39s/it, training loss=0.1184]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 764/1835 [17:48<24:53,  1.39s/it, training loss=0.2243]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 765/1835 [17:48<24:49,  1.39s/it, training loss=0.2243]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 765/1835 [17:50<24:49,  1.39s/it, training loss=0.2015]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 766/1835 [17:50<24:50,  1.39s/it, training loss=0.2015]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 766/1835 [17:51<24:50,  1.39s/it, training loss=0.0356]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 767/1835 [17:51<24:50,  1.40s/it, training loss=0.0356]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 767/1835 [17:52<24:50,  1.40s/it, training loss=0.0995]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 768/1835 [17:52<24:48,  1.40s/it, training loss=0.0995]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 768/1835 [17:54<24:48,  1.40s/it, training loss=0.1974]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 769/1835 [17:54<24:47,  1.40s/it, training loss=0.1974]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 769/1835 [17:55<24:47,  1.40s/it, training loss=0.1513]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 770/1835 [17:55<24:45,  1.40s/it, training loss=0.1513]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 770/1835 [17:57<24:45,  1.40s/it, training loss=0.1100]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 771/1835 [17:57<24:42,  1.39s/it, training loss=0.1100]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 771/1835 [17:58<24:42,  1.39s/it, training loss=0.2142]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 772/1835 [17:58<24:40,  1.39s/it, training loss=0.2142]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 772/1835 [17:59<24:40,  1.39s/it, training loss=0.0825]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 773/1835 [17:59<24:39,  1.39s/it, training loss=0.0825]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 773/1835 [18:01<24:39,  1.39s/it, training loss=0.2134]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 774/1835 [18:01<24:39,  1.39s/it, training loss=0.2134]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 774/1835 [18:02<24:39,  1.39s/it, training loss=0.1795]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 775/1835 [18:02<24:37,  1.39s/it, training loss=0.1795]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 775/1835 [18:04<24:37,  1.39s/it, training loss=0.1213]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 776/1835 [18:04<24:33,  1.39s/it, training loss=0.1213]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 776/1835 [18:05<24:33,  1.39s/it, training loss=0.1227]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 777/1835 [18:05<24:35,  1.39s/it, training loss=0.1227]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 777/1835 [18:06<24:35,  1.39s/it, training loss=0.3697]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 778/1835 [18:06<24:33,  1.39s/it, training loss=0.3697]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 778/1835 [18:08<24:33,  1.39s/it, training loss=0.2372]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 779/1835 [18:08<24:34,  1.40s/it, training loss=0.2372]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 779/1835 [18:09<24:34,  1.40s/it, training loss=0.0399]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 780/1835 [18:09<24:31,  1.40s/it, training loss=0.0399]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 780/1835 [18:11<24:31,  1.40s/it, training loss=0.1054]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 781/1835 [18:11<24:30,  1.40s/it, training loss=0.1054]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 781/1835 [18:12<24:30,  1.40s/it, training loss=0.2340]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 782/1835 [18:12<24:26,  1.39s/it, training loss=0.2340]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 782/1835 [18:13<24:26,  1.39s/it, training loss=0.1129]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 783/1835 [18:13<24:23,  1.39s/it, training loss=0.1129]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 783/1835 [18:15<24:23,  1.39s/it, training loss=0.2956]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 784/1835 [18:15<24:21,  1.39s/it, training loss=0.2956]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 784/1835 [18:16<24:21,  1.39s/it, training loss=0.0435]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 785/1835 [18:16<24:20,  1.39s/it, training loss=0.0435]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 785/1835 [18:17<24:20,  1.39s/it, training loss=0.1634]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 786/1835 [18:17<24:19,  1.39s/it, training loss=0.1634]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 786/1835 [18:19<24:19,  1.39s/it, training loss=0.0309]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 787/1835 [18:19<24:19,  1.39s/it, training loss=0.0309]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 787/1835 [18:20<24:19,  1.39s/it, training loss=0.2043]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 788/1835 [18:20<24:18,  1.39s/it, training loss=0.2043]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 788/1835 [18:22<24:18,  1.39s/it, training loss=0.0702]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 789/1835 [18:22<24:17,  1.39s/it, training loss=0.0702]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 789/1835 [18:23<24:17,  1.39s/it, training loss=0.1771]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 790/1835 [18:23<24:19,  1.40s/it, training loss=0.1771]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 790/1835 [18:24<24:19,  1.40s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 791/1835 [18:24<24:15,  1.39s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 791/1835 [18:26<24:15,  1.39s/it, training loss=0.1232]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 792/1835 [18:26<24:15,  1.40s/it, training loss=0.1232]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 792/1835 [18:27<24:15,  1.40s/it, training loss=0.1608]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 793/1835 [18:27<24:13,  1.40s/it, training loss=0.1608]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 793/1835 [18:29<24:13,  1.40s/it, training loss=0.0953]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 794/1835 [18:29<24:11,  1.39s/it, training loss=0.0953]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 794/1835 [18:30<24:11,  1.39s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 795/1835 [18:30<24:09,  1.39s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 795/1835 [18:31<24:09,  1.39s/it, training loss=0.1929]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 796/1835 [18:31<24:08,  1.39s/it, training loss=0.1929]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 796/1835 [18:33<24:08,  1.39s/it, training loss=0.0443]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 797/1835 [18:33<24:06,  1.39s/it, training loss=0.0443]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 797/1835 [18:34<24:06,  1.39s/it, training loss=0.2095]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 798/1835 [18:34<24:07,  1.40s/it, training loss=0.2095]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 798/1835 [18:36<24:07,  1.40s/it, training loss=0.1398]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 799/1835 [18:36<24:07,  1.40s/it, training loss=0.1398]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 799/1835 [18:37<24:07,  1.40s/it, training loss=0.1687]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 800/1835 [18:37<24:08,  1.40s/it, training loss=0.1687]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 800/1835 [18:38<24:08,  1.40s/it, training loss=0.3048]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 801/1835 [18:38<24:03,  1.40s/it, training loss=0.3048]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 801/1835 [18:40<24:03,  1.40s/it, training loss=0.1441]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 802/1835 [18:40<24:02,  1.40s/it, training loss=0.1441]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 802/1835 [18:41<24:02,  1.40s/it, training loss=0.1948]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 803/1835 [18:41<24:02,  1.40s/it, training loss=0.1948]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 803/1835 [18:43<24:02,  1.40s/it, training loss=0.2078]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 804/1835 [18:43<23:58,  1.40s/it, training loss=0.2078]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 804/1835 [18:44<23:58,  1.40s/it, training loss=0.1955]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 805/1835 [18:44<24:00,  1.40s/it, training loss=0.1955]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 805/1835 [18:45<24:00,  1.40s/it, training loss=0.1216]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 806/1835 [18:45<23:56,  1.40s/it, training loss=0.1216]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 806/1835 [18:47<23:56,  1.40s/it, training loss=0.0873]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 807/1835 [18:47<23:54,  1.40s/it, training loss=0.0873]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 807/1835 [18:48<23:54,  1.40s/it, training loss=0.1739]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 808/1835 [18:48<23:54,  1.40s/it, training loss=0.1739]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 808/1835 [18:50<23:54,  1.40s/it, training loss=0.2268]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 809/1835 [18:50<23:52,  1.40s/it, training loss=0.2268]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 809/1835 [18:51<23:52,  1.40s/it, training loss=0.0826]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 810/1835 [18:51<23:52,  1.40s/it, training loss=0.0826]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 810/1835 [18:52<23:52,  1.40s/it, training loss=0.0909]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 811/1835 [18:52<23:51,  1.40s/it, training loss=0.0909]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 811/1835 [18:54<23:51,  1.40s/it, training loss=0.1887]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 812/1835 [18:54<23:49,  1.40s/it, training loss=0.1887]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 812/1835 [18:55<23:49,  1.40s/it, training loss=0.0914]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 813/1835 [18:55<23:48,  1.40s/it, training loss=0.0914]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 813/1835 [18:57<23:48,  1.40s/it, training loss=0.2746]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 814/1835 [18:57<23:45,  1.40s/it, training loss=0.2746]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 814/1835 [18:58<23:45,  1.40s/it, training loss=0.1873]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 815/1835 [18:58<23:42,  1.39s/it, training loss=0.1873]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 815/1835 [18:59<23:42,  1.39s/it, training loss=0.1150]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 816/1835 [18:59<23:39,  1.39s/it, training loss=0.1150]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 816/1835 [19:01<23:39,  1.39s/it, training loss=0.0908]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 817/1835 [19:01<23:37,  1.39s/it, training loss=0.0908]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 817/1835 [19:02<23:37,  1.39s/it, training loss=0.0624]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 818/1835 [19:02<23:36,  1.39s/it, training loss=0.0624]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 818/1835 [19:04<23:36,  1.39s/it, training loss=0.0823]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 819/1835 [19:04<23:36,  1.39s/it, training loss=0.0823]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 819/1835 [19:05<23:36,  1.39s/it, training loss=0.1137]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 820/1835 [19:05<23:36,  1.40s/it, training loss=0.1137]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 820/1835 [19:06<23:36,  1.40s/it, training loss=0.2062]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 821/1835 [19:06<23:35,  1.40s/it, training loss=0.2062]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 821/1835 [19:08<23:35,  1.40s/it, training loss=0.2857]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 822/1835 [19:08<23:33,  1.40s/it, training loss=0.2857]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 822/1835 [19:09<23:33,  1.40s/it, training loss=0.2523]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 823/1835 [19:09<23:33,  1.40s/it, training loss=0.2523]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 823/1835 [19:10<23:33,  1.40s/it, training loss=0.0932]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 824/1835 [19:11<23:32,  1.40s/it, training loss=0.0932]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 824/1835 [19:12<23:32,  1.40s/it, training loss=0.2055]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 825/1835 [19:12<23:31,  1.40s/it, training loss=0.2055]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 825/1835 [19:13<23:31,  1.40s/it, training loss=0.1568]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 826/1835 [19:13<23:32,  1.40s/it, training loss=0.1568]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 826/1835 [19:15<23:32,  1.40s/it, training loss=0.1388]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 827/1835 [19:15<23:29,  1.40s/it, training loss=0.1388]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 827/1835 [19:16<23:29,  1.40s/it, training loss=0.1799]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 828/1835 [19:16<23:29,  1.40s/it, training loss=0.1799]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 828/1835 [19:17<23:29,  1.40s/it, training loss=0.0662]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 829/1835 [19:18<23:27,  1.40s/it, training loss=0.0662]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 829/1835 [19:19<23:27,  1.40s/it, training loss=0.2588]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 830/1835 [19:19<23:26,  1.40s/it, training loss=0.2588]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 830/1835 [19:20<23:26,  1.40s/it, training loss=0.2925]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 831/1835 [19:20<23:24,  1.40s/it, training loss=0.2925]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 831/1835 [19:22<23:24,  1.40s/it, training loss=0.2610]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 832/1835 [19:22<23:21,  1.40s/it, training loss=0.2610]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 832/1835 [19:23<23:21,  1.40s/it, training loss=0.2383]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 833/1835 [19:23<23:20,  1.40s/it, training loss=0.2383]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 833/1835 [19:24<23:20,  1.40s/it, training loss=0.2476]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 834/1835 [19:24<23:17,  1.40s/it, training loss=0.2476]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 834/1835 [19:26<23:17,  1.40s/it, training loss=0.1666]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 835/1835 [19:26<23:17,  1.40s/it, training loss=0.1666]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 835/1835 [19:27<23:17,  1.40s/it, training loss=0.3217]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 836/1835 [19:27<23:12,  1.39s/it, training loss=0.3217]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 836/1835 [19:29<23:12,  1.39s/it, training loss=0.1375]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 837/1835 [19:29<23:11,  1.39s/it, training loss=0.1375]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 837/1835 [19:30<23:11,  1.39s/it, training loss=0.1645]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 838/1835 [19:30<23:09,  1.39s/it, training loss=0.1645]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 838/1835 [19:31<23:09,  1.39s/it, training loss=0.2311]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 839/1835 [19:31<23:10,  1.40s/it, training loss=0.2311]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 839/1835 [19:33<23:10,  1.40s/it, training loss=0.0657]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 840/1835 [19:33<23:09,  1.40s/it, training loss=0.0657]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 840/1835 [19:34<23:09,  1.40s/it, training loss=0.2117]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 841/1835 [19:34<23:08,  1.40s/it, training loss=0.2117]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 841/1835 [19:36<23:08,  1.40s/it, training loss=0.1526]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 842/1835 [19:36<23:08,  1.40s/it, training loss=0.1526]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 842/1835 [19:37<23:08,  1.40s/it, training loss=0.1157]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 843/1835 [19:37<23:04,  1.40s/it, training loss=0.1157]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 843/1835 [19:38<23:04,  1.40s/it, training loss=0.1100]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 844/1835 [19:38<23:03,  1.40s/it, training loss=0.1100]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 844/1835 [19:40<23:03,  1.40s/it, training loss=0.0886]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 845/1835 [19:40<23:00,  1.39s/it, training loss=0.0886]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 845/1835 [19:41<23:00,  1.39s/it, training loss=0.2001]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 846/1835 [19:41<22:57,  1.39s/it, training loss=0.2001]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 846/1835 [19:43<22:57,  1.39s/it, training loss=0.0848]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 847/1835 [19:43<22:55,  1.39s/it, training loss=0.0848]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 847/1835 [19:44<22:55,  1.39s/it, training loss=0.1403]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 848/1835 [19:44<22:53,  1.39s/it, training loss=0.1403]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 848/1835 [19:45<22:53,  1.39s/it, training loss=0.1380]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 849/1835 [19:45<22:51,  1.39s/it, training loss=0.1380]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 849/1835 [19:47<22:51,  1.39s/it, training loss=0.1131]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 850/1835 [19:47<22:49,  1.39s/it, training loss=0.1131]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 850/1835 [19:48<22:49,  1.39s/it, training loss=0.3196]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 851/1835 [19:48<22:49,  1.39s/it, training loss=0.3196]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 851/1835 [19:50<22:49,  1.39s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 852/1835 [19:50<22:49,  1.39s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 852/1835 [19:51<22:49,  1.39s/it, training loss=0.1088]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 853/1835 [19:51<22:48,  1.39s/it, training loss=0.1088]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 853/1835 [19:52<22:48,  1.39s/it, training loss=0.1328]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 854/1835 [19:52<22:48,  1.40s/it, training loss=0.1328]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 854/1835 [19:54<22:48,  1.40s/it, training loss=0.3199]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 855/1835 [19:54<22:47,  1.40s/it, training loss=0.3199]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 855/1835 [19:55<22:47,  1.40s/it, training loss=0.1403]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 856/1835 [19:55<22:44,  1.39s/it, training loss=0.1403]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 856/1835 [19:57<22:44,  1.39s/it, training loss=0.1473]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 857/1835 [19:57<22:44,  1.40s/it, training loss=0.1473]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 857/1835 [19:58<22:44,  1.40s/it, training loss=0.1279]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 858/1835 [19:58<22:42,  1.39s/it, training loss=0.1279]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 858/1835 [19:59<22:42,  1.39s/it, training loss=0.1423]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 859/1835 [19:59<22:39,  1.39s/it, training loss=0.1423]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 859/1835 [20:01<22:39,  1.39s/it, training loss=0.1031]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 860/1835 [20:01<22:40,  1.40s/it, training loss=0.1031]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 860/1835 [20:02<22:40,  1.40s/it, training loss=0.2246]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 861/1835 [20:02<22:37,  1.39s/it, training loss=0.2246]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 861/1835 [20:04<22:37,  1.39s/it, training loss=0.0930]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 862/1835 [20:04<22:37,  1.40s/it, training loss=0.0930]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 862/1835 [20:05<22:37,  1.40s/it, training loss=0.0539]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 863/1835 [20:05<22:35,  1.39s/it, training loss=0.0539]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 863/1835 [20:06<22:35,  1.39s/it, training loss=0.1381]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 864/1835 [20:06<22:35,  1.40s/it, training loss=0.1381]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 864/1835 [20:08<22:35,  1.40s/it, training loss=0.2047]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 865/1835 [20:08<22:33,  1.40s/it, training loss=0.2047]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 865/1835 [20:09<22:33,  1.40s/it, training loss=0.1709]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 866/1835 [20:09<22:30,  1.39s/it, training loss=0.1709]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 866/1835 [20:10<22:30,  1.39s/it, training loss=0.1310]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 867/1835 [20:10<22:27,  1.39s/it, training loss=0.1310]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 867/1835 [20:12<22:27,  1.39s/it, training loss=0.2499]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 868/1835 [20:12<22:26,  1.39s/it, training loss=0.2499]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 868/1835 [20:13<22:26,  1.39s/it, training loss=0.3837]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 869/1835 [20:13<22:25,  1.39s/it, training loss=0.3837]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 869/1835 [20:15<22:25,  1.39s/it, training loss=0.1274]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 870/1835 [20:15<22:23,  1.39s/it, training loss=0.1274]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 870/1835 [20:16<22:23,  1.39s/it, training loss=0.2200]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 871/1835 [20:16<22:22,  1.39s/it, training loss=0.2200]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 871/1835 [20:17<22:22,  1.39s/it, training loss=0.1656]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 872/1835 [20:17<22:20,  1.39s/it, training loss=0.1656]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 872/1835 [20:19<22:20,  1.39s/it, training loss=0.1698]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 873/1835 [20:19<22:22,  1.40s/it, training loss=0.1698]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 873/1835 [20:20<22:22,  1.40s/it, training loss=0.1269]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 874/1835 [20:20<22:20,  1.40s/it, training loss=0.1269]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 874/1835 [20:22<22:20,  1.40s/it, training loss=0.2437]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 875/1835 [20:22<22:21,  1.40s/it, training loss=0.2437]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 875/1835 [20:23<22:21,  1.40s/it, training loss=0.2664]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 876/1835 [20:23<22:21,  1.40s/it, training loss=0.2664]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 876/1835 [20:24<22:21,  1.40s/it, training loss=0.1084]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 877/1835 [20:24<22:19,  1.40s/it, training loss=0.1084]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 877/1835 [20:26<22:19,  1.40s/it, training loss=0.2192]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 878/1835 [20:26<22:16,  1.40s/it, training loss=0.2192]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 878/1835 [20:27<22:16,  1.40s/it, training loss=0.1926]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 879/1835 [20:27<22:13,  1.39s/it, training loss=0.1926]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 879/1835 [20:29<22:13,  1.39s/it, training loss=0.1412]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 880/1835 [20:29<22:11,  1.39s/it, training loss=0.1412]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 880/1835 [20:30<22:11,  1.39s/it, training loss=0.1146]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 881/1835 [20:30<22:11,  1.40s/it, training loss=0.1146]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 881/1835 [20:31<22:11,  1.40s/it, training loss=0.1178]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 882/1835 [20:31<22:10,  1.40s/it, training loss=0.1178]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 882/1835 [20:33<22:10,  1.40s/it, training loss=0.0543]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 883/1835 [20:33<22:09,  1.40s/it, training loss=0.0543]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 883/1835 [20:34<22:09,  1.40s/it, training loss=0.1696]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 884/1835 [20:34<22:08,  1.40s/it, training loss=0.1696]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 884/1835 [20:36<22:08,  1.40s/it, training loss=0.1495]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 885/1835 [20:36<22:05,  1.40s/it, training loss=0.1495]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 885/1835 [20:37<22:05,  1.40s/it, training loss=0.1943]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 886/1835 [20:37<22:02,  1.39s/it, training loss=0.1943]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 886/1835 [20:38<22:02,  1.39s/it, training loss=0.1783]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 887/1835 [20:38<22:01,  1.39s/it, training loss=0.1783]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 887/1835 [20:40<22:01,  1.39s/it, training loss=0.1035]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 888/1835 [20:40<21:59,  1.39s/it, training loss=0.1035]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 888/1835 [20:41<21:59,  1.39s/it, training loss=0.0648]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 889/1835 [20:41<21:58,  1.39s/it, training loss=0.0648]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 889/1835 [20:43<21:58,  1.39s/it, training loss=0.1132]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 890/1835 [20:43<21:57,  1.39s/it, training loss=0.1132]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 890/1835 [20:44<21:57,  1.39s/it, training loss=0.1362]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 891/1835 [20:44<21:57,  1.40s/it, training loss=0.1362]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 891/1835 [20:45<21:57,  1.40s/it, training loss=0.1637]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 892/1835 [20:45<21:57,  1.40s/it, training loss=0.1637]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 892/1835 [20:47<21:57,  1.40s/it, training loss=0.1480]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 893/1835 [20:47<21:54,  1.40s/it, training loss=0.1480]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 893/1835 [20:48<21:54,  1.40s/it, training loss=0.0472]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 894/1835 [20:48<21:51,  1.39s/it, training loss=0.0472]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 894/1835 [20:50<21:51,  1.39s/it, training loss=0.0585]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 895/1835 [20:50<21:52,  1.40s/it, training loss=0.0585]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 895/1835 [20:51<21:52,  1.40s/it, training loss=0.0701]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 896/1835 [20:51<21:49,  1.40s/it, training loss=0.0701]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 896/1835 [20:52<21:49,  1.40s/it, training loss=0.0810]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 897/1835 [20:52<21:47,  1.39s/it, training loss=0.0810]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 897/1835 [20:54<21:47,  1.39s/it, training loss=0.1288]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 898/1835 [20:54<21:46,  1.39s/it, training loss=0.1288]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 898/1835 [20:55<21:46,  1.39s/it, training loss=0.1544]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 899/1835 [20:55<21:45,  1.39s/it, training loss=0.1544]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 899/1835 [20:57<21:45,  1.39s/it, training loss=0.0713]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 900/1835 [20:57<21:46,  1.40s/it, training loss=0.0713]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 900/1835 [20:58<21:46,  1.40s/it, training loss=0.2031]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 901/1835 [20:58<21:44,  1.40s/it, training loss=0.2031]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 901/1835 [20:59<21:44,  1.40s/it, training loss=0.0673]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 902/1835 [20:59<21:41,  1.40s/it, training loss=0.0673]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 902/1835 [21:01<21:41,  1.40s/it, training loss=0.0672]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 903/1835 [21:01<21:38,  1.39s/it, training loss=0.0672]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 903/1835 [21:02<21:38,  1.39s/it, training loss=0.1425]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 904/1835 [21:02<21:39,  1.40s/it, training loss=0.1425]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 904/1835 [21:03<21:39,  1.40s/it, training loss=0.2320]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 905/1835 [21:04<21:39,  1.40s/it, training loss=0.2320]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 905/1835 [21:05<21:39,  1.40s/it, training loss=0.1746]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 906/1835 [21:05<21:34,  1.39s/it, training loss=0.1746]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 906/1835 [21:06<21:34,  1.39s/it, training loss=0.1555]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 907/1835 [21:06<21:34,  1.40s/it, training loss=0.1555]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 907/1835 [21:08<21:34,  1.40s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 908/1835 [21:08<21:35,  1.40s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 908/1835 [21:09<21:35,  1.40s/it, training loss=0.3471]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 909/1835 [21:09<21:32,  1.40s/it, training loss=0.3471]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 909/1835 [21:10<21:32,  1.40s/it, training loss=0.1009]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 910/1835 [21:10<21:31,  1.40s/it, training loss=0.1009]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 910/1835 [21:12<21:31,  1.40s/it, training loss=0.2557]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 911/1835 [21:12<21:30,  1.40s/it, training loss=0.2557]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 911/1835 [21:13<21:30,  1.40s/it, training loss=0.2998]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 912/1835 [21:13<21:28,  1.40s/it, training loss=0.2998]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 912/1835 [21:15<21:28,  1.40s/it, training loss=0.2164]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 913/1835 [21:15<21:27,  1.40s/it, training loss=0.2164]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 913/1835 [21:16<21:27,  1.40s/it, training loss=0.1944]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 914/1835 [21:16<21:26,  1.40s/it, training loss=0.1944]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 914/1835 [21:17<21:26,  1.40s/it, training loss=0.2500]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 915/1835 [21:17<21:24,  1.40s/it, training loss=0.2500]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 915/1835 [21:19<21:24,  1.40s/it, training loss=0.1205]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 916/1835 [21:19<21:22,  1.40s/it, training loss=0.1205]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 916/1835 [21:20<21:22,  1.40s/it, training loss=0.2164]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 917/1835 [21:20<21:20,  1.40s/it, training loss=0.2164]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 917/1835 [21:22<21:20,  1.40s/it, training loss=0.1181]\u001b[A\n",
            "Epoch 2:  50%|█████     | 918/1835 [21:22<21:16,  1.39s/it, training loss=0.1181]\u001b[A\n",
            "Epoch 2:  50%|█████     | 918/1835 [21:23<21:16,  1.39s/it, training loss=0.0443]\u001b[A\n",
            "Epoch 2:  50%|█████     | 919/1835 [21:23<21:13,  1.39s/it, training loss=0.0443]\u001b[A\n",
            "Epoch 2:  50%|█████     | 919/1835 [21:24<21:13,  1.39s/it, training loss=0.3076]\u001b[A\n",
            "Epoch 2:  50%|█████     | 920/1835 [21:24<21:14,  1.39s/it, training loss=0.3076]\u001b[A\n",
            "Epoch 2:  50%|█████     | 920/1835 [21:26<21:14,  1.39s/it, training loss=0.0369]\u001b[A\n",
            "Epoch 2:  50%|█████     | 921/1835 [21:26<21:11,  1.39s/it, training loss=0.0369]\u001b[A\n",
            "Epoch 2:  50%|█████     | 921/1835 [21:27<21:11,  1.39s/it, training loss=0.1846]\u001b[A\n",
            "Epoch 2:  50%|█████     | 922/1835 [21:27<21:09,  1.39s/it, training loss=0.1846]\u001b[A\n",
            "Epoch 2:  50%|█████     | 922/1835 [21:29<21:09,  1.39s/it, training loss=0.1626]\u001b[A\n",
            "Epoch 2:  50%|█████     | 923/1835 [21:29<21:10,  1.39s/it, training loss=0.1626]\u001b[A\n",
            "Epoch 2:  50%|█████     | 923/1835 [21:30<21:10,  1.39s/it, training loss=0.1246]\u001b[A\n",
            "Epoch 2:  50%|█████     | 924/1835 [21:30<21:07,  1.39s/it, training loss=0.1246]\u001b[A\n",
            "Epoch 2:  50%|█████     | 924/1835 [21:31<21:07,  1.39s/it, training loss=0.1065]\u001b[A\n",
            "Epoch 2:  50%|█████     | 925/1835 [21:31<21:08,  1.39s/it, training loss=0.1065]\u001b[A\n",
            "Epoch 2:  50%|█████     | 925/1835 [21:33<21:08,  1.39s/it, training loss=0.1155]\u001b[A\n",
            "Epoch 2:  50%|█████     | 926/1835 [21:33<21:09,  1.40s/it, training loss=0.1155]\u001b[A\n",
            "Epoch 2:  50%|█████     | 926/1835 [21:34<21:09,  1.40s/it, training loss=0.2670]\u001b[A\n",
            "Epoch 2:  51%|█████     | 927/1835 [21:34<21:08,  1.40s/it, training loss=0.2670]\u001b[A\n",
            "Epoch 2:  51%|█████     | 927/1835 [21:36<21:08,  1.40s/it, training loss=0.1090]\u001b[A\n",
            "Epoch 2:  51%|█████     | 928/1835 [21:36<21:09,  1.40s/it, training loss=0.1090]\u001b[A\n",
            "Epoch 2:  51%|█████     | 928/1835 [21:37<21:09,  1.40s/it, training loss=0.1266]\u001b[A\n",
            "Epoch 2:  51%|█████     | 929/1835 [21:37<21:09,  1.40s/it, training loss=0.1266]\u001b[A\n",
            "Epoch 2:  51%|█████     | 929/1835 [21:38<21:09,  1.40s/it, training loss=0.1704]\u001b[A\n",
            "Epoch 2:  51%|█████     | 930/1835 [21:38<21:06,  1.40s/it, training loss=0.1704]\u001b[A\n",
            "Epoch 2:  51%|█████     | 930/1835 [21:40<21:06,  1.40s/it, training loss=0.3788]\u001b[A\n",
            "Epoch 2:  51%|█████     | 931/1835 [21:40<21:04,  1.40s/it, training loss=0.3788]\u001b[A\n",
            "Epoch 2:  51%|█████     | 931/1835 [21:41<21:04,  1.40s/it, training loss=0.1579]\u001b[A\n",
            "Epoch 2:  51%|█████     | 932/1835 [21:41<21:01,  1.40s/it, training loss=0.1579]\u001b[A\n",
            "Epoch 2:  51%|█████     | 932/1835 [21:43<21:01,  1.40s/it, training loss=0.2198]\u001b[A\n",
            "Epoch 2:  51%|█████     | 933/1835 [21:43<21:00,  1.40s/it, training loss=0.2198]\u001b[A\n",
            "Epoch 2:  51%|█████     | 933/1835 [21:44<21:00,  1.40s/it, training loss=0.2116]\u001b[A\n",
            "Epoch 2:  51%|█████     | 934/1835 [21:44<20:57,  1.40s/it, training loss=0.2116]\u001b[A\n",
            "Epoch 2:  51%|█████     | 934/1835 [21:45<20:57,  1.40s/it, training loss=0.0913]\u001b[A\n",
            "Epoch 2:  51%|█████     | 935/1835 [21:45<20:57,  1.40s/it, training loss=0.0913]\u001b[A\n",
            "Epoch 2:  51%|█████     | 935/1835 [21:47<20:57,  1.40s/it, training loss=0.2110]\u001b[A\n",
            "Epoch 2:  51%|█████     | 936/1835 [21:47<20:56,  1.40s/it, training loss=0.2110]\u001b[A\n",
            "Epoch 2:  51%|█████     | 936/1835 [21:48<20:56,  1.40s/it, training loss=0.3521]\u001b[A\n",
            "Epoch 2:  51%|█████     | 937/1835 [21:48<20:56,  1.40s/it, training loss=0.3521]\u001b[A\n",
            "Epoch 2:  51%|█████     | 937/1835 [21:50<20:56,  1.40s/it, training loss=0.2854]\u001b[A\n",
            "Epoch 2:  51%|█████     | 938/1835 [21:50<20:54,  1.40s/it, training loss=0.2854]\u001b[A\n",
            "Epoch 2:  51%|█████     | 938/1835 [21:51<20:54,  1.40s/it, training loss=0.1645]\u001b[A\n",
            "Epoch 2:  51%|█████     | 939/1835 [21:51<20:52,  1.40s/it, training loss=0.1645]\u001b[A\n",
            "Epoch 2:  51%|█████     | 939/1835 [21:52<20:52,  1.40s/it, training loss=0.2080]\u001b[A\n",
            "Epoch 2:  51%|█████     | 940/1835 [21:52<20:50,  1.40s/it, training loss=0.2080]\u001b[A\n",
            "Epoch 2:  51%|█████     | 940/1835 [21:54<20:50,  1.40s/it, training loss=0.0986]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 941/1835 [21:54<20:47,  1.39s/it, training loss=0.0986]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 941/1835 [21:55<20:47,  1.39s/it, training loss=0.1900]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 942/1835 [21:55<20:45,  1.39s/it, training loss=0.1900]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 942/1835 [21:57<20:45,  1.39s/it, training loss=0.1281]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 943/1835 [21:57<20:43,  1.39s/it, training loss=0.1281]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 943/1835 [21:58<20:43,  1.39s/it, training loss=0.3468]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 944/1835 [21:58<20:41,  1.39s/it, training loss=0.3468]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 944/1835 [21:59<20:41,  1.39s/it, training loss=0.1532]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 945/1835 [21:59<20:41,  1.39s/it, training loss=0.1532]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 945/1835 [22:01<20:41,  1.39s/it, training loss=0.1319]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 946/1835 [22:01<20:38,  1.39s/it, training loss=0.1319]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 946/1835 [22:02<20:38,  1.39s/it, training loss=0.1795]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 947/1835 [22:02<20:37,  1.39s/it, training loss=0.1795]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 947/1835 [22:04<20:37,  1.39s/it, training loss=0.0904]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 948/1835 [22:04<20:38,  1.40s/it, training loss=0.0904]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 948/1835 [22:05<20:38,  1.40s/it, training loss=0.1649]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 949/1835 [22:05<20:37,  1.40s/it, training loss=0.1649]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 949/1835 [22:06<20:37,  1.40s/it, training loss=0.2620]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 950/1835 [22:06<20:37,  1.40s/it, training loss=0.2620]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 950/1835 [22:08<20:37,  1.40s/it, training loss=0.2256]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 951/1835 [22:08<20:35,  1.40s/it, training loss=0.2256]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 951/1835 [22:09<20:35,  1.40s/it, training loss=0.1747]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 952/1835 [22:09<20:36,  1.40s/it, training loss=0.1747]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 952/1835 [22:11<20:36,  1.40s/it, training loss=0.1582]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 953/1835 [22:11<20:33,  1.40s/it, training loss=0.1582]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 953/1835 [22:12<20:33,  1.40s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 954/1835 [22:12<20:32,  1.40s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 954/1835 [22:13<20:32,  1.40s/it, training loss=0.1227]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 955/1835 [22:13<20:30,  1.40s/it, training loss=0.1227]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 955/1835 [22:15<20:30,  1.40s/it, training loss=0.0939]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 956/1835 [22:15<20:27,  1.40s/it, training loss=0.0939]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 956/1835 [22:16<20:27,  1.40s/it, training loss=0.2223]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 957/1835 [22:16<20:27,  1.40s/it, training loss=0.2223]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 957/1835 [22:18<20:27,  1.40s/it, training loss=0.1119]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 958/1835 [22:18<20:24,  1.40s/it, training loss=0.1119]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 958/1835 [22:19<20:24,  1.40s/it, training loss=0.1079]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 959/1835 [22:19<20:24,  1.40s/it, training loss=0.1079]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 959/1835 [22:20<20:24,  1.40s/it, training loss=0.2493]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 960/1835 [22:20<20:22,  1.40s/it, training loss=0.2493]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 960/1835 [22:22<20:22,  1.40s/it, training loss=0.0611]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 961/1835 [22:22<20:21,  1.40s/it, training loss=0.0611]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 961/1835 [22:23<20:21,  1.40s/it, training loss=0.0735]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 962/1835 [22:23<20:20,  1.40s/it, training loss=0.0735]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 962/1835 [22:24<20:20,  1.40s/it, training loss=0.0895]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 963/1835 [22:24<20:18,  1.40s/it, training loss=0.0895]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 963/1835 [22:26<20:18,  1.40s/it, training loss=0.2002]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 964/1835 [22:26<20:17,  1.40s/it, training loss=0.2002]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 964/1835 [22:27<20:17,  1.40s/it, training loss=0.1618]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 965/1835 [22:27<20:16,  1.40s/it, training loss=0.1618]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 965/1835 [22:29<20:16,  1.40s/it, training loss=0.1831]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 966/1835 [22:29<20:14,  1.40s/it, training loss=0.1831]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 966/1835 [22:30<20:14,  1.40s/it, training loss=0.1742]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 967/1835 [22:30<20:14,  1.40s/it, training loss=0.1742]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 967/1835 [22:31<20:14,  1.40s/it, training loss=0.2735]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 968/1835 [22:31<20:10,  1.40s/it, training loss=0.2735]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 968/1835 [22:33<20:10,  1.40s/it, training loss=0.1795]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 969/1835 [22:33<20:09,  1.40s/it, training loss=0.1795]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 969/1835 [22:34<20:09,  1.40s/it, training loss=0.1774]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 970/1835 [22:34<20:07,  1.40s/it, training loss=0.1774]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 970/1835 [22:36<20:07,  1.40s/it, training loss=0.0587]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 971/1835 [22:36<20:05,  1.39s/it, training loss=0.0587]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 971/1835 [22:37<20:05,  1.39s/it, training loss=0.1004]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 972/1835 [22:37<20:02,  1.39s/it, training loss=0.1004]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 972/1835 [22:38<20:02,  1.39s/it, training loss=0.1815]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 973/1835 [22:38<20:02,  1.40s/it, training loss=0.1815]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 973/1835 [22:40<20:02,  1.40s/it, training loss=0.0938]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 974/1835 [22:40<20:00,  1.39s/it, training loss=0.0938]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 974/1835 [22:41<20:00,  1.39s/it, training loss=0.1033]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 975/1835 [22:41<19:58,  1.39s/it, training loss=0.1033]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 975/1835 [22:43<19:58,  1.39s/it, training loss=0.1649]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 976/1835 [22:43<19:57,  1.39s/it, training loss=0.1649]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 976/1835 [22:44<19:57,  1.39s/it, training loss=0.1810]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 977/1835 [22:44<19:56,  1.39s/it, training loss=0.1810]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 977/1835 [22:45<19:56,  1.39s/it, training loss=0.2430]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 978/1835 [22:45<19:54,  1.39s/it, training loss=0.2430]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 978/1835 [22:47<19:54,  1.39s/it, training loss=0.1561]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 979/1835 [22:47<19:54,  1.40s/it, training loss=0.1561]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 979/1835 [22:48<19:54,  1.40s/it, training loss=0.2122]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 980/1835 [22:48<19:54,  1.40s/it, training loss=0.2122]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 980/1835 [22:50<19:54,  1.40s/it, training loss=0.1790]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 981/1835 [22:50<19:53,  1.40s/it, training loss=0.1790]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 981/1835 [22:51<19:53,  1.40s/it, training loss=0.1385]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 982/1835 [22:51<19:51,  1.40s/it, training loss=0.1385]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 982/1835 [22:52<19:51,  1.40s/it, training loss=0.2837]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 983/1835 [22:52<19:49,  1.40s/it, training loss=0.2837]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 983/1835 [22:54<19:49,  1.40s/it, training loss=0.1689]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 984/1835 [22:54<19:48,  1.40s/it, training loss=0.1689]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 984/1835 [22:55<19:48,  1.40s/it, training loss=0.1066]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 985/1835 [22:55<19:49,  1.40s/it, training loss=0.1066]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 985/1835 [22:57<19:49,  1.40s/it, training loss=0.1293]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 986/1835 [22:57<19:47,  1.40s/it, training loss=0.1293]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 986/1835 [22:58<19:47,  1.40s/it, training loss=0.2301]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 987/1835 [22:58<19:45,  1.40s/it, training loss=0.2301]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 987/1835 [22:59<19:45,  1.40s/it, training loss=0.2232]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 988/1835 [22:59<19:44,  1.40s/it, training loss=0.2232]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 988/1835 [23:01<19:44,  1.40s/it, training loss=0.2216]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 989/1835 [23:01<19:43,  1.40s/it, training loss=0.2216]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 989/1835 [23:02<19:43,  1.40s/it, training loss=0.1355]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 990/1835 [23:02<19:41,  1.40s/it, training loss=0.1355]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 990/1835 [23:04<19:41,  1.40s/it, training loss=0.0712]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 991/1835 [23:04<19:38,  1.40s/it, training loss=0.0712]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 991/1835 [23:05<19:38,  1.40s/it, training loss=0.0810]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 992/1835 [23:05<19:35,  1.39s/it, training loss=0.0810]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 992/1835 [23:06<19:35,  1.39s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 993/1835 [23:06<19:32,  1.39s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 993/1835 [23:08<19:32,  1.39s/it, training loss=0.1751]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 994/1835 [23:08<19:28,  1.39s/it, training loss=0.1751]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 994/1835 [23:09<19:28,  1.39s/it, training loss=0.1449]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 995/1835 [23:09<19:27,  1.39s/it, training loss=0.1449]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 995/1835 [23:11<19:27,  1.39s/it, training loss=0.1523]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 996/1835 [23:11<19:28,  1.39s/it, training loss=0.1523]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 996/1835 [23:12<19:28,  1.39s/it, training loss=0.1968]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 997/1835 [23:12<19:28,  1.39s/it, training loss=0.1968]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 997/1835 [23:13<19:28,  1.39s/it, training loss=0.1958]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 998/1835 [23:13<19:27,  1.40s/it, training loss=0.1958]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 998/1835 [23:15<19:27,  1.40s/it, training loss=0.0709]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 999/1835 [23:15<19:26,  1.39s/it, training loss=0.0709]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 999/1835 [23:16<19:26,  1.39s/it, training loss=0.1828]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 1000/1835 [23:16<19:24,  1.39s/it, training loss=0.1828]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 1000/1835 [23:18<19:24,  1.39s/it, training loss=0.0791]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1001/1835 [23:18<19:22,  1.39s/it, training loss=0.0791]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1001/1835 [23:19<19:22,  1.39s/it, training loss=0.2300]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1002/1835 [23:19<19:19,  1.39s/it, training loss=0.2300]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1002/1835 [23:20<19:19,  1.39s/it, training loss=0.1641]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1003/1835 [23:20<19:19,  1.39s/it, training loss=0.1641]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1003/1835 [23:22<19:19,  1.39s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1004/1835 [23:22<19:17,  1.39s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1004/1835 [23:23<19:17,  1.39s/it, training loss=0.1491]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1005/1835 [23:23<19:16,  1.39s/it, training loss=0.1491]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1005/1835 [23:24<19:16,  1.39s/it, training loss=0.1664]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1006/1835 [23:24<19:15,  1.39s/it, training loss=0.1664]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1006/1835 [23:26<19:15,  1.39s/it, training loss=0.2043]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1007/1835 [23:26<19:12,  1.39s/it, training loss=0.2043]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1007/1835 [23:27<19:12,  1.39s/it, training loss=0.3744]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1008/1835 [23:27<19:09,  1.39s/it, training loss=0.3744]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1008/1835 [23:29<19:09,  1.39s/it, training loss=0.1852]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1009/1835 [23:29<19:08,  1.39s/it, training loss=0.1852]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 1009/1835 [23:30<19:08,  1.39s/it, training loss=0.0670]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1010/1835 [23:30<19:07,  1.39s/it, training loss=0.0670]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1010/1835 [23:31<19:07,  1.39s/it, training loss=0.1403]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1011/1835 [23:31<19:06,  1.39s/it, training loss=0.1403]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1011/1835 [23:33<19:06,  1.39s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1012/1835 [23:33<19:04,  1.39s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1012/1835 [23:34<19:04,  1.39s/it, training loss=0.0899]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1013/1835 [23:34<19:02,  1.39s/it, training loss=0.0899]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1013/1835 [23:36<19:02,  1.39s/it, training loss=0.2580]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1014/1835 [23:36<19:02,  1.39s/it, training loss=0.2580]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1014/1835 [23:37<19:02,  1.39s/it, training loss=0.2768]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1015/1835 [23:37<19:01,  1.39s/it, training loss=0.2768]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1015/1835 [23:38<19:01,  1.39s/it, training loss=0.1047]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1016/1835 [23:38<19:01,  1.39s/it, training loss=0.1047]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1016/1835 [23:40<19:01,  1.39s/it, training loss=0.3270]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1017/1835 [23:40<18:58,  1.39s/it, training loss=0.3270]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1017/1835 [23:41<18:58,  1.39s/it, training loss=0.1011]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1018/1835 [23:41<18:57,  1.39s/it, training loss=0.1011]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 1018/1835 [23:43<18:57,  1.39s/it, training loss=0.1691]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1019/1835 [23:43<18:55,  1.39s/it, training loss=0.1691]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1019/1835 [23:44<18:55,  1.39s/it, training loss=0.1318]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1020/1835 [23:44<18:53,  1.39s/it, training loss=0.1318]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1020/1835 [23:45<18:53,  1.39s/it, training loss=0.3109]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1021/1835 [23:45<18:53,  1.39s/it, training loss=0.3109]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1021/1835 [23:47<18:53,  1.39s/it, training loss=0.0529]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1022/1835 [23:47<18:50,  1.39s/it, training loss=0.0529]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1022/1835 [23:48<18:50,  1.39s/it, training loss=0.1297]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1023/1835 [23:48<18:50,  1.39s/it, training loss=0.1297]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1023/1835 [23:50<18:50,  1.39s/it, training loss=0.0983]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1024/1835 [23:50<18:49,  1.39s/it, training loss=0.0983]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1024/1835 [23:51<18:49,  1.39s/it, training loss=0.1726]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1025/1835 [23:51<18:51,  1.40s/it, training loss=0.1726]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1025/1835 [23:52<18:51,  1.40s/it, training loss=0.0902]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1026/1835 [23:52<18:49,  1.40s/it, training loss=0.0902]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1026/1835 [23:54<18:49,  1.40s/it, training loss=0.1442]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1027/1835 [23:54<18:46,  1.39s/it, training loss=0.1442]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1027/1835 [23:55<18:46,  1.39s/it, training loss=0.0777]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1028/1835 [23:55<18:44,  1.39s/it, training loss=0.0777]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1028/1835 [23:57<18:44,  1.39s/it, training loss=0.1825]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1029/1835 [23:57<18:45,  1.40s/it, training loss=0.1825]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1029/1835 [23:58<18:45,  1.40s/it, training loss=0.0828]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1030/1835 [23:58<18:43,  1.40s/it, training loss=0.0828]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1030/1835 [23:59<18:43,  1.40s/it, training loss=0.2210]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1031/1835 [23:59<18:41,  1.39s/it, training loss=0.2210]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1031/1835 [24:01<18:41,  1.39s/it, training loss=0.1903]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1032/1835 [24:01<18:40,  1.40s/it, training loss=0.1903]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 1032/1835 [24:02<18:40,  1.40s/it, training loss=0.2231]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 1033/1835 [24:02<18:39,  1.40s/it, training loss=0.2231]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 1033/1835 [24:03<18:39,  1.40s/it, training loss=0.0636]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 1034/1835 [24:04<18:37,  1.40s/it, training loss=0.0636]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 1034/1835 [24:05<18:37,  1.40s/it, training loss=0.0944]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 1035/1835 [24:05<18:36,  1.40s/it, training loss=0.0944]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 1035/1835 [24:06<18:36,  1.40s/it, training loss=0.1256]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 1036/1835 [24:06<18:35,  1.40s/it, training loss=0.1256]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 1036/1835 [24:08<18:35,  1.40s/it, training loss=0.1206]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1037/1835 [24:08<18:34,  1.40s/it, training loss=0.1206]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1037/1835 [24:09<18:34,  1.40s/it, training loss=0.1638]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1038/1835 [24:09<18:31,  1.40s/it, training loss=0.1638]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1038/1835 [24:10<18:31,  1.40s/it, training loss=0.0844]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1039/1835 [24:10<18:31,  1.40s/it, training loss=0.0844]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1039/1835 [24:12<18:31,  1.40s/it, training loss=0.0935]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1040/1835 [24:12<18:31,  1.40s/it, training loss=0.0935]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1040/1835 [24:13<18:31,  1.40s/it, training loss=0.0725]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1041/1835 [24:13<18:29,  1.40s/it, training loss=0.0725]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1041/1835 [24:15<18:29,  1.40s/it, training loss=0.1643]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1042/1835 [24:15<18:28,  1.40s/it, training loss=0.1643]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1042/1835 [24:16<18:28,  1.40s/it, training loss=0.2058]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1043/1835 [24:16<18:25,  1.40s/it, training loss=0.2058]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1043/1835 [24:17<18:25,  1.40s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1044/1835 [24:17<18:22,  1.39s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1044/1835 [24:19<18:22,  1.39s/it, training loss=0.0816]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1045/1835 [24:19<18:21,  1.39s/it, training loss=0.0816]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1045/1835 [24:20<18:21,  1.39s/it, training loss=0.2865]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1046/1835 [24:20<18:19,  1.39s/it, training loss=0.2865]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1046/1835 [24:22<18:19,  1.39s/it, training loss=0.1463]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1047/1835 [24:22<18:16,  1.39s/it, training loss=0.1463]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1047/1835 [24:23<18:16,  1.39s/it, training loss=0.2080]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1048/1835 [24:23<18:17,  1.39s/it, training loss=0.2080]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1048/1835 [24:24<18:17,  1.39s/it, training loss=0.0837]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1049/1835 [24:24<18:16,  1.40s/it, training loss=0.0837]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1049/1835 [24:26<18:16,  1.40s/it, training loss=0.2306]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1050/1835 [24:26<18:15,  1.39s/it, training loss=0.2306]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1050/1835 [24:27<18:15,  1.39s/it, training loss=0.1804]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1051/1835 [24:27<18:14,  1.40s/it, training loss=0.1804]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1051/1835 [24:29<18:14,  1.40s/it, training loss=0.0700]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1052/1835 [24:29<18:13,  1.40s/it, training loss=0.0700]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1052/1835 [24:30<18:13,  1.40s/it, training loss=0.1217]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1053/1835 [24:30<18:11,  1.40s/it, training loss=0.1217]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1053/1835 [24:31<18:11,  1.40s/it, training loss=0.1786]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1054/1835 [24:31<18:10,  1.40s/it, training loss=0.1786]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1054/1835 [24:33<18:10,  1.40s/it, training loss=0.0984]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1055/1835 [24:33<18:08,  1.40s/it, training loss=0.0984]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 1055/1835 [24:34<18:08,  1.40s/it, training loss=0.2409]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1056/1835 [24:34<18:06,  1.39s/it, training loss=0.2409]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1056/1835 [24:36<18:06,  1.39s/it, training loss=0.2212]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1057/1835 [24:36<18:04,  1.39s/it, training loss=0.2212]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1057/1835 [24:37<18:04,  1.39s/it, training loss=0.0939]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1058/1835 [24:37<18:03,  1.39s/it, training loss=0.0939]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1058/1835 [24:38<18:03,  1.39s/it, training loss=0.1055]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1059/1835 [24:38<18:01,  1.39s/it, training loss=0.1055]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1059/1835 [24:40<18:01,  1.39s/it, training loss=0.1455]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1060/1835 [24:40<18:01,  1.40s/it, training loss=0.1455]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1060/1835 [24:41<18:01,  1.40s/it, training loss=0.1665]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1061/1835 [24:41<18:00,  1.40s/it, training loss=0.1665]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1061/1835 [24:43<18:00,  1.40s/it, training loss=0.0695]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1062/1835 [24:43<17:59,  1.40s/it, training loss=0.0695]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1062/1835 [24:44<17:59,  1.40s/it, training loss=0.1428]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1063/1835 [24:44<17:55,  1.39s/it, training loss=0.1428]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1063/1835 [24:45<17:55,  1.39s/it, training loss=0.1684]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1064/1835 [24:45<17:56,  1.40s/it, training loss=0.1684]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1064/1835 [24:47<17:56,  1.40s/it, training loss=0.3670]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1065/1835 [24:47<17:55,  1.40s/it, training loss=0.3670]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1065/1835 [24:48<17:55,  1.40s/it, training loss=0.2009]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1066/1835 [24:48<17:56,  1.40s/it, training loss=0.2009]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1066/1835 [24:50<17:56,  1.40s/it, training loss=0.0819]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1067/1835 [24:50<17:54,  1.40s/it, training loss=0.0819]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1067/1835 [24:51<17:54,  1.40s/it, training loss=0.2890]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1068/1835 [24:51<17:52,  1.40s/it, training loss=0.2890]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1068/1835 [24:52<17:52,  1.40s/it, training loss=0.2167]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1069/1835 [24:52<17:52,  1.40s/it, training loss=0.2167]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1069/1835 [24:54<17:52,  1.40s/it, training loss=0.1598]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1070/1835 [24:54<17:50,  1.40s/it, training loss=0.1598]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1070/1835 [24:55<17:50,  1.40s/it, training loss=0.2619]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1071/1835 [24:55<17:47,  1.40s/it, training loss=0.2619]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1071/1835 [24:57<17:47,  1.40s/it, training loss=0.1483]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1072/1835 [24:57<17:47,  1.40s/it, training loss=0.1483]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1072/1835 [24:58<17:47,  1.40s/it, training loss=0.1192]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1073/1835 [24:58<17:45,  1.40s/it, training loss=0.1192]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 1073/1835 [24:59<17:45,  1.40s/it, training loss=0.2547]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 1074/1835 [24:59<17:44,  1.40s/it, training loss=0.2547]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 1074/1835 [25:01<17:44,  1.40s/it, training loss=0.0726]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 1075/1835 [25:01<17:42,  1.40s/it, training loss=0.0726]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 1075/1835 [25:02<17:42,  1.40s/it, training loss=0.0732]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 1076/1835 [25:02<17:39,  1.40s/it, training loss=0.0732]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 1076/1835 [25:04<17:39,  1.40s/it, training loss=0.1627]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 1077/1835 [25:04<17:37,  1.40s/it, training loss=0.1627]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 1077/1835 [25:05<17:37,  1.40s/it, training loss=0.0862]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 1078/1835 [25:05<17:36,  1.40s/it, training loss=0.0862]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 1078/1835 [25:06<17:36,  1.40s/it, training loss=0.1311]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1079/1835 [25:06<17:37,  1.40s/it, training loss=0.1311]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1079/1835 [25:08<17:37,  1.40s/it, training loss=0.1532]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1080/1835 [25:08<17:36,  1.40s/it, training loss=0.1532]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1080/1835 [25:09<17:36,  1.40s/it, training loss=0.0686]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1081/1835 [25:09<17:33,  1.40s/it, training loss=0.0686]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1081/1835 [25:11<17:33,  1.40s/it, training loss=0.1109]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1082/1835 [25:11<17:33,  1.40s/it, training loss=0.1109]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1082/1835 [25:12<17:33,  1.40s/it, training loss=0.2889]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1083/1835 [25:12<17:30,  1.40s/it, training loss=0.2889]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1083/1835 [25:13<17:30,  1.40s/it, training loss=0.0757]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1084/1835 [25:13<17:28,  1.40s/it, training loss=0.0757]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1084/1835 [25:15<17:28,  1.40s/it, training loss=0.1722]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1085/1835 [25:15<17:26,  1.40s/it, training loss=0.1722]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1085/1835 [25:16<17:26,  1.40s/it, training loss=0.2887]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1086/1835 [25:16<17:25,  1.40s/it, training loss=0.2887]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1086/1835 [25:17<17:25,  1.40s/it, training loss=0.1409]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1087/1835 [25:18<17:23,  1.39s/it, training loss=0.1409]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1087/1835 [25:19<17:23,  1.39s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1088/1835 [25:19<17:22,  1.40s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1088/1835 [25:20<17:22,  1.40s/it, training loss=0.1944]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1089/1835 [25:20<17:21,  1.40s/it, training loss=0.1944]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1089/1835 [25:22<17:21,  1.40s/it, training loss=0.2676]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1090/1835 [25:22<17:19,  1.40s/it, training loss=0.2676]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1090/1835 [25:23<17:19,  1.40s/it, training loss=0.1812]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1091/1835 [25:23<17:18,  1.40s/it, training loss=0.1812]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 1091/1835 [25:24<17:18,  1.40s/it, training loss=0.0840]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1092/1835 [25:24<17:17,  1.40s/it, training loss=0.0840]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1092/1835 [25:26<17:17,  1.40s/it, training loss=0.1606]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1093/1835 [25:26<17:16,  1.40s/it, training loss=0.1606]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1093/1835 [25:27<17:16,  1.40s/it, training loss=0.1889]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1094/1835 [25:27<17:14,  1.40s/it, training loss=0.1889]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1094/1835 [25:29<17:14,  1.40s/it, training loss=0.1969]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1095/1835 [25:29<17:12,  1.40s/it, training loss=0.1969]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1095/1835 [25:30<17:12,  1.40s/it, training loss=0.0776]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1096/1835 [25:30<17:11,  1.40s/it, training loss=0.0776]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1096/1835 [25:31<17:11,  1.40s/it, training loss=0.1600]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1097/1835 [25:31<17:10,  1.40s/it, training loss=0.1600]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1097/1835 [25:33<17:10,  1.40s/it, training loss=0.2185]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1098/1835 [25:33<17:09,  1.40s/it, training loss=0.2185]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1098/1835 [25:34<17:09,  1.40s/it, training loss=0.0969]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1099/1835 [25:34<17:09,  1.40s/it, training loss=0.0969]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1099/1835 [25:36<17:09,  1.40s/it, training loss=0.1251]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1100/1835 [25:36<17:08,  1.40s/it, training loss=0.1251]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1100/1835 [25:37<17:08,  1.40s/it, training loss=0.1425]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1101/1835 [25:37<17:06,  1.40s/it, training loss=0.1425]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1101/1835 [25:38<17:06,  1.40s/it, training loss=0.1888]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1102/1835 [25:38<17:04,  1.40s/it, training loss=0.1888]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1102/1835 [25:40<17:04,  1.40s/it, training loss=0.2058]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1103/1835 [25:40<17:02,  1.40s/it, training loss=0.2058]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1103/1835 [25:41<17:02,  1.40s/it, training loss=0.1816]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1104/1835 [25:41<17:01,  1.40s/it, training loss=0.1816]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1104/1835 [25:43<17:01,  1.40s/it, training loss=0.1913]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1105/1835 [25:43<17:00,  1.40s/it, training loss=0.1913]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1105/1835 [25:44<17:00,  1.40s/it, training loss=0.0757]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1106/1835 [25:44<16:58,  1.40s/it, training loss=0.0757]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1106/1835 [25:45<16:58,  1.40s/it, training loss=0.2487]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1107/1835 [25:45<16:57,  1.40s/it, training loss=0.2487]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1107/1835 [25:47<16:57,  1.40s/it, training loss=0.0832]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1108/1835 [25:47<16:56,  1.40s/it, training loss=0.0832]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1108/1835 [25:48<16:56,  1.40s/it, training loss=0.1134]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1109/1835 [25:48<16:54,  1.40s/it, training loss=0.1134]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1109/1835 [25:50<16:54,  1.40s/it, training loss=0.0841]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1110/1835 [25:50<16:54,  1.40s/it, training loss=0.0841]\u001b[A\n",
            "Epoch 2:  60%|██████    | 1110/1835 [25:51<16:54,  1.40s/it, training loss=0.2171]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1111/1835 [25:51<16:51,  1.40s/it, training loss=0.2171]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1111/1835 [25:52<16:51,  1.40s/it, training loss=0.1883]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1112/1835 [25:52<16:50,  1.40s/it, training loss=0.1883]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1112/1835 [25:54<16:50,  1.40s/it, training loss=0.2720]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1113/1835 [25:54<16:48,  1.40s/it, training loss=0.2720]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1113/1835 [25:55<16:48,  1.40s/it, training loss=0.1205]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1114/1835 [25:55<16:46,  1.40s/it, training loss=0.1205]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1114/1835 [25:57<16:46,  1.40s/it, training loss=0.0902]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1115/1835 [25:57<16:49,  1.40s/it, training loss=0.0902]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1115/1835 [25:58<16:49,  1.40s/it, training loss=0.1868]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1116/1835 [25:58<16:47,  1.40s/it, training loss=0.1868]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1116/1835 [25:59<16:47,  1.40s/it, training loss=0.2241]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1117/1835 [25:59<16:43,  1.40s/it, training loss=0.2241]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1117/1835 [26:01<16:43,  1.40s/it, training loss=0.1270]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1118/1835 [26:01<16:42,  1.40s/it, training loss=0.1270]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1118/1835 [26:02<16:42,  1.40s/it, training loss=0.1444]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1119/1835 [26:02<16:41,  1.40s/it, training loss=0.1444]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1119/1835 [26:04<16:41,  1.40s/it, training loss=0.1918]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1120/1835 [26:04<16:38,  1.40s/it, training loss=0.1918]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1120/1835 [26:05<16:38,  1.40s/it, training loss=0.0889]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1121/1835 [26:05<16:36,  1.40s/it, training loss=0.0889]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1121/1835 [26:06<16:36,  1.40s/it, training loss=0.1581]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1122/1835 [26:06<16:36,  1.40s/it, training loss=0.1581]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1122/1835 [26:08<16:36,  1.40s/it, training loss=0.2455]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1123/1835 [26:08<16:35,  1.40s/it, training loss=0.2455]\u001b[A\n",
            "Epoch 2:  61%|██████    | 1123/1835 [26:09<16:35,  1.40s/it, training loss=0.2292]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 1124/1835 [26:09<16:34,  1.40s/it, training loss=0.2292]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 1124/1835 [26:11<16:34,  1.40s/it, training loss=0.2039]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 1125/1835 [26:11<16:31,  1.40s/it, training loss=0.2039]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 1125/1835 [26:12<16:31,  1.40s/it, training loss=0.1045]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 1126/1835 [26:12<16:29,  1.40s/it, training loss=0.1045]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 1126/1835 [26:13<16:29,  1.40s/it, training loss=0.1601]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 1127/1835 [26:13<16:26,  1.39s/it, training loss=0.1601]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 1127/1835 [26:15<16:26,  1.39s/it, training loss=0.2275]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 1128/1835 [26:15<16:25,  1.39s/it, training loss=0.2275]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 1128/1835 [26:16<16:25,  1.39s/it, training loss=0.2404]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1129/1835 [26:16<16:25,  1.40s/it, training loss=0.2404]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1129/1835 [26:18<16:25,  1.40s/it, training loss=0.1452]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1130/1835 [26:18<16:24,  1.40s/it, training loss=0.1452]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1130/1835 [26:19<16:24,  1.40s/it, training loss=0.1658]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1131/1835 [26:19<16:23,  1.40s/it, training loss=0.1658]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1131/1835 [26:20<16:23,  1.40s/it, training loss=0.1117]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1132/1835 [26:20<16:23,  1.40s/it, training loss=0.1117]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1132/1835 [26:22<16:23,  1.40s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1133/1835 [26:22<16:21,  1.40s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1133/1835 [26:23<16:21,  1.40s/it, training loss=0.1424]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1134/1835 [26:23<16:20,  1.40s/it, training loss=0.1424]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1134/1835 [26:25<16:20,  1.40s/it, training loss=0.2212]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1135/1835 [26:25<16:19,  1.40s/it, training loss=0.2212]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1135/1835 [26:26<16:19,  1.40s/it, training loss=0.3797]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1136/1835 [26:26<16:17,  1.40s/it, training loss=0.3797]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1136/1835 [26:27<16:17,  1.40s/it, training loss=0.1644]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1137/1835 [26:27<16:15,  1.40s/it, training loss=0.1644]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1137/1835 [26:29<16:15,  1.40s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1138/1835 [26:29<16:14,  1.40s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1138/1835 [26:30<16:14,  1.40s/it, training loss=0.2015]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1139/1835 [26:30<16:13,  1.40s/it, training loss=0.2015]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1139/1835 [26:32<16:13,  1.40s/it, training loss=0.1815]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1140/1835 [26:32<16:10,  1.40s/it, training loss=0.1815]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1140/1835 [26:33<16:10,  1.40s/it, training loss=0.1728]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1141/1835 [26:33<16:08,  1.40s/it, training loss=0.1728]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1141/1835 [26:34<16:08,  1.40s/it, training loss=0.0979]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1142/1835 [26:34<16:08,  1.40s/it, training loss=0.0979]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1142/1835 [26:36<16:08,  1.40s/it, training loss=0.1801]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1143/1835 [26:36<16:06,  1.40s/it, training loss=0.1801]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1143/1835 [26:37<16:06,  1.40s/it, training loss=0.1841]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1144/1835 [26:37<16:05,  1.40s/it, training loss=0.1841]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1144/1835 [26:39<16:05,  1.40s/it, training loss=0.1220]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1145/1835 [26:39<16:04,  1.40s/it, training loss=0.1220]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1145/1835 [26:40<16:04,  1.40s/it, training loss=0.1324]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1146/1835 [26:40<16:02,  1.40s/it, training loss=0.1324]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 1146/1835 [26:41<16:02,  1.40s/it, training loss=0.2337]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1147/1835 [26:41<16:01,  1.40s/it, training loss=0.2337]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1147/1835 [26:43<16:01,  1.40s/it, training loss=0.1573]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1148/1835 [26:43<16:01,  1.40s/it, training loss=0.1573]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1148/1835 [26:44<16:01,  1.40s/it, training loss=0.2597]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1149/1835 [26:44<16:00,  1.40s/it, training loss=0.2597]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1149/1835 [26:46<16:00,  1.40s/it, training loss=0.0754]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1150/1835 [26:46<15:59,  1.40s/it, training loss=0.0754]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1150/1835 [26:47<15:59,  1.40s/it, training loss=0.1430]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1151/1835 [26:47<15:56,  1.40s/it, training loss=0.1430]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1151/1835 [26:48<15:56,  1.40s/it, training loss=0.1499]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1152/1835 [26:48<15:54,  1.40s/it, training loss=0.1499]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1152/1835 [26:50<15:54,  1.40s/it, training loss=0.1319]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1153/1835 [26:50<15:53,  1.40s/it, training loss=0.1319]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1153/1835 [26:51<15:53,  1.40s/it, training loss=0.1508]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1154/1835 [26:51<15:51,  1.40s/it, training loss=0.1508]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1154/1835 [26:53<15:51,  1.40s/it, training loss=0.0743]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1155/1835 [26:53<15:49,  1.40s/it, training loss=0.0743]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1155/1835 [26:54<15:49,  1.40s/it, training loss=0.2209]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1156/1835 [26:54<15:48,  1.40s/it, training loss=0.2209]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1156/1835 [26:55<15:48,  1.40s/it, training loss=0.0933]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1157/1835 [26:55<15:46,  1.40s/it, training loss=0.0933]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1157/1835 [26:57<15:46,  1.40s/it, training loss=0.1223]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1158/1835 [26:57<15:46,  1.40s/it, training loss=0.1223]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1158/1835 [26:58<15:46,  1.40s/it, training loss=0.1644]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1159/1835 [26:58<15:44,  1.40s/it, training loss=0.1644]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1159/1835 [27:00<15:44,  1.40s/it, training loss=0.1008]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1160/1835 [27:00<15:44,  1.40s/it, training loss=0.1008]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1160/1835 [27:01<15:44,  1.40s/it, training loss=0.1766]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1161/1835 [27:01<15:43,  1.40s/it, training loss=0.1766]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1161/1835 [27:02<15:43,  1.40s/it, training loss=0.1982]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1162/1835 [27:02<15:41,  1.40s/it, training loss=0.1982]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1162/1835 [27:04<15:41,  1.40s/it, training loss=0.1823]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1163/1835 [27:04<15:41,  1.40s/it, training loss=0.1823]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1163/1835 [27:05<15:41,  1.40s/it, training loss=0.1048]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1164/1835 [27:05<15:39,  1.40s/it, training loss=0.1048]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1164/1835 [27:07<15:39,  1.40s/it, training loss=0.1405]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1165/1835 [27:07<15:37,  1.40s/it, training loss=0.1405]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 1165/1835 [27:08<15:37,  1.40s/it, training loss=0.1634]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 1166/1835 [27:08<15:36,  1.40s/it, training loss=0.1634]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 1166/1835 [27:09<15:36,  1.40s/it, training loss=0.2010]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 1167/1835 [27:09<15:33,  1.40s/it, training loss=0.2010]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 1167/1835 [27:11<15:33,  1.40s/it, training loss=0.1765]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 1168/1835 [27:11<15:32,  1.40s/it, training loss=0.1765]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 1168/1835 [27:12<15:32,  1.40s/it, training loss=0.1095]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 1169/1835 [27:12<15:31,  1.40s/it, training loss=0.1095]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 1169/1835 [27:14<15:31,  1.40s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1170/1835 [27:14<15:29,  1.40s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1170/1835 [27:15<15:29,  1.40s/it, training loss=0.0800]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1171/1835 [27:15<15:27,  1.40s/it, training loss=0.0800]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1171/1835 [27:16<15:27,  1.40s/it, training loss=0.2037]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1172/1835 [27:16<15:25,  1.40s/it, training loss=0.2037]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1172/1835 [27:18<15:25,  1.40s/it, training loss=0.1438]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1173/1835 [27:18<15:23,  1.40s/it, training loss=0.1438]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1173/1835 [27:19<15:23,  1.40s/it, training loss=0.1295]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1174/1835 [27:19<15:23,  1.40s/it, training loss=0.1295]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1174/1835 [27:20<15:23,  1.40s/it, training loss=0.2393]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1175/1835 [27:20<15:21,  1.40s/it, training loss=0.2393]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1175/1835 [27:22<15:21,  1.40s/it, training loss=0.1734]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1176/1835 [27:22<15:19,  1.39s/it, training loss=0.1734]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1176/1835 [27:23<15:19,  1.39s/it, training loss=0.1429]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1177/1835 [27:23<15:17,  1.39s/it, training loss=0.1429]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1177/1835 [27:25<15:17,  1.39s/it, training loss=0.1799]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1178/1835 [27:25<15:15,  1.39s/it, training loss=0.1799]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1178/1835 [27:26<15:15,  1.39s/it, training loss=0.1124]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1179/1835 [27:26<15:14,  1.39s/it, training loss=0.1124]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1179/1835 [27:27<15:14,  1.39s/it, training loss=0.1926]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1180/1835 [27:27<15:13,  1.39s/it, training loss=0.1926]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1180/1835 [27:29<15:13,  1.39s/it, training loss=0.0936]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1181/1835 [27:29<15:12,  1.39s/it, training loss=0.0936]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1181/1835 [27:30<15:12,  1.39s/it, training loss=0.0746]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1182/1835 [27:30<15:10,  1.40s/it, training loss=0.0746]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1182/1835 [27:32<15:10,  1.40s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1183/1835 [27:32<15:09,  1.40s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 1183/1835 [27:33<15:09,  1.40s/it, training loss=0.0644]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1184/1835 [27:33<15:08,  1.40s/it, training loss=0.0644]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1184/1835 [27:34<15:08,  1.40s/it, training loss=0.1177]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1185/1835 [27:34<15:07,  1.40s/it, training loss=0.1177]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1185/1835 [27:36<15:07,  1.40s/it, training loss=0.1559]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1186/1835 [27:36<15:06,  1.40s/it, training loss=0.1559]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1186/1835 [27:37<15:06,  1.40s/it, training loss=0.2294]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1187/1835 [27:37<15:05,  1.40s/it, training loss=0.2294]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1187/1835 [27:39<15:05,  1.40s/it, training loss=0.0448]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1188/1835 [27:39<15:04,  1.40s/it, training loss=0.0448]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1188/1835 [27:40<15:04,  1.40s/it, training loss=0.2536]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1189/1835 [27:40<15:02,  1.40s/it, training loss=0.2536]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1189/1835 [27:41<15:02,  1.40s/it, training loss=0.1153]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1190/1835 [27:41<15:01,  1.40s/it, training loss=0.1153]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1190/1835 [27:43<15:01,  1.40s/it, training loss=0.0902]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1191/1835 [27:43<15:00,  1.40s/it, training loss=0.0902]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1191/1835 [27:44<15:00,  1.40s/it, training loss=0.0488]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1192/1835 [27:44<14:57,  1.40s/it, training loss=0.0488]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 1192/1835 [27:46<14:57,  1.40s/it, training loss=0.0973]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1193/1835 [27:46<14:57,  1.40s/it, training loss=0.0973]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1193/1835 [27:47<14:57,  1.40s/it, training loss=0.1091]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1194/1835 [27:47<14:55,  1.40s/it, training loss=0.1091]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1194/1835 [27:48<14:55,  1.40s/it, training loss=0.0819]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1195/1835 [27:48<14:53,  1.40s/it, training loss=0.0819]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1195/1835 [27:50<14:53,  1.40s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1196/1835 [27:50<14:51,  1.40s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1196/1835 [27:51<14:51,  1.40s/it, training loss=0.1884]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1197/1835 [27:51<14:48,  1.39s/it, training loss=0.1884]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1197/1835 [27:53<14:48,  1.39s/it, training loss=0.0891]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1198/1835 [27:53<14:47,  1.39s/it, training loss=0.0891]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1198/1835 [27:54<14:47,  1.39s/it, training loss=0.1269]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1199/1835 [27:54<14:47,  1.40s/it, training loss=0.1269]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1199/1835 [27:55<14:47,  1.40s/it, training loss=0.2994]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1200/1835 [27:55<14:45,  1.39s/it, training loss=0.2994]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1200/1835 [27:57<14:45,  1.39s/it, training loss=0.1066]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1201/1835 [27:57<14:44,  1.40s/it, training loss=0.1066]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 1201/1835 [27:58<14:44,  1.40s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1202/1835 [27:58<14:43,  1.40s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1202/1835 [28:00<14:43,  1.40s/it, training loss=0.1299]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1203/1835 [28:00<14:42,  1.40s/it, training loss=0.1299]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1203/1835 [28:01<14:42,  1.40s/it, training loss=0.1901]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1204/1835 [28:01<14:39,  1.39s/it, training loss=0.1901]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1204/1835 [28:02<14:39,  1.39s/it, training loss=0.2813]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1205/1835 [28:02<14:39,  1.40s/it, training loss=0.2813]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1205/1835 [28:04<14:39,  1.40s/it, training loss=0.1997]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1206/1835 [28:04<14:36,  1.39s/it, training loss=0.1997]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1206/1835 [28:05<14:36,  1.39s/it, training loss=0.0137]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1207/1835 [28:05<14:33,  1.39s/it, training loss=0.0137]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1207/1835 [28:07<14:33,  1.39s/it, training loss=0.1314]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1208/1835 [28:07<14:34,  1.39s/it, training loss=0.1314]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1208/1835 [28:08<14:34,  1.39s/it, training loss=0.1417]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1209/1835 [28:08<14:31,  1.39s/it, training loss=0.1417]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1209/1835 [28:09<14:31,  1.39s/it, training loss=0.0887]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1210/1835 [28:09<14:31,  1.39s/it, training loss=0.0887]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1210/1835 [28:11<14:31,  1.39s/it, training loss=0.1084]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1211/1835 [28:11<14:30,  1.40s/it, training loss=0.1084]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1211/1835 [28:12<14:30,  1.40s/it, training loss=0.1650]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1212/1835 [28:12<14:29,  1.40s/it, training loss=0.1650]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1212/1835 [28:13<14:29,  1.40s/it, training loss=0.0956]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1213/1835 [28:14<14:28,  1.40s/it, training loss=0.0956]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1213/1835 [28:15<14:28,  1.40s/it, training loss=0.0398]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1214/1835 [28:15<14:26,  1.40s/it, training loss=0.0398]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1214/1835 [28:16<14:26,  1.40s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1215/1835 [28:16<14:26,  1.40s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 1215/1835 [28:18<14:26,  1.40s/it, training loss=0.2985]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 1216/1835 [28:18<14:25,  1.40s/it, training loss=0.2985]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 1216/1835 [28:19<14:25,  1.40s/it, training loss=0.2482]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 1217/1835 [28:19<14:22,  1.40s/it, training loss=0.2482]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 1217/1835 [28:20<14:22,  1.40s/it, training loss=0.1393]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 1218/1835 [28:20<14:20,  1.40s/it, training loss=0.1393]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 1218/1835 [28:22<14:20,  1.40s/it, training loss=0.0629]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 1219/1835 [28:22<14:21,  1.40s/it, training loss=0.0629]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 1219/1835 [28:23<14:21,  1.40s/it, training loss=0.2210]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 1220/1835 [28:23<14:20,  1.40s/it, training loss=0.2210]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 1220/1835 [28:25<14:20,  1.40s/it, training loss=0.1317]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1221/1835 [28:25<14:18,  1.40s/it, training loss=0.1317]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1221/1835 [28:26<14:18,  1.40s/it, training loss=0.1414]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1222/1835 [28:26<14:15,  1.39s/it, training loss=0.1414]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1222/1835 [28:27<14:15,  1.39s/it, training loss=0.0721]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1223/1835 [28:27<14:13,  1.39s/it, training loss=0.0721]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1223/1835 [28:29<14:13,  1.39s/it, training loss=0.2491]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1224/1835 [28:29<14:10,  1.39s/it, training loss=0.2491]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1224/1835 [28:30<14:10,  1.39s/it, training loss=0.1953]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1225/1835 [28:30<14:07,  1.39s/it, training loss=0.1953]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1225/1835 [28:32<14:07,  1.39s/it, training loss=0.1698]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1226/1835 [28:32<14:06,  1.39s/it, training loss=0.1698]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1226/1835 [28:33<14:06,  1.39s/it, training loss=0.1858]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1227/1835 [28:33<14:05,  1.39s/it, training loss=0.1858]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1227/1835 [28:34<14:05,  1.39s/it, training loss=0.1469]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1228/1835 [28:34<14:04,  1.39s/it, training loss=0.1469]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1228/1835 [28:36<14:04,  1.39s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1229/1835 [28:36<14:03,  1.39s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1229/1835 [28:37<14:03,  1.39s/it, training loss=0.2328]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1230/1835 [28:37<14:03,  1.39s/it, training loss=0.2328]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1230/1835 [28:39<14:03,  1.39s/it, training loss=0.1433]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1231/1835 [28:39<14:00,  1.39s/it, training loss=0.1433]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1231/1835 [28:40<14:00,  1.39s/it, training loss=0.1101]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1232/1835 [28:40<13:58,  1.39s/it, training loss=0.1101]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1232/1835 [28:41<13:58,  1.39s/it, training loss=0.1187]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1233/1835 [28:41<13:57,  1.39s/it, training loss=0.1187]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1233/1835 [28:43<13:57,  1.39s/it, training loss=0.1308]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1234/1835 [28:43<13:55,  1.39s/it, training loss=0.1308]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1234/1835 [28:44<13:55,  1.39s/it, training loss=0.1224]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1235/1835 [28:44<13:55,  1.39s/it, training loss=0.1224]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1235/1835 [28:46<13:55,  1.39s/it, training loss=0.0942]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1236/1835 [28:46<13:53,  1.39s/it, training loss=0.0942]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1236/1835 [28:47<13:53,  1.39s/it, training loss=0.2552]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1237/1835 [28:47<13:52,  1.39s/it, training loss=0.2552]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1237/1835 [28:48<13:52,  1.39s/it, training loss=0.0799]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1238/1835 [28:48<13:52,  1.39s/it, training loss=0.0799]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 1238/1835 [28:50<13:52,  1.39s/it, training loss=0.2779]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1239/1835 [28:50<13:51,  1.39s/it, training loss=0.2779]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1239/1835 [28:51<13:51,  1.39s/it, training loss=0.1342]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1240/1835 [28:51<13:49,  1.39s/it, training loss=0.1342]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1240/1835 [28:53<13:49,  1.39s/it, training loss=0.1411]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1241/1835 [28:53<13:50,  1.40s/it, training loss=0.1411]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1241/1835 [28:54<13:50,  1.40s/it, training loss=0.1842]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1242/1835 [28:54<13:49,  1.40s/it, training loss=0.1842]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1242/1835 [28:55<13:49,  1.40s/it, training loss=0.0880]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1243/1835 [28:55<13:47,  1.40s/it, training loss=0.0880]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1243/1835 [28:57<13:47,  1.40s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1244/1835 [28:57<13:46,  1.40s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1244/1835 [28:58<13:46,  1.40s/it, training loss=0.1020]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1245/1835 [28:58<13:44,  1.40s/it, training loss=0.1020]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1245/1835 [29:00<13:44,  1.40s/it, training loss=0.1688]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1246/1835 [29:00<13:43,  1.40s/it, training loss=0.1688]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1246/1835 [29:01<13:43,  1.40s/it, training loss=0.1274]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1247/1835 [29:01<13:40,  1.40s/it, training loss=0.1274]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1247/1835 [29:02<13:40,  1.40s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1248/1835 [29:02<13:39,  1.40s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1248/1835 [29:04<13:39,  1.40s/it, training loss=0.1185]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1249/1835 [29:04<13:38,  1.40s/it, training loss=0.1185]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1249/1835 [29:05<13:38,  1.40s/it, training loss=0.1360]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1250/1835 [29:05<13:36,  1.39s/it, training loss=0.1360]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1250/1835 [29:06<13:36,  1.39s/it, training loss=0.2747]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1251/1835 [29:06<13:34,  1.39s/it, training loss=0.2747]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1251/1835 [29:08<13:34,  1.39s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1252/1835 [29:08<13:32,  1.39s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1252/1835 [29:09<13:32,  1.39s/it, training loss=0.1367]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1253/1835 [29:09<13:30,  1.39s/it, training loss=0.1367]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1253/1835 [29:11<13:30,  1.39s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1254/1835 [29:11<13:30,  1.40s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1254/1835 [29:12<13:30,  1.40s/it, training loss=0.1915]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1255/1835 [29:12<13:29,  1.40s/it, training loss=0.1915]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1255/1835 [29:13<13:29,  1.40s/it, training loss=0.1960]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1256/1835 [29:13<13:28,  1.40s/it, training loss=0.1960]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 1256/1835 [29:15<13:28,  1.40s/it, training loss=0.0437]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 1257/1835 [29:15<13:26,  1.40s/it, training loss=0.0437]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 1257/1835 [29:16<13:26,  1.40s/it, training loss=0.0603]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 1258/1835 [29:16<13:24,  1.39s/it, training loss=0.0603]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 1258/1835 [29:18<13:24,  1.39s/it, training loss=0.1190]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 1259/1835 [29:18<13:24,  1.40s/it, training loss=0.1190]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 1259/1835 [29:19<13:24,  1.40s/it, training loss=0.0654]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 1260/1835 [29:19<13:21,  1.39s/it, training loss=0.0654]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 1260/1835 [29:20<13:21,  1.39s/it, training loss=0.1680]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 1261/1835 [29:20<13:19,  1.39s/it, training loss=0.1680]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 1261/1835 [29:22<13:19,  1.39s/it, training loss=0.0861]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1262/1835 [29:22<13:18,  1.39s/it, training loss=0.0861]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1262/1835 [29:23<13:18,  1.39s/it, training loss=0.2304]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1263/1835 [29:23<13:17,  1.39s/it, training loss=0.2304]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1263/1835 [29:25<13:17,  1.39s/it, training loss=0.0831]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1264/1835 [29:25<13:16,  1.39s/it, training loss=0.0831]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1264/1835 [29:26<13:16,  1.39s/it, training loss=0.1938]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1265/1835 [29:26<13:15,  1.40s/it, training loss=0.1938]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1265/1835 [29:27<13:15,  1.40s/it, training loss=0.1286]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1266/1835 [29:27<13:15,  1.40s/it, training loss=0.1286]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1266/1835 [29:29<13:15,  1.40s/it, training loss=0.1129]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1267/1835 [29:29<13:12,  1.40s/it, training loss=0.1129]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1267/1835 [29:30<13:12,  1.40s/it, training loss=0.1818]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1268/1835 [29:30<13:12,  1.40s/it, training loss=0.1818]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1268/1835 [29:32<13:12,  1.40s/it, training loss=0.1608]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1269/1835 [29:32<13:11,  1.40s/it, training loss=0.1608]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1269/1835 [29:33<13:11,  1.40s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1270/1835 [29:33<13:09,  1.40s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1270/1835 [29:34<13:09,  1.40s/it, training loss=0.2752]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1271/1835 [29:34<13:08,  1.40s/it, training loss=0.2752]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1271/1835 [29:36<13:08,  1.40s/it, training loss=0.1768]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1272/1835 [29:36<13:07,  1.40s/it, training loss=0.1768]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1272/1835 [29:37<13:07,  1.40s/it, training loss=0.1450]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1273/1835 [29:37<13:04,  1.40s/it, training loss=0.1450]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1273/1835 [29:39<13:04,  1.40s/it, training loss=0.1170]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1274/1835 [29:39<13:03,  1.40s/it, training loss=0.1170]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1274/1835 [29:40<13:03,  1.40s/it, training loss=0.1321]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1275/1835 [29:40<13:02,  1.40s/it, training loss=0.1321]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 1275/1835 [29:41<13:02,  1.40s/it, training loss=0.2192]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1276/1835 [29:41<13:00,  1.40s/it, training loss=0.2192]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1276/1835 [29:43<13:00,  1.40s/it, training loss=0.0703]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1277/1835 [29:43<12:58,  1.40s/it, training loss=0.0703]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1277/1835 [29:44<12:58,  1.40s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1278/1835 [29:44<12:57,  1.40s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1278/1835 [29:46<12:57,  1.40s/it, training loss=0.1904]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1279/1835 [29:46<12:56,  1.40s/it, training loss=0.1904]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1279/1835 [29:47<12:56,  1.40s/it, training loss=0.1585]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1280/1835 [29:47<12:55,  1.40s/it, training loss=0.1585]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1280/1835 [29:48<12:55,  1.40s/it, training loss=0.0978]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1281/1835 [29:48<12:53,  1.40s/it, training loss=0.0978]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1281/1835 [29:50<12:53,  1.40s/it, training loss=0.1589]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1282/1835 [29:50<12:51,  1.40s/it, training loss=0.1589]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1282/1835 [29:51<12:51,  1.40s/it, training loss=0.0880]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1283/1835 [29:51<12:50,  1.40s/it, training loss=0.0880]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1283/1835 [29:53<12:50,  1.40s/it, training loss=0.1249]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1284/1835 [29:53<12:49,  1.40s/it, training loss=0.1249]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1284/1835 [29:54<12:49,  1.40s/it, training loss=0.0504]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1285/1835 [29:54<12:46,  1.39s/it, training loss=0.0504]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1285/1835 [29:55<12:46,  1.39s/it, training loss=0.1402]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1286/1835 [29:55<12:45,  1.39s/it, training loss=0.1402]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1286/1835 [29:57<12:45,  1.39s/it, training loss=0.1928]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1287/1835 [29:57<12:44,  1.40s/it, training loss=0.1928]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1287/1835 [29:58<12:44,  1.40s/it, training loss=0.1268]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1288/1835 [29:58<12:43,  1.39s/it, training loss=0.1268]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1288/1835 [30:00<12:43,  1.39s/it, training loss=0.0846]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1289/1835 [30:00<12:42,  1.40s/it, training loss=0.0846]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1289/1835 [30:01<12:42,  1.40s/it, training loss=0.2683]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1290/1835 [30:01<12:41,  1.40s/it, training loss=0.2683]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1290/1835 [30:02<12:41,  1.40s/it, training loss=0.2058]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1291/1835 [30:02<12:39,  1.40s/it, training loss=0.2058]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1291/1835 [30:04<12:39,  1.40s/it, training loss=0.0623]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1292/1835 [30:04<12:38,  1.40s/it, training loss=0.0623]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1292/1835 [30:05<12:38,  1.40s/it, training loss=0.0820]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1293/1835 [30:05<12:36,  1.40s/it, training loss=0.0820]\u001b[A\n",
            "Epoch 2:  70%|███████   | 1293/1835 [30:07<12:36,  1.40s/it, training loss=0.0828]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1294/1835 [30:07<12:36,  1.40s/it, training loss=0.0828]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1294/1835 [30:08<12:36,  1.40s/it, training loss=0.1542]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1295/1835 [30:08<12:34,  1.40s/it, training loss=0.1542]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1295/1835 [30:09<12:34,  1.40s/it, training loss=0.1210]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1296/1835 [30:09<12:34,  1.40s/it, training loss=0.1210]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1296/1835 [30:11<12:34,  1.40s/it, training loss=0.2372]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1297/1835 [30:11<12:32,  1.40s/it, training loss=0.2372]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1297/1835 [30:12<12:32,  1.40s/it, training loss=0.0792]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1298/1835 [30:12<12:31,  1.40s/it, training loss=0.0792]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1298/1835 [30:14<12:31,  1.40s/it, training loss=0.1211]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1299/1835 [30:14<12:30,  1.40s/it, training loss=0.1211]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1299/1835 [30:15<12:30,  1.40s/it, training loss=0.1239]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1300/1835 [30:15<12:29,  1.40s/it, training loss=0.1239]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1300/1835 [30:16<12:29,  1.40s/it, training loss=0.1566]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1301/1835 [30:16<12:26,  1.40s/it, training loss=0.1566]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1301/1835 [30:18<12:26,  1.40s/it, training loss=0.0326]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1302/1835 [30:18<12:23,  1.40s/it, training loss=0.0326]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1302/1835 [30:19<12:23,  1.40s/it, training loss=0.0956]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1303/1835 [30:19<12:22,  1.40s/it, training loss=0.0956]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1303/1835 [30:20<12:22,  1.40s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1304/1835 [30:21<12:22,  1.40s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1304/1835 [30:22<12:22,  1.40s/it, training loss=0.2108]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1305/1835 [30:22<12:20,  1.40s/it, training loss=0.2108]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1305/1835 [30:23<12:20,  1.40s/it, training loss=0.1127]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1306/1835 [30:23<12:18,  1.40s/it, training loss=0.1127]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1306/1835 [30:25<12:18,  1.40s/it, training loss=0.1534]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1307/1835 [30:25<12:18,  1.40s/it, training loss=0.1534]\u001b[A\n",
            "Epoch 2:  71%|███████   | 1307/1835 [30:26<12:18,  1.40s/it, training loss=0.2076]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 1308/1835 [30:26<12:16,  1.40s/it, training loss=0.2076]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 1308/1835 [30:27<12:16,  1.40s/it, training loss=0.1475]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 1309/1835 [30:27<12:15,  1.40s/it, training loss=0.1475]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 1309/1835 [30:29<12:15,  1.40s/it, training loss=0.1156]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 1310/1835 [30:29<12:13,  1.40s/it, training loss=0.1156]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 1310/1835 [30:30<12:13,  1.40s/it, training loss=0.1023]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 1311/1835 [30:30<12:12,  1.40s/it, training loss=0.1023]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 1311/1835 [30:32<12:12,  1.40s/it, training loss=0.2464]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 1312/1835 [30:32<12:09,  1.40s/it, training loss=0.2464]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 1312/1835 [30:33<12:09,  1.40s/it, training loss=0.2242]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1313/1835 [30:33<12:08,  1.40s/it, training loss=0.2242]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1313/1835 [30:34<12:08,  1.40s/it, training loss=0.1461]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1314/1835 [30:34<12:08,  1.40s/it, training loss=0.1461]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1314/1835 [30:36<12:08,  1.40s/it, training loss=0.1335]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1315/1835 [30:36<12:05,  1.40s/it, training loss=0.1335]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1315/1835 [30:37<12:05,  1.40s/it, training loss=0.0825]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1316/1835 [30:37<12:03,  1.39s/it, training loss=0.0825]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1316/1835 [30:39<12:03,  1.39s/it, training loss=0.1096]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1317/1835 [30:39<12:03,  1.40s/it, training loss=0.1096]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1317/1835 [30:40<12:03,  1.40s/it, training loss=0.1067]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1318/1835 [30:40<12:01,  1.40s/it, training loss=0.1067]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1318/1835 [30:41<12:01,  1.40s/it, training loss=0.0833]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1319/1835 [30:41<11:59,  1.39s/it, training loss=0.0833]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1319/1835 [30:43<11:59,  1.39s/it, training loss=0.1666]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1320/1835 [30:43<11:58,  1.40s/it, training loss=0.1666]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1320/1835 [30:44<11:58,  1.40s/it, training loss=0.1121]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1321/1835 [30:44<11:57,  1.40s/it, training loss=0.1121]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1321/1835 [30:46<11:57,  1.40s/it, training loss=0.1853]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1322/1835 [30:46<11:57,  1.40s/it, training loss=0.1853]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1322/1835 [30:47<11:57,  1.40s/it, training loss=0.2737]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1323/1835 [30:47<11:55,  1.40s/it, training loss=0.2737]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1323/1835 [30:48<11:55,  1.40s/it, training loss=0.0547]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1324/1835 [30:48<11:54,  1.40s/it, training loss=0.0547]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1324/1835 [30:50<11:54,  1.40s/it, training loss=0.1322]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1325/1835 [30:50<11:52,  1.40s/it, training loss=0.1322]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1325/1835 [30:51<11:52,  1.40s/it, training loss=0.1015]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1326/1835 [30:51<11:51,  1.40s/it, training loss=0.1015]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1326/1835 [30:53<11:51,  1.40s/it, training loss=0.1755]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1327/1835 [30:53<11:50,  1.40s/it, training loss=0.1755]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1327/1835 [30:54<11:50,  1.40s/it, training loss=0.1512]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1328/1835 [30:54<11:48,  1.40s/it, training loss=0.1512]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1328/1835 [30:55<11:48,  1.40s/it, training loss=0.1953]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1329/1835 [30:55<11:47,  1.40s/it, training loss=0.1953]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1329/1835 [30:57<11:47,  1.40s/it, training loss=0.3405]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1330/1835 [30:57<11:45,  1.40s/it, training loss=0.3405]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 1330/1835 [30:58<11:45,  1.40s/it, training loss=0.2175]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1331/1835 [30:58<11:43,  1.40s/it, training loss=0.2175]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1331/1835 [31:00<11:43,  1.40s/it, training loss=0.1834]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1332/1835 [31:00<11:41,  1.40s/it, training loss=0.1834]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1332/1835 [31:01<11:41,  1.40s/it, training loss=0.1491]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1333/1835 [31:01<11:39,  1.39s/it, training loss=0.1491]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1333/1835 [31:02<11:39,  1.39s/it, training loss=0.1400]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1334/1835 [31:02<11:38,  1.39s/it, training loss=0.1400]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1334/1835 [31:04<11:38,  1.39s/it, training loss=0.0874]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1335/1835 [31:04<11:36,  1.39s/it, training loss=0.0874]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1335/1835 [31:05<11:36,  1.39s/it, training loss=0.2058]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1336/1835 [31:05<11:36,  1.40s/it, training loss=0.2058]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1336/1835 [31:07<11:36,  1.40s/it, training loss=0.1638]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1337/1835 [31:07<11:34,  1.39s/it, training loss=0.1638]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1337/1835 [31:08<11:34,  1.39s/it, training loss=0.0958]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1338/1835 [31:08<11:33,  1.40s/it, training loss=0.0958]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1338/1835 [31:09<11:33,  1.40s/it, training loss=0.2441]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1339/1835 [31:09<11:33,  1.40s/it, training loss=0.2441]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1339/1835 [31:11<11:33,  1.40s/it, training loss=0.2639]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1340/1835 [31:11<11:31,  1.40s/it, training loss=0.2639]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1340/1835 [31:12<11:31,  1.40s/it, training loss=0.1800]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1341/1835 [31:12<11:30,  1.40s/it, training loss=0.1800]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1341/1835 [31:14<11:30,  1.40s/it, training loss=0.1624]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1342/1835 [31:14<11:28,  1.40s/it, training loss=0.1624]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1342/1835 [31:15<11:28,  1.40s/it, training loss=0.2828]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1343/1835 [31:15<11:27,  1.40s/it, training loss=0.2828]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1343/1835 [31:16<11:27,  1.40s/it, training loss=0.1296]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1344/1835 [31:16<11:25,  1.40s/it, training loss=0.1296]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1344/1835 [31:18<11:25,  1.40s/it, training loss=0.2484]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1345/1835 [31:18<11:24,  1.40s/it, training loss=0.2484]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1345/1835 [31:19<11:24,  1.40s/it, training loss=0.2889]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1346/1835 [31:19<11:23,  1.40s/it, training loss=0.2889]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1346/1835 [31:21<11:23,  1.40s/it, training loss=0.1725]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1347/1835 [31:21<11:21,  1.40s/it, training loss=0.1725]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1347/1835 [31:22<11:21,  1.40s/it, training loss=0.1073]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1348/1835 [31:22<11:19,  1.40s/it, training loss=0.1073]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 1348/1835 [31:23<11:19,  1.40s/it, training loss=0.0920]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 1349/1835 [31:23<11:19,  1.40s/it, training loss=0.0920]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 1349/1835 [31:25<11:19,  1.40s/it, training loss=0.0968]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 1350/1835 [31:25<11:18,  1.40s/it, training loss=0.0968]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 1350/1835 [31:26<11:18,  1.40s/it, training loss=0.2714]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 1351/1835 [31:26<11:16,  1.40s/it, training loss=0.2714]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 1351/1835 [31:28<11:16,  1.40s/it, training loss=0.1888]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 1352/1835 [31:28<11:14,  1.40s/it, training loss=0.1888]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 1352/1835 [31:29<11:14,  1.40s/it, training loss=0.0625]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 1353/1835 [31:29<11:13,  1.40s/it, training loss=0.0625]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 1353/1835 [31:30<11:13,  1.40s/it, training loss=0.1291]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1354/1835 [31:30<11:12,  1.40s/it, training loss=0.1291]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1354/1835 [31:32<11:12,  1.40s/it, training loss=0.2781]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1355/1835 [31:32<11:10,  1.40s/it, training loss=0.2781]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1355/1835 [31:33<11:10,  1.40s/it, training loss=0.1676]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1356/1835 [31:33<11:08,  1.40s/it, training loss=0.1676]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1356/1835 [31:35<11:08,  1.40s/it, training loss=0.2259]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1357/1835 [31:35<11:08,  1.40s/it, training loss=0.2259]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1357/1835 [31:36<11:08,  1.40s/it, training loss=0.1665]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1358/1835 [31:36<11:06,  1.40s/it, training loss=0.1665]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1358/1835 [31:37<11:06,  1.40s/it, training loss=0.1856]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1359/1835 [31:37<11:05,  1.40s/it, training loss=0.1856]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1359/1835 [31:39<11:05,  1.40s/it, training loss=0.2182]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1360/1835 [31:39<11:03,  1.40s/it, training loss=0.2182]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1360/1835 [31:40<11:03,  1.40s/it, training loss=0.1616]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1361/1835 [31:40<11:02,  1.40s/it, training loss=0.1616]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1361/1835 [31:42<11:02,  1.40s/it, training loss=0.1035]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1362/1835 [31:42<10:59,  1.40s/it, training loss=0.1035]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1362/1835 [31:43<10:59,  1.40s/it, training loss=0.1745]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1363/1835 [31:43<10:58,  1.40s/it, training loss=0.1745]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1363/1835 [31:44<10:58,  1.40s/it, training loss=0.1411]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1364/1835 [31:44<10:57,  1.40s/it, training loss=0.1411]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1364/1835 [31:46<10:57,  1.40s/it, training loss=0.2652]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1365/1835 [31:46<10:55,  1.39s/it, training loss=0.2652]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1365/1835 [31:47<10:55,  1.39s/it, training loss=0.1373]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1366/1835 [31:47<10:55,  1.40s/it, training loss=0.1373]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1366/1835 [31:48<10:55,  1.40s/it, training loss=0.1936]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1367/1835 [31:48<10:52,  1.39s/it, training loss=0.1936]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 1367/1835 [31:50<10:52,  1.39s/it, training loss=0.1338]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1368/1835 [31:50<10:51,  1.39s/it, training loss=0.1338]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1368/1835 [31:51<10:51,  1.39s/it, training loss=0.1115]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1369/1835 [31:51<10:50,  1.40s/it, training loss=0.1115]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1369/1835 [31:53<10:50,  1.40s/it, training loss=0.1187]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1370/1835 [31:53<10:49,  1.40s/it, training loss=0.1187]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1370/1835 [31:54<10:49,  1.40s/it, training loss=0.1901]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1371/1835 [31:54<10:47,  1.40s/it, training loss=0.1901]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1371/1835 [31:55<10:47,  1.40s/it, training loss=0.1785]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1372/1835 [31:55<10:44,  1.39s/it, training loss=0.1785]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1372/1835 [31:57<10:44,  1.39s/it, training loss=0.1436]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1373/1835 [31:57<10:44,  1.39s/it, training loss=0.1436]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1373/1835 [31:58<10:44,  1.39s/it, training loss=0.2293]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1374/1835 [31:58<10:42,  1.39s/it, training loss=0.2293]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1374/1835 [32:00<10:42,  1.39s/it, training loss=0.0919]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1375/1835 [32:00<10:42,  1.40s/it, training loss=0.0919]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1375/1835 [32:01<10:42,  1.40s/it, training loss=0.1501]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1376/1835 [32:01<10:40,  1.40s/it, training loss=0.1501]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 1376/1835 [32:02<10:40,  1.40s/it, training loss=0.1548]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1377/1835 [32:02<10:39,  1.40s/it, training loss=0.1548]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1377/1835 [32:04<10:39,  1.40s/it, training loss=0.2250]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1378/1835 [32:04<10:38,  1.40s/it, training loss=0.2250]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1378/1835 [32:05<10:38,  1.40s/it, training loss=0.1494]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1379/1835 [32:05<10:36,  1.40s/it, training loss=0.1494]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1379/1835 [32:07<10:36,  1.40s/it, training loss=0.1048]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1380/1835 [32:07<10:35,  1.40s/it, training loss=0.1048]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1380/1835 [32:08<10:35,  1.40s/it, training loss=0.1924]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1381/1835 [32:08<10:34,  1.40s/it, training loss=0.1924]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1381/1835 [32:09<10:34,  1.40s/it, training loss=0.2056]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1382/1835 [32:09<10:31,  1.39s/it, training loss=0.2056]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1382/1835 [32:11<10:31,  1.39s/it, training loss=0.1187]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1383/1835 [32:11<10:30,  1.39s/it, training loss=0.1187]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1383/1835 [32:12<10:30,  1.39s/it, training loss=0.1638]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1384/1835 [32:12<10:29,  1.40s/it, training loss=0.1638]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1384/1835 [32:14<10:29,  1.40s/it, training loss=0.1314]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1385/1835 [32:14<10:28,  1.40s/it, training loss=0.1314]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 1385/1835 [32:15<10:28,  1.40s/it, training loss=0.1211]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1386/1835 [32:15<10:26,  1.40s/it, training loss=0.1211]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1386/1835 [32:16<10:26,  1.40s/it, training loss=0.2076]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1387/1835 [32:16<10:26,  1.40s/it, training loss=0.2076]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1387/1835 [32:18<10:26,  1.40s/it, training loss=0.1509]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1388/1835 [32:18<10:24,  1.40s/it, training loss=0.1509]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1388/1835 [32:19<10:24,  1.40s/it, training loss=0.1481]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1389/1835 [32:19<10:23,  1.40s/it, training loss=0.1481]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1389/1835 [32:21<10:23,  1.40s/it, training loss=0.2236]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1390/1835 [32:21<10:21,  1.40s/it, training loss=0.2236]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1390/1835 [32:22<10:21,  1.40s/it, training loss=0.0455]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1391/1835 [32:22<10:20,  1.40s/it, training loss=0.0455]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1391/1835 [32:23<10:20,  1.40s/it, training loss=0.1516]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1392/1835 [32:23<10:19,  1.40s/it, training loss=0.1516]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1392/1835 [32:25<10:19,  1.40s/it, training loss=0.2576]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1393/1835 [32:25<10:16,  1.40s/it, training loss=0.2576]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1393/1835 [32:26<10:16,  1.40s/it, training loss=0.1726]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1394/1835 [32:26<10:15,  1.39s/it, training loss=0.1726]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1394/1835 [32:28<10:15,  1.39s/it, training loss=0.2051]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1395/1835 [32:28<10:14,  1.40s/it, training loss=0.2051]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1395/1835 [32:29<10:14,  1.40s/it, training loss=0.3093]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1396/1835 [32:29<10:13,  1.40s/it, training loss=0.3093]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1396/1835 [32:30<10:13,  1.40s/it, training loss=0.1234]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1397/1835 [32:30<10:12,  1.40s/it, training loss=0.1234]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1397/1835 [32:32<10:12,  1.40s/it, training loss=0.1299]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1398/1835 [32:32<10:11,  1.40s/it, training loss=0.1299]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1398/1835 [32:33<10:11,  1.40s/it, training loss=0.2078]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1399/1835 [32:33<10:09,  1.40s/it, training loss=0.2078]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 1399/1835 [32:35<10:09,  1.40s/it, training loss=0.2002]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 1400/1835 [32:35<10:08,  1.40s/it, training loss=0.2002]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 1400/1835 [32:36<10:08,  1.40s/it, training loss=0.1459]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 1401/1835 [32:36<10:07,  1.40s/it, training loss=0.1459]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 1401/1835 [32:37<10:07,  1.40s/it, training loss=0.3101]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 1402/1835 [32:37<10:05,  1.40s/it, training loss=0.3101]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 1402/1835 [32:39<10:05,  1.40s/it, training loss=0.1467]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 1403/1835 [32:39<10:02,  1.40s/it, training loss=0.1467]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 1403/1835 [32:40<10:02,  1.40s/it, training loss=0.1197]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1404/1835 [32:40<10:02,  1.40s/it, training loss=0.1197]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1404/1835 [32:42<10:02,  1.40s/it, training loss=0.1152]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1405/1835 [32:42<10:00,  1.40s/it, training loss=0.1152]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1405/1835 [32:43<10:00,  1.40s/it, training loss=0.0733]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1406/1835 [32:43<09:59,  1.40s/it, training loss=0.0733]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1406/1835 [32:44<09:59,  1.40s/it, training loss=0.2034]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1407/1835 [32:44<09:56,  1.39s/it, training loss=0.2034]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1407/1835 [32:46<09:56,  1.39s/it, training loss=0.1096]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1408/1835 [32:46<09:55,  1.39s/it, training loss=0.1096]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1408/1835 [32:47<09:55,  1.39s/it, training loss=0.1777]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1409/1835 [32:47<09:52,  1.39s/it, training loss=0.1777]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1409/1835 [32:48<09:52,  1.39s/it, training loss=0.1210]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1410/1835 [32:49<09:51,  1.39s/it, training loss=0.1210]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1410/1835 [32:50<09:51,  1.39s/it, training loss=0.1903]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1411/1835 [32:50<09:50,  1.39s/it, training loss=0.1903]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1411/1835 [32:51<09:50,  1.39s/it, training loss=0.1276]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1412/1835 [32:51<09:48,  1.39s/it, training loss=0.1276]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1412/1835 [32:53<09:48,  1.39s/it, training loss=0.0962]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1413/1835 [32:53<09:47,  1.39s/it, training loss=0.0962]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1413/1835 [32:54<09:47,  1.39s/it, training loss=0.0825]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1414/1835 [32:54<09:45,  1.39s/it, training loss=0.0825]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1414/1835 [32:55<09:45,  1.39s/it, training loss=0.1299]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1415/1835 [32:55<09:44,  1.39s/it, training loss=0.1299]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1415/1835 [32:57<09:44,  1.39s/it, training loss=0.0734]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1416/1835 [32:57<09:42,  1.39s/it, training loss=0.0734]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1416/1835 [32:58<09:42,  1.39s/it, training loss=0.2149]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1417/1835 [32:58<09:41,  1.39s/it, training loss=0.2149]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1417/1835 [33:00<09:41,  1.39s/it, training loss=0.2093]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1418/1835 [33:00<09:39,  1.39s/it, training loss=0.2093]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1418/1835 [33:01<09:39,  1.39s/it, training loss=0.1314]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1419/1835 [33:01<09:38,  1.39s/it, training loss=0.1314]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1419/1835 [33:02<09:38,  1.39s/it, training loss=0.1850]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1420/1835 [33:02<09:36,  1.39s/it, training loss=0.1850]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1420/1835 [33:04<09:36,  1.39s/it, training loss=0.2543]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1421/1835 [33:04<09:35,  1.39s/it, training loss=0.2543]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1421/1835 [33:05<09:35,  1.39s/it, training loss=0.1412]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1422/1835 [33:05<09:34,  1.39s/it, training loss=0.1412]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 1422/1835 [33:07<09:34,  1.39s/it, training loss=0.1218]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1423/1835 [33:07<09:33,  1.39s/it, training loss=0.1218]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1423/1835 [33:08<09:33,  1.39s/it, training loss=0.1842]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1424/1835 [33:08<09:33,  1.39s/it, training loss=0.1842]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1424/1835 [33:09<09:33,  1.39s/it, training loss=0.1344]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1425/1835 [33:09<09:31,  1.39s/it, training loss=0.1344]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1425/1835 [33:11<09:31,  1.39s/it, training loss=0.0920]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1426/1835 [33:11<09:29,  1.39s/it, training loss=0.0920]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1426/1835 [33:12<09:29,  1.39s/it, training loss=0.1587]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1427/1835 [33:12<09:28,  1.39s/it, training loss=0.1587]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1427/1835 [33:14<09:28,  1.39s/it, training loss=0.2571]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1428/1835 [33:14<09:27,  1.39s/it, training loss=0.2571]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1428/1835 [33:15<09:27,  1.39s/it, training loss=0.1227]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1429/1835 [33:15<09:25,  1.39s/it, training loss=0.1227]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1429/1835 [33:16<09:25,  1.39s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1430/1835 [33:16<09:25,  1.40s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1430/1835 [33:18<09:25,  1.40s/it, training loss=0.3207]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1431/1835 [33:18<09:23,  1.39s/it, training loss=0.3207]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1431/1835 [33:19<09:23,  1.39s/it, training loss=0.1441]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1432/1835 [33:19<09:21,  1.39s/it, training loss=0.1441]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1432/1835 [33:21<09:21,  1.39s/it, training loss=0.0914]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1433/1835 [33:21<09:20,  1.39s/it, training loss=0.0914]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1433/1835 [33:22<09:20,  1.39s/it, training loss=0.1610]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1434/1835 [33:22<09:19,  1.39s/it, training loss=0.1610]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1434/1835 [33:23<09:19,  1.39s/it, training loss=0.0695]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1435/1835 [33:23<09:18,  1.40s/it, training loss=0.0695]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1435/1835 [33:25<09:18,  1.40s/it, training loss=0.1440]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1436/1835 [33:25<09:18,  1.40s/it, training loss=0.1440]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1436/1835 [33:26<09:18,  1.40s/it, training loss=0.1823]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1437/1835 [33:26<09:14,  1.39s/it, training loss=0.1823]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1437/1835 [33:28<09:14,  1.39s/it, training loss=0.3323]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1438/1835 [33:28<09:14,  1.40s/it, training loss=0.3323]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1438/1835 [33:29<09:14,  1.40s/it, training loss=0.2570]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1439/1835 [33:29<09:12,  1.39s/it, training loss=0.2570]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1439/1835 [33:30<09:12,  1.39s/it, training loss=0.2243]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1440/1835 [33:30<09:10,  1.39s/it, training loss=0.2243]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 1440/1835 [33:32<09:10,  1.39s/it, training loss=0.1325]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 1441/1835 [33:32<09:08,  1.39s/it, training loss=0.1325]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 1441/1835 [33:33<09:08,  1.39s/it, training loss=0.1257]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 1442/1835 [33:33<09:08,  1.40s/it, training loss=0.1257]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 1442/1835 [33:34<09:08,  1.40s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 1443/1835 [33:34<09:07,  1.40s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 1443/1835 [33:36<09:07,  1.40s/it, training loss=0.0710]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 1444/1835 [33:36<09:05,  1.39s/it, training loss=0.0710]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 1444/1835 [33:37<09:05,  1.39s/it, training loss=0.1173]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 1445/1835 [33:37<09:03,  1.39s/it, training loss=0.1173]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 1445/1835 [33:39<09:03,  1.39s/it, training loss=0.1679]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1446/1835 [33:39<09:01,  1.39s/it, training loss=0.1679]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1446/1835 [33:40<09:01,  1.39s/it, training loss=0.1501]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1447/1835 [33:40<09:00,  1.39s/it, training loss=0.1501]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1447/1835 [33:41<09:00,  1.39s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1448/1835 [33:41<08:59,  1.39s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1448/1835 [33:43<08:59,  1.39s/it, training loss=0.2502]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1449/1835 [33:43<08:58,  1.39s/it, training loss=0.2502]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1449/1835 [33:44<08:58,  1.39s/it, training loss=0.2199]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1450/1835 [33:44<08:57,  1.39s/it, training loss=0.2199]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1450/1835 [33:46<08:57,  1.39s/it, training loss=0.1686]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1451/1835 [33:46<08:55,  1.40s/it, training loss=0.1686]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1451/1835 [33:47<08:55,  1.40s/it, training loss=0.0749]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1452/1835 [33:47<08:54,  1.40s/it, training loss=0.0749]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1452/1835 [33:48<08:54,  1.40s/it, training loss=0.0545]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1453/1835 [33:48<08:54,  1.40s/it, training loss=0.0545]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1453/1835 [33:50<08:54,  1.40s/it, training loss=0.1210]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1454/1835 [33:50<08:51,  1.40s/it, training loss=0.1210]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1454/1835 [33:51<08:51,  1.40s/it, training loss=0.1940]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1455/1835 [33:51<08:50,  1.40s/it, training loss=0.1940]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1455/1835 [33:53<08:50,  1.40s/it, training loss=0.1502]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1456/1835 [33:53<08:48,  1.39s/it, training loss=0.1502]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1456/1835 [33:54<08:48,  1.39s/it, training loss=0.1068]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1457/1835 [33:54<08:47,  1.39s/it, training loss=0.1068]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1457/1835 [33:55<08:47,  1.39s/it, training loss=0.1357]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1458/1835 [33:55<08:45,  1.39s/it, training loss=0.1357]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 1458/1835 [33:57<08:45,  1.39s/it, training loss=0.0539]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1459/1835 [33:57<08:44,  1.40s/it, training loss=0.0539]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1459/1835 [33:58<08:44,  1.40s/it, training loss=0.0671]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1460/1835 [33:58<08:42,  1.39s/it, training loss=0.0671]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1460/1835 [34:00<08:42,  1.39s/it, training loss=0.1637]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1461/1835 [34:00<08:41,  1.39s/it, training loss=0.1637]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1461/1835 [34:01<08:41,  1.39s/it, training loss=0.1271]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1462/1835 [34:01<08:38,  1.39s/it, training loss=0.1271]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1462/1835 [34:02<08:38,  1.39s/it, training loss=0.1740]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1463/1835 [34:02<08:37,  1.39s/it, training loss=0.1740]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1463/1835 [34:04<08:37,  1.39s/it, training loss=0.0926]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1464/1835 [34:04<08:37,  1.39s/it, training loss=0.0926]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1464/1835 [34:05<08:37,  1.39s/it, training loss=0.1056]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1465/1835 [34:05<08:36,  1.39s/it, training loss=0.1056]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1465/1835 [34:07<08:36,  1.39s/it, training loss=0.1005]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1466/1835 [34:07<08:34,  1.39s/it, training loss=0.1005]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1466/1835 [34:08<08:34,  1.39s/it, training loss=0.3050]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1467/1835 [34:08<08:34,  1.40s/it, training loss=0.3050]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1467/1835 [34:09<08:34,  1.40s/it, training loss=0.2237]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1468/1835 [34:09<08:31,  1.39s/it, training loss=0.2237]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1468/1835 [34:11<08:31,  1.39s/it, training loss=0.1375]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1469/1835 [34:11<08:30,  1.39s/it, training loss=0.1375]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1469/1835 [34:12<08:30,  1.39s/it, training loss=0.1905]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1470/1835 [34:12<08:29,  1.40s/it, training loss=0.1905]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1470/1835 [34:14<08:29,  1.40s/it, training loss=0.1423]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1471/1835 [34:14<08:28,  1.40s/it, training loss=0.1423]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1471/1835 [34:15<08:28,  1.40s/it, training loss=0.1715]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1472/1835 [34:15<08:26,  1.39s/it, training loss=0.1715]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1472/1835 [34:16<08:26,  1.39s/it, training loss=0.1564]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1473/1835 [34:16<08:25,  1.40s/it, training loss=0.1564]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1473/1835 [34:18<08:25,  1.40s/it, training loss=0.1458]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1474/1835 [34:18<08:24,  1.40s/it, training loss=0.1458]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1474/1835 [34:19<08:24,  1.40s/it, training loss=0.0914]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1475/1835 [34:19<08:22,  1.40s/it, training loss=0.0914]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1475/1835 [34:21<08:22,  1.40s/it, training loss=0.1997]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1476/1835 [34:21<08:22,  1.40s/it, training loss=0.1997]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1476/1835 [34:22<08:22,  1.40s/it, training loss=0.2178]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1477/1835 [34:22<08:20,  1.40s/it, training loss=0.2178]\u001b[A\n",
            "Epoch 2:  80%|████████  | 1477/1835 [34:23<08:20,  1.40s/it, training loss=0.1558]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1478/1835 [34:23<08:18,  1.40s/it, training loss=0.1558]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1478/1835 [34:25<08:18,  1.40s/it, training loss=0.1509]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1479/1835 [34:25<08:17,  1.40s/it, training loss=0.1509]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1479/1835 [34:26<08:17,  1.40s/it, training loss=0.1806]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1480/1835 [34:26<08:15,  1.40s/it, training loss=0.1806]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1480/1835 [34:27<08:15,  1.40s/it, training loss=0.1296]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1481/1835 [34:28<08:13,  1.39s/it, training loss=0.1296]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1481/1835 [34:29<08:13,  1.39s/it, training loss=0.1835]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1482/1835 [34:29<08:12,  1.40s/it, training loss=0.1835]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1482/1835 [34:30<08:12,  1.40s/it, training loss=0.1060]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1483/1835 [34:30<08:10,  1.39s/it, training loss=0.1060]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1483/1835 [34:32<08:10,  1.39s/it, training loss=0.1997]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1484/1835 [34:32<08:10,  1.40s/it, training loss=0.1997]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1484/1835 [34:33<08:10,  1.40s/it, training loss=0.2082]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1485/1835 [34:33<08:09,  1.40s/it, training loss=0.2082]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1485/1835 [34:34<08:09,  1.40s/it, training loss=0.0959]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1486/1835 [34:34<08:08,  1.40s/it, training loss=0.0959]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1486/1835 [34:36<08:08,  1.40s/it, training loss=0.1156]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1487/1835 [34:36<08:07,  1.40s/it, training loss=0.1156]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1487/1835 [34:37<08:07,  1.40s/it, training loss=0.1309]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1488/1835 [34:37<08:05,  1.40s/it, training loss=0.1309]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1488/1835 [34:39<08:05,  1.40s/it, training loss=0.1193]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1489/1835 [34:39<08:04,  1.40s/it, training loss=0.1193]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1489/1835 [34:40<08:04,  1.40s/it, training loss=0.2086]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1490/1835 [34:40<08:02,  1.40s/it, training loss=0.2086]\u001b[A\n",
            "Epoch 2:  81%|████████  | 1490/1835 [34:41<08:02,  1.40s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 1491/1835 [34:41<08:00,  1.40s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 1491/1835 [34:43<08:00,  1.40s/it, training loss=0.1641]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 1492/1835 [34:43<07:59,  1.40s/it, training loss=0.1641]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 1492/1835 [34:44<07:59,  1.40s/it, training loss=0.1530]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 1493/1835 [34:44<07:57,  1.39s/it, training loss=0.1530]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 1493/1835 [34:46<07:57,  1.39s/it, training loss=0.2058]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 1494/1835 [34:46<07:55,  1.39s/it, training loss=0.2058]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 1494/1835 [34:47<07:55,  1.39s/it, training loss=0.1510]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 1495/1835 [34:47<07:53,  1.39s/it, training loss=0.1510]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 1495/1835 [34:48<07:53,  1.39s/it, training loss=0.2264]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1496/1835 [34:48<07:52,  1.39s/it, training loss=0.2264]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1496/1835 [34:50<07:52,  1.39s/it, training loss=0.0814]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1497/1835 [34:50<07:51,  1.40s/it, training loss=0.0814]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1497/1835 [34:51<07:51,  1.40s/it, training loss=0.2377]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1498/1835 [34:51<07:51,  1.40s/it, training loss=0.2377]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1498/1835 [34:53<07:51,  1.40s/it, training loss=0.1904]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1499/1835 [34:53<07:48,  1.40s/it, training loss=0.1904]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1499/1835 [34:54<07:48,  1.40s/it, training loss=0.1971]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1500/1835 [34:54<07:47,  1.39s/it, training loss=0.1971]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1500/1835 [34:55<07:47,  1.39s/it, training loss=0.2428]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1501/1835 [34:55<07:46,  1.40s/it, training loss=0.2428]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1501/1835 [34:57<07:46,  1.40s/it, training loss=0.1730]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1502/1835 [34:57<07:44,  1.39s/it, training loss=0.1730]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1502/1835 [34:58<07:44,  1.39s/it, training loss=0.2122]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1503/1835 [34:58<07:43,  1.40s/it, training loss=0.2122]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1503/1835 [35:00<07:43,  1.40s/it, training loss=0.1642]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1504/1835 [35:00<07:41,  1.39s/it, training loss=0.1642]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1504/1835 [35:01<07:41,  1.39s/it, training loss=0.1607]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1505/1835 [35:01<07:39,  1.39s/it, training loss=0.1607]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1505/1835 [35:02<07:39,  1.39s/it, training loss=0.2049]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1506/1835 [35:02<07:38,  1.39s/it, training loss=0.2049]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1506/1835 [35:04<07:38,  1.39s/it, training loss=0.0515]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1507/1835 [35:04<07:37,  1.39s/it, training loss=0.0515]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1507/1835 [35:05<07:37,  1.39s/it, training loss=0.1258]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1508/1835 [35:05<07:36,  1.40s/it, training loss=0.1258]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1508/1835 [35:07<07:36,  1.40s/it, training loss=0.1631]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1509/1835 [35:07<07:35,  1.40s/it, training loss=0.1631]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1509/1835 [35:08<07:35,  1.40s/it, training loss=0.2189]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1510/1835 [35:08<07:33,  1.40s/it, training loss=0.2189]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1510/1835 [35:09<07:33,  1.40s/it, training loss=0.1229]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1511/1835 [35:09<07:32,  1.40s/it, training loss=0.1229]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1511/1835 [35:11<07:32,  1.40s/it, training loss=0.2783]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1512/1835 [35:11<07:30,  1.40s/it, training loss=0.2783]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1512/1835 [35:12<07:30,  1.40s/it, training loss=0.1358]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1513/1835 [35:12<07:29,  1.40s/it, training loss=0.1358]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 1513/1835 [35:14<07:29,  1.40s/it, training loss=0.0637]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1514/1835 [35:14<07:27,  1.40s/it, training loss=0.0637]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1514/1835 [35:15<07:27,  1.40s/it, training loss=0.1392]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1515/1835 [35:15<07:26,  1.39s/it, training loss=0.1392]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1515/1835 [35:16<07:26,  1.39s/it, training loss=0.2003]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1516/1835 [35:16<07:25,  1.40s/it, training loss=0.2003]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1516/1835 [35:18<07:25,  1.40s/it, training loss=0.1024]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1517/1835 [35:18<07:23,  1.40s/it, training loss=0.1024]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1517/1835 [35:19<07:23,  1.40s/it, training loss=0.1031]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1518/1835 [35:19<07:23,  1.40s/it, training loss=0.1031]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1518/1835 [35:21<07:23,  1.40s/it, training loss=0.1355]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1519/1835 [35:21<07:21,  1.40s/it, training loss=0.1355]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1519/1835 [35:22<07:21,  1.40s/it, training loss=0.0910]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1520/1835 [35:22<07:19,  1.40s/it, training loss=0.0910]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1520/1835 [35:23<07:19,  1.40s/it, training loss=0.1124]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1521/1835 [35:23<07:18,  1.40s/it, training loss=0.1124]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1521/1835 [35:25<07:18,  1.40s/it, training loss=0.1399]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1522/1835 [35:25<07:17,  1.40s/it, training loss=0.1399]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1522/1835 [35:26<07:17,  1.40s/it, training loss=0.1646]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1523/1835 [35:26<07:15,  1.40s/it, training loss=0.1646]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1523/1835 [35:28<07:15,  1.40s/it, training loss=0.1092]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1524/1835 [35:28<07:14,  1.40s/it, training loss=0.1092]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1524/1835 [35:29<07:14,  1.40s/it, training loss=0.0968]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1525/1835 [35:29<07:12,  1.39s/it, training loss=0.0968]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1525/1835 [35:30<07:12,  1.39s/it, training loss=0.1688]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1526/1835 [35:30<07:11,  1.40s/it, training loss=0.1688]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1526/1835 [35:32<07:11,  1.40s/it, training loss=0.1099]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1527/1835 [35:32<07:09,  1.39s/it, training loss=0.1099]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1527/1835 [35:33<07:09,  1.39s/it, training loss=0.1855]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1528/1835 [35:33<07:08,  1.40s/it, training loss=0.1855]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1528/1835 [35:35<07:08,  1.40s/it, training loss=0.1873]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1529/1835 [35:35<07:07,  1.40s/it, training loss=0.1873]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1529/1835 [35:36<07:07,  1.40s/it, training loss=0.2603]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1530/1835 [35:36<07:05,  1.40s/it, training loss=0.2603]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1530/1835 [35:37<07:05,  1.40s/it, training loss=0.3040]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1531/1835 [35:37<07:04,  1.40s/it, training loss=0.3040]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1531/1835 [35:39<07:04,  1.40s/it, training loss=0.0950]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1532/1835 [35:39<07:03,  1.40s/it, training loss=0.0950]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 1532/1835 [35:40<07:03,  1.40s/it, training loss=0.1552]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 1533/1835 [35:40<07:02,  1.40s/it, training loss=0.1552]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 1533/1835 [35:42<07:02,  1.40s/it, training loss=0.1948]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 1534/1835 [35:42<07:01,  1.40s/it, training loss=0.1948]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 1534/1835 [35:43<07:01,  1.40s/it, training loss=0.1181]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 1535/1835 [35:43<07:00,  1.40s/it, training loss=0.1181]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 1535/1835 [35:44<07:00,  1.40s/it, training loss=0.2693]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 1536/1835 [35:44<06:58,  1.40s/it, training loss=0.2693]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 1536/1835 [35:46<06:58,  1.40s/it, training loss=0.2878]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1537/1835 [35:46<06:56,  1.40s/it, training loss=0.2878]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1537/1835 [35:47<06:56,  1.40s/it, training loss=0.1725]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1538/1835 [35:47<06:54,  1.40s/it, training loss=0.1725]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1538/1835 [35:48<06:54,  1.40s/it, training loss=0.1175]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1539/1835 [35:49<06:53,  1.40s/it, training loss=0.1175]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1539/1835 [35:50<06:53,  1.40s/it, training loss=0.3216]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1540/1835 [35:50<06:51,  1.40s/it, training loss=0.3216]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1540/1835 [35:51<06:51,  1.40s/it, training loss=0.0783]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1541/1835 [35:51<06:51,  1.40s/it, training loss=0.0783]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1541/1835 [35:53<06:51,  1.40s/it, training loss=0.2704]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1542/1835 [35:53<06:49,  1.40s/it, training loss=0.2704]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1542/1835 [35:54<06:49,  1.40s/it, training loss=0.0793]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1543/1835 [35:54<06:47,  1.40s/it, training loss=0.0793]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1543/1835 [35:55<06:47,  1.40s/it, training loss=0.2256]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1544/1835 [35:55<06:46,  1.40s/it, training loss=0.2256]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1544/1835 [35:57<06:46,  1.40s/it, training loss=0.2339]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1545/1835 [35:57<06:45,  1.40s/it, training loss=0.2339]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1545/1835 [35:58<06:45,  1.40s/it, training loss=0.1463]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1546/1835 [35:58<06:44,  1.40s/it, training loss=0.1463]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1546/1835 [36:00<06:44,  1.40s/it, training loss=0.1480]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1547/1835 [36:00<06:42,  1.40s/it, training loss=0.1480]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1547/1835 [36:01<06:42,  1.40s/it, training loss=0.1645]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1548/1835 [36:01<06:40,  1.40s/it, training loss=0.1645]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1548/1835 [36:02<06:40,  1.40s/it, training loss=0.2949]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1549/1835 [36:02<06:39,  1.40s/it, training loss=0.2949]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1549/1835 [36:04<06:39,  1.40s/it, training loss=0.1344]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1550/1835 [36:04<06:38,  1.40s/it, training loss=0.1344]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 1550/1835 [36:05<06:38,  1.40s/it, training loss=0.0978]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1551/1835 [36:05<06:36,  1.40s/it, training loss=0.0978]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1551/1835 [36:07<06:36,  1.40s/it, training loss=0.1590]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1552/1835 [36:07<06:35,  1.40s/it, training loss=0.1590]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1552/1835 [36:08<06:35,  1.40s/it, training loss=0.2309]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1553/1835 [36:08<06:33,  1.40s/it, training loss=0.2309]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1553/1835 [36:09<06:33,  1.40s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1554/1835 [36:09<06:32,  1.40s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1554/1835 [36:11<06:32,  1.40s/it, training loss=0.1592]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1555/1835 [36:11<06:30,  1.40s/it, training loss=0.1592]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1555/1835 [36:12<06:30,  1.40s/it, training loss=0.1573]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1556/1835 [36:12<06:29,  1.40s/it, training loss=0.1573]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1556/1835 [36:14<06:29,  1.40s/it, training loss=0.3721]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1557/1835 [36:14<06:28,  1.40s/it, training loss=0.3721]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1557/1835 [36:15<06:28,  1.40s/it, training loss=0.2351]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1558/1835 [36:15<06:27,  1.40s/it, training loss=0.2351]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1558/1835 [36:16<06:27,  1.40s/it, training loss=0.2177]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1559/1835 [36:16<06:26,  1.40s/it, training loss=0.2177]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 1559/1835 [36:18<06:26,  1.40s/it, training loss=0.0944]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1560/1835 [36:18<06:24,  1.40s/it, training loss=0.0944]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1560/1835 [36:19<06:24,  1.40s/it, training loss=0.0976]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1561/1835 [36:19<06:23,  1.40s/it, training loss=0.0976]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1561/1835 [36:21<06:23,  1.40s/it, training loss=0.1272]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1562/1835 [36:21<06:22,  1.40s/it, training loss=0.1272]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1562/1835 [36:22<06:22,  1.40s/it, training loss=0.1524]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1563/1835 [36:22<06:20,  1.40s/it, training loss=0.1524]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1563/1835 [36:23<06:20,  1.40s/it, training loss=0.2483]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1564/1835 [36:23<06:19,  1.40s/it, training loss=0.2483]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1564/1835 [36:25<06:19,  1.40s/it, training loss=0.0930]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1565/1835 [36:25<06:18,  1.40s/it, training loss=0.0930]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1565/1835 [36:26<06:18,  1.40s/it, training loss=0.1106]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1566/1835 [36:26<06:16,  1.40s/it, training loss=0.1106]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1566/1835 [36:28<06:16,  1.40s/it, training loss=0.1085]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1567/1835 [36:28<06:15,  1.40s/it, training loss=0.1085]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1567/1835 [36:29<06:15,  1.40s/it, training loss=0.1660]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1568/1835 [36:29<06:13,  1.40s/it, training loss=0.1660]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 1568/1835 [36:30<06:13,  1.40s/it, training loss=0.0491]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1569/1835 [36:30<06:12,  1.40s/it, training loss=0.0491]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1569/1835 [36:32<06:12,  1.40s/it, training loss=0.0865]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1570/1835 [36:32<06:11,  1.40s/it, training loss=0.0865]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1570/1835 [36:33<06:11,  1.40s/it, training loss=0.0929]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1571/1835 [36:33<06:09,  1.40s/it, training loss=0.0929]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1571/1835 [36:35<06:09,  1.40s/it, training loss=0.3682]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1572/1835 [36:35<06:07,  1.40s/it, training loss=0.3682]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1572/1835 [36:36<06:07,  1.40s/it, training loss=0.1200]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1573/1835 [36:36<06:05,  1.40s/it, training loss=0.1200]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1573/1835 [36:37<06:05,  1.40s/it, training loss=0.1020]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1574/1835 [36:37<06:04,  1.40s/it, training loss=0.1020]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1574/1835 [36:39<06:04,  1.40s/it, training loss=0.2553]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1575/1835 [36:39<06:03,  1.40s/it, training loss=0.2553]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1575/1835 [36:40<06:03,  1.40s/it, training loss=0.2828]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1576/1835 [36:40<06:01,  1.40s/it, training loss=0.2828]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1576/1835 [36:42<06:01,  1.40s/it, training loss=0.0730]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1577/1835 [36:42<06:00,  1.40s/it, training loss=0.0730]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1577/1835 [36:43<06:00,  1.40s/it, training loss=0.1626]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1578/1835 [36:43<05:58,  1.40s/it, training loss=0.1626]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1578/1835 [36:44<05:58,  1.40s/it, training loss=0.2535]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1579/1835 [36:44<05:57,  1.40s/it, training loss=0.2535]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1579/1835 [36:46<05:57,  1.40s/it, training loss=0.1259]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1580/1835 [36:46<05:56,  1.40s/it, training loss=0.1259]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1580/1835 [36:47<05:56,  1.40s/it, training loss=0.2103]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1581/1835 [36:47<05:54,  1.40s/it, training loss=0.2103]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1581/1835 [36:49<05:54,  1.40s/it, training loss=0.1929]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1582/1835 [36:49<05:53,  1.40s/it, training loss=0.1929]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 1582/1835 [36:50<05:53,  1.40s/it, training loss=0.0892]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1583/1835 [36:50<05:51,  1.40s/it, training loss=0.0892]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1583/1835 [36:51<05:51,  1.40s/it, training loss=0.1834]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1584/1835 [36:51<05:50,  1.40s/it, training loss=0.1834]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1584/1835 [36:53<05:50,  1.40s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1585/1835 [36:53<05:49,  1.40s/it, training loss=0.1899]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1585/1835 [36:54<05:49,  1.40s/it, training loss=0.0660]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1586/1835 [36:54<05:48,  1.40s/it, training loss=0.0660]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1586/1835 [36:56<05:48,  1.40s/it, training loss=0.1228]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1587/1835 [36:56<05:46,  1.40s/it, training loss=0.1228]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 1587/1835 [36:57<05:46,  1.40s/it, training loss=0.0614]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1588/1835 [36:57<05:45,  1.40s/it, training loss=0.0614]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1588/1835 [36:58<05:45,  1.40s/it, training loss=0.2008]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1589/1835 [36:58<05:43,  1.39s/it, training loss=0.2008]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1589/1835 [37:00<05:43,  1.39s/it, training loss=0.1584]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1590/1835 [37:00<05:41,  1.39s/it, training loss=0.1584]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1590/1835 [37:01<05:41,  1.39s/it, training loss=0.2769]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1591/1835 [37:01<05:39,  1.39s/it, training loss=0.2769]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1591/1835 [37:03<05:39,  1.39s/it, training loss=0.1371]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1592/1835 [37:03<05:38,  1.39s/it, training loss=0.1371]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1592/1835 [37:04<05:38,  1.39s/it, training loss=0.1081]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1593/1835 [37:04<05:36,  1.39s/it, training loss=0.1081]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1593/1835 [37:05<05:36,  1.39s/it, training loss=0.0762]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1594/1835 [37:05<05:36,  1.40s/it, training loss=0.0762]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1594/1835 [37:07<05:36,  1.40s/it, training loss=0.1262]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1595/1835 [37:07<05:34,  1.39s/it, training loss=0.1262]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1595/1835 [37:08<05:34,  1.39s/it, training loss=0.1053]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1596/1835 [37:08<05:32,  1.39s/it, training loss=0.1053]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1596/1835 [37:10<05:32,  1.39s/it, training loss=0.2454]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1597/1835 [37:10<05:32,  1.40s/it, training loss=0.2454]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1597/1835 [37:11<05:32,  1.40s/it, training loss=0.1413]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1598/1835 [37:11<05:31,  1.40s/it, training loss=0.1413]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1598/1835 [37:12<05:31,  1.40s/it, training loss=0.1063]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1599/1835 [37:12<05:29,  1.40s/it, training loss=0.1063]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1599/1835 [37:14<05:29,  1.40s/it, training loss=0.2802]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1600/1835 [37:14<05:28,  1.40s/it, training loss=0.2802]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1600/1835 [37:15<05:28,  1.40s/it, training loss=0.1440]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1601/1835 [37:15<05:26,  1.40s/it, training loss=0.1440]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1601/1835 [37:17<05:26,  1.40s/it, training loss=0.2082]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1602/1835 [37:17<05:25,  1.40s/it, training loss=0.2082]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1602/1835 [37:18<05:25,  1.40s/it, training loss=0.1108]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1603/1835 [37:18<05:24,  1.40s/it, training loss=0.1108]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1603/1835 [37:19<05:24,  1.40s/it, training loss=0.1735]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1604/1835 [37:19<05:22,  1.40s/it, training loss=0.1735]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1604/1835 [37:21<05:22,  1.40s/it, training loss=0.1078]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1605/1835 [37:21<05:20,  1.39s/it, training loss=0.1078]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 1605/1835 [37:22<05:20,  1.39s/it, training loss=0.1695]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1606/1835 [37:22<05:19,  1.39s/it, training loss=0.1695]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1606/1835 [37:23<05:19,  1.39s/it, training loss=0.1358]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1607/1835 [37:23<05:17,  1.39s/it, training loss=0.1358]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1607/1835 [37:25<05:17,  1.39s/it, training loss=0.1772]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1608/1835 [37:25<05:16,  1.39s/it, training loss=0.1772]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1608/1835 [37:26<05:16,  1.39s/it, training loss=0.2492]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1609/1835 [37:26<05:15,  1.40s/it, training loss=0.2492]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1609/1835 [37:28<05:15,  1.40s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1610/1835 [37:28<05:14,  1.40s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1610/1835 [37:29<05:14,  1.40s/it, training loss=0.1935]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1611/1835 [37:29<05:13,  1.40s/it, training loss=0.1935]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1611/1835 [37:30<05:13,  1.40s/it, training loss=0.2007]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1612/1835 [37:30<05:11,  1.40s/it, training loss=0.2007]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1612/1835 [37:32<05:11,  1.40s/it, training loss=0.1702]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1613/1835 [37:32<05:10,  1.40s/it, training loss=0.1702]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1613/1835 [37:33<05:10,  1.40s/it, training loss=0.0373]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1614/1835 [37:33<05:08,  1.40s/it, training loss=0.0373]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1614/1835 [37:35<05:08,  1.40s/it, training loss=0.1966]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1615/1835 [37:35<05:07,  1.40s/it, training loss=0.1966]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1615/1835 [37:36<05:07,  1.40s/it, training loss=0.1668]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1616/1835 [37:36<05:05,  1.40s/it, training loss=0.1668]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1616/1835 [37:37<05:05,  1.40s/it, training loss=0.2812]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1617/1835 [37:37<05:04,  1.40s/it, training loss=0.2812]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1617/1835 [37:39<05:04,  1.40s/it, training loss=0.0793]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1618/1835 [37:39<05:02,  1.40s/it, training loss=0.0793]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1618/1835 [37:40<05:02,  1.40s/it, training loss=0.0801]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1619/1835 [37:40<05:01,  1.40s/it, training loss=0.0801]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1619/1835 [37:42<05:01,  1.40s/it, training loss=0.2080]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1620/1835 [37:42<05:00,  1.40s/it, training loss=0.2080]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1620/1835 [37:43<05:00,  1.40s/it, training loss=0.2579]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1621/1835 [37:43<04:59,  1.40s/it, training loss=0.2579]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1621/1835 [37:44<04:59,  1.40s/it, training loss=0.1621]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1622/1835 [37:44<04:57,  1.40s/it, training loss=0.1621]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1622/1835 [37:46<04:57,  1.40s/it, training loss=0.2084]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1623/1835 [37:46<04:56,  1.40s/it, training loss=0.2084]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 1623/1835 [37:47<04:56,  1.40s/it, training loss=0.0875]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1624/1835 [37:47<04:54,  1.40s/it, training loss=0.0875]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1624/1835 [37:49<04:54,  1.40s/it, training loss=0.1521]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1625/1835 [37:49<04:53,  1.40s/it, training loss=0.1521]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1625/1835 [37:50<04:53,  1.40s/it, training loss=0.0694]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1626/1835 [37:50<04:51,  1.40s/it, training loss=0.0694]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1626/1835 [37:51<04:51,  1.40s/it, training loss=0.1068]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1627/1835 [37:51<04:50,  1.39s/it, training loss=0.1068]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1627/1835 [37:53<04:50,  1.39s/it, training loss=0.2035]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1628/1835 [37:53<04:48,  1.39s/it, training loss=0.2035]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 1628/1835 [37:54<04:48,  1.39s/it, training loss=0.0946]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1629/1835 [37:54<04:46,  1.39s/it, training loss=0.0946]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1629/1835 [37:56<04:46,  1.39s/it, training loss=0.1115]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1630/1835 [37:56<04:45,  1.39s/it, training loss=0.1115]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1630/1835 [37:57<04:45,  1.39s/it, training loss=0.1219]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1631/1835 [37:57<04:43,  1.39s/it, training loss=0.1219]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1631/1835 [37:58<04:43,  1.39s/it, training loss=0.2881]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1632/1835 [37:58<04:42,  1.39s/it, training loss=0.2881]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1632/1835 [38:00<04:42,  1.39s/it, training loss=0.1345]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1633/1835 [38:00<04:40,  1.39s/it, training loss=0.1345]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1633/1835 [38:01<04:40,  1.39s/it, training loss=0.0948]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1634/1835 [38:01<04:39,  1.39s/it, training loss=0.0948]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1634/1835 [38:03<04:39,  1.39s/it, training loss=0.1908]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1635/1835 [38:03<04:37,  1.39s/it, training loss=0.1908]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1635/1835 [38:04<04:37,  1.39s/it, training loss=0.0947]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1636/1835 [38:04<04:37,  1.39s/it, training loss=0.0947]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1636/1835 [38:05<04:37,  1.39s/it, training loss=0.1162]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1637/1835 [38:05<04:35,  1.39s/it, training loss=0.1162]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1637/1835 [38:07<04:35,  1.39s/it, training loss=0.1228]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1638/1835 [38:07<04:34,  1.39s/it, training loss=0.1228]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1638/1835 [38:08<04:34,  1.39s/it, training loss=0.2051]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1639/1835 [38:08<04:33,  1.40s/it, training loss=0.2051]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1639/1835 [38:10<04:33,  1.40s/it, training loss=0.0774]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1640/1835 [38:10<04:32,  1.40s/it, training loss=0.0774]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1640/1835 [38:11<04:32,  1.40s/it, training loss=0.0748]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1641/1835 [38:11<04:30,  1.40s/it, training loss=0.0748]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1641/1835 [38:12<04:30,  1.40s/it, training loss=0.1861]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1642/1835 [38:12<04:29,  1.40s/it, training loss=0.1861]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 1642/1835 [38:14<04:29,  1.40s/it, training loss=0.1614]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1643/1835 [38:14<04:28,  1.40s/it, training loss=0.1614]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1643/1835 [38:15<04:28,  1.40s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1644/1835 [38:15<04:26,  1.40s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1644/1835 [38:17<04:26,  1.40s/it, training loss=0.0535]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1645/1835 [38:17<04:25,  1.40s/it, training loss=0.0535]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1645/1835 [38:18<04:25,  1.40s/it, training loss=0.2107]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1646/1835 [38:18<04:23,  1.40s/it, training loss=0.2107]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1646/1835 [38:19<04:23,  1.40s/it, training loss=0.2004]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1647/1835 [38:19<04:22,  1.40s/it, training loss=0.2004]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1647/1835 [38:21<04:22,  1.40s/it, training loss=0.1429]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1648/1835 [38:21<04:21,  1.40s/it, training loss=0.1429]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1648/1835 [38:22<04:21,  1.40s/it, training loss=0.1184]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1649/1835 [38:22<04:19,  1.39s/it, training loss=0.1184]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1649/1835 [38:23<04:19,  1.39s/it, training loss=0.1263]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1650/1835 [38:23<04:17,  1.39s/it, training loss=0.1263]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1650/1835 [38:25<04:17,  1.39s/it, training loss=0.1763]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1651/1835 [38:25<04:16,  1.39s/it, training loss=0.1763]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1651/1835 [38:26<04:16,  1.39s/it, training loss=0.1218]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1652/1835 [38:26<04:14,  1.39s/it, training loss=0.1218]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1652/1835 [38:28<04:14,  1.39s/it, training loss=0.0202]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1653/1835 [38:28<04:13,  1.39s/it, training loss=0.0202]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1653/1835 [38:29<04:13,  1.39s/it, training loss=0.0489]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1654/1835 [38:29<04:11,  1.39s/it, training loss=0.0489]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1654/1835 [38:30<04:11,  1.39s/it, training loss=0.1773]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1655/1835 [38:30<04:10,  1.39s/it, training loss=0.1773]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1655/1835 [38:32<04:10,  1.39s/it, training loss=0.1723]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1656/1835 [38:32<04:09,  1.39s/it, training loss=0.1723]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1656/1835 [38:33<04:09,  1.39s/it, training loss=0.0604]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1657/1835 [38:33<04:07,  1.39s/it, training loss=0.0604]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1657/1835 [38:35<04:07,  1.39s/it, training loss=0.1315]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1658/1835 [38:35<04:06,  1.39s/it, training loss=0.1315]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1658/1835 [38:36<04:06,  1.39s/it, training loss=0.1242]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1659/1835 [38:36<04:04,  1.39s/it, training loss=0.1242]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1659/1835 [38:37<04:04,  1.39s/it, training loss=0.2699]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1660/1835 [38:37<04:03,  1.39s/it, training loss=0.2699]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 1660/1835 [38:39<04:03,  1.39s/it, training loss=0.0597]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1661/1835 [38:39<04:02,  1.39s/it, training loss=0.0597]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1661/1835 [38:40<04:02,  1.39s/it, training loss=0.0525]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1662/1835 [38:40<04:01,  1.40s/it, training loss=0.0525]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1662/1835 [38:42<04:01,  1.40s/it, training loss=0.1316]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1663/1835 [38:42<04:00,  1.40s/it, training loss=0.1316]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1663/1835 [38:43<04:00,  1.40s/it, training loss=0.0661]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1664/1835 [38:43<03:58,  1.40s/it, training loss=0.0661]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1664/1835 [38:44<03:58,  1.40s/it, training loss=0.1572]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1665/1835 [38:44<03:57,  1.40s/it, training loss=0.1572]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1665/1835 [38:46<03:57,  1.40s/it, training loss=0.0744]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1666/1835 [38:46<03:56,  1.40s/it, training loss=0.0744]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1666/1835 [38:47<03:56,  1.40s/it, training loss=0.2592]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1667/1835 [38:47<03:54,  1.40s/it, training loss=0.2592]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1667/1835 [38:49<03:54,  1.40s/it, training loss=0.0429]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1668/1835 [38:49<03:53,  1.40s/it, training loss=0.0429]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1668/1835 [38:50<03:53,  1.40s/it, training loss=0.2476]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1669/1835 [38:50<03:52,  1.40s/it, training loss=0.2476]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1669/1835 [38:51<03:52,  1.40s/it, training loss=0.2530]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1670/1835 [38:51<03:50,  1.40s/it, training loss=0.2530]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1670/1835 [38:53<03:50,  1.40s/it, training loss=0.2207]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1671/1835 [38:53<03:49,  1.40s/it, training loss=0.2207]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1671/1835 [38:54<03:49,  1.40s/it, training loss=0.1105]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1672/1835 [38:54<03:47,  1.40s/it, training loss=0.1105]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1672/1835 [38:56<03:47,  1.40s/it, training loss=0.0754]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1673/1835 [38:56<03:46,  1.40s/it, training loss=0.0754]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1673/1835 [38:57<03:46,  1.40s/it, training loss=0.1383]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1674/1835 [38:57<03:45,  1.40s/it, training loss=0.1383]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 1674/1835 [38:58<03:45,  1.40s/it, training loss=0.0577]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1675/1835 [38:58<03:43,  1.40s/it, training loss=0.0577]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1675/1835 [39:00<03:43,  1.40s/it, training loss=0.0652]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1676/1835 [39:00<03:42,  1.40s/it, training loss=0.0652]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1676/1835 [39:01<03:42,  1.40s/it, training loss=0.0581]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1677/1835 [39:01<03:40,  1.39s/it, training loss=0.0581]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1677/1835 [39:03<03:40,  1.39s/it, training loss=0.1331]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1678/1835 [39:03<03:39,  1.40s/it, training loss=0.1331]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1678/1835 [39:04<03:39,  1.40s/it, training loss=0.2626]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1679/1835 [39:04<03:37,  1.40s/it, training loss=0.2626]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 1679/1835 [39:05<03:37,  1.40s/it, training loss=0.1943]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1680/1835 [39:05<03:35,  1.39s/it, training loss=0.1943]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1680/1835 [39:07<03:35,  1.39s/it, training loss=0.0514]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1681/1835 [39:07<03:34,  1.39s/it, training loss=0.0514]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1681/1835 [39:08<03:34,  1.39s/it, training loss=0.0767]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1682/1835 [39:08<03:33,  1.39s/it, training loss=0.0767]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1682/1835 [39:10<03:33,  1.39s/it, training loss=0.1252]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1683/1835 [39:10<03:32,  1.40s/it, training loss=0.1252]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1683/1835 [39:11<03:32,  1.40s/it, training loss=0.1283]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1684/1835 [39:11<03:30,  1.39s/it, training loss=0.1283]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1684/1835 [39:12<03:30,  1.39s/it, training loss=0.0956]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1685/1835 [39:12<03:29,  1.39s/it, training loss=0.0956]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1685/1835 [39:14<03:29,  1.39s/it, training loss=0.1712]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1686/1835 [39:14<03:27,  1.39s/it, training loss=0.1712]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1686/1835 [39:15<03:27,  1.39s/it, training loss=0.0591]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1687/1835 [39:15<03:26,  1.39s/it, training loss=0.0591]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1687/1835 [39:16<03:26,  1.39s/it, training loss=0.1172]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1688/1835 [39:17<03:25,  1.40s/it, training loss=0.1172]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1688/1835 [39:18<03:25,  1.40s/it, training loss=0.0531]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1689/1835 [39:18<03:24,  1.40s/it, training loss=0.0531]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1689/1835 [39:19<03:24,  1.40s/it, training loss=0.1034]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1690/1835 [39:19<03:22,  1.40s/it, training loss=0.1034]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1690/1835 [39:21<03:22,  1.40s/it, training loss=0.1919]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1691/1835 [39:21<03:21,  1.40s/it, training loss=0.1919]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1691/1835 [39:22<03:21,  1.40s/it, training loss=0.0458]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1692/1835 [39:22<03:19,  1.40s/it, training loss=0.0458]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1692/1835 [39:23<03:19,  1.40s/it, training loss=0.0456]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1693/1835 [39:23<03:18,  1.40s/it, training loss=0.0456]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1693/1835 [39:25<03:18,  1.40s/it, training loss=0.0528]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1694/1835 [39:25<03:17,  1.40s/it, training loss=0.0528]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1694/1835 [39:26<03:17,  1.40s/it, training loss=0.2261]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1695/1835 [39:26<03:15,  1.40s/it, training loss=0.2261]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1695/1835 [39:28<03:15,  1.40s/it, training loss=0.2150]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1696/1835 [39:28<03:14,  1.40s/it, training loss=0.2150]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1696/1835 [39:29<03:14,  1.40s/it, training loss=0.1191]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1697/1835 [39:29<03:12,  1.40s/it, training loss=0.1191]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 1697/1835 [39:30<03:12,  1.40s/it, training loss=0.0999]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1698/1835 [39:30<03:11,  1.40s/it, training loss=0.0999]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1698/1835 [39:32<03:11,  1.40s/it, training loss=0.1593]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1699/1835 [39:32<03:10,  1.40s/it, training loss=0.1593]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1699/1835 [39:33<03:10,  1.40s/it, training loss=0.0349]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1700/1835 [39:33<03:08,  1.40s/it, training loss=0.0349]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1700/1835 [39:35<03:08,  1.40s/it, training loss=0.0944]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1701/1835 [39:35<03:07,  1.40s/it, training loss=0.0944]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1701/1835 [39:36<03:07,  1.40s/it, training loss=0.3270]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1702/1835 [39:36<03:06,  1.40s/it, training loss=0.3270]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1702/1835 [39:37<03:06,  1.40s/it, training loss=0.1513]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1703/1835 [39:37<03:04,  1.40s/it, training loss=0.1513]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1703/1835 [39:39<03:04,  1.40s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1704/1835 [39:39<03:03,  1.40s/it, training loss=0.2000]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1704/1835 [39:40<03:03,  1.40s/it, training loss=0.2148]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1705/1835 [39:40<03:01,  1.40s/it, training loss=0.2148]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1705/1835 [39:42<03:01,  1.40s/it, training loss=0.2655]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1706/1835 [39:42<03:00,  1.40s/it, training loss=0.2655]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1706/1835 [39:43<03:00,  1.40s/it, training loss=0.1147]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1707/1835 [39:43<02:58,  1.40s/it, training loss=0.1147]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1707/1835 [39:44<02:58,  1.40s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1708/1835 [39:44<02:57,  1.40s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1708/1835 [39:46<02:57,  1.40s/it, training loss=0.0171]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1709/1835 [39:46<02:56,  1.40s/it, training loss=0.0171]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1709/1835 [39:47<02:56,  1.40s/it, training loss=0.0658]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1710/1835 [39:47<02:54,  1.40s/it, training loss=0.0658]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1710/1835 [39:49<02:54,  1.40s/it, training loss=0.0643]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1711/1835 [39:49<02:53,  1.40s/it, training loss=0.0643]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1711/1835 [39:50<02:53,  1.40s/it, training loss=0.3173]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1712/1835 [39:50<02:51,  1.40s/it, training loss=0.3173]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1712/1835 [39:51<02:51,  1.40s/it, training loss=0.2294]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1713/1835 [39:51<02:49,  1.39s/it, training loss=0.2294]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1713/1835 [39:53<02:49,  1.39s/it, training loss=0.1563]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1714/1835 [39:53<02:48,  1.39s/it, training loss=0.1563]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1714/1835 [39:54<02:48,  1.39s/it, training loss=0.1026]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1715/1835 [39:54<02:47,  1.40s/it, training loss=0.1026]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 1715/1835 [39:56<02:47,  1.40s/it, training loss=0.0737]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1716/1835 [39:56<02:46,  1.40s/it, training loss=0.0737]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1716/1835 [39:57<02:46,  1.40s/it, training loss=0.1054]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1717/1835 [39:57<02:45,  1.40s/it, training loss=0.1054]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1717/1835 [39:58<02:45,  1.40s/it, training loss=0.2715]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1718/1835 [39:58<02:43,  1.40s/it, training loss=0.2715]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1718/1835 [40:00<02:43,  1.40s/it, training loss=0.2213]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1719/1835 [40:00<02:42,  1.40s/it, training loss=0.2213]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1719/1835 [40:01<02:42,  1.40s/it, training loss=0.0732]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1720/1835 [40:01<02:40,  1.40s/it, training loss=0.0732]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 1720/1835 [40:03<02:40,  1.40s/it, training loss=0.1822]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1721/1835 [40:03<02:39,  1.40s/it, training loss=0.1822]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1721/1835 [40:04<02:39,  1.40s/it, training loss=0.1722]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1722/1835 [40:04<02:37,  1.40s/it, training loss=0.1722]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1722/1835 [40:05<02:37,  1.40s/it, training loss=0.1283]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1723/1835 [40:05<02:36,  1.39s/it, training loss=0.1283]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1723/1835 [40:07<02:36,  1.39s/it, training loss=0.1296]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1724/1835 [40:07<02:35,  1.40s/it, training loss=0.1296]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1724/1835 [40:08<02:35,  1.40s/it, training loss=0.1289]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1725/1835 [40:08<02:33,  1.40s/it, training loss=0.1289]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1725/1835 [40:10<02:33,  1.40s/it, training loss=0.0760]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1726/1835 [40:10<02:32,  1.40s/it, training loss=0.0760]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1726/1835 [40:11<02:32,  1.40s/it, training loss=0.1993]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1727/1835 [40:11<02:30,  1.40s/it, training loss=0.1993]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1727/1835 [40:12<02:30,  1.40s/it, training loss=0.1776]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1728/1835 [40:12<02:29,  1.40s/it, training loss=0.1776]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1728/1835 [40:14<02:29,  1.40s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1729/1835 [40:14<02:28,  1.40s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1729/1835 [40:15<02:28,  1.40s/it, training loss=0.2321]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1730/1835 [40:15<02:26,  1.39s/it, training loss=0.2321]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1730/1835 [40:17<02:26,  1.39s/it, training loss=0.1165]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1731/1835 [40:17<02:24,  1.39s/it, training loss=0.1165]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1731/1835 [40:18<02:24,  1.39s/it, training loss=0.1328]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1732/1835 [40:18<02:23,  1.39s/it, training loss=0.1328]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1732/1835 [40:19<02:23,  1.39s/it, training loss=0.1238]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1733/1835 [40:19<02:22,  1.39s/it, training loss=0.1238]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1733/1835 [40:21<02:22,  1.39s/it, training loss=0.1181]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1734/1835 [40:21<02:20,  1.39s/it, training loss=0.1181]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 1734/1835 [40:22<02:20,  1.39s/it, training loss=0.0892]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1735/1835 [40:22<02:19,  1.40s/it, training loss=0.0892]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1735/1835 [40:24<02:19,  1.40s/it, training loss=0.0733]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1736/1835 [40:24<02:18,  1.40s/it, training loss=0.0733]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1736/1835 [40:25<02:18,  1.40s/it, training loss=0.2014]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1737/1835 [40:25<02:16,  1.40s/it, training loss=0.2014]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1737/1835 [40:26<02:16,  1.40s/it, training loss=0.0902]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1738/1835 [40:26<02:15,  1.40s/it, training loss=0.0902]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1738/1835 [40:28<02:15,  1.40s/it, training loss=0.2561]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1739/1835 [40:28<02:14,  1.40s/it, training loss=0.2561]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1739/1835 [40:29<02:14,  1.40s/it, training loss=0.0636]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1740/1835 [40:29<02:12,  1.40s/it, training loss=0.0636]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1740/1835 [40:31<02:12,  1.40s/it, training loss=0.1685]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1741/1835 [40:31<02:11,  1.40s/it, training loss=0.1685]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1741/1835 [40:32<02:11,  1.40s/it, training loss=0.1409]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1742/1835 [40:32<02:09,  1.39s/it, training loss=0.1409]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1742/1835 [40:33<02:09,  1.39s/it, training loss=0.0809]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1743/1835 [40:33<02:08,  1.39s/it, training loss=0.0809]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 1743/1835 [40:35<02:08,  1.39s/it, training loss=0.1124]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1744/1835 [40:35<02:06,  1.39s/it, training loss=0.1124]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1744/1835 [40:36<02:06,  1.39s/it, training loss=0.1851]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1745/1835 [40:36<02:05,  1.40s/it, training loss=0.1851]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1745/1835 [40:38<02:05,  1.40s/it, training loss=0.2285]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1746/1835 [40:38<02:04,  1.40s/it, training loss=0.2285]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1746/1835 [40:39<02:04,  1.40s/it, training loss=0.1688]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1747/1835 [40:39<02:02,  1.40s/it, training loss=0.1688]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1747/1835 [40:40<02:02,  1.40s/it, training loss=0.1753]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1748/1835 [40:40<02:01,  1.39s/it, training loss=0.1753]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1748/1835 [40:42<02:01,  1.39s/it, training loss=0.1532]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1749/1835 [40:42<01:59,  1.39s/it, training loss=0.1532]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1749/1835 [40:43<01:59,  1.39s/it, training loss=0.2897]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1750/1835 [40:43<01:58,  1.39s/it, training loss=0.2897]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1750/1835 [40:44<01:58,  1.39s/it, training loss=0.1728]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1751/1835 [40:45<01:57,  1.40s/it, training loss=0.1728]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1751/1835 [40:46<01:57,  1.40s/it, training loss=0.1036]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1752/1835 [40:46<01:55,  1.40s/it, training loss=0.1036]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 1752/1835 [40:47<01:55,  1.40s/it, training loss=0.2006]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1753/1835 [40:47<01:54,  1.39s/it, training loss=0.2006]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1753/1835 [40:49<01:54,  1.39s/it, training loss=0.1186]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1754/1835 [40:49<01:52,  1.39s/it, training loss=0.1186]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1754/1835 [40:50<01:52,  1.39s/it, training loss=0.2742]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1755/1835 [40:50<01:51,  1.40s/it, training loss=0.2742]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1755/1835 [40:51<01:51,  1.40s/it, training loss=0.2060]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1756/1835 [40:51<01:50,  1.40s/it, training loss=0.2060]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1756/1835 [40:53<01:50,  1.40s/it, training loss=0.2060]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1757/1835 [40:53<01:48,  1.39s/it, training loss=0.2060]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1757/1835 [40:54<01:48,  1.39s/it, training loss=0.2258]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1758/1835 [40:54<01:47,  1.39s/it, training loss=0.2258]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1758/1835 [40:56<01:47,  1.39s/it, training loss=0.1476]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1759/1835 [40:56<01:45,  1.39s/it, training loss=0.1476]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1759/1835 [40:57<01:45,  1.39s/it, training loss=0.0593]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1760/1835 [40:57<01:44,  1.39s/it, training loss=0.0593]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1760/1835 [40:58<01:44,  1.39s/it, training loss=0.0506]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1761/1835 [40:58<01:43,  1.39s/it, training loss=0.0506]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1761/1835 [41:00<01:43,  1.39s/it, training loss=0.1222]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1762/1835 [41:00<01:41,  1.39s/it, training loss=0.1222]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1762/1835 [41:01<01:41,  1.39s/it, training loss=0.0698]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1763/1835 [41:01<01:40,  1.39s/it, training loss=0.0698]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1763/1835 [41:03<01:40,  1.39s/it, training loss=0.3169]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1764/1835 [41:03<01:38,  1.39s/it, training loss=0.3169]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1764/1835 [41:04<01:38,  1.39s/it, training loss=0.1796]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1765/1835 [41:04<01:37,  1.39s/it, training loss=0.1796]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1765/1835 [41:05<01:37,  1.39s/it, training loss=0.0858]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1766/1835 [41:05<01:36,  1.39s/it, training loss=0.0858]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 1766/1835 [41:07<01:36,  1.39s/it, training loss=0.1388]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1767/1835 [41:07<01:34,  1.39s/it, training loss=0.1388]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1767/1835 [41:08<01:34,  1.39s/it, training loss=0.1599]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1768/1835 [41:08<01:33,  1.40s/it, training loss=0.1599]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1768/1835 [41:10<01:33,  1.40s/it, training loss=0.2490]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1769/1835 [41:10<01:32,  1.40s/it, training loss=0.2490]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1769/1835 [41:11<01:32,  1.40s/it, training loss=0.0630]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1770/1835 [41:11<01:30,  1.40s/it, training loss=0.0630]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 1770/1835 [41:12<01:30,  1.40s/it, training loss=0.2931]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1771/1835 [41:12<01:29,  1.40s/it, training loss=0.2931]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1771/1835 [41:14<01:29,  1.40s/it, training loss=0.1561]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1772/1835 [41:14<01:28,  1.40s/it, training loss=0.1561]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1772/1835 [41:15<01:28,  1.40s/it, training loss=0.1795]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1773/1835 [41:15<01:26,  1.40s/it, training loss=0.1795]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1773/1835 [41:17<01:26,  1.40s/it, training loss=0.1821]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1774/1835 [41:17<01:25,  1.40s/it, training loss=0.1821]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1774/1835 [41:18<01:25,  1.40s/it, training loss=0.0864]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1775/1835 [41:18<01:23,  1.39s/it, training loss=0.0864]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1775/1835 [41:19<01:23,  1.39s/it, training loss=0.1291]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1776/1835 [41:19<01:22,  1.40s/it, training loss=0.1291]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1776/1835 [41:21<01:22,  1.40s/it, training loss=0.0859]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1777/1835 [41:21<01:20,  1.39s/it, training loss=0.0859]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1777/1835 [41:22<01:20,  1.39s/it, training loss=0.1595]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1778/1835 [41:22<01:19,  1.39s/it, training loss=0.1595]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1778/1835 [41:24<01:19,  1.39s/it, training loss=0.1098]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1779/1835 [41:24<01:18,  1.40s/it, training loss=0.1098]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1779/1835 [41:25<01:18,  1.40s/it, training loss=0.1183]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1780/1835 [41:25<01:16,  1.39s/it, training loss=0.1183]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1780/1835 [41:26<01:16,  1.39s/it, training loss=0.2018]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1781/1835 [41:26<01:15,  1.40s/it, training loss=0.2018]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1781/1835 [41:28<01:15,  1.40s/it, training loss=0.1090]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1782/1835 [41:28<01:13,  1.39s/it, training loss=0.1090]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1782/1835 [41:29<01:13,  1.39s/it, training loss=0.0876]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1783/1835 [41:29<01:12,  1.39s/it, training loss=0.0876]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1783/1835 [41:31<01:12,  1.39s/it, training loss=0.1781]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1784/1835 [41:31<01:11,  1.39s/it, training loss=0.1781]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1784/1835 [41:32<01:11,  1.39s/it, training loss=0.2113]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1785/1835 [41:32<01:09,  1.40s/it, training loss=0.2113]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1785/1835 [41:33<01:09,  1.40s/it, training loss=0.0994]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1786/1835 [41:33<01:08,  1.40s/it, training loss=0.0994]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1786/1835 [41:35<01:08,  1.40s/it, training loss=0.2408]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1787/1835 [41:35<01:06,  1.39s/it, training loss=0.2408]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1787/1835 [41:36<01:06,  1.39s/it, training loss=0.1517]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1788/1835 [41:36<01:05,  1.39s/it, training loss=0.1517]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1788/1835 [41:38<01:05,  1.39s/it, training loss=0.0541]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1789/1835 [41:38<01:04,  1.40s/it, training loss=0.0541]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 1789/1835 [41:39<01:04,  1.40s/it, training loss=0.1546]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1790/1835 [41:39<01:02,  1.40s/it, training loss=0.1546]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1790/1835 [41:40<01:02,  1.40s/it, training loss=0.0977]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1791/1835 [41:40<01:01,  1.40s/it, training loss=0.0977]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1791/1835 [41:42<01:01,  1.40s/it, training loss=0.2363]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1792/1835 [41:42<01:00,  1.40s/it, training loss=0.2363]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1792/1835 [41:43<01:00,  1.40s/it, training loss=0.1348]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1793/1835 [41:43<00:58,  1.40s/it, training loss=0.1348]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1793/1835 [41:44<00:58,  1.40s/it, training loss=0.1565]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1794/1835 [41:44<00:57,  1.40s/it, training loss=0.1565]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1794/1835 [41:46<00:57,  1.40s/it, training loss=0.1254]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1795/1835 [41:46<00:55,  1.40s/it, training loss=0.1254]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1795/1835 [41:47<00:55,  1.40s/it, training loss=0.2597]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1796/1835 [41:47<00:54,  1.40s/it, training loss=0.2597]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1796/1835 [41:49<00:54,  1.40s/it, training loss=0.1392]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1797/1835 [41:49<00:53,  1.40s/it, training loss=0.1392]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1797/1835 [41:50<00:53,  1.40s/it, training loss=0.2986]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1798/1835 [41:50<00:51,  1.40s/it, training loss=0.2986]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1798/1835 [41:51<00:51,  1.40s/it, training loss=0.1815]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1799/1835 [41:51<00:50,  1.40s/it, training loss=0.1815]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1799/1835 [41:53<00:50,  1.40s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1800/1835 [41:53<00:48,  1.40s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1800/1835 [41:54<00:48,  1.40s/it, training loss=0.1644]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1801/1835 [41:54<00:47,  1.40s/it, training loss=0.1644]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1801/1835 [41:56<00:47,  1.40s/it, training loss=0.2336]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1802/1835 [41:56<00:46,  1.40s/it, training loss=0.2336]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1802/1835 [41:57<00:46,  1.40s/it, training loss=0.2136]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1803/1835 [41:57<00:44,  1.40s/it, training loss=0.2136]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1803/1835 [41:58<00:44,  1.40s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1804/1835 [41:58<00:43,  1.40s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1804/1835 [42:00<00:43,  1.40s/it, training loss=0.0698]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1805/1835 [42:00<00:41,  1.40s/it, training loss=0.0698]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1805/1835 [42:01<00:41,  1.40s/it, training loss=0.1566]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1806/1835 [42:01<00:40,  1.40s/it, training loss=0.1566]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1806/1835 [42:03<00:40,  1.40s/it, training loss=0.0624]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1807/1835 [42:03<00:39,  1.40s/it, training loss=0.0624]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 1807/1835 [42:04<00:39,  1.40s/it, training loss=0.0786]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1808/1835 [42:04<00:37,  1.40s/it, training loss=0.0786]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1808/1835 [42:05<00:37,  1.40s/it, training loss=0.1732]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1809/1835 [42:05<00:36,  1.40s/it, training loss=0.1732]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1809/1835 [42:07<00:36,  1.40s/it, training loss=0.1714]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1810/1835 [42:07<00:34,  1.40s/it, training loss=0.1714]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1810/1835 [42:08<00:34,  1.40s/it, training loss=0.1130]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1811/1835 [42:08<00:33,  1.40s/it, training loss=0.1130]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1811/1835 [42:10<00:33,  1.40s/it, training loss=0.0863]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1812/1835 [42:10<00:32,  1.40s/it, training loss=0.0863]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 1812/1835 [42:11<00:32,  1.40s/it, training loss=0.1665]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1813/1835 [42:11<00:30,  1.40s/it, training loss=0.1665]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1813/1835 [42:12<00:30,  1.40s/it, training loss=0.1360]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1814/1835 [42:12<00:29,  1.39s/it, training loss=0.1360]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1814/1835 [42:14<00:29,  1.39s/it, training loss=0.0858]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1815/1835 [42:14<00:27,  1.40s/it, training loss=0.0858]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1815/1835 [42:15<00:27,  1.40s/it, training loss=0.1402]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1816/1835 [42:15<00:26,  1.40s/it, training loss=0.1402]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1816/1835 [42:17<00:26,  1.40s/it, training loss=0.2170]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1817/1835 [42:17<00:25,  1.40s/it, training loss=0.2170]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1817/1835 [42:18<00:25,  1.40s/it, training loss=0.0701]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1818/1835 [42:18<00:23,  1.40s/it, training loss=0.0701]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1818/1835 [42:19<00:23,  1.40s/it, training loss=0.1615]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1819/1835 [42:19<00:22,  1.40s/it, training loss=0.1615]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1819/1835 [42:21<00:22,  1.40s/it, training loss=0.1363]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1820/1835 [42:21<00:21,  1.40s/it, training loss=0.1363]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1820/1835 [42:22<00:21,  1.40s/it, training loss=0.1011]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1821/1835 [42:22<00:19,  1.40s/it, training loss=0.1011]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1821/1835 [42:24<00:19,  1.40s/it, training loss=0.1631]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1822/1835 [42:24<00:18,  1.40s/it, training loss=0.1631]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1822/1835 [42:25<00:18,  1.40s/it, training loss=0.0681]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1823/1835 [42:25<00:16,  1.40s/it, training loss=0.0681]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1823/1835 [42:26<00:16,  1.40s/it, training loss=0.0369]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1824/1835 [42:26<00:15,  1.40s/it, training loss=0.0369]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1824/1835 [42:28<00:15,  1.40s/it, training loss=0.0976]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1825/1835 [42:28<00:13,  1.40s/it, training loss=0.0976]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 1825/1835 [42:29<00:13,  1.40s/it, training loss=0.1023]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1826/1835 [42:29<00:12,  1.40s/it, training loss=0.1023]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1826/1835 [42:31<00:12,  1.40s/it, training loss=0.2291]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1827/1835 [42:31<00:11,  1.40s/it, training loss=0.2291]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1827/1835 [42:32<00:11,  1.40s/it, training loss=0.0731]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1828/1835 [42:32<00:09,  1.40s/it, training loss=0.0731]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1828/1835 [42:33<00:09,  1.40s/it, training loss=0.1879]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1829/1835 [42:33<00:08,  1.40s/it, training loss=0.1879]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1829/1835 [42:35<00:08,  1.40s/it, training loss=0.0815]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1830/1835 [42:35<00:06,  1.40s/it, training loss=0.0815]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1830/1835 [42:36<00:06,  1.40s/it, training loss=0.1774]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1831/1835 [42:36<00:05,  1.40s/it, training loss=0.1774]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1831/1835 [42:38<00:05,  1.40s/it, training loss=0.2508]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1832/1835 [42:38<00:04,  1.40s/it, training loss=0.2508]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1832/1835 [42:39<00:04,  1.40s/it, training loss=0.1413]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1833/1835 [42:39<00:02,  1.40s/it, training loss=0.1413]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1833/1835 [42:40<00:02,  1.40s/it, training loss=0.1324]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1834/1835 [42:40<00:01,  1.40s/it, training loss=0.1324]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1834/1835 [42:41<00:01,  1.40s/it, training loss=0.2263]\u001b[A\n",
            "Epoch 2: 100%|██████████| 1835/1835 [42:41<00:00,  1.25s/it, training loss=0.2263]\u001b[A\n",
            " 33%|███▎      | 1/3 [1:27:10<1:28:57, 2668.72s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch {epoch}\n",
            "Training loss: 0.46794488246499355\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 2/3 [1:28:54<44:27, 2667.14s/it]  "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5557995826444205\n",
            "F1 Score (weighted): 0.7872336905437135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 3:   0%|          | 0/1835 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:   0%|          | 0/1835 [00:01<?, ?it/s, training loss=0.1607]\u001b[A\n",
            "Epoch 3:   0%|          | 1/1835 [00:01<41:59,  1.37s/it, training loss=0.1607]\u001b[A\n",
            "Epoch 3:   0%|          | 1/1835 [00:02<41:59,  1.37s/it, training loss=0.1259]\u001b[A\n",
            "Epoch 3:   0%|          | 2/1835 [00:02<42:16,  1.38s/it, training loss=0.1259]\u001b[A\n",
            "Epoch 3:   0%|          | 2/1835 [00:04<42:16,  1.38s/it, training loss=0.2165]\u001b[A\n",
            "Epoch 3:   0%|          | 3/1835 [00:04<42:20,  1.39s/it, training loss=0.2165]\u001b[A\n",
            "Epoch 3:   0%|          | 3/1835 [00:05<42:20,  1.39s/it, training loss=0.1287]\u001b[A\n",
            "Epoch 3:   0%|          | 4/1835 [00:05<42:19,  1.39s/it, training loss=0.1287]\u001b[A\n",
            "Epoch 3:   0%|          | 4/1835 [00:06<42:19,  1.39s/it, training loss=0.1153]\u001b[A\n",
            "Epoch 3:   0%|          | 5/1835 [00:06<42:25,  1.39s/it, training loss=0.1153]\u001b[A\n",
            "Epoch 3:   0%|          | 5/1835 [00:08<42:25,  1.39s/it, training loss=0.0442]\u001b[A\n",
            "Epoch 3:   0%|          | 6/1835 [00:08<42:29,  1.39s/it, training loss=0.0442]\u001b[A\n",
            "Epoch 3:   0%|          | 6/1835 [00:09<42:29,  1.39s/it, training loss=0.1677]\u001b[A\n",
            "Epoch 3:   0%|          | 7/1835 [00:09<42:32,  1.40s/it, training loss=0.1677]\u001b[A\n",
            "Epoch 3:   0%|          | 7/1835 [00:11<42:32,  1.40s/it, training loss=0.0775]\u001b[A\n",
            "Epoch 3:   0%|          | 8/1835 [00:11<42:29,  1.40s/it, training loss=0.0775]\u001b[A\n",
            "Epoch 3:   0%|          | 8/1835 [00:12<42:29,  1.40s/it, training loss=0.0501]\u001b[A\n",
            "Epoch 3:   0%|          | 9/1835 [00:12<42:32,  1.40s/it, training loss=0.0501]\u001b[A\n",
            "Epoch 3:   0%|          | 9/1835 [00:13<42:32,  1.40s/it, training loss=0.0850]\u001b[A\n",
            "Epoch 3:   1%|          | 10/1835 [00:13<42:27,  1.40s/it, training loss=0.0850]\u001b[A\n",
            "Epoch 3:   1%|          | 10/1835 [00:15<42:27,  1.40s/it, training loss=0.1720]\u001b[A\n",
            "Epoch 3:   1%|          | 11/1835 [00:15<42:20,  1.39s/it, training loss=0.1720]\u001b[A\n",
            "Epoch 3:   1%|          | 11/1835 [00:16<42:20,  1.39s/it, training loss=0.0362]\u001b[A\n",
            "Epoch 3:   1%|          | 12/1835 [00:16<42:20,  1.39s/it, training loss=0.0362]\u001b[A\n",
            "Epoch 3:   1%|          | 12/1835 [00:18<42:20,  1.39s/it, training loss=0.0420]\u001b[A\n",
            "Epoch 3:   1%|          | 13/1835 [00:18<42:22,  1.40s/it, training loss=0.0420]\u001b[A\n",
            "Epoch 3:   1%|          | 13/1835 [00:19<42:22,  1.40s/it, training loss=0.0440]\u001b[A\n",
            "Epoch 3:   1%|          | 14/1835 [00:19<42:21,  1.40s/it, training loss=0.0440]\u001b[A\n",
            "Epoch 3:   1%|          | 14/1835 [00:20<42:21,  1.40s/it, training loss=0.0750]\u001b[A\n",
            "Epoch 3:   1%|          | 15/1835 [00:20<42:18,  1.39s/it, training loss=0.0750]\u001b[A\n",
            "Epoch 3:   1%|          | 15/1835 [00:22<42:18,  1.39s/it, training loss=0.0932]\u001b[A\n",
            "Epoch 3:   1%|          | 16/1835 [00:22<42:17,  1.40s/it, training loss=0.0932]\u001b[A\n",
            "Epoch 3:   1%|          | 16/1835 [00:23<42:17,  1.40s/it, training loss=0.0581]\u001b[A\n",
            "Epoch 3:   1%|          | 17/1835 [00:23<42:17,  1.40s/it, training loss=0.0581]\u001b[A\n",
            "Epoch 3:   1%|          | 17/1835 [00:25<42:17,  1.40s/it, training loss=0.1373]\u001b[A\n",
            "Epoch 3:   1%|          | 18/1835 [00:25<42:15,  1.40s/it, training loss=0.1373]\u001b[A\n",
            "Epoch 3:   1%|          | 18/1835 [00:26<42:15,  1.40s/it, training loss=0.1200]\u001b[A\n",
            "Epoch 3:   1%|          | 19/1835 [00:26<42:13,  1.40s/it, training loss=0.1200]\u001b[A\n",
            "Epoch 3:   1%|          | 19/1835 [00:27<42:13,  1.40s/it, training loss=0.0937]\u001b[A\n",
            "Epoch 3:   1%|          | 20/1835 [00:27<42:11,  1.39s/it, training loss=0.0937]\u001b[A\n",
            "Epoch 3:   1%|          | 20/1835 [00:29<42:11,  1.39s/it, training loss=0.0367]\u001b[A\n",
            "Epoch 3:   1%|          | 21/1835 [00:29<42:04,  1.39s/it, training loss=0.0367]\u001b[A\n",
            "Epoch 3:   1%|          | 21/1835 [00:30<42:04,  1.39s/it, training loss=0.0694]\u001b[A\n",
            "Epoch 3:   1%|          | 22/1835 [00:30<42:04,  1.39s/it, training loss=0.0694]\u001b[A\n",
            "Epoch 3:   1%|          | 22/1835 [00:32<42:04,  1.39s/it, training loss=0.1170]\u001b[A\n",
            "Epoch 3:   1%|▏         | 23/1835 [00:32<42:03,  1.39s/it, training loss=0.1170]\u001b[A\n",
            "Epoch 3:   1%|▏         | 23/1835 [00:33<42:03,  1.39s/it, training loss=0.0416]\u001b[A\n",
            "Epoch 3:   1%|▏         | 24/1835 [00:33<42:05,  1.39s/it, training loss=0.0416]\u001b[A\n",
            "Epoch 3:   1%|▏         | 24/1835 [00:34<42:05,  1.39s/it, training loss=0.0935]\u001b[A\n",
            "Epoch 3:   1%|▏         | 25/1835 [00:34<42:04,  1.40s/it, training loss=0.0935]\u001b[A\n",
            "Epoch 3:   1%|▏         | 25/1835 [00:36<42:04,  1.40s/it, training loss=0.0869]\u001b[A\n",
            "Epoch 3:   1%|▏         | 26/1835 [00:36<42:04,  1.40s/it, training loss=0.0869]\u001b[A\n",
            "Epoch 3:   1%|▏         | 26/1835 [00:37<42:04,  1.40s/it, training loss=0.0839]\u001b[A\n",
            "Epoch 3:   1%|▏         | 27/1835 [00:37<42:05,  1.40s/it, training loss=0.0839]\u001b[A\n",
            "Epoch 3:   1%|▏         | 27/1835 [00:39<42:05,  1.40s/it, training loss=0.1061]\u001b[A\n",
            "Epoch 3:   2%|▏         | 28/1835 [00:39<42:01,  1.40s/it, training loss=0.1061]\u001b[A\n",
            "Epoch 3:   2%|▏         | 28/1835 [00:40<42:01,  1.40s/it, training loss=0.0651]\u001b[A\n",
            "Epoch 3:   2%|▏         | 29/1835 [00:40<41:57,  1.39s/it, training loss=0.0651]\u001b[A\n",
            "Epoch 3:   2%|▏         | 29/1835 [00:41<41:57,  1.39s/it, training loss=0.0382]\u001b[A\n",
            "Epoch 3:   2%|▏         | 30/1835 [00:41<41:59,  1.40s/it, training loss=0.0382]\u001b[A\n",
            "Epoch 3:   2%|▏         | 30/1835 [00:43<41:59,  1.40s/it, training loss=0.0170]\u001b[A\n",
            "Epoch 3:   2%|▏         | 31/1835 [00:43<42:01,  1.40s/it, training loss=0.0170]\u001b[A\n",
            "Epoch 3:   2%|▏         | 31/1835 [00:44<42:01,  1.40s/it, training loss=0.0429]\u001b[A\n",
            "Epoch 3:   2%|▏         | 32/1835 [00:44<41:55,  1.39s/it, training loss=0.0429]\u001b[A\n",
            "Epoch 3:   2%|▏         | 32/1835 [00:46<41:55,  1.39s/it, training loss=0.1261]\u001b[A\n",
            "Epoch 3:   2%|▏         | 33/1835 [00:46<41:56,  1.40s/it, training loss=0.1261]\u001b[A\n",
            "Epoch 3:   2%|▏         | 33/1835 [00:47<41:56,  1.40s/it, training loss=0.0748]\u001b[A\n",
            "Epoch 3:   2%|▏         | 34/1835 [00:47<41:51,  1.39s/it, training loss=0.0748]\u001b[A\n",
            "Epoch 3:   2%|▏         | 34/1835 [00:48<41:51,  1.39s/it, training loss=0.1940]\u001b[A\n",
            "Epoch 3:   2%|▏         | 35/1835 [00:48<41:50,  1.39s/it, training loss=0.1940]\u001b[A\n",
            "Epoch 3:   2%|▏         | 35/1835 [00:50<41:50,  1.39s/it, training loss=0.2712]\u001b[A\n",
            "Epoch 3:   2%|▏         | 36/1835 [00:50<41:53,  1.40s/it, training loss=0.2712]\u001b[A\n",
            "Epoch 3:   2%|▏         | 36/1835 [00:51<41:53,  1.40s/it, training loss=0.1995]\u001b[A\n",
            "Epoch 3:   2%|▏         | 37/1835 [00:51<41:52,  1.40s/it, training loss=0.1995]\u001b[A\n",
            "Epoch 3:   2%|▏         | 37/1835 [00:52<41:52,  1.40s/it, training loss=0.1495]\u001b[A\n",
            "Epoch 3:   2%|▏         | 38/1835 [00:53<41:55,  1.40s/it, training loss=0.1495]\u001b[A\n",
            "Epoch 3:   2%|▏         | 38/1835 [00:54<41:55,  1.40s/it, training loss=0.1726]\u001b[A\n",
            "Epoch 3:   2%|▏         | 39/1835 [00:54<41:54,  1.40s/it, training loss=0.1726]\u001b[A\n",
            "Epoch 3:   2%|▏         | 39/1835 [00:55<41:54,  1.40s/it, training loss=0.1331]\u001b[A\n",
            "Epoch 3:   2%|▏         | 40/1835 [00:55<41:56,  1.40s/it, training loss=0.1331]\u001b[A\n",
            "Epoch 3:   2%|▏         | 40/1835 [00:57<41:56,  1.40s/it, training loss=0.0145]\u001b[A\n",
            "Epoch 3:   2%|▏         | 41/1835 [00:57<41:54,  1.40s/it, training loss=0.0145]\u001b[A\n",
            "Epoch 3:   2%|▏         | 41/1835 [00:58<41:54,  1.40s/it, training loss=0.0958]\u001b[A\n",
            "Epoch 3:   2%|▏         | 42/1835 [00:58<41:53,  1.40s/it, training loss=0.0958]\u001b[A\n",
            "Epoch 3:   2%|▏         | 42/1835 [01:00<41:53,  1.40s/it, training loss=0.1371]\u001b[A\n",
            "Epoch 3:   2%|▏         | 43/1835 [01:00<41:50,  1.40s/it, training loss=0.1371]\u001b[A\n",
            "Epoch 3:   2%|▏         | 43/1835 [01:01<41:50,  1.40s/it, training loss=0.0494]\u001b[A\n",
            "Epoch 3:   2%|▏         | 44/1835 [01:01<41:49,  1.40s/it, training loss=0.0494]\u001b[A\n",
            "Epoch 3:   2%|▏         | 44/1835 [01:02<41:49,  1.40s/it, training loss=0.1108]\u001b[A\n",
            "Epoch 3:   2%|▏         | 45/1835 [01:02<41:41,  1.40s/it, training loss=0.1108]\u001b[A\n",
            "Epoch 3:   2%|▏         | 45/1835 [01:04<41:41,  1.40s/it, training loss=0.0320]\u001b[A\n",
            "Epoch 3:   3%|▎         | 46/1835 [01:04<41:40,  1.40s/it, training loss=0.0320]\u001b[A\n",
            "Epoch 3:   3%|▎         | 46/1835 [01:05<41:40,  1.40s/it, training loss=0.3168]\u001b[A\n",
            "Epoch 3:   3%|▎         | 47/1835 [01:05<41:39,  1.40s/it, training loss=0.3168]\u001b[A\n",
            "Epoch 3:   3%|▎         | 47/1835 [01:06<41:39,  1.40s/it, training loss=0.1104]\u001b[A\n",
            "Epoch 3:   3%|▎         | 48/1835 [01:07<41:41,  1.40s/it, training loss=0.1104]\u001b[A\n",
            "Epoch 3:   3%|▎         | 48/1835 [01:08<41:41,  1.40s/it, training loss=0.1134]\u001b[A\n",
            "Epoch 3:   3%|▎         | 49/1835 [01:08<41:41,  1.40s/it, training loss=0.1134]\u001b[A\n",
            "Epoch 3:   3%|▎         | 49/1835 [01:09<41:41,  1.40s/it, training loss=0.1767]\u001b[A\n",
            "Epoch 3:   3%|▎         | 50/1835 [01:09<41:38,  1.40s/it, training loss=0.1767]\u001b[A\n",
            "Epoch 3:   3%|▎         | 50/1835 [01:11<41:38,  1.40s/it, training loss=0.0409]\u001b[A\n",
            "Epoch 3:   3%|▎         | 51/1835 [01:11<41:35,  1.40s/it, training loss=0.0409]\u001b[A\n",
            "Epoch 3:   3%|▎         | 51/1835 [01:12<41:35,  1.40s/it, training loss=0.2783]\u001b[A\n",
            "Epoch 3:   3%|▎         | 52/1835 [01:12<41:38,  1.40s/it, training loss=0.2783]\u001b[A\n",
            "Epoch 3:   3%|▎         | 52/1835 [01:13<41:38,  1.40s/it, training loss=0.0250]\u001b[A\n",
            "Epoch 3:   3%|▎         | 53/1835 [01:14<41:33,  1.40s/it, training loss=0.0250]\u001b[A\n",
            "Epoch 3:   3%|▎         | 53/1835 [01:15<41:33,  1.40s/it, training loss=0.0479]\u001b[A\n",
            "Epoch 3:   3%|▎         | 54/1835 [01:15<41:30,  1.40s/it, training loss=0.0479]\u001b[A\n",
            "Epoch 3:   3%|▎         | 54/1835 [01:16<41:30,  1.40s/it, training loss=0.1097]\u001b[A\n",
            "Epoch 3:   3%|▎         | 55/1835 [01:16<41:27,  1.40s/it, training loss=0.1097]\u001b[A\n",
            "Epoch 3:   3%|▎         | 55/1835 [01:18<41:27,  1.40s/it, training loss=0.1282]\u001b[A\n",
            "Epoch 3:   3%|▎         | 56/1835 [01:18<41:24,  1.40s/it, training loss=0.1282]\u001b[A\n",
            "Epoch 3:   3%|▎         | 56/1835 [01:19<41:24,  1.40s/it, training loss=0.0479]\u001b[A\n",
            "Epoch 3:   3%|▎         | 57/1835 [01:19<41:21,  1.40s/it, training loss=0.0479]\u001b[A\n",
            "Epoch 3:   3%|▎         | 57/1835 [01:20<41:21,  1.40s/it, training loss=0.2204]\u001b[A\n",
            "Epoch 3:   3%|▎         | 58/1835 [01:20<41:26,  1.40s/it, training loss=0.2204]\u001b[A\n",
            "Epoch 3:   3%|▎         | 58/1835 [01:22<41:26,  1.40s/it, training loss=0.0436]\u001b[A\n",
            "Epoch 3:   3%|▎         | 59/1835 [01:22<41:27,  1.40s/it, training loss=0.0436]\u001b[A\n",
            "Epoch 3:   3%|▎         | 59/1835 [01:23<41:27,  1.40s/it, training loss=0.0590]\u001b[A\n",
            "Epoch 3:   3%|▎         | 60/1835 [01:23<41:25,  1.40s/it, training loss=0.0590]\u001b[A\n",
            "Epoch 3:   3%|▎         | 60/1835 [01:25<41:25,  1.40s/it, training loss=0.0402]\u001b[A\n",
            "Epoch 3:   3%|▎         | 61/1835 [01:25<41:25,  1.40s/it, training loss=0.0402]\u001b[A\n",
            "Epoch 3:   3%|▎         | 61/1835 [01:26<41:25,  1.40s/it, training loss=0.0296]\u001b[A\n",
            "Epoch 3:   3%|▎         | 62/1835 [01:26<41:24,  1.40s/it, training loss=0.0296]\u001b[A\n",
            "Epoch 3:   3%|▎         | 62/1835 [01:27<41:24,  1.40s/it, training loss=0.1320]\u001b[A\n",
            "Epoch 3:   3%|▎         | 63/1835 [01:28<41:24,  1.40s/it, training loss=0.1320]\u001b[A\n",
            "Epoch 3:   3%|▎         | 63/1835 [01:29<41:24,  1.40s/it, training loss=0.1687]\u001b[A\n",
            "Epoch 3:   3%|▎         | 64/1835 [01:29<41:26,  1.40s/it, training loss=0.1687]\u001b[A\n",
            "Epoch 3:   3%|▎         | 64/1835 [01:30<41:26,  1.40s/it, training loss=0.1248]\u001b[A\n",
            "Epoch 3:   4%|▎         | 65/1835 [01:30<41:21,  1.40s/it, training loss=0.1248]\u001b[A\n",
            "Epoch 3:   4%|▎         | 65/1835 [01:32<41:21,  1.40s/it, training loss=0.0874]\u001b[A\n",
            "Epoch 3:   4%|▎         | 66/1835 [01:32<41:15,  1.40s/it, training loss=0.0874]\u001b[A\n",
            "Epoch 3:   4%|▎         | 66/1835 [01:33<41:15,  1.40s/it, training loss=0.0134]\u001b[A\n",
            "Epoch 3:   4%|▎         | 67/1835 [01:33<41:20,  1.40s/it, training loss=0.0134]\u001b[A\n",
            "Epoch 3:   4%|▎         | 67/1835 [01:35<41:20,  1.40s/it, training loss=0.1785]\u001b[A\n",
            "Epoch 3:   4%|▎         | 68/1835 [01:35<41:16,  1.40s/it, training loss=0.1785]\u001b[A\n",
            "Epoch 3:   4%|▎         | 68/1835 [01:36<41:16,  1.40s/it, training loss=0.1178]\u001b[A\n",
            "Epoch 3:   4%|▍         | 69/1835 [01:36<41:14,  1.40s/it, training loss=0.1178]\u001b[A\n",
            "Epoch 3:   4%|▍         | 69/1835 [01:37<41:14,  1.40s/it, training loss=0.1772]\u001b[A\n",
            "Epoch 3:   4%|▍         | 70/1835 [01:37<41:13,  1.40s/it, training loss=0.1772]\u001b[A\n",
            "Epoch 3:   4%|▍         | 70/1835 [01:39<41:13,  1.40s/it, training loss=0.0480]\u001b[A\n",
            "Epoch 3:   4%|▍         | 71/1835 [01:39<41:13,  1.40s/it, training loss=0.0480]\u001b[A\n",
            "Epoch 3:   4%|▍         | 71/1835 [01:40<41:13,  1.40s/it, training loss=0.0547]\u001b[A\n",
            "Epoch 3:   4%|▍         | 72/1835 [01:40<41:08,  1.40s/it, training loss=0.0547]\u001b[A\n",
            "Epoch 3:   4%|▍         | 72/1835 [01:42<41:08,  1.40s/it, training loss=0.0927]\u001b[A\n",
            "Epoch 3:   4%|▍         | 73/1835 [01:42<41:07,  1.40s/it, training loss=0.0927]\u001b[A\n",
            "Epoch 3:   4%|▍         | 73/1835 [01:43<41:07,  1.40s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 3:   4%|▍         | 74/1835 [01:43<41:04,  1.40s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 3:   4%|▍         | 74/1835 [01:44<41:04,  1.40s/it, training loss=0.0588]\u001b[A\n",
            "Epoch 3:   4%|▍         | 75/1835 [01:44<41:01,  1.40s/it, training loss=0.0588]\u001b[A\n",
            "Epoch 3:   4%|▍         | 75/1835 [01:46<41:01,  1.40s/it, training loss=0.0898]\u001b[A\n",
            "Epoch 3:   4%|▍         | 76/1835 [01:46<41:03,  1.40s/it, training loss=0.0898]\u001b[A\n",
            "Epoch 3:   4%|▍         | 76/1835 [01:47<41:03,  1.40s/it, training loss=0.1239]\u001b[A\n",
            "Epoch 3:   4%|▍         | 77/1835 [01:47<41:01,  1.40s/it, training loss=0.1239]\u001b[A\n",
            "Epoch 3:   4%|▍         | 77/1835 [01:48<41:01,  1.40s/it, training loss=0.0480]\u001b[A\n",
            "Epoch 3:   4%|▍         | 78/1835 [01:49<40:56,  1.40s/it, training loss=0.0480]\u001b[A\n",
            "Epoch 3:   4%|▍         | 78/1835 [01:50<40:56,  1.40s/it, training loss=0.1838]\u001b[A\n",
            "Epoch 3:   4%|▍         | 79/1835 [01:50<40:52,  1.40s/it, training loss=0.1838]\u001b[A\n",
            "Epoch 3:   4%|▍         | 79/1835 [01:51<40:52,  1.40s/it, training loss=0.1609]\u001b[A\n",
            "Epoch 3:   4%|▍         | 80/1835 [01:51<40:53,  1.40s/it, training loss=0.1609]\u001b[A\n",
            "Epoch 3:   4%|▍         | 80/1835 [01:53<40:53,  1.40s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 3:   4%|▍         | 81/1835 [01:53<40:51,  1.40s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 3:   4%|▍         | 81/1835 [01:54<40:51,  1.40s/it, training loss=0.0201]\u001b[A\n",
            "Epoch 3:   4%|▍         | 82/1835 [01:54<40:50,  1.40s/it, training loss=0.0201]\u001b[A\n",
            "Epoch 3:   4%|▍         | 82/1835 [01:55<40:50,  1.40s/it, training loss=0.1036]\u001b[A\n",
            "Epoch 3:   5%|▍         | 83/1835 [01:55<40:46,  1.40s/it, training loss=0.1036]\u001b[A\n",
            "Epoch 3:   5%|▍         | 83/1835 [01:57<40:46,  1.40s/it, training loss=0.1685]\u001b[A\n",
            "Epoch 3:   5%|▍         | 84/1835 [01:57<40:49,  1.40s/it, training loss=0.1685]\u001b[A\n",
            "Epoch 3:   5%|▍         | 84/1835 [01:58<40:49,  1.40s/it, training loss=0.0965]\u001b[A\n",
            "Epoch 3:   5%|▍         | 85/1835 [01:58<40:52,  1.40s/it, training loss=0.0965]\u001b[A\n",
            "Epoch 3:   5%|▍         | 85/1835 [02:00<40:52,  1.40s/it, training loss=0.1262]\u001b[A\n",
            "Epoch 3:   5%|▍         | 86/1835 [02:00<40:50,  1.40s/it, training loss=0.1262]\u001b[A\n",
            "Epoch 3:   5%|▍         | 86/1835 [02:01<40:50,  1.40s/it, training loss=0.0270]\u001b[A\n",
            "Epoch 3:   5%|▍         | 87/1835 [02:01<40:52,  1.40s/it, training loss=0.0270]\u001b[A\n",
            "Epoch 3:   5%|▍         | 87/1835 [02:02<40:52,  1.40s/it, training loss=0.0929]\u001b[A\n",
            "Epoch 3:   5%|▍         | 88/1835 [02:03<40:46,  1.40s/it, training loss=0.0929]\u001b[A\n",
            "Epoch 3:   5%|▍         | 88/1835 [02:04<40:46,  1.40s/it, training loss=0.0933]\u001b[A\n",
            "Epoch 3:   5%|▍         | 89/1835 [02:04<40:43,  1.40s/it, training loss=0.0933]\u001b[A\n",
            "Epoch 3:   5%|▍         | 89/1835 [02:05<40:43,  1.40s/it, training loss=0.2774]\u001b[A\n",
            "Epoch 3:   5%|▍         | 90/1835 [02:05<40:45,  1.40s/it, training loss=0.2774]\u001b[A\n",
            "Epoch 3:   5%|▍         | 90/1835 [02:07<40:45,  1.40s/it, training loss=0.1241]\u001b[A\n",
            "Epoch 3:   5%|▍         | 91/1835 [02:07<40:38,  1.40s/it, training loss=0.1241]\u001b[A\n",
            "Epoch 3:   5%|▍         | 91/1835 [02:08<40:38,  1.40s/it, training loss=0.2021]\u001b[A\n",
            "Epoch 3:   5%|▌         | 92/1835 [02:08<40:39,  1.40s/it, training loss=0.2021]\u001b[A\n",
            "Epoch 3:   5%|▌         | 92/1835 [02:09<40:39,  1.40s/it, training loss=0.1964]\u001b[A\n",
            "Epoch 3:   5%|▌         | 93/1835 [02:09<40:38,  1.40s/it, training loss=0.1964]\u001b[A\n",
            "Epoch 3:   5%|▌         | 93/1835 [02:11<40:38,  1.40s/it, training loss=0.0631]\u001b[A\n",
            "Epoch 3:   5%|▌         | 94/1835 [02:11<40:38,  1.40s/it, training loss=0.0631]\u001b[A\n",
            "Epoch 3:   5%|▌         | 94/1835 [02:12<40:38,  1.40s/it, training loss=0.1238]\u001b[A\n",
            "Epoch 3:   5%|▌         | 95/1835 [02:12<40:38,  1.40s/it, training loss=0.1238]\u001b[A\n",
            "Epoch 3:   5%|▌         | 95/1835 [02:14<40:38,  1.40s/it, training loss=0.0825]\u001b[A\n",
            "Epoch 3:   5%|▌         | 96/1835 [02:14<40:32,  1.40s/it, training loss=0.0825]\u001b[A\n",
            "Epoch 3:   5%|▌         | 96/1835 [02:15<40:32,  1.40s/it, training loss=0.0808]\u001b[A\n",
            "Epoch 3:   5%|▌         | 97/1835 [02:15<40:29,  1.40s/it, training loss=0.0808]\u001b[A\n",
            "Epoch 3:   5%|▌         | 97/1835 [02:16<40:29,  1.40s/it, training loss=0.2152]\u001b[A\n",
            "Epoch 3:   5%|▌         | 98/1835 [02:16<40:22,  1.39s/it, training loss=0.2152]\u001b[A\n",
            "Epoch 3:   5%|▌         | 98/1835 [02:18<40:22,  1.39s/it, training loss=0.0145]\u001b[A\n",
            "Epoch 3:   5%|▌         | 99/1835 [02:18<40:24,  1.40s/it, training loss=0.0145]\u001b[A\n",
            "Epoch 3:   5%|▌         | 99/1835 [02:19<40:24,  1.40s/it, training loss=0.0329]\u001b[A\n",
            "Epoch 3:   5%|▌         | 100/1835 [02:19<40:21,  1.40s/it, training loss=0.0329]\u001b[A\n",
            "Epoch 3:   5%|▌         | 100/1835 [02:21<40:21,  1.40s/it, training loss=0.1461]\u001b[A\n",
            "Epoch 3:   6%|▌         | 101/1835 [02:21<40:19,  1.40s/it, training loss=0.1461]\u001b[A\n",
            "Epoch 3:   6%|▌         | 101/1835 [02:22<40:19,  1.40s/it, training loss=0.2120]\u001b[A\n",
            "Epoch 3:   6%|▌         | 102/1835 [02:22<40:17,  1.40s/it, training loss=0.2120]\u001b[A\n",
            "Epoch 3:   6%|▌         | 102/1835 [02:23<40:17,  1.40s/it, training loss=0.0445]\u001b[A\n",
            "Epoch 3:   6%|▌         | 103/1835 [02:23<40:16,  1.40s/it, training loss=0.0445]\u001b[A\n",
            "Epoch 3:   6%|▌         | 103/1835 [02:25<40:16,  1.40s/it, training loss=0.1880]\u001b[A\n",
            "Epoch 3:   6%|▌         | 104/1835 [02:25<40:18,  1.40s/it, training loss=0.1880]\u001b[A\n",
            "Epoch 3:   6%|▌         | 104/1835 [02:26<40:18,  1.40s/it, training loss=0.0934]\u001b[A\n",
            "Epoch 3:   6%|▌         | 105/1835 [02:26<40:14,  1.40s/it, training loss=0.0934]\u001b[A\n",
            "Epoch 3:   6%|▌         | 105/1835 [02:28<40:14,  1.40s/it, training loss=0.0947]\u001b[A\n",
            "Epoch 3:   6%|▌         | 106/1835 [02:28<40:14,  1.40s/it, training loss=0.0947]\u001b[A\n",
            "Epoch 3:   6%|▌         | 106/1835 [02:29<40:14,  1.40s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:   6%|▌         | 107/1835 [02:29<40:18,  1.40s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:   6%|▌         | 107/1835 [02:30<40:18,  1.40s/it, training loss=0.0814]\u001b[A\n",
            "Epoch 3:   6%|▌         | 108/1835 [02:30<40:10,  1.40s/it, training loss=0.0814]\u001b[A\n",
            "Epoch 3:   6%|▌         | 108/1835 [02:32<40:10,  1.40s/it, training loss=0.1256]\u001b[A\n",
            "Epoch 3:   6%|▌         | 109/1835 [02:32<40:08,  1.40s/it, training loss=0.1256]\u001b[A\n",
            "Epoch 3:   6%|▌         | 109/1835 [02:33<40:08,  1.40s/it, training loss=0.1600]\u001b[A\n",
            "Epoch 3:   6%|▌         | 110/1835 [02:33<40:06,  1.40s/it, training loss=0.1600]\u001b[A\n",
            "Epoch 3:   6%|▌         | 110/1835 [02:35<40:06,  1.40s/it, training loss=0.0462]\u001b[A\n",
            "Epoch 3:   6%|▌         | 111/1835 [02:35<40:06,  1.40s/it, training loss=0.0462]\u001b[A\n",
            "Epoch 3:   6%|▌         | 111/1835 [02:36<40:06,  1.40s/it, training loss=0.1567]\u001b[A\n",
            "Epoch 3:   6%|▌         | 112/1835 [02:36<40:07,  1.40s/it, training loss=0.1567]\u001b[A\n",
            "Epoch 3:   6%|▌         | 112/1835 [02:37<40:07,  1.40s/it, training loss=0.0234]\u001b[A\n",
            "Epoch 3:   6%|▌         | 113/1835 [02:37<40:05,  1.40s/it, training loss=0.0234]\u001b[A\n",
            "Epoch 3:   6%|▌         | 113/1835 [02:39<40:05,  1.40s/it, training loss=0.1163]\u001b[A\n",
            "Epoch 3:   6%|▌         | 114/1835 [02:39<40:03,  1.40s/it, training loss=0.1163]\u001b[A\n",
            "Epoch 3:   6%|▌         | 114/1835 [02:40<40:03,  1.40s/it, training loss=0.1365]\u001b[A\n",
            "Epoch 3:   6%|▋         | 115/1835 [02:40<40:04,  1.40s/it, training loss=0.1365]\u001b[A\n",
            "Epoch 3:   6%|▋         | 115/1835 [02:42<40:04,  1.40s/it, training loss=0.0765]\u001b[A\n",
            "Epoch 3:   6%|▋         | 116/1835 [02:42<39:59,  1.40s/it, training loss=0.0765]\u001b[A\n",
            "Epoch 3:   6%|▋         | 116/1835 [02:43<39:59,  1.40s/it, training loss=0.0537]\u001b[A\n",
            "Epoch 3:   6%|▋         | 117/1835 [02:43<40:00,  1.40s/it, training loss=0.0537]\u001b[A\n",
            "Epoch 3:   6%|▋         | 117/1835 [02:44<40:00,  1.40s/it, training loss=0.1758]\u001b[A\n",
            "Epoch 3:   6%|▋         | 118/1835 [02:44<39:56,  1.40s/it, training loss=0.1758]\u001b[A\n",
            "Epoch 3:   6%|▋         | 118/1835 [02:46<39:56,  1.40s/it, training loss=0.0125]\u001b[A\n",
            "Epoch 3:   6%|▋         | 119/1835 [02:46<39:58,  1.40s/it, training loss=0.0125]\u001b[A\n",
            "Epoch 3:   6%|▋         | 119/1835 [02:47<39:58,  1.40s/it, training loss=0.0553]\u001b[A\n",
            "Epoch 3:   7%|▋         | 120/1835 [02:47<39:55,  1.40s/it, training loss=0.0553]\u001b[A\n",
            "Epoch 3:   7%|▋         | 120/1835 [02:49<39:55,  1.40s/it, training loss=0.2025]\u001b[A\n",
            "Epoch 3:   7%|▋         | 121/1835 [02:49<39:53,  1.40s/it, training loss=0.2025]\u001b[A\n",
            "Epoch 3:   7%|▋         | 121/1835 [02:50<39:53,  1.40s/it, training loss=0.0574]\u001b[A\n",
            "Epoch 3:   7%|▋         | 122/1835 [02:50<39:51,  1.40s/it, training loss=0.0574]\u001b[A\n",
            "Epoch 3:   7%|▋         | 122/1835 [02:51<39:51,  1.40s/it, training loss=0.1645]\u001b[A\n",
            "Epoch 3:   7%|▋         | 123/1835 [02:51<39:50,  1.40s/it, training loss=0.1645]\u001b[A\n",
            "Epoch 3:   7%|▋         | 123/1835 [02:53<39:50,  1.40s/it, training loss=0.0406]\u001b[A\n",
            "Epoch 3:   7%|▋         | 124/1835 [02:53<39:45,  1.39s/it, training loss=0.0406]\u001b[A\n",
            "Epoch 3:   7%|▋         | 124/1835 [02:54<39:45,  1.39s/it, training loss=0.0357]\u001b[A\n",
            "Epoch 3:   7%|▋         | 125/1835 [02:54<39:43,  1.39s/it, training loss=0.0357]\u001b[A\n",
            "Epoch 3:   7%|▋         | 125/1835 [02:56<39:43,  1.39s/it, training loss=0.0150]\u001b[A\n",
            "Epoch 3:   7%|▋         | 126/1835 [02:56<39:44,  1.40s/it, training loss=0.0150]\u001b[A\n",
            "Epoch 3:   7%|▋         | 126/1835 [02:57<39:44,  1.40s/it, training loss=0.1228]\u001b[A\n",
            "Epoch 3:   7%|▋         | 127/1835 [02:57<39:40,  1.39s/it, training loss=0.1228]\u001b[A\n",
            "Epoch 3:   7%|▋         | 127/1835 [02:58<39:40,  1.39s/it, training loss=0.1432]\u001b[A\n",
            "Epoch 3:   7%|▋         | 128/1835 [02:58<39:42,  1.40s/it, training loss=0.1432]\u001b[A\n",
            "Epoch 3:   7%|▋         | 128/1835 [03:00<39:42,  1.40s/it, training loss=0.0861]\u001b[A\n",
            "Epoch 3:   7%|▋         | 129/1835 [03:00<39:42,  1.40s/it, training loss=0.0861]\u001b[A\n",
            "Epoch 3:   7%|▋         | 129/1835 [03:01<39:42,  1.40s/it, training loss=0.0403]\u001b[A\n",
            "Epoch 3:   7%|▋         | 130/1835 [03:01<39:37,  1.39s/it, training loss=0.0403]\u001b[A\n",
            "Epoch 3:   7%|▋         | 130/1835 [03:03<39:37,  1.39s/it, training loss=0.1634]\u001b[A\n",
            "Epoch 3:   7%|▋         | 131/1835 [03:03<39:35,  1.39s/it, training loss=0.1634]\u001b[A\n",
            "Epoch 3:   7%|▋         | 131/1835 [03:04<39:35,  1.39s/it, training loss=0.2012]\u001b[A\n",
            "Epoch 3:   7%|▋         | 132/1835 [03:04<39:42,  1.40s/it, training loss=0.2012]\u001b[A\n",
            "Epoch 3:   7%|▋         | 132/1835 [03:05<39:42,  1.40s/it, training loss=0.0900]\u001b[A\n",
            "Epoch 3:   7%|▋         | 133/1835 [03:05<39:38,  1.40s/it, training loss=0.0900]\u001b[A\n",
            "Epoch 3:   7%|▋         | 133/1835 [03:07<39:38,  1.40s/it, training loss=0.2563]\u001b[A\n",
            "Epoch 3:   7%|▋         | 134/1835 [03:07<39:36,  1.40s/it, training loss=0.2563]\u001b[A\n",
            "Epoch 3:   7%|▋         | 134/1835 [03:08<39:36,  1.40s/it, training loss=0.4177]\u001b[A\n",
            "Epoch 3:   7%|▋         | 135/1835 [03:08<39:38,  1.40s/it, training loss=0.4177]\u001b[A\n",
            "Epoch 3:   7%|▋         | 135/1835 [03:10<39:38,  1.40s/it, training loss=0.0092]\u001b[A\n",
            "Epoch 3:   7%|▋         | 136/1835 [03:10<39:32,  1.40s/it, training loss=0.0092]\u001b[A\n",
            "Epoch 3:   7%|▋         | 136/1835 [03:11<39:32,  1.40s/it, training loss=0.0434]\u001b[A\n",
            "Epoch 3:   7%|▋         | 137/1835 [03:11<39:34,  1.40s/it, training loss=0.0434]\u001b[A\n",
            "Epoch 3:   7%|▋         | 137/1835 [03:12<39:34,  1.40s/it, training loss=0.1537]\u001b[A\n",
            "Epoch 3:   8%|▊         | 138/1835 [03:12<39:31,  1.40s/it, training loss=0.1537]\u001b[A\n",
            "Epoch 3:   8%|▊         | 138/1835 [03:14<39:31,  1.40s/it, training loss=0.2033]\u001b[A\n",
            "Epoch 3:   8%|▊         | 139/1835 [03:14<39:31,  1.40s/it, training loss=0.2033]\u001b[A\n",
            "Epoch 3:   8%|▊         | 139/1835 [03:15<39:31,  1.40s/it, training loss=0.0500]\u001b[A\n",
            "Epoch 3:   8%|▊         | 140/1835 [03:15<39:32,  1.40s/it, training loss=0.0500]\u001b[A\n",
            "Epoch 3:   8%|▊         | 140/1835 [03:17<39:32,  1.40s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 3:   8%|▊         | 141/1835 [03:17<39:31,  1.40s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 3:   8%|▊         | 141/1835 [03:18<39:31,  1.40s/it, training loss=0.2167]\u001b[A\n",
            "Epoch 3:   8%|▊         | 142/1835 [03:18<39:26,  1.40s/it, training loss=0.2167]\u001b[A\n",
            "Epoch 3:   8%|▊         | 142/1835 [03:19<39:26,  1.40s/it, training loss=0.1713]\u001b[A\n",
            "Epoch 3:   8%|▊         | 143/1835 [03:19<39:25,  1.40s/it, training loss=0.1713]\u001b[A\n",
            "Epoch 3:   8%|▊         | 143/1835 [03:21<39:25,  1.40s/it, training loss=0.2464]\u001b[A\n",
            "Epoch 3:   8%|▊         | 144/1835 [03:21<39:22,  1.40s/it, training loss=0.2464]\u001b[A\n",
            "Epoch 3:   8%|▊         | 144/1835 [03:22<39:22,  1.40s/it, training loss=0.0166]\u001b[A\n",
            "Epoch 3:   8%|▊         | 145/1835 [03:22<39:20,  1.40s/it, training loss=0.0166]\u001b[A\n",
            "Epoch 3:   8%|▊         | 145/1835 [03:24<39:20,  1.40s/it, training loss=0.1431]\u001b[A\n",
            "Epoch 3:   8%|▊         | 146/1835 [03:24<39:18,  1.40s/it, training loss=0.1431]\u001b[A\n",
            "Epoch 3:   8%|▊         | 146/1835 [03:25<39:18,  1.40s/it, training loss=0.1076]\u001b[A\n",
            "Epoch 3:   8%|▊         | 147/1835 [03:25<39:16,  1.40s/it, training loss=0.1076]\u001b[A\n",
            "Epoch 3:   8%|▊         | 147/1835 [03:26<39:16,  1.40s/it, training loss=0.0655]\u001b[A\n",
            "Epoch 3:   8%|▊         | 148/1835 [03:26<39:14,  1.40s/it, training loss=0.0655]\u001b[A\n",
            "Epoch 3:   8%|▊         | 148/1835 [03:28<39:14,  1.40s/it, training loss=0.0896]\u001b[A\n",
            "Epoch 3:   8%|▊         | 149/1835 [03:28<39:12,  1.40s/it, training loss=0.0896]\u001b[A\n",
            "Epoch 3:   8%|▊         | 149/1835 [03:29<39:12,  1.40s/it, training loss=0.1082]\u001b[A\n",
            "Epoch 3:   8%|▊         | 150/1835 [03:29<39:08,  1.39s/it, training loss=0.1082]\u001b[A\n",
            "Epoch 3:   8%|▊         | 150/1835 [03:30<39:08,  1.39s/it, training loss=0.1333]\u001b[A\n",
            "Epoch 3:   8%|▊         | 151/1835 [03:30<39:06,  1.39s/it, training loss=0.1333]\u001b[A\n",
            "Epoch 3:   8%|▊         | 151/1835 [03:32<39:06,  1.39s/it, training loss=0.0762]\u001b[A\n",
            "Epoch 3:   8%|▊         | 152/1835 [03:32<39:10,  1.40s/it, training loss=0.0762]\u001b[A\n",
            "Epoch 3:   8%|▊         | 152/1835 [03:33<39:10,  1.40s/it, training loss=0.1726]\u001b[A\n",
            "Epoch 3:   8%|▊         | 153/1835 [03:33<39:05,  1.39s/it, training loss=0.1726]\u001b[A\n",
            "Epoch 3:   8%|▊         | 153/1835 [03:35<39:05,  1.39s/it, training loss=0.0529]\u001b[A\n",
            "Epoch 3:   8%|▊         | 154/1835 [03:35<39:08,  1.40s/it, training loss=0.0529]\u001b[A\n",
            "Epoch 3:   8%|▊         | 154/1835 [03:36<39:08,  1.40s/it, training loss=0.1044]\u001b[A\n",
            "Epoch 3:   8%|▊         | 155/1835 [03:36<39:07,  1.40s/it, training loss=0.1044]\u001b[A\n",
            "Epoch 3:   8%|▊         | 155/1835 [03:37<39:07,  1.40s/it, training loss=0.1385]\u001b[A\n",
            "Epoch 3:   9%|▊         | 156/1835 [03:37<39:04,  1.40s/it, training loss=0.1385]\u001b[A\n",
            "Epoch 3:   9%|▊         | 156/1835 [03:39<39:04,  1.40s/it, training loss=0.1100]\u001b[A\n",
            "Epoch 3:   9%|▊         | 157/1835 [03:39<39:05,  1.40s/it, training loss=0.1100]\u001b[A\n",
            "Epoch 3:   9%|▊         | 157/1835 [03:40<39:05,  1.40s/it, training loss=0.1588]\u001b[A\n",
            "Epoch 3:   9%|▊         | 158/1835 [03:40<39:02,  1.40s/it, training loss=0.1588]\u001b[A\n",
            "Epoch 3:   9%|▊         | 158/1835 [03:42<39:02,  1.40s/it, training loss=0.0428]\u001b[A\n",
            "Epoch 3:   9%|▊         | 159/1835 [03:42<39:02,  1.40s/it, training loss=0.0428]\u001b[A\n",
            "Epoch 3:   9%|▊         | 159/1835 [03:43<39:02,  1.40s/it, training loss=0.0323]\u001b[A\n",
            "Epoch 3:   9%|▊         | 160/1835 [03:43<38:57,  1.40s/it, training loss=0.0323]\u001b[A\n",
            "Epoch 3:   9%|▊         | 160/1835 [03:44<38:57,  1.40s/it, training loss=0.2300]\u001b[A\n",
            "Epoch 3:   9%|▉         | 161/1835 [03:44<38:57,  1.40s/it, training loss=0.2300]\u001b[A\n",
            "Epoch 3:   9%|▉         | 161/1835 [03:46<38:57,  1.40s/it, training loss=0.0364]\u001b[A\n",
            "Epoch 3:   9%|▉         | 162/1835 [03:46<38:58,  1.40s/it, training loss=0.0364]\u001b[A\n",
            "Epoch 3:   9%|▉         | 162/1835 [03:47<38:58,  1.40s/it, training loss=0.0624]\u001b[A\n",
            "Epoch 3:   9%|▉         | 163/1835 [03:47<38:58,  1.40s/it, training loss=0.0624]\u001b[A\n",
            "Epoch 3:   9%|▉         | 163/1835 [03:49<38:58,  1.40s/it, training loss=0.1074]\u001b[A\n",
            "Epoch 3:   9%|▉         | 164/1835 [03:49<38:57,  1.40s/it, training loss=0.1074]\u001b[A\n",
            "Epoch 3:   9%|▉         | 164/1835 [03:50<38:57,  1.40s/it, training loss=0.2538]\u001b[A\n",
            "Epoch 3:   9%|▉         | 165/1835 [03:50<38:55,  1.40s/it, training loss=0.2538]\u001b[A\n",
            "Epoch 3:   9%|▉         | 165/1835 [03:51<38:55,  1.40s/it, training loss=0.2103]\u001b[A\n",
            "Epoch 3:   9%|▉         | 166/1835 [03:51<38:52,  1.40s/it, training loss=0.2103]\u001b[A\n",
            "Epoch 3:   9%|▉         | 166/1835 [03:53<38:52,  1.40s/it, training loss=0.0571]\u001b[A\n",
            "Epoch 3:   9%|▉         | 167/1835 [03:53<38:54,  1.40s/it, training loss=0.0571]\u001b[A\n",
            "Epoch 3:   9%|▉         | 167/1835 [03:54<38:54,  1.40s/it, training loss=0.0772]\u001b[A\n",
            "Epoch 3:   9%|▉         | 168/1835 [03:54<38:52,  1.40s/it, training loss=0.0772]\u001b[A\n",
            "Epoch 3:   9%|▉         | 168/1835 [03:56<38:52,  1.40s/it, training loss=0.0711]\u001b[A\n",
            "Epoch 3:   9%|▉         | 169/1835 [03:56<38:53,  1.40s/it, training loss=0.0711]\u001b[A\n",
            "Epoch 3:   9%|▉         | 169/1835 [03:57<38:53,  1.40s/it, training loss=0.2057]\u001b[A\n",
            "Epoch 3:   9%|▉         | 170/1835 [03:57<38:52,  1.40s/it, training loss=0.2057]\u001b[A\n",
            "Epoch 3:   9%|▉         | 170/1835 [03:58<38:52,  1.40s/it, training loss=0.2659]\u001b[A\n",
            "Epoch 3:   9%|▉         | 171/1835 [03:58<38:46,  1.40s/it, training loss=0.2659]\u001b[A\n",
            "Epoch 3:   9%|▉         | 171/1835 [04:00<38:46,  1.40s/it, training loss=0.1294]\u001b[A\n",
            "Epoch 3:   9%|▉         | 172/1835 [04:00<38:40,  1.40s/it, training loss=0.1294]\u001b[A\n",
            "Epoch 3:   9%|▉         | 172/1835 [04:01<38:40,  1.40s/it, training loss=0.1718]\u001b[A\n",
            "Epoch 3:   9%|▉         | 173/1835 [04:01<38:41,  1.40s/it, training loss=0.1718]\u001b[A\n",
            "Epoch 3:   9%|▉         | 173/1835 [04:03<38:41,  1.40s/it, training loss=0.0168]\u001b[A\n",
            "Epoch 3:   9%|▉         | 174/1835 [04:03<38:39,  1.40s/it, training loss=0.0168]\u001b[A\n",
            "Epoch 3:   9%|▉         | 174/1835 [04:04<38:39,  1.40s/it, training loss=0.1122]\u001b[A\n",
            "Epoch 3:  10%|▉         | 175/1835 [04:04<38:40,  1.40s/it, training loss=0.1122]\u001b[A\n",
            "Epoch 3:  10%|▉         | 175/1835 [04:05<38:40,  1.40s/it, training loss=0.1193]\u001b[A\n",
            "Epoch 3:  10%|▉         | 176/1835 [04:05<38:34,  1.40s/it, training loss=0.1193]\u001b[A\n",
            "Epoch 3:  10%|▉         | 176/1835 [04:07<38:34,  1.40s/it, training loss=0.0785]\u001b[A\n",
            "Epoch 3:  10%|▉         | 177/1835 [04:07<38:34,  1.40s/it, training loss=0.0785]\u001b[A\n",
            "Epoch 3:  10%|▉         | 177/1835 [04:08<38:34,  1.40s/it, training loss=0.0554]\u001b[A\n",
            "Epoch 3:  10%|▉         | 178/1835 [04:08<38:34,  1.40s/it, training loss=0.0554]\u001b[A\n",
            "Epoch 3:  10%|▉         | 178/1835 [04:10<38:34,  1.40s/it, training loss=0.0540]\u001b[A\n",
            "Epoch 3:  10%|▉         | 179/1835 [04:10<38:30,  1.40s/it, training loss=0.0540]\u001b[A\n",
            "Epoch 3:  10%|▉         | 179/1835 [04:11<38:30,  1.40s/it, training loss=0.1040]\u001b[A\n",
            "Epoch 3:  10%|▉         | 180/1835 [04:11<38:24,  1.39s/it, training loss=0.1040]\u001b[A\n",
            "Epoch 3:  10%|▉         | 180/1835 [04:12<38:24,  1.39s/it, training loss=0.0967]\u001b[A\n",
            "Epoch 3:  10%|▉         | 181/1835 [04:12<38:24,  1.39s/it, training loss=0.0967]\u001b[A\n",
            "Epoch 3:  10%|▉         | 181/1835 [04:14<38:24,  1.39s/it, training loss=0.0303]\u001b[A\n",
            "Epoch 3:  10%|▉         | 182/1835 [04:14<38:23,  1.39s/it, training loss=0.0303]\u001b[A\n",
            "Epoch 3:  10%|▉         | 182/1835 [04:15<38:23,  1.39s/it, training loss=0.0320]\u001b[A\n",
            "Epoch 3:  10%|▉         | 183/1835 [04:15<38:23,  1.39s/it, training loss=0.0320]\u001b[A\n",
            "Epoch 3:  10%|▉         | 183/1835 [04:17<38:23,  1.39s/it, training loss=0.1272]\u001b[A\n",
            "Epoch 3:  10%|█         | 184/1835 [04:17<38:22,  1.39s/it, training loss=0.1272]\u001b[A\n",
            "Epoch 3:  10%|█         | 184/1835 [04:18<38:22,  1.39s/it, training loss=0.1343]\u001b[A\n",
            "Epoch 3:  10%|█         | 185/1835 [04:18<38:19,  1.39s/it, training loss=0.1343]\u001b[A\n",
            "Epoch 3:  10%|█         | 185/1835 [04:19<38:19,  1.39s/it, training loss=0.1633]\u001b[A\n",
            "Epoch 3:  10%|█         | 186/1835 [04:19<38:19,  1.39s/it, training loss=0.1633]\u001b[A\n",
            "Epoch 3:  10%|█         | 186/1835 [04:21<38:19,  1.39s/it, training loss=0.1154]\u001b[A\n",
            "Epoch 3:  10%|█         | 187/1835 [04:21<38:16,  1.39s/it, training loss=0.1154]\u001b[A\n",
            "Epoch 3:  10%|█         | 187/1835 [04:22<38:16,  1.39s/it, training loss=0.2320]\u001b[A\n",
            "Epoch 3:  10%|█         | 188/1835 [04:22<38:13,  1.39s/it, training loss=0.2320]\u001b[A\n",
            "Epoch 3:  10%|█         | 188/1835 [04:24<38:13,  1.39s/it, training loss=0.0791]\u001b[A\n",
            "Epoch 3:  10%|█         | 189/1835 [04:24<38:15,  1.39s/it, training loss=0.0791]\u001b[A\n",
            "Epoch 3:  10%|█         | 189/1835 [04:25<38:15,  1.39s/it, training loss=0.1120]\u001b[A\n",
            "Epoch 3:  10%|█         | 190/1835 [04:25<38:15,  1.40s/it, training loss=0.1120]\u001b[A\n",
            "Epoch 3:  10%|█         | 190/1835 [04:26<38:15,  1.40s/it, training loss=0.0540]\u001b[A\n",
            "Epoch 3:  10%|█         | 191/1835 [04:26<38:14,  1.40s/it, training loss=0.0540]\u001b[A\n",
            "Epoch 3:  10%|█         | 191/1835 [04:28<38:14,  1.40s/it, training loss=0.1344]\u001b[A\n",
            "Epoch 3:  10%|█         | 192/1835 [04:28<38:14,  1.40s/it, training loss=0.1344]\u001b[A\n",
            "Epoch 3:  10%|█         | 192/1835 [04:29<38:14,  1.40s/it, training loss=0.0871]\u001b[A\n",
            "Epoch 3:  11%|█         | 193/1835 [04:29<38:12,  1.40s/it, training loss=0.0871]\u001b[A\n",
            "Epoch 3:  11%|█         | 193/1835 [04:31<38:12,  1.40s/it, training loss=0.1532]\u001b[A\n",
            "Epoch 3:  11%|█         | 194/1835 [04:31<38:09,  1.40s/it, training loss=0.1532]\u001b[A\n",
            "Epoch 3:  11%|█         | 194/1835 [04:32<38:09,  1.40s/it, training loss=0.0447]\u001b[A\n",
            "Epoch 3:  11%|█         | 195/1835 [04:32<38:05,  1.39s/it, training loss=0.0447]\u001b[A\n",
            "Epoch 3:  11%|█         | 195/1835 [04:33<38:05,  1.39s/it, training loss=0.3439]\u001b[A\n",
            "Epoch 3:  11%|█         | 196/1835 [04:33<38:04,  1.39s/it, training loss=0.3439]\u001b[A\n",
            "Epoch 3:  11%|█         | 196/1835 [04:35<38:04,  1.39s/it, training loss=0.0399]\u001b[A\n",
            "Epoch 3:  11%|█         | 197/1835 [04:35<38:06,  1.40s/it, training loss=0.0399]\u001b[A\n",
            "Epoch 3:  11%|█         | 197/1835 [04:36<38:06,  1.40s/it, training loss=0.0733]\u001b[A\n",
            "Epoch 3:  11%|█         | 198/1835 [04:36<38:01,  1.39s/it, training loss=0.0733]\u001b[A\n",
            "Epoch 3:  11%|█         | 198/1835 [04:37<38:01,  1.39s/it, training loss=0.0571]\u001b[A\n",
            "Epoch 3:  11%|█         | 199/1835 [04:37<37:59,  1.39s/it, training loss=0.0571]\u001b[A\n",
            "Epoch 3:  11%|█         | 199/1835 [04:39<37:59,  1.39s/it, training loss=0.1323]\u001b[A\n",
            "Epoch 3:  11%|█         | 200/1835 [04:39<37:56,  1.39s/it, training loss=0.1323]\u001b[A\n",
            "Epoch 3:  11%|█         | 200/1835 [04:40<37:56,  1.39s/it, training loss=0.0723]\u001b[A\n",
            "Epoch 3:  11%|█         | 201/1835 [04:40<37:56,  1.39s/it, training loss=0.0723]\u001b[A\n",
            "Epoch 3:  11%|█         | 201/1835 [04:42<37:56,  1.39s/it, training loss=0.1114]\u001b[A\n",
            "Epoch 3:  11%|█         | 202/1835 [04:42<37:53,  1.39s/it, training loss=0.1114]\u001b[A\n",
            "Epoch 3:  11%|█         | 202/1835 [04:43<37:53,  1.39s/it, training loss=0.1583]\u001b[A\n",
            "Epoch 3:  11%|█         | 203/1835 [04:43<37:56,  1.39s/it, training loss=0.1583]\u001b[A\n",
            "Epoch 3:  11%|█         | 203/1835 [04:44<37:56,  1.39s/it, training loss=0.1048]\u001b[A\n",
            "Epoch 3:  11%|█         | 204/1835 [04:44<37:53,  1.39s/it, training loss=0.1048]\u001b[A\n",
            "Epoch 3:  11%|█         | 204/1835 [04:46<37:53,  1.39s/it, training loss=0.1576]\u001b[A\n",
            "Epoch 3:  11%|█         | 205/1835 [04:46<37:56,  1.40s/it, training loss=0.1576]\u001b[A\n",
            "Epoch 3:  11%|█         | 205/1835 [04:47<37:56,  1.40s/it, training loss=0.1173]\u001b[A\n",
            "Epoch 3:  11%|█         | 206/1835 [04:47<37:58,  1.40s/it, training loss=0.1173]\u001b[A\n",
            "Epoch 3:  11%|█         | 206/1835 [04:49<37:58,  1.40s/it, training loss=0.0826]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 207/1835 [04:49<37:58,  1.40s/it, training loss=0.0826]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 207/1835 [04:50<37:58,  1.40s/it, training loss=0.0700]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 208/1835 [04:50<37:56,  1.40s/it, training loss=0.0700]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 208/1835 [04:51<37:56,  1.40s/it, training loss=0.1131]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 209/1835 [04:51<37:54,  1.40s/it, training loss=0.1131]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 209/1835 [04:53<37:54,  1.40s/it, training loss=0.1484]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 210/1835 [04:53<37:54,  1.40s/it, training loss=0.1484]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 210/1835 [04:54<37:54,  1.40s/it, training loss=0.0949]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 211/1835 [04:54<37:49,  1.40s/it, training loss=0.0949]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 211/1835 [04:56<37:49,  1.40s/it, training loss=0.0435]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 212/1835 [04:56<37:47,  1.40s/it, training loss=0.0435]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 212/1835 [04:57<37:47,  1.40s/it, training loss=0.0658]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 213/1835 [04:57<37:44,  1.40s/it, training loss=0.0658]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 213/1835 [04:58<37:44,  1.40s/it, training loss=0.1642]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 214/1835 [04:58<37:42,  1.40s/it, training loss=0.1642]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 214/1835 [05:00<37:42,  1.40s/it, training loss=0.1994]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 215/1835 [05:00<37:44,  1.40s/it, training loss=0.1994]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 215/1835 [05:01<37:44,  1.40s/it, training loss=0.0659]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 216/1835 [05:01<37:42,  1.40s/it, training loss=0.0659]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 216/1835 [05:03<37:42,  1.40s/it, training loss=0.0756]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 217/1835 [05:03<37:40,  1.40s/it, training loss=0.0756]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 217/1835 [05:04<37:40,  1.40s/it, training loss=0.2071]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 218/1835 [05:04<37:44,  1.40s/it, training loss=0.2071]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 218/1835 [05:05<37:44,  1.40s/it, training loss=0.0345]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 219/1835 [05:05<37:42,  1.40s/it, training loss=0.0345]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 219/1835 [05:07<37:42,  1.40s/it, training loss=0.1850]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 220/1835 [05:07<37:40,  1.40s/it, training loss=0.1850]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 220/1835 [05:08<37:40,  1.40s/it, training loss=0.0401]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 221/1835 [05:08<37:34,  1.40s/it, training loss=0.0401]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 221/1835 [05:10<37:34,  1.40s/it, training loss=0.2418]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 222/1835 [05:10<37:33,  1.40s/it, training loss=0.2418]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 222/1835 [05:11<37:33,  1.40s/it, training loss=0.0782]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 223/1835 [05:11<37:35,  1.40s/it, training loss=0.0782]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 223/1835 [05:12<37:35,  1.40s/it, training loss=0.1896]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 224/1835 [05:12<37:31,  1.40s/it, training loss=0.1896]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 224/1835 [05:14<37:31,  1.40s/it, training loss=0.0815]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 225/1835 [05:14<37:28,  1.40s/it, training loss=0.0815]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 225/1835 [05:15<37:28,  1.40s/it, training loss=0.1806]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 226/1835 [05:15<37:29,  1.40s/it, training loss=0.1806]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 226/1835 [05:17<37:29,  1.40s/it, training loss=0.1203]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 227/1835 [05:17<37:27,  1.40s/it, training loss=0.1203]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 227/1835 [05:18<37:27,  1.40s/it, training loss=0.2159]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 228/1835 [05:18<37:26,  1.40s/it, training loss=0.2159]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 228/1835 [05:19<37:26,  1.40s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 229/1835 [05:19<37:22,  1.40s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 229/1835 [05:21<37:22,  1.40s/it, training loss=0.0438]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 230/1835 [05:21<37:21,  1.40s/it, training loss=0.0438]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 230/1835 [05:22<37:21,  1.40s/it, training loss=0.0543]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 231/1835 [05:22<37:15,  1.39s/it, training loss=0.0543]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 231/1835 [05:24<37:15,  1.39s/it, training loss=0.0259]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 232/1835 [05:24<37:11,  1.39s/it, training loss=0.0259]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 232/1835 [05:25<37:11,  1.39s/it, training loss=0.0159]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 233/1835 [05:25<37:15,  1.40s/it, training loss=0.0159]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 233/1835 [05:26<37:15,  1.40s/it, training loss=0.2382]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 234/1835 [05:26<37:15,  1.40s/it, training loss=0.2382]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 234/1835 [05:28<37:15,  1.40s/it, training loss=0.0763]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 235/1835 [05:28<37:11,  1.39s/it, training loss=0.0763]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 235/1835 [05:29<37:11,  1.39s/it, training loss=0.0278]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 236/1835 [05:29<37:12,  1.40s/it, training loss=0.0278]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 236/1835 [05:31<37:12,  1.40s/it, training loss=0.1177]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 237/1835 [05:31<37:09,  1.40s/it, training loss=0.1177]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 237/1835 [05:32<37:09,  1.40s/it, training loss=0.2256]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 238/1835 [05:32<37:09,  1.40s/it, training loss=0.2256]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 238/1835 [05:33<37:09,  1.40s/it, training loss=0.0527]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 239/1835 [05:33<37:09,  1.40s/it, training loss=0.0527]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 239/1835 [05:35<37:09,  1.40s/it, training loss=0.0836]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 240/1835 [05:35<37:10,  1.40s/it, training loss=0.0836]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 240/1835 [05:36<37:10,  1.40s/it, training loss=0.0337]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 241/1835 [05:36<37:09,  1.40s/it, training loss=0.0337]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 241/1835 [05:38<37:09,  1.40s/it, training loss=0.1561]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 242/1835 [05:38<37:11,  1.40s/it, training loss=0.1561]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 242/1835 [05:39<37:11,  1.40s/it, training loss=0.0211]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 243/1835 [05:39<37:07,  1.40s/it, training loss=0.0211]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 243/1835 [05:40<37:07,  1.40s/it, training loss=0.1238]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 244/1835 [05:40<37:02,  1.40s/it, training loss=0.1238]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 244/1835 [05:42<37:02,  1.40s/it, training loss=0.0220]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 245/1835 [05:42<36:59,  1.40s/it, training loss=0.0220]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 245/1835 [05:43<36:59,  1.40s/it, training loss=0.0458]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 246/1835 [05:43<36:59,  1.40s/it, training loss=0.0458]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 246/1835 [05:45<36:59,  1.40s/it, training loss=0.0800]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 247/1835 [05:45<37:00,  1.40s/it, training loss=0.0800]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 247/1835 [05:46<37:00,  1.40s/it, training loss=0.0858]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 248/1835 [05:46<36:58,  1.40s/it, training loss=0.0858]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 248/1835 [05:47<36:58,  1.40s/it, training loss=0.3008]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 249/1835 [05:47<36:58,  1.40s/it, training loss=0.3008]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 249/1835 [05:49<36:58,  1.40s/it, training loss=0.2376]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 250/1835 [05:49<36:53,  1.40s/it, training loss=0.2376]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 250/1835 [05:50<36:53,  1.40s/it, training loss=0.1953]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 251/1835 [05:50<36:48,  1.39s/it, training loss=0.1953]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 251/1835 [05:52<36:48,  1.39s/it, training loss=0.0368]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 252/1835 [05:52<36:47,  1.39s/it, training loss=0.0368]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 252/1835 [05:53<36:47,  1.39s/it, training loss=0.1064]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 253/1835 [05:53<36:45,  1.39s/it, training loss=0.1064]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 253/1835 [05:54<36:45,  1.39s/it, training loss=0.1010]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 254/1835 [05:54<36:44,  1.39s/it, training loss=0.1010]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 254/1835 [05:56<36:44,  1.39s/it, training loss=0.0528]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 255/1835 [05:56<36:42,  1.39s/it, training loss=0.0528]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 255/1835 [05:57<36:42,  1.39s/it, training loss=0.1715]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 256/1835 [05:57<36:41,  1.39s/it, training loss=0.1715]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 256/1835 [05:59<36:41,  1.39s/it, training loss=0.0303]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 257/1835 [05:59<36:41,  1.39s/it, training loss=0.0303]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 257/1835 [06:00<36:41,  1.39s/it, training loss=0.1074]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 258/1835 [06:00<36:37,  1.39s/it, training loss=0.1074]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 258/1835 [06:01<36:37,  1.39s/it, training loss=0.1433]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 259/1835 [06:01<36:35,  1.39s/it, training loss=0.1433]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 259/1835 [06:03<36:35,  1.39s/it, training loss=0.0255]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 260/1835 [06:03<36:36,  1.39s/it, training loss=0.0255]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 260/1835 [06:04<36:36,  1.39s/it, training loss=0.0829]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 261/1835 [06:04<36:33,  1.39s/it, training loss=0.0829]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 261/1835 [06:05<36:33,  1.39s/it, training loss=0.0626]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 262/1835 [06:05<36:34,  1.40s/it, training loss=0.0626]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 262/1835 [06:07<36:34,  1.40s/it, training loss=0.0405]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 263/1835 [06:07<36:31,  1.39s/it, training loss=0.0405]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 263/1835 [06:08<36:31,  1.39s/it, training loss=0.0612]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 264/1835 [06:08<36:32,  1.40s/it, training loss=0.0612]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 264/1835 [06:10<36:32,  1.40s/it, training loss=0.1547]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 265/1835 [06:10<36:35,  1.40s/it, training loss=0.1547]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 265/1835 [06:11<36:35,  1.40s/it, training loss=0.0515]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 266/1835 [06:11<36:32,  1.40s/it, training loss=0.0515]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 266/1835 [06:12<36:32,  1.40s/it, training loss=0.1684]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 267/1835 [06:12<36:35,  1.40s/it, training loss=0.1684]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 267/1835 [06:14<36:35,  1.40s/it, training loss=0.0410]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 268/1835 [06:14<36:34,  1.40s/it, training loss=0.0410]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 268/1835 [06:15<36:34,  1.40s/it, training loss=0.0125]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 269/1835 [06:15<36:32,  1.40s/it, training loss=0.0125]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 269/1835 [06:17<36:32,  1.40s/it, training loss=0.2521]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 270/1835 [06:17<36:31,  1.40s/it, training loss=0.2521]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 270/1835 [06:18<36:31,  1.40s/it, training loss=0.1497]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 271/1835 [06:18<36:27,  1.40s/it, training loss=0.1497]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 271/1835 [06:19<36:27,  1.40s/it, training loss=0.0751]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 272/1835 [06:19<36:25,  1.40s/it, training loss=0.0751]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 272/1835 [06:21<36:25,  1.40s/it, training loss=0.0549]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 273/1835 [06:21<36:23,  1.40s/it, training loss=0.0549]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 273/1835 [06:22<36:23,  1.40s/it, training loss=0.1766]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 274/1835 [06:22<36:23,  1.40s/it, training loss=0.1766]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 274/1835 [06:24<36:23,  1.40s/it, training loss=0.0639]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 275/1835 [06:24<36:20,  1.40s/it, training loss=0.0639]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 275/1835 [06:25<36:20,  1.40s/it, training loss=0.1169]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 276/1835 [06:25<36:16,  1.40s/it, training loss=0.1169]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 276/1835 [06:26<36:16,  1.40s/it, training loss=0.1279]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 277/1835 [06:26<36:13,  1.40s/it, training loss=0.1279]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 277/1835 [06:28<36:13,  1.40s/it, training loss=0.0534]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 278/1835 [06:28<36:12,  1.39s/it, training loss=0.0534]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 278/1835 [06:29<36:12,  1.39s/it, training loss=0.0828]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 279/1835 [06:29<36:11,  1.40s/it, training loss=0.0828]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 279/1835 [06:31<36:11,  1.40s/it, training loss=0.1047]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 280/1835 [06:31<36:10,  1.40s/it, training loss=0.1047]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 280/1835 [06:32<36:10,  1.40s/it, training loss=0.1905]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 281/1835 [06:32<36:07,  1.40s/it, training loss=0.1905]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 281/1835 [06:33<36:07,  1.40s/it, training loss=0.1856]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 282/1835 [06:33<36:04,  1.39s/it, training loss=0.1856]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 282/1835 [06:35<36:04,  1.39s/it, training loss=0.0315]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 283/1835 [06:35<36:03,  1.39s/it, training loss=0.0315]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 283/1835 [06:36<36:03,  1.39s/it, training loss=0.0554]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 284/1835 [06:36<36:02,  1.39s/it, training loss=0.0554]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 284/1835 [06:38<36:02,  1.39s/it, training loss=0.1364]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 285/1835 [06:38<36:03,  1.40s/it, training loss=0.1364]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 285/1835 [06:39<36:03,  1.40s/it, training loss=0.0706]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 286/1835 [06:39<36:02,  1.40s/it, training loss=0.0706]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 286/1835 [06:40<36:02,  1.40s/it, training loss=0.0590]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 287/1835 [06:40<35:58,  1.39s/it, training loss=0.0590]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 287/1835 [06:42<35:58,  1.39s/it, training loss=0.0918]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 288/1835 [06:42<35:56,  1.39s/it, training loss=0.0918]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 288/1835 [06:43<35:56,  1.39s/it, training loss=0.1695]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 289/1835 [06:43<35:54,  1.39s/it, training loss=0.1695]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 289/1835 [06:45<35:54,  1.39s/it, training loss=0.1270]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 290/1835 [06:45<35:54,  1.39s/it, training loss=0.1270]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 290/1835 [06:46<35:54,  1.39s/it, training loss=0.2061]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 291/1835 [06:46<35:52,  1.39s/it, training loss=0.2061]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 291/1835 [06:47<35:52,  1.39s/it, training loss=0.1238]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 292/1835 [06:47<35:53,  1.40s/it, training loss=0.1238]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 292/1835 [06:49<35:53,  1.40s/it, training loss=0.0462]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 293/1835 [06:49<35:50,  1.39s/it, training loss=0.0462]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 293/1835 [06:50<35:50,  1.39s/it, training loss=0.1414]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 294/1835 [06:50<35:51,  1.40s/it, training loss=0.1414]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 294/1835 [06:52<35:51,  1.40s/it, training loss=0.0500]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 295/1835 [06:52<35:52,  1.40s/it, training loss=0.0500]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 295/1835 [06:53<35:52,  1.40s/it, training loss=0.0466]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 296/1835 [06:53<35:48,  1.40s/it, training loss=0.0466]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 296/1835 [06:54<35:48,  1.40s/it, training loss=0.0989]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 297/1835 [06:54<35:49,  1.40s/it, training loss=0.0989]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 297/1835 [06:56<35:49,  1.40s/it, training loss=0.0781]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 298/1835 [06:56<35:48,  1.40s/it, training loss=0.0781]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 298/1835 [06:57<35:48,  1.40s/it, training loss=0.0967]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 299/1835 [06:57<35:48,  1.40s/it, training loss=0.0967]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 299/1835 [06:59<35:48,  1.40s/it, training loss=0.1366]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 300/1835 [06:59<35:47,  1.40s/it, training loss=0.1366]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 300/1835 [07:00<35:47,  1.40s/it, training loss=0.1295]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 301/1835 [07:00<35:45,  1.40s/it, training loss=0.1295]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 301/1835 [07:01<35:45,  1.40s/it, training loss=0.1717]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 302/1835 [07:01<35:43,  1.40s/it, training loss=0.1717]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 302/1835 [07:03<35:43,  1.40s/it, training loss=0.0774]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 303/1835 [07:03<35:38,  1.40s/it, training loss=0.0774]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 303/1835 [07:04<35:38,  1.40s/it, training loss=0.1281]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 304/1835 [07:04<35:33,  1.39s/it, training loss=0.1281]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 304/1835 [07:06<35:33,  1.39s/it, training loss=0.0973]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 305/1835 [07:06<35:31,  1.39s/it, training loss=0.0973]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 305/1835 [07:07<35:31,  1.39s/it, training loss=0.0725]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 306/1835 [07:07<35:32,  1.39s/it, training loss=0.0725]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 306/1835 [07:08<35:32,  1.39s/it, training loss=0.1397]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 307/1835 [07:08<35:29,  1.39s/it, training loss=0.1397]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 307/1835 [07:10<35:29,  1.39s/it, training loss=0.0827]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 308/1835 [07:10<35:26,  1.39s/it, training loss=0.0827]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 308/1835 [07:11<35:26,  1.39s/it, training loss=0.0622]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 309/1835 [07:11<35:33,  1.40s/it, training loss=0.0622]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 309/1835 [07:13<35:33,  1.40s/it, training loss=0.1287]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 310/1835 [07:13<35:30,  1.40s/it, training loss=0.1287]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 310/1835 [07:14<35:30,  1.40s/it, training loss=0.0758]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 311/1835 [07:14<35:24,  1.39s/it, training loss=0.0758]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 311/1835 [07:15<35:24,  1.39s/it, training loss=0.0858]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 312/1835 [07:15<35:24,  1.39s/it, training loss=0.0858]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 312/1835 [07:17<35:24,  1.39s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 313/1835 [07:17<35:21,  1.39s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 313/1835 [07:18<35:21,  1.39s/it, training loss=0.1790]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 314/1835 [07:18<35:16,  1.39s/it, training loss=0.1790]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 314/1835 [07:19<35:16,  1.39s/it, training loss=0.0258]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 315/1835 [07:19<35:16,  1.39s/it, training loss=0.0258]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 315/1835 [07:21<35:16,  1.39s/it, training loss=0.1067]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 316/1835 [07:21<35:15,  1.39s/it, training loss=0.1067]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 316/1835 [07:22<35:15,  1.39s/it, training loss=0.0284]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 317/1835 [07:22<35:15,  1.39s/it, training loss=0.0284]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 317/1835 [07:24<35:15,  1.39s/it, training loss=0.0657]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 318/1835 [07:24<35:11,  1.39s/it, training loss=0.0657]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 318/1835 [07:25<35:11,  1.39s/it, training loss=0.1850]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 319/1835 [07:25<35:16,  1.40s/it, training loss=0.1850]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 319/1835 [07:26<35:16,  1.40s/it, training loss=0.2072]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 320/1835 [07:26<35:15,  1.40s/it, training loss=0.2072]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 320/1835 [07:28<35:15,  1.40s/it, training loss=0.0550]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 321/1835 [07:28<35:13,  1.40s/it, training loss=0.0550]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 321/1835 [07:29<35:13,  1.40s/it, training loss=0.0712]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 322/1835 [07:29<35:13,  1.40s/it, training loss=0.0712]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 322/1835 [07:31<35:13,  1.40s/it, training loss=0.0198]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 323/1835 [07:31<35:11,  1.40s/it, training loss=0.0198]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 323/1835 [07:32<35:11,  1.40s/it, training loss=0.0820]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 324/1835 [07:32<35:09,  1.40s/it, training loss=0.0820]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 324/1835 [07:33<35:09,  1.40s/it, training loss=0.0405]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 325/1835 [07:33<35:12,  1.40s/it, training loss=0.0405]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 325/1835 [07:35<35:12,  1.40s/it, training loss=0.1250]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 326/1835 [07:35<35:08,  1.40s/it, training loss=0.1250]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 326/1835 [07:36<35:08,  1.40s/it, training loss=0.0747]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 327/1835 [07:36<35:08,  1.40s/it, training loss=0.0747]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 327/1835 [07:38<35:08,  1.40s/it, training loss=0.1354]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 328/1835 [07:38<35:07,  1.40s/it, training loss=0.1354]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 328/1835 [07:39<35:07,  1.40s/it, training loss=0.1073]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 329/1835 [07:39<35:06,  1.40s/it, training loss=0.1073]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 329/1835 [07:40<35:06,  1.40s/it, training loss=0.2503]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 330/1835 [07:40<35:01,  1.40s/it, training loss=0.2503]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 330/1835 [07:42<35:01,  1.40s/it, training loss=0.1541]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 331/1835 [07:42<34:56,  1.39s/it, training loss=0.1541]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 331/1835 [07:43<34:56,  1.39s/it, training loss=0.0516]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 332/1835 [07:43<34:56,  1.39s/it, training loss=0.0516]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 332/1835 [07:45<34:56,  1.39s/it, training loss=0.1127]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 333/1835 [07:45<34:52,  1.39s/it, training loss=0.1127]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 333/1835 [07:46<34:52,  1.39s/it, training loss=0.0544]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 334/1835 [07:46<34:53,  1.39s/it, training loss=0.0544]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 334/1835 [07:47<34:53,  1.39s/it, training loss=0.0743]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 335/1835 [07:47<34:54,  1.40s/it, training loss=0.0743]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 335/1835 [07:49<34:54,  1.40s/it, training loss=0.0959]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 336/1835 [07:49<34:50,  1.39s/it, training loss=0.0959]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 336/1835 [07:50<34:50,  1.39s/it, training loss=0.1465]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 337/1835 [07:50<34:52,  1.40s/it, training loss=0.1465]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 337/1835 [07:52<34:52,  1.40s/it, training loss=0.0731]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 338/1835 [07:52<34:50,  1.40s/it, training loss=0.0731]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 338/1835 [07:53<34:50,  1.40s/it, training loss=0.0745]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 339/1835 [07:53<34:46,  1.39s/it, training loss=0.0745]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 339/1835 [07:54<34:46,  1.39s/it, training loss=0.0182]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 340/1835 [07:54<34:49,  1.40s/it, training loss=0.0182]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 340/1835 [07:56<34:49,  1.40s/it, training loss=0.1627]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 341/1835 [07:56<34:45,  1.40s/it, training loss=0.1627]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 341/1835 [07:57<34:45,  1.40s/it, training loss=0.3139]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 342/1835 [07:57<34:45,  1.40s/it, training loss=0.3139]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 342/1835 [07:59<34:45,  1.40s/it, training loss=0.1225]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 343/1835 [07:59<34:45,  1.40s/it, training loss=0.1225]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 343/1835 [08:00<34:45,  1.40s/it, training loss=0.0538]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 344/1835 [08:00<34:43,  1.40s/it, training loss=0.0538]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 344/1835 [08:01<34:43,  1.40s/it, training loss=0.1560]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 345/1835 [08:01<34:40,  1.40s/it, training loss=0.1560]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 345/1835 [08:03<34:40,  1.40s/it, training loss=0.1216]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 346/1835 [08:03<34:43,  1.40s/it, training loss=0.1216]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 346/1835 [08:04<34:43,  1.40s/it, training loss=0.0294]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 347/1835 [08:04<34:44,  1.40s/it, training loss=0.0294]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 347/1835 [08:06<34:44,  1.40s/it, training loss=0.0914]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 348/1835 [08:06<34:36,  1.40s/it, training loss=0.0914]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 348/1835 [08:07<34:36,  1.40s/it, training loss=0.1362]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 349/1835 [08:07<34:34,  1.40s/it, training loss=0.1362]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 349/1835 [08:08<34:34,  1.40s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 350/1835 [08:08<34:33,  1.40s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 350/1835 [08:10<34:33,  1.40s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 351/1835 [08:10<34:31,  1.40s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 351/1835 [08:11<34:31,  1.40s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 352/1835 [08:11<34:32,  1.40s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 352/1835 [08:13<34:32,  1.40s/it, training loss=0.0356]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 353/1835 [08:13<34:28,  1.40s/it, training loss=0.0356]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 353/1835 [08:14<34:28,  1.40s/it, training loss=0.0959]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 354/1835 [08:14<34:27,  1.40s/it, training loss=0.0959]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 354/1835 [08:15<34:27,  1.40s/it, training loss=0.0990]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 355/1835 [08:15<34:27,  1.40s/it, training loss=0.0990]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 355/1835 [08:17<34:27,  1.40s/it, training loss=0.0447]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 356/1835 [08:17<34:27,  1.40s/it, training loss=0.0447]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 356/1835 [08:18<34:27,  1.40s/it, training loss=0.0689]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 357/1835 [08:18<34:25,  1.40s/it, training loss=0.0689]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 357/1835 [08:20<34:25,  1.40s/it, training loss=0.0420]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 358/1835 [08:20<34:21,  1.40s/it, training loss=0.0420]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 358/1835 [08:21<34:21,  1.40s/it, training loss=0.0814]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 359/1835 [08:21<34:17,  1.39s/it, training loss=0.0814]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 359/1835 [08:22<34:17,  1.39s/it, training loss=0.1466]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 360/1835 [08:22<34:15,  1.39s/it, training loss=0.1466]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 360/1835 [08:24<34:15,  1.39s/it, training loss=0.0862]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 361/1835 [08:24<34:15,  1.39s/it, training loss=0.0862]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 361/1835 [08:25<34:15,  1.39s/it, training loss=0.0612]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 362/1835 [08:25<34:11,  1.39s/it, training loss=0.0612]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 362/1835 [08:26<34:11,  1.39s/it, training loss=0.1120]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 363/1835 [08:26<34:13,  1.40s/it, training loss=0.1120]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 363/1835 [08:28<34:13,  1.40s/it, training loss=0.1618]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 364/1835 [08:28<34:10,  1.39s/it, training loss=0.1618]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 364/1835 [08:29<34:10,  1.39s/it, training loss=0.1347]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 365/1835 [08:29<34:06,  1.39s/it, training loss=0.1347]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 365/1835 [08:31<34:06,  1.39s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 366/1835 [08:31<34:05,  1.39s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 366/1835 [08:32<34:05,  1.39s/it, training loss=0.0350]\u001b[A\n",
            "Epoch 3:  20%|██        | 367/1835 [08:32<34:07,  1.39s/it, training loss=0.0350]\u001b[A\n",
            "Epoch 3:  20%|██        | 367/1835 [08:33<34:07,  1.39s/it, training loss=0.0878]\u001b[A\n",
            "Epoch 3:  20%|██        | 368/1835 [08:33<34:06,  1.40s/it, training loss=0.0878]\u001b[A\n",
            "Epoch 3:  20%|██        | 368/1835 [08:35<34:06,  1.40s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:  20%|██        | 369/1835 [08:35<34:02,  1.39s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:  20%|██        | 369/1835 [08:36<34:02,  1.39s/it, training loss=0.1174]\u001b[A\n",
            "Epoch 3:  20%|██        | 370/1835 [08:36<34:05,  1.40s/it, training loss=0.1174]\u001b[A\n",
            "Epoch 3:  20%|██        | 370/1835 [08:38<34:05,  1.40s/it, training loss=0.0873]\u001b[A\n",
            "Epoch 3:  20%|██        | 371/1835 [08:38<34:01,  1.39s/it, training loss=0.0873]\u001b[A\n",
            "Epoch 3:  20%|██        | 371/1835 [08:39<34:01,  1.39s/it, training loss=0.2308]\u001b[A\n",
            "Epoch 3:  20%|██        | 372/1835 [08:39<34:04,  1.40s/it, training loss=0.2308]\u001b[A\n",
            "Epoch 3:  20%|██        | 372/1835 [08:40<34:04,  1.40s/it, training loss=0.0300]\u001b[A\n",
            "Epoch 3:  20%|██        | 373/1835 [08:40<34:02,  1.40s/it, training loss=0.0300]\u001b[A\n",
            "Epoch 3:  20%|██        | 373/1835 [08:42<34:02,  1.40s/it, training loss=0.1543]\u001b[A\n",
            "Epoch 3:  20%|██        | 374/1835 [08:42<33:59,  1.40s/it, training loss=0.1543]\u001b[A\n",
            "Epoch 3:  20%|██        | 374/1835 [08:43<33:59,  1.40s/it, training loss=0.2104]\u001b[A\n",
            "Epoch 3:  20%|██        | 375/1835 [08:43<33:57,  1.40s/it, training loss=0.2104]\u001b[A\n",
            "Epoch 3:  20%|██        | 375/1835 [08:45<33:57,  1.40s/it, training loss=0.0395]\u001b[A\n",
            "Epoch 3:  20%|██        | 376/1835 [08:45<33:56,  1.40s/it, training loss=0.0395]\u001b[A\n",
            "Epoch 3:  20%|██        | 376/1835 [08:46<33:56,  1.40s/it, training loss=0.0848]\u001b[A\n",
            "Epoch 3:  21%|██        | 377/1835 [08:46<33:55,  1.40s/it, training loss=0.0848]\u001b[A\n",
            "Epoch 3:  21%|██        | 377/1835 [08:47<33:55,  1.40s/it, training loss=0.0904]\u001b[A\n",
            "Epoch 3:  21%|██        | 378/1835 [08:47<33:53,  1.40s/it, training loss=0.0904]\u001b[A\n",
            "Epoch 3:  21%|██        | 378/1835 [08:49<33:53,  1.40s/it, training loss=0.0786]\u001b[A\n",
            "Epoch 3:  21%|██        | 379/1835 [08:49<33:55,  1.40s/it, training loss=0.0786]\u001b[A\n",
            "Epoch 3:  21%|██        | 379/1835 [08:50<33:55,  1.40s/it, training loss=0.0863]\u001b[A\n",
            "Epoch 3:  21%|██        | 380/1835 [08:50<33:54,  1.40s/it, training loss=0.0863]\u001b[A\n",
            "Epoch 3:  21%|██        | 380/1835 [08:52<33:54,  1.40s/it, training loss=0.0547]\u001b[A\n",
            "Epoch 3:  21%|██        | 381/1835 [08:52<33:53,  1.40s/it, training loss=0.0547]\u001b[A\n",
            "Epoch 3:  21%|██        | 381/1835 [08:53<33:53,  1.40s/it, training loss=0.1786]\u001b[A\n",
            "Epoch 3:  21%|██        | 382/1835 [08:53<33:52,  1.40s/it, training loss=0.1786]\u001b[A\n",
            "Epoch 3:  21%|██        | 382/1835 [08:54<33:52,  1.40s/it, training loss=0.3113]\u001b[A\n",
            "Epoch 3:  21%|██        | 383/1835 [08:54<33:52,  1.40s/it, training loss=0.3113]\u001b[A\n",
            "Epoch 3:  21%|██        | 383/1835 [08:56<33:52,  1.40s/it, training loss=0.1383]\u001b[A\n",
            "Epoch 3:  21%|██        | 384/1835 [08:56<33:46,  1.40s/it, training loss=0.1383]\u001b[A\n",
            "Epoch 3:  21%|██        | 384/1835 [08:57<33:46,  1.40s/it, training loss=0.0744]\u001b[A\n",
            "Epoch 3:  21%|██        | 385/1835 [08:57<33:44,  1.40s/it, training loss=0.0744]\u001b[A\n",
            "Epoch 3:  21%|██        | 385/1835 [08:59<33:44,  1.40s/it, training loss=0.0340]\u001b[A\n",
            "Epoch 3:  21%|██        | 386/1835 [08:59<33:43,  1.40s/it, training loss=0.0340]\u001b[A\n",
            "Epoch 3:  21%|██        | 386/1835 [09:00<33:43,  1.40s/it, training loss=0.0895]\u001b[A\n",
            "Epoch 3:  21%|██        | 387/1835 [09:00<33:40,  1.40s/it, training loss=0.0895]\u001b[A\n",
            "Epoch 3:  21%|██        | 387/1835 [09:01<33:40,  1.40s/it, training loss=0.1331]\u001b[A\n",
            "Epoch 3:  21%|██        | 388/1835 [09:01<33:40,  1.40s/it, training loss=0.1331]\u001b[A\n",
            "Epoch 3:  21%|██        | 388/1835 [09:03<33:40,  1.40s/it, training loss=0.1632]\u001b[A\n",
            "Epoch 3:  21%|██        | 389/1835 [09:03<33:39,  1.40s/it, training loss=0.1632]\u001b[A\n",
            "Epoch 3:  21%|██        | 389/1835 [09:04<33:39,  1.40s/it, training loss=0.1052]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 390/1835 [09:04<33:39,  1.40s/it, training loss=0.1052]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 390/1835 [09:06<33:39,  1.40s/it, training loss=0.1659]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 391/1835 [09:06<33:39,  1.40s/it, training loss=0.1659]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 391/1835 [09:07<33:39,  1.40s/it, training loss=0.0898]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 392/1835 [09:07<33:37,  1.40s/it, training loss=0.0898]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 392/1835 [09:08<33:37,  1.40s/it, training loss=0.0195]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 393/1835 [09:08<33:31,  1.40s/it, training loss=0.0195]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 393/1835 [09:10<33:31,  1.40s/it, training loss=0.0565]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 394/1835 [09:10<33:31,  1.40s/it, training loss=0.0565]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 394/1835 [09:11<33:31,  1.40s/it, training loss=0.2274]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 395/1835 [09:11<33:35,  1.40s/it, training loss=0.2274]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 395/1835 [09:13<33:35,  1.40s/it, training loss=0.0907]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 396/1835 [09:13<33:29,  1.40s/it, training loss=0.0907]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 396/1835 [09:14<33:29,  1.40s/it, training loss=0.0693]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 397/1835 [09:14<33:28,  1.40s/it, training loss=0.0693]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 397/1835 [09:15<33:28,  1.40s/it, training loss=0.1127]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 398/1835 [09:15<33:29,  1.40s/it, training loss=0.1127]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 398/1835 [09:17<33:29,  1.40s/it, training loss=0.0568]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 399/1835 [09:17<33:29,  1.40s/it, training loss=0.0568]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 399/1835 [09:18<33:29,  1.40s/it, training loss=0.0978]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 400/1835 [09:18<33:27,  1.40s/it, training loss=0.0978]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 400/1835 [09:20<33:27,  1.40s/it, training loss=0.0558]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 401/1835 [09:20<33:25,  1.40s/it, training loss=0.0558]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 401/1835 [09:21<33:25,  1.40s/it, training loss=0.1961]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 402/1835 [09:21<33:24,  1.40s/it, training loss=0.1961]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 402/1835 [09:22<33:24,  1.40s/it, training loss=0.0575]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 403/1835 [09:22<33:24,  1.40s/it, training loss=0.0575]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 403/1835 [09:24<33:24,  1.40s/it, training loss=0.0869]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 404/1835 [09:24<33:20,  1.40s/it, training loss=0.0869]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 404/1835 [09:25<33:20,  1.40s/it, training loss=0.1826]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 405/1835 [09:25<33:21,  1.40s/it, training loss=0.1826]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 405/1835 [09:27<33:21,  1.40s/it, training loss=0.1871]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 406/1835 [09:27<33:16,  1.40s/it, training loss=0.1871]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 406/1835 [09:28<33:16,  1.40s/it, training loss=0.0168]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 407/1835 [09:28<33:15,  1.40s/it, training loss=0.0168]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 407/1835 [09:29<33:15,  1.40s/it, training loss=0.1067]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 408/1835 [09:29<33:12,  1.40s/it, training loss=0.1067]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 408/1835 [09:31<33:12,  1.40s/it, training loss=0.1058]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 409/1835 [09:31<33:13,  1.40s/it, training loss=0.1058]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 409/1835 [09:32<33:13,  1.40s/it, training loss=0.1485]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 410/1835 [09:32<33:09,  1.40s/it, training loss=0.1485]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 410/1835 [09:34<33:09,  1.40s/it, training loss=0.1240]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 411/1835 [09:34<33:07,  1.40s/it, training loss=0.1240]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 411/1835 [09:35<33:07,  1.40s/it, training loss=0.0244]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 412/1835 [09:35<33:03,  1.39s/it, training loss=0.0244]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 412/1835 [09:36<33:03,  1.39s/it, training loss=0.2093]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 413/1835 [09:36<33:02,  1.39s/it, training loss=0.2093]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 413/1835 [09:38<33:02,  1.39s/it, training loss=0.1022]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 414/1835 [09:38<33:02,  1.40s/it, training loss=0.1022]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 414/1835 [09:39<33:02,  1.40s/it, training loss=0.1882]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 415/1835 [09:39<32:59,  1.39s/it, training loss=0.1882]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 415/1835 [09:40<32:59,  1.39s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 416/1835 [09:41<32:57,  1.39s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 416/1835 [09:42<32:57,  1.39s/it, training loss=0.0722]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 417/1835 [09:42<32:58,  1.40s/it, training loss=0.0722]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 417/1835 [09:43<32:58,  1.40s/it, training loss=0.1039]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 418/1835 [09:43<32:56,  1.40s/it, training loss=0.1039]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 418/1835 [09:45<32:56,  1.40s/it, training loss=0.0989]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 419/1835 [09:45<32:58,  1.40s/it, training loss=0.0989]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 419/1835 [09:46<32:58,  1.40s/it, training loss=0.0397]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 420/1835 [09:46<32:56,  1.40s/it, training loss=0.0397]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 420/1835 [09:47<32:56,  1.40s/it, training loss=0.1735]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 421/1835 [09:47<32:53,  1.40s/it, training loss=0.1735]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 421/1835 [09:49<32:53,  1.40s/it, training loss=0.1819]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 422/1835 [09:49<32:51,  1.40s/it, training loss=0.1819]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 422/1835 [09:50<32:51,  1.40s/it, training loss=0.1464]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 423/1835 [09:50<32:50,  1.40s/it, training loss=0.1464]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 423/1835 [09:52<32:50,  1.40s/it, training loss=0.1220]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 424/1835 [09:52<32:50,  1.40s/it, training loss=0.1220]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 424/1835 [09:53<32:50,  1.40s/it, training loss=0.1422]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 425/1835 [09:53<32:49,  1.40s/it, training loss=0.1422]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 425/1835 [09:54<32:49,  1.40s/it, training loss=0.0963]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 426/1835 [09:54<32:49,  1.40s/it, training loss=0.0963]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 426/1835 [09:56<32:49,  1.40s/it, training loss=0.1201]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 427/1835 [09:56<32:49,  1.40s/it, training loss=0.1201]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 427/1835 [09:57<32:49,  1.40s/it, training loss=0.0870]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 428/1835 [09:57<32:45,  1.40s/it, training loss=0.0870]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 428/1835 [09:59<32:45,  1.40s/it, training loss=0.0722]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 429/1835 [09:59<32:45,  1.40s/it, training loss=0.0722]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 429/1835 [10:00<32:45,  1.40s/it, training loss=0.0873]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 430/1835 [10:00<32:41,  1.40s/it, training loss=0.0873]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 430/1835 [10:01<32:41,  1.40s/it, training loss=0.0431]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 431/1835 [10:01<32:38,  1.39s/it, training loss=0.0431]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 431/1835 [10:03<32:38,  1.39s/it, training loss=0.2406]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 432/1835 [10:03<32:34,  1.39s/it, training loss=0.2406]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 432/1835 [10:04<32:34,  1.39s/it, training loss=0.0684]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 433/1835 [10:04<32:34,  1.39s/it, training loss=0.0684]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 433/1835 [10:06<32:34,  1.39s/it, training loss=0.2107]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 434/1835 [10:06<32:33,  1.39s/it, training loss=0.2107]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 434/1835 [10:07<32:33,  1.39s/it, training loss=0.0661]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 435/1835 [10:07<32:32,  1.39s/it, training loss=0.0661]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 435/1835 [10:08<32:32,  1.39s/it, training loss=0.1543]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 436/1835 [10:08<32:33,  1.40s/it, training loss=0.1543]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 436/1835 [10:10<32:33,  1.40s/it, training loss=0.0539]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 437/1835 [10:10<32:29,  1.39s/it, training loss=0.0539]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 437/1835 [10:11<32:29,  1.39s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 438/1835 [10:11<32:25,  1.39s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 438/1835 [10:13<32:25,  1.39s/it, training loss=0.1396]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 439/1835 [10:13<32:25,  1.39s/it, training loss=0.1396]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 439/1835 [10:14<32:25,  1.39s/it, training loss=0.2088]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 440/1835 [10:14<32:24,  1.39s/it, training loss=0.2088]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 440/1835 [10:15<32:24,  1.39s/it, training loss=0.0284]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 441/1835 [10:15<32:26,  1.40s/it, training loss=0.0284]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 441/1835 [10:17<32:26,  1.40s/it, training loss=0.1656]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 442/1835 [10:17<32:24,  1.40s/it, training loss=0.1656]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 442/1835 [10:18<32:24,  1.40s/it, training loss=0.0284]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 443/1835 [10:18<32:22,  1.40s/it, training loss=0.0284]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 443/1835 [10:20<32:22,  1.40s/it, training loss=0.1243]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 444/1835 [10:20<32:21,  1.40s/it, training loss=0.1243]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 444/1835 [10:21<32:21,  1.40s/it, training loss=0.0460]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 445/1835 [10:21<32:21,  1.40s/it, training loss=0.0460]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 445/1835 [10:22<32:21,  1.40s/it, training loss=0.0729]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 446/1835 [10:22<32:21,  1.40s/it, training loss=0.0729]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 446/1835 [10:24<32:21,  1.40s/it, training loss=0.1165]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 447/1835 [10:24<32:17,  1.40s/it, training loss=0.1165]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 447/1835 [10:25<32:17,  1.40s/it, training loss=0.0592]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 448/1835 [10:25<32:19,  1.40s/it, training loss=0.0592]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 448/1835 [10:27<32:19,  1.40s/it, training loss=0.0881]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 449/1835 [10:27<32:18,  1.40s/it, training loss=0.0881]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 449/1835 [10:28<32:18,  1.40s/it, training loss=0.0603]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 450/1835 [10:28<32:16,  1.40s/it, training loss=0.0603]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 450/1835 [10:29<32:16,  1.40s/it, training loss=0.0902]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 451/1835 [10:29<32:14,  1.40s/it, training loss=0.0902]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 451/1835 [10:31<32:14,  1.40s/it, training loss=0.0619]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 452/1835 [10:31<32:13,  1.40s/it, training loss=0.0619]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 452/1835 [10:32<32:13,  1.40s/it, training loss=0.1281]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 453/1835 [10:32<32:08,  1.40s/it, training loss=0.1281]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 453/1835 [10:34<32:08,  1.40s/it, training loss=0.1345]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 454/1835 [10:34<32:08,  1.40s/it, training loss=0.1345]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 454/1835 [10:35<32:08,  1.40s/it, training loss=0.0152]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 455/1835 [10:35<32:06,  1.40s/it, training loss=0.0152]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 455/1835 [10:36<32:06,  1.40s/it, training loss=0.1926]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 456/1835 [10:36<32:04,  1.40s/it, training loss=0.1926]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 456/1835 [10:38<32:04,  1.40s/it, training loss=0.0369]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 457/1835 [10:38<32:03,  1.40s/it, training loss=0.0369]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 457/1835 [10:39<32:03,  1.40s/it, training loss=0.1957]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 458/1835 [10:39<32:01,  1.40s/it, training loss=0.1957]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 458/1835 [10:41<32:01,  1.40s/it, training loss=0.1024]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 459/1835 [10:41<31:59,  1.39s/it, training loss=0.1024]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 459/1835 [10:42<31:59,  1.39s/it, training loss=0.1558]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 460/1835 [10:42<31:56,  1.39s/it, training loss=0.1558]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 460/1835 [10:43<31:56,  1.39s/it, training loss=0.0223]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 461/1835 [10:43<31:54,  1.39s/it, training loss=0.0223]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 461/1835 [10:45<31:54,  1.39s/it, training loss=0.1267]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 462/1835 [10:45<31:50,  1.39s/it, training loss=0.1267]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 462/1835 [10:46<31:50,  1.39s/it, training loss=0.0493]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 463/1835 [10:46<31:49,  1.39s/it, training loss=0.0493]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 463/1835 [10:47<31:49,  1.39s/it, training loss=0.1714]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 464/1835 [10:47<31:51,  1.39s/it, training loss=0.1714]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 464/1835 [10:49<31:51,  1.39s/it, training loss=0.1812]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 465/1835 [10:49<31:49,  1.39s/it, training loss=0.1812]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 465/1835 [10:50<31:49,  1.39s/it, training loss=0.2357]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 466/1835 [10:50<31:51,  1.40s/it, training loss=0.2357]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 466/1835 [10:52<31:51,  1.40s/it, training loss=0.3081]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 467/1835 [10:52<31:48,  1.39s/it, training loss=0.3081]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 467/1835 [10:53<31:48,  1.39s/it, training loss=0.0585]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 468/1835 [10:53<31:46,  1.39s/it, training loss=0.0585]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 468/1835 [10:54<31:46,  1.39s/it, training loss=0.0589]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 469/1835 [10:54<31:44,  1.39s/it, training loss=0.0589]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 469/1835 [10:56<31:44,  1.39s/it, training loss=0.0505]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 470/1835 [10:56<31:44,  1.40s/it, training loss=0.0505]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 470/1835 [10:57<31:44,  1.40s/it, training loss=0.1204]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 471/1835 [10:57<31:43,  1.40s/it, training loss=0.1204]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 471/1835 [10:59<31:43,  1.40s/it, training loss=0.0563]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 472/1835 [10:59<31:41,  1.39s/it, training loss=0.0563]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 472/1835 [11:00<31:41,  1.39s/it, training loss=0.0227]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 473/1835 [11:00<31:37,  1.39s/it, training loss=0.0227]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 473/1835 [11:01<31:37,  1.39s/it, training loss=0.0614]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 474/1835 [11:01<31:37,  1.39s/it, training loss=0.0614]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 474/1835 [11:03<31:37,  1.39s/it, training loss=0.0721]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 475/1835 [11:03<31:35,  1.39s/it, training loss=0.0721]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 475/1835 [11:04<31:35,  1.39s/it, training loss=0.1199]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 476/1835 [11:04<31:33,  1.39s/it, training loss=0.1199]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 476/1835 [11:06<31:33,  1.39s/it, training loss=0.1545]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 477/1835 [11:06<31:34,  1.39s/it, training loss=0.1545]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 477/1835 [11:07<31:34,  1.39s/it, training loss=0.1624]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 478/1835 [11:07<31:33,  1.40s/it, training loss=0.1624]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 478/1835 [11:08<31:33,  1.40s/it, training loss=0.1202]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 479/1835 [11:08<31:30,  1.39s/it, training loss=0.1202]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 479/1835 [11:10<31:30,  1.39s/it, training loss=0.0541]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 480/1835 [11:10<31:33,  1.40s/it, training loss=0.0541]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 480/1835 [11:11<31:33,  1.40s/it, training loss=0.1092]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 481/1835 [11:11<31:31,  1.40s/it, training loss=0.1092]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 481/1835 [11:13<31:31,  1.40s/it, training loss=0.0164]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 482/1835 [11:13<31:28,  1.40s/it, training loss=0.0164]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 482/1835 [11:14<31:28,  1.40s/it, training loss=0.2433]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 483/1835 [11:14<31:30,  1.40s/it, training loss=0.2433]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 483/1835 [11:15<31:30,  1.40s/it, training loss=0.1941]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 484/1835 [11:15<31:26,  1.40s/it, training loss=0.1941]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 484/1835 [11:17<31:26,  1.40s/it, training loss=0.0889]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 485/1835 [11:17<31:27,  1.40s/it, training loss=0.0889]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 485/1835 [11:18<31:27,  1.40s/it, training loss=0.0165]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 486/1835 [11:18<31:28,  1.40s/it, training loss=0.0165]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 486/1835 [11:20<31:28,  1.40s/it, training loss=0.1571]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 487/1835 [11:20<31:26,  1.40s/it, training loss=0.1571]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 487/1835 [11:21<31:26,  1.40s/it, training loss=0.1661]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 488/1835 [11:21<31:23,  1.40s/it, training loss=0.1661]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 488/1835 [11:22<31:23,  1.40s/it, training loss=0.0486]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 489/1835 [11:22<31:22,  1.40s/it, training loss=0.0486]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 489/1835 [11:24<31:22,  1.40s/it, training loss=0.2205]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 490/1835 [11:24<31:20,  1.40s/it, training loss=0.2205]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 490/1835 [11:25<31:20,  1.40s/it, training loss=0.0956]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 491/1835 [11:25<31:17,  1.40s/it, training loss=0.0956]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 491/1835 [11:27<31:17,  1.40s/it, training loss=0.1771]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 492/1835 [11:27<31:13,  1.40s/it, training loss=0.1771]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 492/1835 [11:28<31:13,  1.40s/it, training loss=0.1975]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 493/1835 [11:28<31:12,  1.40s/it, training loss=0.1975]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 493/1835 [11:29<31:12,  1.40s/it, training loss=0.1971]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 494/1835 [11:29<31:08,  1.39s/it, training loss=0.1971]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 494/1835 [11:31<31:08,  1.39s/it, training loss=0.1917]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 495/1835 [11:31<31:08,  1.39s/it, training loss=0.1917]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 495/1835 [11:32<31:08,  1.39s/it, training loss=0.1579]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 496/1835 [11:32<31:08,  1.40s/it, training loss=0.1579]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 496/1835 [11:34<31:08,  1.40s/it, training loss=0.0694]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 497/1835 [11:34<31:06,  1.40s/it, training loss=0.0694]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 497/1835 [11:35<31:06,  1.40s/it, training loss=0.0474]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 498/1835 [11:35<31:05,  1.40s/it, training loss=0.0474]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 498/1835 [11:36<31:05,  1.40s/it, training loss=0.2009]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 499/1835 [11:36<31:00,  1.39s/it, training loss=0.2009]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 499/1835 [11:38<31:00,  1.39s/it, training loss=0.1150]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 500/1835 [11:38<31:01,  1.39s/it, training loss=0.1150]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 500/1835 [11:39<31:01,  1.39s/it, training loss=0.1326]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 501/1835 [11:39<31:01,  1.40s/it, training loss=0.1326]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 501/1835 [11:41<31:01,  1.40s/it, training loss=0.1551]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 502/1835 [11:41<30:58,  1.39s/it, training loss=0.1551]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 502/1835 [11:42<30:58,  1.39s/it, training loss=0.1641]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 503/1835 [11:42<30:54,  1.39s/it, training loss=0.1641]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 503/1835 [11:43<30:54,  1.39s/it, training loss=0.0363]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 504/1835 [11:43<30:50,  1.39s/it, training loss=0.0363]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 504/1835 [11:45<30:50,  1.39s/it, training loss=0.0472]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 505/1835 [11:45<30:54,  1.39s/it, training loss=0.0472]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 505/1835 [11:46<30:54,  1.39s/it, training loss=0.2924]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 506/1835 [11:46<30:53,  1.39s/it, training loss=0.2924]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 506/1835 [11:47<30:53,  1.39s/it, training loss=0.1533]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 507/1835 [11:47<30:50,  1.39s/it, training loss=0.1533]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 507/1835 [11:49<30:50,  1.39s/it, training loss=0.1350]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 508/1835 [11:49<30:49,  1.39s/it, training loss=0.1350]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 508/1835 [11:50<30:49,  1.39s/it, training loss=0.0888]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 509/1835 [11:50<30:49,  1.40s/it, training loss=0.0888]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 509/1835 [11:52<30:49,  1.40s/it, training loss=0.0716]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 510/1835 [11:52<30:51,  1.40s/it, training loss=0.0716]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 510/1835 [11:53<30:51,  1.40s/it, training loss=0.0843]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 511/1835 [11:53<30:49,  1.40s/it, training loss=0.0843]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 511/1835 [11:54<30:49,  1.40s/it, training loss=0.1061]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 512/1835 [11:54<30:48,  1.40s/it, training loss=0.1061]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 512/1835 [11:56<30:48,  1.40s/it, training loss=0.1293]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 513/1835 [11:56<30:49,  1.40s/it, training loss=0.1293]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 513/1835 [11:57<30:49,  1.40s/it, training loss=0.2080]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 514/1835 [11:57<30:48,  1.40s/it, training loss=0.2080]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 514/1835 [11:59<30:48,  1.40s/it, training loss=0.2294]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 515/1835 [11:59<30:44,  1.40s/it, training loss=0.2294]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 515/1835 [12:00<30:44,  1.40s/it, training loss=0.1284]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 516/1835 [12:00<30:45,  1.40s/it, training loss=0.1284]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 516/1835 [12:01<30:45,  1.40s/it, training loss=0.0759]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 517/1835 [12:01<30:43,  1.40s/it, training loss=0.0759]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 517/1835 [12:03<30:43,  1.40s/it, training loss=0.1969]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 518/1835 [12:03<30:39,  1.40s/it, training loss=0.1969]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 518/1835 [12:04<30:39,  1.40s/it, training loss=0.2331]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 519/1835 [12:04<30:40,  1.40s/it, training loss=0.2331]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 519/1835 [12:06<30:40,  1.40s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 520/1835 [12:06<30:42,  1.40s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 520/1835 [12:07<30:42,  1.40s/it, training loss=0.0518]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 521/1835 [12:07<30:37,  1.40s/it, training loss=0.0518]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 521/1835 [12:08<30:37,  1.40s/it, training loss=0.0492]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 522/1835 [12:08<30:36,  1.40s/it, training loss=0.0492]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 522/1835 [12:10<30:36,  1.40s/it, training loss=0.0438]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 523/1835 [12:10<30:34,  1.40s/it, training loss=0.0438]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 523/1835 [12:11<30:34,  1.40s/it, training loss=0.1473]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 524/1835 [12:11<30:35,  1.40s/it, training loss=0.1473]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 524/1835 [12:13<30:35,  1.40s/it, training loss=0.1314]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 525/1835 [12:13<30:30,  1.40s/it, training loss=0.1314]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 525/1835 [12:14<30:30,  1.40s/it, training loss=0.0477]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 526/1835 [12:14<30:28,  1.40s/it, training loss=0.0477]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 526/1835 [12:15<30:28,  1.40s/it, training loss=0.1148]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 527/1835 [12:15<30:30,  1.40s/it, training loss=0.1148]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 527/1835 [12:17<30:30,  1.40s/it, training loss=0.1344]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 528/1835 [12:17<30:29,  1.40s/it, training loss=0.1344]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 528/1835 [12:18<30:29,  1.40s/it, training loss=0.0566]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 529/1835 [12:18<30:26,  1.40s/it, training loss=0.0566]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 529/1835 [12:20<30:26,  1.40s/it, training loss=0.0855]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 530/1835 [12:20<30:24,  1.40s/it, training loss=0.0855]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 530/1835 [12:21<30:24,  1.40s/it, training loss=0.1621]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 531/1835 [12:21<30:23,  1.40s/it, training loss=0.1621]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 531/1835 [12:22<30:23,  1.40s/it, training loss=0.3658]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 532/1835 [12:22<30:25,  1.40s/it, training loss=0.3658]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 532/1835 [12:24<30:25,  1.40s/it, training loss=0.2543]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 533/1835 [12:24<30:24,  1.40s/it, training loss=0.2543]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 533/1835 [12:25<30:24,  1.40s/it, training loss=0.0276]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 534/1835 [12:25<30:21,  1.40s/it, training loss=0.0276]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 534/1835 [12:27<30:21,  1.40s/it, training loss=0.1246]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 535/1835 [12:27<30:19,  1.40s/it, training loss=0.1246]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 535/1835 [12:28<30:19,  1.40s/it, training loss=0.0659]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 536/1835 [12:28<30:18,  1.40s/it, training loss=0.0659]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 536/1835 [12:29<30:18,  1.40s/it, training loss=0.0792]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 537/1835 [12:29<30:16,  1.40s/it, training loss=0.0792]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 537/1835 [12:31<30:16,  1.40s/it, training loss=0.0560]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 538/1835 [12:31<30:15,  1.40s/it, training loss=0.0560]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 538/1835 [12:32<30:15,  1.40s/it, training loss=0.1335]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 539/1835 [12:32<30:11,  1.40s/it, training loss=0.1335]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 539/1835 [12:34<30:11,  1.40s/it, training loss=0.2011]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 540/1835 [12:34<30:08,  1.40s/it, training loss=0.2011]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 540/1835 [12:35<30:08,  1.40s/it, training loss=0.1198]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 541/1835 [12:35<30:06,  1.40s/it, training loss=0.1198]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 541/1835 [12:36<30:06,  1.40s/it, training loss=0.0331]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 542/1835 [12:36<30:03,  1.39s/it, training loss=0.0331]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 542/1835 [12:38<30:03,  1.39s/it, training loss=0.1187]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 543/1835 [12:38<30:00,  1.39s/it, training loss=0.1187]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 543/1835 [12:39<30:00,  1.39s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 544/1835 [12:39<30:00,  1.39s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 544/1835 [12:41<30:00,  1.39s/it, training loss=0.0927]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 545/1835 [12:41<29:57,  1.39s/it, training loss=0.0927]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 545/1835 [12:42<29:57,  1.39s/it, training loss=0.0286]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 546/1835 [12:42<29:57,  1.39s/it, training loss=0.0286]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 546/1835 [12:43<29:57,  1.39s/it, training loss=0.1251]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 547/1835 [12:43<29:58,  1.40s/it, training loss=0.1251]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 547/1835 [12:45<29:58,  1.40s/it, training loss=0.0730]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 548/1835 [12:45<29:55,  1.39s/it, training loss=0.0730]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 548/1835 [12:46<29:55,  1.39s/it, training loss=0.1218]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 549/1835 [12:46<29:55,  1.40s/it, training loss=0.1218]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 549/1835 [12:48<29:55,  1.40s/it, training loss=0.1479]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 550/1835 [12:48<29:55,  1.40s/it, training loss=0.1479]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 550/1835 [12:49<29:55,  1.40s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 3:  30%|███       | 551/1835 [12:49<29:51,  1.40s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 3:  30%|███       | 551/1835 [12:50<29:51,  1.40s/it, training loss=0.0901]\u001b[A\n",
            "Epoch 3:  30%|███       | 552/1835 [12:50<29:50,  1.40s/it, training loss=0.0901]\u001b[A\n",
            "Epoch 3:  30%|███       | 552/1835 [12:52<29:50,  1.40s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 3:  30%|███       | 553/1835 [12:52<29:51,  1.40s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 3:  30%|███       | 553/1835 [12:53<29:51,  1.40s/it, training loss=0.0873]\u001b[A\n",
            "Epoch 3:  30%|███       | 554/1835 [12:53<29:47,  1.40s/it, training loss=0.0873]\u001b[A\n",
            "Epoch 3:  30%|███       | 554/1835 [12:55<29:47,  1.40s/it, training loss=0.1054]\u001b[A\n",
            "Epoch 3:  30%|███       | 555/1835 [12:55<29:46,  1.40s/it, training loss=0.1054]\u001b[A\n",
            "Epoch 3:  30%|███       | 555/1835 [12:56<29:46,  1.40s/it, training loss=0.0739]\u001b[A\n",
            "Epoch 3:  30%|███       | 556/1835 [12:56<29:44,  1.40s/it, training loss=0.0739]\u001b[A\n",
            "Epoch 3:  30%|███       | 556/1835 [12:57<29:44,  1.40s/it, training loss=0.0662]\u001b[A\n",
            "Epoch 3:  30%|███       | 557/1835 [12:57<29:46,  1.40s/it, training loss=0.0662]\u001b[A\n",
            "Epoch 3:  30%|███       | 557/1835 [12:59<29:46,  1.40s/it, training loss=0.0940]\u001b[A\n",
            "Epoch 3:  30%|███       | 558/1835 [12:59<29:42,  1.40s/it, training loss=0.0940]\u001b[A\n",
            "Epoch 3:  30%|███       | 558/1835 [13:00<29:42,  1.40s/it, training loss=0.0963]\u001b[A\n",
            "Epoch 3:  30%|███       | 559/1835 [13:00<29:42,  1.40s/it, training loss=0.0963]\u001b[A\n",
            "Epoch 3:  30%|███       | 559/1835 [13:02<29:42,  1.40s/it, training loss=0.1767]\u001b[A\n",
            "Epoch 3:  31%|███       | 560/1835 [13:02<29:41,  1.40s/it, training loss=0.1767]\u001b[A\n",
            "Epoch 3:  31%|███       | 560/1835 [13:03<29:41,  1.40s/it, training loss=0.2143]\u001b[A\n",
            "Epoch 3:  31%|███       | 561/1835 [13:03<29:40,  1.40s/it, training loss=0.2143]\u001b[A\n",
            "Epoch 3:  31%|███       | 561/1835 [13:04<29:40,  1.40s/it, training loss=0.0165]\u001b[A\n",
            "Epoch 3:  31%|███       | 562/1835 [13:04<29:45,  1.40s/it, training loss=0.0165]\u001b[A\n",
            "Epoch 3:  31%|███       | 562/1835 [13:06<29:45,  1.40s/it, training loss=0.1849]\u001b[A\n",
            "Epoch 3:  31%|███       | 563/1835 [13:06<29:40,  1.40s/it, training loss=0.1849]\u001b[A\n",
            "Epoch 3:  31%|███       | 563/1835 [13:07<29:40,  1.40s/it, training loss=0.0685]\u001b[A\n",
            "Epoch 3:  31%|███       | 564/1835 [13:07<29:37,  1.40s/it, training loss=0.0685]\u001b[A\n",
            "Epoch 3:  31%|███       | 564/1835 [13:09<29:37,  1.40s/it, training loss=0.2290]\u001b[A\n",
            "Epoch 3:  31%|███       | 565/1835 [13:09<29:36,  1.40s/it, training loss=0.2290]\u001b[A\n",
            "Epoch 3:  31%|███       | 565/1835 [13:10<29:36,  1.40s/it, training loss=0.0652]\u001b[A\n",
            "Epoch 3:  31%|███       | 566/1835 [13:10<29:35,  1.40s/it, training loss=0.0652]\u001b[A\n",
            "Epoch 3:  31%|███       | 566/1835 [13:11<29:35,  1.40s/it, training loss=0.0557]\u001b[A\n",
            "Epoch 3:  31%|███       | 567/1835 [13:11<29:33,  1.40s/it, training loss=0.0557]\u001b[A\n",
            "Epoch 3:  31%|███       | 567/1835 [13:13<29:33,  1.40s/it, training loss=0.0270]\u001b[A\n",
            "Epoch 3:  31%|███       | 568/1835 [13:13<29:30,  1.40s/it, training loss=0.0270]\u001b[A\n",
            "Epoch 3:  31%|███       | 568/1835 [13:14<29:30,  1.40s/it, training loss=0.1245]\u001b[A\n",
            "Epoch 3:  31%|███       | 569/1835 [13:14<29:28,  1.40s/it, training loss=0.1245]\u001b[A\n",
            "Epoch 3:  31%|███       | 569/1835 [13:16<29:28,  1.40s/it, training loss=0.0781]\u001b[A\n",
            "Epoch 3:  31%|███       | 570/1835 [13:16<29:26,  1.40s/it, training loss=0.0781]\u001b[A\n",
            "Epoch 3:  31%|███       | 570/1835 [13:17<29:26,  1.40s/it, training loss=0.0318]\u001b[A\n",
            "Epoch 3:  31%|███       | 571/1835 [13:17<29:22,  1.39s/it, training loss=0.0318]\u001b[A\n",
            "Epoch 3:  31%|███       | 571/1835 [13:18<29:22,  1.39s/it, training loss=0.2191]\u001b[A\n",
            "Epoch 3:  31%|███       | 572/1835 [13:18<29:19,  1.39s/it, training loss=0.2191]\u001b[A\n",
            "Epoch 3:  31%|███       | 572/1835 [13:20<29:19,  1.39s/it, training loss=0.0321]\u001b[A\n",
            "Epoch 3:  31%|███       | 573/1835 [13:20<29:16,  1.39s/it, training loss=0.0321]\u001b[A\n",
            "Epoch 3:  31%|███       | 573/1835 [13:21<29:16,  1.39s/it, training loss=0.1297]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 574/1835 [13:21<29:16,  1.39s/it, training loss=0.1297]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 574/1835 [13:23<29:16,  1.39s/it, training loss=0.2740]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 575/1835 [13:23<29:17,  1.40s/it, training loss=0.2740]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 575/1835 [13:24<29:17,  1.40s/it, training loss=0.1455]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 576/1835 [13:24<29:15,  1.39s/it, training loss=0.1455]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 576/1835 [13:25<29:15,  1.39s/it, training loss=0.1423]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 577/1835 [13:25<29:14,  1.39s/it, training loss=0.1423]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 577/1835 [13:27<29:14,  1.39s/it, training loss=0.0573]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 578/1835 [13:27<29:14,  1.40s/it, training loss=0.0573]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 578/1835 [13:28<29:14,  1.40s/it, training loss=0.0963]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 579/1835 [13:28<29:10,  1.39s/it, training loss=0.0963]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 579/1835 [13:29<29:10,  1.39s/it, training loss=0.1022]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 580/1835 [13:29<29:07,  1.39s/it, training loss=0.1022]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 580/1835 [13:31<29:07,  1.39s/it, training loss=0.2271]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 581/1835 [13:31<29:07,  1.39s/it, training loss=0.2271]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 581/1835 [13:32<29:07,  1.39s/it, training loss=0.1093]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 582/1835 [13:32<29:08,  1.40s/it, training loss=0.1093]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 582/1835 [13:34<29:08,  1.40s/it, training loss=0.1497]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 583/1835 [13:34<29:09,  1.40s/it, training loss=0.1497]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 583/1835 [13:35<29:09,  1.40s/it, training loss=0.2092]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 584/1835 [13:35<29:08,  1.40s/it, training loss=0.2092]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 584/1835 [13:36<29:08,  1.40s/it, training loss=0.1256]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 585/1835 [13:36<29:07,  1.40s/it, training loss=0.1256]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 585/1835 [13:38<29:07,  1.40s/it, training loss=0.0599]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 586/1835 [13:38<29:03,  1.40s/it, training loss=0.0599]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 586/1835 [13:39<29:03,  1.40s/it, training loss=0.0320]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 587/1835 [13:39<29:03,  1.40s/it, training loss=0.0320]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 587/1835 [13:41<29:03,  1.40s/it, training loss=0.1038]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 588/1835 [13:41<29:03,  1.40s/it, training loss=0.1038]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 588/1835 [13:42<29:03,  1.40s/it, training loss=0.2707]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 589/1835 [13:42<29:01,  1.40s/it, training loss=0.2707]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 589/1835 [13:43<29:01,  1.40s/it, training loss=0.1047]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 590/1835 [13:43<28:57,  1.40s/it, training loss=0.1047]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 590/1835 [13:45<28:57,  1.40s/it, training loss=0.0193]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 591/1835 [13:45<28:57,  1.40s/it, training loss=0.0193]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 591/1835 [13:46<28:57,  1.40s/it, training loss=0.0524]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 592/1835 [13:46<28:54,  1.40s/it, training loss=0.0524]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 592/1835 [13:48<28:54,  1.40s/it, training loss=0.1443]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 593/1835 [13:48<28:54,  1.40s/it, training loss=0.1443]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 593/1835 [13:49<28:54,  1.40s/it, training loss=0.1119]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 594/1835 [13:49<28:53,  1.40s/it, training loss=0.1119]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 594/1835 [13:50<28:53,  1.40s/it, training loss=0.0621]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 595/1835 [13:50<28:51,  1.40s/it, training loss=0.0621]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 595/1835 [13:52<28:51,  1.40s/it, training loss=0.0719]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 596/1835 [13:52<28:49,  1.40s/it, training loss=0.0719]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 596/1835 [13:53<28:49,  1.40s/it, training loss=0.1205]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 597/1835 [13:53<28:46,  1.39s/it, training loss=0.1205]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 597/1835 [13:55<28:46,  1.39s/it, training loss=0.0748]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 598/1835 [13:55<28:44,  1.39s/it, training loss=0.0748]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 598/1835 [13:56<28:44,  1.39s/it, training loss=0.0473]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 599/1835 [13:56<28:43,  1.39s/it, training loss=0.0473]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 599/1835 [13:57<28:43,  1.39s/it, training loss=0.2529]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 600/1835 [13:57<28:40,  1.39s/it, training loss=0.2529]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 600/1835 [13:59<28:40,  1.39s/it, training loss=0.0491]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 601/1835 [13:59<28:36,  1.39s/it, training loss=0.0491]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 601/1835 [14:00<28:36,  1.39s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 602/1835 [14:00<28:37,  1.39s/it, training loss=0.1505]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 602/1835 [14:02<28:37,  1.39s/it, training loss=0.1033]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 603/1835 [14:02<28:38,  1.39s/it, training loss=0.1033]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 603/1835 [14:03<28:38,  1.39s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 604/1835 [14:03<28:37,  1.40s/it, training loss=0.1386]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 604/1835 [14:04<28:37,  1.40s/it, training loss=0.2168]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 605/1835 [14:04<28:37,  1.40s/it, training loss=0.2168]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 605/1835 [14:06<28:37,  1.40s/it, training loss=0.0119]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 606/1835 [14:06<28:35,  1.40s/it, training loss=0.0119]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 606/1835 [14:07<28:35,  1.40s/it, training loss=0.0259]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 607/1835 [14:07<28:32,  1.39s/it, training loss=0.0259]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 607/1835 [14:09<28:32,  1.39s/it, training loss=0.2809]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 608/1835 [14:09<28:33,  1.40s/it, training loss=0.2809]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 608/1835 [14:10<28:33,  1.40s/it, training loss=0.2627]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 609/1835 [14:10<28:31,  1.40s/it, training loss=0.2627]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 609/1835 [14:11<28:31,  1.40s/it, training loss=0.1952]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 610/1835 [14:11<28:29,  1.40s/it, training loss=0.1952]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 610/1835 [14:13<28:29,  1.40s/it, training loss=0.0911]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 611/1835 [14:13<28:26,  1.39s/it, training loss=0.0911]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 611/1835 [14:14<28:26,  1.39s/it, training loss=0.1145]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 612/1835 [14:14<28:24,  1.39s/it, training loss=0.1145]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 612/1835 [14:16<28:24,  1.39s/it, training loss=0.2149]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 613/1835 [14:16<28:25,  1.40s/it, training loss=0.2149]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 613/1835 [14:17<28:25,  1.40s/it, training loss=0.0838]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 614/1835 [14:17<28:26,  1.40s/it, training loss=0.0838]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 614/1835 [14:18<28:26,  1.40s/it, training loss=0.0242]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 615/1835 [14:18<28:27,  1.40s/it, training loss=0.0242]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 615/1835 [14:20<28:27,  1.40s/it, training loss=0.0674]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 616/1835 [14:20<28:28,  1.40s/it, training loss=0.0674]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 616/1835 [14:21<28:28,  1.40s/it, training loss=0.1826]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 617/1835 [14:21<28:23,  1.40s/it, training loss=0.1826]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 617/1835 [14:23<28:23,  1.40s/it, training loss=0.1676]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 618/1835 [14:23<28:26,  1.40s/it, training loss=0.1676]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 618/1835 [14:24<28:26,  1.40s/it, training loss=0.1070]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 619/1835 [14:24<28:27,  1.40s/it, training loss=0.1070]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 619/1835 [14:25<28:27,  1.40s/it, training loss=0.0359]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 620/1835 [14:25<28:21,  1.40s/it, training loss=0.0359]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 620/1835 [14:27<28:21,  1.40s/it, training loss=0.1049]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 621/1835 [14:27<28:19,  1.40s/it, training loss=0.1049]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 621/1835 [14:28<28:19,  1.40s/it, training loss=0.0762]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 622/1835 [14:28<28:20,  1.40s/it, training loss=0.0762]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 622/1835 [14:30<28:20,  1.40s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 623/1835 [14:30<28:17,  1.40s/it, training loss=0.1490]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 623/1835 [14:31<28:17,  1.40s/it, training loss=0.1492]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 624/1835 [14:31<28:14,  1.40s/it, training loss=0.1492]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 624/1835 [14:32<28:14,  1.40s/it, training loss=0.2368]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 625/1835 [14:32<28:12,  1.40s/it, training loss=0.2368]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 625/1835 [14:34<28:12,  1.40s/it, training loss=0.1778]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 626/1835 [14:34<28:10,  1.40s/it, training loss=0.1778]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 626/1835 [14:35<28:10,  1.40s/it, training loss=0.0624]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 627/1835 [14:35<28:08,  1.40s/it, training loss=0.0624]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 627/1835 [14:37<28:08,  1.40s/it, training loss=0.0493]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 628/1835 [14:37<28:06,  1.40s/it, training loss=0.0493]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 628/1835 [14:38<28:06,  1.40s/it, training loss=0.2655]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 629/1835 [14:38<28:07,  1.40s/it, training loss=0.2655]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 629/1835 [14:39<28:07,  1.40s/it, training loss=0.0895]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 630/1835 [14:39<28:06,  1.40s/it, training loss=0.0895]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 630/1835 [14:41<28:06,  1.40s/it, training loss=0.1116]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 631/1835 [14:41<28:03,  1.40s/it, training loss=0.1116]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 631/1835 [14:42<28:03,  1.40s/it, training loss=0.0843]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 632/1835 [14:42<27:58,  1.40s/it, training loss=0.0843]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 632/1835 [14:44<27:58,  1.40s/it, training loss=0.2019]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 633/1835 [14:44<27:59,  1.40s/it, training loss=0.2019]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 633/1835 [14:45<27:59,  1.40s/it, training loss=0.0856]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 634/1835 [14:45<27:56,  1.40s/it, training loss=0.0856]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 634/1835 [14:46<27:56,  1.40s/it, training loss=0.0309]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 635/1835 [14:46<27:56,  1.40s/it, training loss=0.0309]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 635/1835 [14:48<27:56,  1.40s/it, training loss=0.0958]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 636/1835 [14:48<27:53,  1.40s/it, training loss=0.0958]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 636/1835 [14:49<27:53,  1.40s/it, training loss=0.0187]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 637/1835 [14:49<27:54,  1.40s/it, training loss=0.0187]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 637/1835 [14:51<27:54,  1.40s/it, training loss=0.0378]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 638/1835 [14:51<27:53,  1.40s/it, training loss=0.0378]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 638/1835 [14:52<27:53,  1.40s/it, training loss=0.0319]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 639/1835 [14:52<27:52,  1.40s/it, training loss=0.0319]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 639/1835 [14:53<27:52,  1.40s/it, training loss=0.0717]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 640/1835 [14:53<27:49,  1.40s/it, training loss=0.0717]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 640/1835 [14:55<27:49,  1.40s/it, training loss=0.2159]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 641/1835 [14:55<27:48,  1.40s/it, training loss=0.2159]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 641/1835 [14:56<27:48,  1.40s/it, training loss=0.0453]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 642/1835 [14:56<27:48,  1.40s/it, training loss=0.0453]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 642/1835 [14:57<27:48,  1.40s/it, training loss=0.0384]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 643/1835 [14:58<27:44,  1.40s/it, training loss=0.0384]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 643/1835 [14:59<27:44,  1.40s/it, training loss=0.0529]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 644/1835 [14:59<27:40,  1.39s/it, training loss=0.0529]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 644/1835 [15:00<27:40,  1.39s/it, training loss=0.1034]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 645/1835 [15:00<27:40,  1.40s/it, training loss=0.1034]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 645/1835 [15:02<27:40,  1.40s/it, training loss=0.1253]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 646/1835 [15:02<27:36,  1.39s/it, training loss=0.1253]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 646/1835 [15:03<27:36,  1.39s/it, training loss=0.1070]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 647/1835 [15:03<27:33,  1.39s/it, training loss=0.1070]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 647/1835 [15:04<27:33,  1.39s/it, training loss=0.1056]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 648/1835 [15:04<27:31,  1.39s/it, training loss=0.1056]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 648/1835 [15:06<27:31,  1.39s/it, training loss=0.0802]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 649/1835 [15:06<27:32,  1.39s/it, training loss=0.0802]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 649/1835 [15:07<27:32,  1.39s/it, training loss=0.1041]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 650/1835 [15:07<27:31,  1.39s/it, training loss=0.1041]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 650/1835 [15:09<27:31,  1.39s/it, training loss=0.1209]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 651/1835 [15:09<27:30,  1.39s/it, training loss=0.1209]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 651/1835 [15:10<27:30,  1.39s/it, training loss=0.1076]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 652/1835 [15:10<27:28,  1.39s/it, training loss=0.1076]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 652/1835 [15:11<27:28,  1.39s/it, training loss=0.1418]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 653/1835 [15:11<27:24,  1.39s/it, training loss=0.1418]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 653/1835 [15:13<27:24,  1.39s/it, training loss=0.1440]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 654/1835 [15:13<27:23,  1.39s/it, training loss=0.1440]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 654/1835 [15:14<27:23,  1.39s/it, training loss=0.2117]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 655/1835 [15:14<27:21,  1.39s/it, training loss=0.2117]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 655/1835 [15:16<27:21,  1.39s/it, training loss=0.0422]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 656/1835 [15:16<27:20,  1.39s/it, training loss=0.0422]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 656/1835 [15:17<27:20,  1.39s/it, training loss=0.0990]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 657/1835 [15:17<27:19,  1.39s/it, training loss=0.0990]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 657/1835 [15:18<27:19,  1.39s/it, training loss=0.2499]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 658/1835 [15:18<27:18,  1.39s/it, training loss=0.2499]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 658/1835 [15:20<27:18,  1.39s/it, training loss=0.2611]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 659/1835 [15:20<27:17,  1.39s/it, training loss=0.2611]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 659/1835 [15:21<27:17,  1.39s/it, training loss=0.1593]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 660/1835 [15:21<27:15,  1.39s/it, training loss=0.1593]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 660/1835 [15:23<27:15,  1.39s/it, training loss=0.1503]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 661/1835 [15:23<27:14,  1.39s/it, training loss=0.1503]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 661/1835 [15:24<27:14,  1.39s/it, training loss=0.0768]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 662/1835 [15:24<27:14,  1.39s/it, training loss=0.0768]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 662/1835 [15:25<27:14,  1.39s/it, training loss=0.0243]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 663/1835 [15:25<27:12,  1.39s/it, training loss=0.0243]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 663/1835 [15:27<27:12,  1.39s/it, training loss=0.0174]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 664/1835 [15:27<27:12,  1.39s/it, training loss=0.0174]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 664/1835 [15:28<27:12,  1.39s/it, training loss=0.0097]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 665/1835 [15:28<27:12,  1.40s/it, training loss=0.0097]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 665/1835 [15:30<27:12,  1.40s/it, training loss=0.1676]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 666/1835 [15:30<27:14,  1.40s/it, training loss=0.1676]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 666/1835 [15:31<27:14,  1.40s/it, training loss=0.1152]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 667/1835 [15:31<27:12,  1.40s/it, training loss=0.1152]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 667/1835 [15:32<27:12,  1.40s/it, training loss=0.1716]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 668/1835 [15:32<27:10,  1.40s/it, training loss=0.1716]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 668/1835 [15:34<27:10,  1.40s/it, training loss=0.2013]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 669/1835 [15:34<27:08,  1.40s/it, training loss=0.2013]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 669/1835 [15:35<27:08,  1.40s/it, training loss=0.1207]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 670/1835 [15:35<27:05,  1.40s/it, training loss=0.1207]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 670/1835 [15:37<27:05,  1.40s/it, training loss=0.1312]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 671/1835 [15:37<27:04,  1.40s/it, training loss=0.1312]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 671/1835 [15:38<27:04,  1.40s/it, training loss=0.2374]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 672/1835 [15:38<27:01,  1.39s/it, training loss=0.2374]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 672/1835 [15:39<27:01,  1.39s/it, training loss=0.1210]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 673/1835 [15:39<27:01,  1.40s/it, training loss=0.1210]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 673/1835 [15:41<27:01,  1.40s/it, training loss=0.1654]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 674/1835 [15:41<26:59,  1.39s/it, training loss=0.1654]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 674/1835 [15:42<26:59,  1.39s/it, training loss=0.0705]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 675/1835 [15:42<26:57,  1.39s/it, training loss=0.0705]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 675/1835 [15:43<26:57,  1.39s/it, training loss=0.0933]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 676/1835 [15:43<26:54,  1.39s/it, training loss=0.0933]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 676/1835 [15:45<26:54,  1.39s/it, training loss=0.0186]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 677/1835 [15:45<26:55,  1.39s/it, training loss=0.0186]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 677/1835 [15:46<26:55,  1.39s/it, training loss=0.0969]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 678/1835 [15:46<26:53,  1.39s/it, training loss=0.0969]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 678/1835 [15:48<26:53,  1.39s/it, training loss=0.1953]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 679/1835 [15:48<26:51,  1.39s/it, training loss=0.1953]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 679/1835 [15:49<26:51,  1.39s/it, training loss=0.1300]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 680/1835 [15:49<26:47,  1.39s/it, training loss=0.1300]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 680/1835 [15:50<26:47,  1.39s/it, training loss=0.0516]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 681/1835 [15:50<26:47,  1.39s/it, training loss=0.0516]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 681/1835 [15:52<26:47,  1.39s/it, training loss=0.0573]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 682/1835 [15:52<26:45,  1.39s/it, training loss=0.0573]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 682/1835 [15:53<26:45,  1.39s/it, training loss=0.3926]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 683/1835 [15:53<26:46,  1.39s/it, training loss=0.3926]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 683/1835 [15:55<26:46,  1.39s/it, training loss=0.1390]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 684/1835 [15:55<26:44,  1.39s/it, training loss=0.1390]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 684/1835 [15:56<26:44,  1.39s/it, training loss=0.1009]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 685/1835 [15:56<26:43,  1.39s/it, training loss=0.1009]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 685/1835 [15:57<26:43,  1.39s/it, training loss=0.1564]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 686/1835 [15:57<26:42,  1.40s/it, training loss=0.1564]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 686/1835 [15:59<26:42,  1.40s/it, training loss=0.1343]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 687/1835 [15:59<26:37,  1.39s/it, training loss=0.1343]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 687/1835 [16:00<26:37,  1.39s/it, training loss=0.0520]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 688/1835 [16:00<26:36,  1.39s/it, training loss=0.0520]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 688/1835 [16:02<26:36,  1.39s/it, training loss=0.1456]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 689/1835 [16:02<26:34,  1.39s/it, training loss=0.1456]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 689/1835 [16:03<26:34,  1.39s/it, training loss=0.0599]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 690/1835 [16:03<26:31,  1.39s/it, training loss=0.0599]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 690/1835 [16:04<26:31,  1.39s/it, training loss=0.2532]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 691/1835 [16:04<26:34,  1.39s/it, training loss=0.2532]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 691/1835 [16:06<26:34,  1.39s/it, training loss=0.0830]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 692/1835 [16:06<26:33,  1.39s/it, training loss=0.0830]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 692/1835 [16:07<26:33,  1.39s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 693/1835 [16:07<26:30,  1.39s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 693/1835 [16:09<26:30,  1.39s/it, training loss=0.0318]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 694/1835 [16:09<26:28,  1.39s/it, training loss=0.0318]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 694/1835 [16:10<26:28,  1.39s/it, training loss=0.0687]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 695/1835 [16:10<26:26,  1.39s/it, training loss=0.0687]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 695/1835 [16:11<26:26,  1.39s/it, training loss=0.0575]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 696/1835 [16:11<26:25,  1.39s/it, training loss=0.0575]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 696/1835 [16:13<26:25,  1.39s/it, training loss=0.2555]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 697/1835 [16:13<26:23,  1.39s/it, training loss=0.2555]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 697/1835 [16:14<26:23,  1.39s/it, training loss=0.0403]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 698/1835 [16:14<26:18,  1.39s/it, training loss=0.0403]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 698/1835 [16:15<26:18,  1.39s/it, training loss=0.2217]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 699/1835 [16:16<26:17,  1.39s/it, training loss=0.2217]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 699/1835 [16:17<26:17,  1.39s/it, training loss=0.1764]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 700/1835 [16:17<26:16,  1.39s/it, training loss=0.1764]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 700/1835 [16:18<26:16,  1.39s/it, training loss=0.2078]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 701/1835 [16:18<26:13,  1.39s/it, training loss=0.2078]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 701/1835 [16:20<26:13,  1.39s/it, training loss=0.0366]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 702/1835 [16:20<26:12,  1.39s/it, training loss=0.0366]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 702/1835 [16:21<26:12,  1.39s/it, training loss=0.0794]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 703/1835 [16:21<26:11,  1.39s/it, training loss=0.0794]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 703/1835 [16:22<26:11,  1.39s/it, training loss=0.1551]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 704/1835 [16:22<26:11,  1.39s/it, training loss=0.1551]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 704/1835 [16:24<26:11,  1.39s/it, training loss=0.0553]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 705/1835 [16:24<26:08,  1.39s/it, training loss=0.0553]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 705/1835 [16:25<26:08,  1.39s/it, training loss=0.1376]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 706/1835 [16:25<26:10,  1.39s/it, training loss=0.1376]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 706/1835 [16:27<26:10,  1.39s/it, training loss=0.0302]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 707/1835 [16:27<26:12,  1.39s/it, training loss=0.0302]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 707/1835 [16:28<26:12,  1.39s/it, training loss=0.0496]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 708/1835 [16:28<26:13,  1.40s/it, training loss=0.0496]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 708/1835 [16:29<26:13,  1.40s/it, training loss=0.1423]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 709/1835 [16:29<26:11,  1.40s/it, training loss=0.1423]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 709/1835 [16:31<26:11,  1.40s/it, training loss=0.0941]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 710/1835 [16:31<26:12,  1.40s/it, training loss=0.0941]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 710/1835 [16:32<26:12,  1.40s/it, training loss=0.1611]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 711/1835 [16:32<26:08,  1.40s/it, training loss=0.1611]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 711/1835 [16:34<26:08,  1.40s/it, training loss=0.1206]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 712/1835 [16:34<26:05,  1.39s/it, training loss=0.1206]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 712/1835 [16:35<26:05,  1.39s/it, training loss=0.1918]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 713/1835 [16:35<26:04,  1.39s/it, training loss=0.1918]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 713/1835 [16:36<26:04,  1.39s/it, training loss=0.0669]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 714/1835 [16:36<26:05,  1.40s/it, training loss=0.0669]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 714/1835 [16:38<26:05,  1.40s/it, training loss=0.1435]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 715/1835 [16:38<26:02,  1.40s/it, training loss=0.1435]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 715/1835 [16:39<26:02,  1.40s/it, training loss=0.0298]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 716/1835 [16:39<26:02,  1.40s/it, training loss=0.0298]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 716/1835 [16:41<26:02,  1.40s/it, training loss=0.0956]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 717/1835 [16:41<26:02,  1.40s/it, training loss=0.0956]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 717/1835 [16:42<26:02,  1.40s/it, training loss=0.1594]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 718/1835 [16:42<26:00,  1.40s/it, training loss=0.1594]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 718/1835 [16:43<26:00,  1.40s/it, training loss=0.1785]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 719/1835 [16:43<25:58,  1.40s/it, training loss=0.1785]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 719/1835 [16:45<25:58,  1.40s/it, training loss=0.0354]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 720/1835 [16:45<25:57,  1.40s/it, training loss=0.0354]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 720/1835 [16:46<25:57,  1.40s/it, training loss=0.1127]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 721/1835 [16:46<25:53,  1.39s/it, training loss=0.1127]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 721/1835 [16:48<25:53,  1.39s/it, training loss=0.1495]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 722/1835 [16:48<25:51,  1.39s/it, training loss=0.1495]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 722/1835 [16:49<25:51,  1.39s/it, training loss=0.0325]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 723/1835 [16:49<25:51,  1.39s/it, training loss=0.0325]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 723/1835 [16:50<25:51,  1.39s/it, training loss=0.1259]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 724/1835 [16:50<25:49,  1.39s/it, training loss=0.1259]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 724/1835 [16:52<25:49,  1.39s/it, training loss=0.0966]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 725/1835 [16:52<25:46,  1.39s/it, training loss=0.0966]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 725/1835 [16:53<25:46,  1.39s/it, training loss=0.0690]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 726/1835 [16:53<25:45,  1.39s/it, training loss=0.0690]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 726/1835 [16:55<25:45,  1.39s/it, training loss=0.0905]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 727/1835 [16:55<25:44,  1.39s/it, training loss=0.0905]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 727/1835 [16:56<25:44,  1.39s/it, training loss=0.1520]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 728/1835 [16:56<25:43,  1.39s/it, training loss=0.1520]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 728/1835 [16:57<25:43,  1.39s/it, training loss=0.0599]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 729/1835 [16:57<25:44,  1.40s/it, training loss=0.0599]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 729/1835 [16:59<25:44,  1.40s/it, training loss=0.2957]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 730/1835 [16:59<25:44,  1.40s/it, training loss=0.2957]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 730/1835 [17:00<25:44,  1.40s/it, training loss=0.0763]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 731/1835 [17:00<25:44,  1.40s/it, training loss=0.0763]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 731/1835 [17:02<25:44,  1.40s/it, training loss=0.3144]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 732/1835 [17:02<25:40,  1.40s/it, training loss=0.3144]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 732/1835 [17:03<25:40,  1.40s/it, training loss=0.1456]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 733/1835 [17:03<25:39,  1.40s/it, training loss=0.1456]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 733/1835 [17:04<25:39,  1.40s/it, training loss=0.1314]\u001b[A\n",
            "Epoch 3:  40%|████      | 734/1835 [17:04<25:37,  1.40s/it, training loss=0.1314]\u001b[A\n",
            "Epoch 3:  40%|████      | 734/1835 [17:06<25:37,  1.40s/it, training loss=0.1470]\u001b[A\n",
            "Epoch 3:  40%|████      | 735/1835 [17:06<25:36,  1.40s/it, training loss=0.1470]\u001b[A\n",
            "Epoch 3:  40%|████      | 735/1835 [17:07<25:36,  1.40s/it, training loss=0.0647]\u001b[A\n",
            "Epoch 3:  40%|████      | 736/1835 [17:07<25:35,  1.40s/it, training loss=0.0647]\u001b[A\n",
            "Epoch 3:  40%|████      | 736/1835 [17:09<25:35,  1.40s/it, training loss=0.0937]\u001b[A\n",
            "Epoch 3:  40%|████      | 737/1835 [17:09<25:33,  1.40s/it, training loss=0.0937]\u001b[A\n",
            "Epoch 3:  40%|████      | 737/1835 [17:10<25:33,  1.40s/it, training loss=0.0750]\u001b[A\n",
            "Epoch 3:  40%|████      | 738/1835 [17:10<25:33,  1.40s/it, training loss=0.0750]\u001b[A\n",
            "Epoch 3:  40%|████      | 738/1835 [17:11<25:33,  1.40s/it, training loss=0.0564]\u001b[A\n",
            "Epoch 3:  40%|████      | 739/1835 [17:11<25:30,  1.40s/it, training loss=0.0564]\u001b[A\n",
            "Epoch 3:  40%|████      | 739/1835 [17:13<25:30,  1.40s/it, training loss=0.0229]\u001b[A\n",
            "Epoch 3:  40%|████      | 740/1835 [17:13<25:28,  1.40s/it, training loss=0.0229]\u001b[A\n",
            "Epoch 3:  40%|████      | 740/1835 [17:14<25:28,  1.40s/it, training loss=0.0827]\u001b[A\n",
            "Epoch 3:  40%|████      | 741/1835 [17:14<25:30,  1.40s/it, training loss=0.0827]\u001b[A\n",
            "Epoch 3:  40%|████      | 741/1835 [17:15<25:30,  1.40s/it, training loss=0.0788]\u001b[A\n",
            "Epoch 3:  40%|████      | 742/1835 [17:16<25:25,  1.40s/it, training loss=0.0788]\u001b[A\n",
            "Epoch 3:  40%|████      | 742/1835 [17:17<25:25,  1.40s/it, training loss=0.1387]\u001b[A\n",
            "Epoch 3:  40%|████      | 743/1835 [17:17<25:25,  1.40s/it, training loss=0.1387]\u001b[A\n",
            "Epoch 3:  40%|████      | 743/1835 [17:18<25:25,  1.40s/it, training loss=0.0339]\u001b[A\n",
            "Epoch 3:  41%|████      | 744/1835 [17:18<25:25,  1.40s/it, training loss=0.0339]\u001b[A\n",
            "Epoch 3:  41%|████      | 744/1835 [17:20<25:25,  1.40s/it, training loss=0.0187]\u001b[A\n",
            "Epoch 3:  41%|████      | 745/1835 [17:20<25:22,  1.40s/it, training loss=0.0187]\u001b[A\n",
            "Epoch 3:  41%|████      | 745/1835 [17:21<25:22,  1.40s/it, training loss=0.1781]\u001b[A\n",
            "Epoch 3:  41%|████      | 746/1835 [17:21<25:18,  1.39s/it, training loss=0.1781]\u001b[A\n",
            "Epoch 3:  41%|████      | 746/1835 [17:22<25:18,  1.39s/it, training loss=0.0776]\u001b[A\n",
            "Epoch 3:  41%|████      | 747/1835 [17:22<25:21,  1.40s/it, training loss=0.0776]\u001b[A\n",
            "Epoch 3:  41%|████      | 747/1835 [17:24<25:21,  1.40s/it, training loss=0.2101]\u001b[A\n",
            "Epoch 3:  41%|████      | 748/1835 [17:24<25:18,  1.40s/it, training loss=0.2101]\u001b[A\n",
            "Epoch 3:  41%|████      | 748/1835 [17:25<25:18,  1.40s/it, training loss=0.0834]\u001b[A\n",
            "Epoch 3:  41%|████      | 749/1835 [17:25<25:14,  1.39s/it, training loss=0.0834]\u001b[A\n",
            "Epoch 3:  41%|████      | 749/1835 [17:27<25:14,  1.39s/it, training loss=0.1827]\u001b[A\n",
            "Epoch 3:  41%|████      | 750/1835 [17:27<25:14,  1.40s/it, training loss=0.1827]\u001b[A\n",
            "Epoch 3:  41%|████      | 750/1835 [17:28<25:14,  1.40s/it, training loss=0.0821]\u001b[A\n",
            "Epoch 3:  41%|████      | 751/1835 [17:28<25:13,  1.40s/it, training loss=0.0821]\u001b[A\n",
            "Epoch 3:  41%|████      | 751/1835 [17:29<25:13,  1.40s/it, training loss=0.1599]\u001b[A\n",
            "Epoch 3:  41%|████      | 752/1835 [17:29<25:12,  1.40s/it, training loss=0.1599]\u001b[A\n",
            "Epoch 3:  41%|████      | 752/1835 [17:31<25:12,  1.40s/it, training loss=0.0491]\u001b[A\n",
            "Epoch 3:  41%|████      | 753/1835 [17:31<25:09,  1.40s/it, training loss=0.0491]\u001b[A\n",
            "Epoch 3:  41%|████      | 753/1835 [17:32<25:09,  1.40s/it, training loss=0.1468]\u001b[A\n",
            "Epoch 3:  41%|████      | 754/1835 [17:32<25:09,  1.40s/it, training loss=0.1468]\u001b[A\n",
            "Epoch 3:  41%|████      | 754/1835 [17:34<25:09,  1.40s/it, training loss=0.1460]\u001b[A\n",
            "Epoch 3:  41%|████      | 755/1835 [17:34<25:06,  1.40s/it, training loss=0.1460]\u001b[A\n",
            "Epoch 3:  41%|████      | 755/1835 [17:35<25:06,  1.40s/it, training loss=0.2567]\u001b[A\n",
            "Epoch 3:  41%|████      | 756/1835 [17:35<25:06,  1.40s/it, training loss=0.2567]\u001b[A\n",
            "Epoch 3:  41%|████      | 756/1835 [17:36<25:06,  1.40s/it, training loss=0.0560]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 757/1835 [17:36<25:04,  1.40s/it, training loss=0.0560]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 757/1835 [17:38<25:04,  1.40s/it, training loss=0.0262]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 758/1835 [17:38<25:03,  1.40s/it, training loss=0.0262]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 758/1835 [17:39<25:03,  1.40s/it, training loss=0.0762]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 759/1835 [17:39<25:01,  1.40s/it, training loss=0.0762]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 759/1835 [17:41<25:01,  1.40s/it, training loss=0.0735]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 760/1835 [17:41<24:59,  1.39s/it, training loss=0.0735]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 760/1835 [17:42<24:59,  1.39s/it, training loss=0.0802]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 761/1835 [17:42<24:59,  1.40s/it, training loss=0.0802]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 761/1835 [17:43<24:59,  1.40s/it, training loss=0.0998]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 762/1835 [17:43<24:54,  1.39s/it, training loss=0.0998]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 762/1835 [17:45<24:54,  1.39s/it, training loss=0.1145]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 763/1835 [17:45<24:53,  1.39s/it, training loss=0.1145]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 763/1835 [17:46<24:53,  1.39s/it, training loss=0.1274]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 764/1835 [17:46<24:55,  1.40s/it, training loss=0.1274]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 764/1835 [17:48<24:55,  1.40s/it, training loss=0.2061]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 765/1835 [17:48<24:52,  1.39s/it, training loss=0.2061]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 765/1835 [17:49<24:52,  1.39s/it, training loss=0.1573]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 766/1835 [17:49<24:57,  1.40s/it, training loss=0.1573]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 766/1835 [17:50<24:57,  1.40s/it, training loss=0.1337]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 767/1835 [17:50<24:53,  1.40s/it, training loss=0.1337]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 767/1835 [17:52<24:53,  1.40s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 768/1835 [17:52<24:50,  1.40s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 768/1835 [17:53<24:50,  1.40s/it, training loss=0.0623]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 769/1835 [17:53<24:48,  1.40s/it, training loss=0.0623]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 769/1835 [17:55<24:48,  1.40s/it, training loss=0.0448]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 770/1835 [17:55<24:46,  1.40s/it, training loss=0.0448]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 770/1835 [17:56<24:46,  1.40s/it, training loss=0.0701]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 771/1835 [17:56<24:42,  1.39s/it, training loss=0.0701]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 771/1835 [17:57<24:42,  1.39s/it, training loss=0.0478]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 772/1835 [17:57<24:44,  1.40s/it, training loss=0.0478]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 772/1835 [17:59<24:44,  1.40s/it, training loss=0.1741]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 773/1835 [17:59<24:42,  1.40s/it, training loss=0.1741]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 773/1835 [18:00<24:42,  1.40s/it, training loss=0.0549]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 774/1835 [18:00<24:41,  1.40s/it, training loss=0.0549]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 774/1835 [18:02<24:41,  1.40s/it, training loss=0.1252]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 775/1835 [18:02<24:38,  1.40s/it, training loss=0.1252]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 775/1835 [18:03<24:38,  1.40s/it, training loss=0.1315]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 776/1835 [18:03<24:35,  1.39s/it, training loss=0.1315]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 776/1835 [18:04<24:35,  1.39s/it, training loss=0.0552]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 777/1835 [18:04<24:32,  1.39s/it, training loss=0.0552]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 777/1835 [18:06<24:32,  1.39s/it, training loss=0.0172]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 778/1835 [18:06<24:30,  1.39s/it, training loss=0.0172]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 778/1835 [18:07<24:30,  1.39s/it, training loss=0.0431]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 779/1835 [18:07<24:29,  1.39s/it, training loss=0.0431]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 779/1835 [18:09<24:29,  1.39s/it, training loss=0.0744]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 780/1835 [18:09<24:25,  1.39s/it, training loss=0.0744]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 780/1835 [18:10<24:25,  1.39s/it, training loss=0.1551]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 781/1835 [18:10<24:23,  1.39s/it, training loss=0.1551]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 781/1835 [18:11<24:23,  1.39s/it, training loss=0.1016]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 782/1835 [18:11<24:25,  1.39s/it, training loss=0.1016]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 782/1835 [18:13<24:25,  1.39s/it, training loss=0.0786]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 783/1835 [18:13<24:23,  1.39s/it, training loss=0.0786]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 783/1835 [18:14<24:23,  1.39s/it, training loss=0.1296]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 784/1835 [18:14<24:22,  1.39s/it, training loss=0.1296]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 784/1835 [18:15<24:22,  1.39s/it, training loss=0.0594]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 785/1835 [18:15<24:23,  1.39s/it, training loss=0.0594]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 785/1835 [18:17<24:23,  1.39s/it, training loss=0.2113]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 786/1835 [18:17<24:21,  1.39s/it, training loss=0.2113]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 786/1835 [18:18<24:21,  1.39s/it, training loss=0.0719]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 787/1835 [18:18<24:19,  1.39s/it, training loss=0.0719]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 787/1835 [18:20<24:19,  1.39s/it, training loss=0.1492]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 788/1835 [18:20<24:20,  1.40s/it, training loss=0.1492]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 788/1835 [18:21<24:20,  1.40s/it, training loss=0.0410]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 789/1835 [18:21<24:18,  1.39s/it, training loss=0.0410]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 789/1835 [18:22<24:18,  1.39s/it, training loss=0.2814]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 790/1835 [18:22<24:16,  1.39s/it, training loss=0.2814]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 790/1835 [18:24<24:16,  1.39s/it, training loss=0.0774]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 791/1835 [18:24<24:14,  1.39s/it, training loss=0.0774]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 791/1835 [18:25<24:14,  1.39s/it, training loss=0.1040]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 792/1835 [18:25<24:13,  1.39s/it, training loss=0.1040]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 792/1835 [18:27<24:13,  1.39s/it, training loss=0.0712]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 793/1835 [18:27<24:10,  1.39s/it, training loss=0.0712]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 793/1835 [18:28<24:10,  1.39s/it, training loss=0.1214]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 794/1835 [18:28<24:08,  1.39s/it, training loss=0.1214]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 794/1835 [18:29<24:08,  1.39s/it, training loss=0.0440]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 795/1835 [18:29<24:06,  1.39s/it, training loss=0.0440]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 795/1835 [18:31<24:06,  1.39s/it, training loss=0.0431]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 796/1835 [18:31<24:08,  1.39s/it, training loss=0.0431]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 796/1835 [18:32<24:08,  1.39s/it, training loss=0.1041]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 797/1835 [18:32<24:09,  1.40s/it, training loss=0.1041]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 797/1835 [18:34<24:09,  1.40s/it, training loss=0.0832]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 798/1835 [18:34<24:05,  1.39s/it, training loss=0.0832]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 798/1835 [18:35<24:05,  1.39s/it, training loss=0.0740]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 799/1835 [18:35<24:03,  1.39s/it, training loss=0.0740]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 799/1835 [18:36<24:03,  1.39s/it, training loss=0.0968]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 800/1835 [18:36<24:04,  1.40s/it, training loss=0.0968]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 800/1835 [18:38<24:04,  1.40s/it, training loss=0.0557]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 801/1835 [18:38<24:04,  1.40s/it, training loss=0.0557]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 801/1835 [18:39<24:04,  1.40s/it, training loss=0.2472]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 802/1835 [18:39<24:00,  1.39s/it, training loss=0.2472]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 802/1835 [18:41<24:00,  1.39s/it, training loss=0.0847]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 803/1835 [18:41<23:59,  1.39s/it, training loss=0.0847]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 803/1835 [18:42<23:59,  1.39s/it, training loss=0.0916]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 804/1835 [18:42<23:58,  1.39s/it, training loss=0.0916]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 804/1835 [18:43<23:58,  1.39s/it, training loss=0.1197]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 805/1835 [18:43<23:53,  1.39s/it, training loss=0.1197]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 805/1835 [18:45<23:53,  1.39s/it, training loss=0.1273]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 806/1835 [18:45<23:52,  1.39s/it, training loss=0.1273]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 806/1835 [18:46<23:52,  1.39s/it, training loss=0.1725]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 807/1835 [18:46<23:50,  1.39s/it, training loss=0.1725]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 807/1835 [18:48<23:50,  1.39s/it, training loss=0.1392]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 808/1835 [18:48<23:48,  1.39s/it, training loss=0.1392]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 808/1835 [18:49<23:48,  1.39s/it, training loss=0.2275]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 809/1835 [18:49<23:48,  1.39s/it, training loss=0.2275]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 809/1835 [18:50<23:48,  1.39s/it, training loss=0.1157]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 810/1835 [18:50<23:51,  1.40s/it, training loss=0.1157]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 810/1835 [18:52<23:51,  1.40s/it, training loss=0.1034]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 811/1835 [18:52<23:47,  1.39s/it, training loss=0.1034]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 811/1835 [18:53<23:47,  1.39s/it, training loss=0.2056]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 812/1835 [18:53<23:47,  1.39s/it, training loss=0.2056]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 812/1835 [18:55<23:47,  1.39s/it, training loss=0.0537]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 813/1835 [18:55<23:46,  1.40s/it, training loss=0.0537]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 813/1835 [18:56<23:46,  1.40s/it, training loss=0.1727]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 814/1835 [18:56<23:43,  1.39s/it, training loss=0.1727]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 814/1835 [18:57<23:43,  1.39s/it, training loss=0.0386]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 815/1835 [18:57<23:39,  1.39s/it, training loss=0.0386]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 815/1835 [18:59<23:39,  1.39s/it, training loss=0.0726]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 816/1835 [18:59<23:39,  1.39s/it, training loss=0.0726]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 816/1835 [19:00<23:39,  1.39s/it, training loss=0.1876]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 817/1835 [19:00<23:40,  1.40s/it, training loss=0.1876]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 817/1835 [19:01<23:40,  1.40s/it, training loss=0.0159]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 818/1835 [19:01<23:39,  1.40s/it, training loss=0.0159]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 818/1835 [19:03<23:39,  1.40s/it, training loss=0.1357]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 819/1835 [19:03<23:37,  1.39s/it, training loss=0.1357]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 819/1835 [19:04<23:37,  1.39s/it, training loss=0.0074]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 820/1835 [19:04<23:34,  1.39s/it, training loss=0.0074]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 820/1835 [19:06<23:34,  1.39s/it, training loss=0.1164]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 821/1835 [19:06<23:36,  1.40s/it, training loss=0.1164]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 821/1835 [19:07<23:36,  1.40s/it, training loss=0.0603]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 822/1835 [19:07<23:34,  1.40s/it, training loss=0.0603]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 822/1835 [19:08<23:34,  1.40s/it, training loss=0.1908]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 823/1835 [19:08<23:32,  1.40s/it, training loss=0.1908]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 823/1835 [19:10<23:32,  1.40s/it, training loss=0.0441]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 824/1835 [19:10<23:30,  1.40s/it, training loss=0.0441]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 824/1835 [19:11<23:30,  1.40s/it, training loss=0.0645]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 825/1835 [19:11<23:29,  1.40s/it, training loss=0.0645]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 825/1835 [19:13<23:29,  1.40s/it, training loss=0.0344]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 826/1835 [19:13<23:30,  1.40s/it, training loss=0.0344]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 826/1835 [19:14<23:30,  1.40s/it, training loss=0.1767]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 827/1835 [19:14<23:29,  1.40s/it, training loss=0.1767]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 827/1835 [19:15<23:29,  1.40s/it, training loss=0.1421]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 828/1835 [19:15<23:25,  1.40s/it, training loss=0.1421]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 828/1835 [19:17<23:25,  1.40s/it, training loss=0.2905]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 829/1835 [19:17<23:23,  1.40s/it, training loss=0.2905]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 829/1835 [19:18<23:23,  1.40s/it, training loss=0.0712]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 830/1835 [19:18<23:23,  1.40s/it, training loss=0.0712]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 830/1835 [19:20<23:23,  1.40s/it, training loss=0.2248]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 831/1835 [19:20<23:19,  1.39s/it, training loss=0.2248]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 831/1835 [19:21<23:19,  1.39s/it, training loss=0.1332]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 832/1835 [19:21<23:16,  1.39s/it, training loss=0.1332]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 832/1835 [19:22<23:16,  1.39s/it, training loss=0.0827]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 833/1835 [19:22<23:15,  1.39s/it, training loss=0.0827]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 833/1835 [19:24<23:15,  1.39s/it, training loss=0.0480]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 834/1835 [19:24<23:14,  1.39s/it, training loss=0.0480]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 834/1835 [19:25<23:14,  1.39s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 835/1835 [19:25<23:14,  1.39s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 835/1835 [19:27<23:14,  1.39s/it, training loss=0.0560]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 836/1835 [19:27<23:12,  1.39s/it, training loss=0.0560]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 836/1835 [19:28<23:12,  1.39s/it, training loss=0.0719]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 837/1835 [19:28<23:12,  1.40s/it, training loss=0.0719]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 837/1835 [19:29<23:12,  1.40s/it, training loss=0.1393]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 838/1835 [19:29<23:11,  1.40s/it, training loss=0.1393]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 838/1835 [19:31<23:11,  1.40s/it, training loss=0.1545]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 839/1835 [19:31<23:10,  1.40s/it, training loss=0.1545]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 839/1835 [19:32<23:10,  1.40s/it, training loss=0.1225]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 840/1835 [19:32<23:06,  1.39s/it, training loss=0.1225]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 840/1835 [19:34<23:06,  1.39s/it, training loss=0.0900]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 841/1835 [19:34<23:06,  1.39s/it, training loss=0.0900]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 841/1835 [19:35<23:06,  1.39s/it, training loss=0.0589]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 842/1835 [19:35<23:04,  1.39s/it, training loss=0.0589]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 842/1835 [19:36<23:04,  1.39s/it, training loss=0.1222]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 843/1835 [19:36<23:03,  1.39s/it, training loss=0.1222]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 843/1835 [19:38<23:03,  1.39s/it, training loss=0.1474]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 844/1835 [19:38<23:02,  1.40s/it, training loss=0.1474]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 844/1835 [19:39<23:02,  1.40s/it, training loss=0.2461]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 845/1835 [19:39<23:01,  1.40s/it, training loss=0.2461]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 845/1835 [19:41<23:01,  1.40s/it, training loss=0.1473]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 846/1835 [19:41<22:59,  1.39s/it, training loss=0.1473]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 846/1835 [19:42<22:59,  1.39s/it, training loss=0.0714]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 847/1835 [19:42<23:01,  1.40s/it, training loss=0.0714]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 847/1835 [19:43<23:01,  1.40s/it, training loss=0.0743]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 848/1835 [19:43<22:57,  1.40s/it, training loss=0.0743]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 848/1835 [19:45<22:57,  1.40s/it, training loss=0.2497]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 849/1835 [19:45<22:55,  1.40s/it, training loss=0.2497]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 849/1835 [19:46<22:55,  1.40s/it, training loss=0.1264]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 850/1835 [19:46<22:55,  1.40s/it, training loss=0.1264]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 850/1835 [19:48<22:55,  1.40s/it, training loss=0.0590]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 851/1835 [19:48<22:55,  1.40s/it, training loss=0.0590]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 851/1835 [19:49<22:55,  1.40s/it, training loss=0.2939]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 852/1835 [19:49<22:53,  1.40s/it, training loss=0.2939]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 852/1835 [19:50<22:53,  1.40s/it, training loss=0.0702]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 853/1835 [19:50<22:51,  1.40s/it, training loss=0.0702]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 853/1835 [19:52<22:51,  1.40s/it, training loss=0.2031]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 854/1835 [19:52<22:51,  1.40s/it, training loss=0.2031]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 854/1835 [19:53<22:51,  1.40s/it, training loss=0.1872]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 855/1835 [19:53<22:47,  1.40s/it, training loss=0.1872]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 855/1835 [19:54<22:47,  1.40s/it, training loss=0.0579]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 856/1835 [19:55<22:46,  1.40s/it, training loss=0.0579]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 856/1835 [19:56<22:46,  1.40s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 857/1835 [19:56<22:44,  1.40s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 857/1835 [19:57<22:44,  1.40s/it, training loss=0.1824]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 858/1835 [19:57<22:41,  1.39s/it, training loss=0.1824]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 858/1835 [19:59<22:41,  1.39s/it, training loss=0.0950]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 859/1835 [19:59<22:37,  1.39s/it, training loss=0.0950]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 859/1835 [20:00<22:37,  1.39s/it, training loss=0.0412]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 860/1835 [20:00<22:36,  1.39s/it, training loss=0.0412]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 860/1835 [20:01<22:36,  1.39s/it, training loss=0.2395]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 861/1835 [20:01<22:36,  1.39s/it, training loss=0.2395]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 861/1835 [20:03<22:36,  1.39s/it, training loss=0.0962]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 862/1835 [20:03<22:35,  1.39s/it, training loss=0.0962]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 862/1835 [20:04<22:35,  1.39s/it, training loss=0.0491]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 863/1835 [20:04<22:33,  1.39s/it, training loss=0.0491]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 863/1835 [20:06<22:33,  1.39s/it, training loss=0.1225]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 864/1835 [20:06<22:34,  1.39s/it, training loss=0.1225]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 864/1835 [20:07<22:34,  1.39s/it, training loss=0.1336]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 865/1835 [20:07<22:36,  1.40s/it, training loss=0.1336]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 865/1835 [20:08<22:36,  1.40s/it, training loss=0.0810]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 866/1835 [20:08<22:32,  1.40s/it, training loss=0.0810]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 866/1835 [20:10<22:32,  1.40s/it, training loss=0.1889]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 867/1835 [20:10<22:31,  1.40s/it, training loss=0.1889]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 867/1835 [20:11<22:31,  1.40s/it, training loss=0.0964]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 868/1835 [20:11<22:32,  1.40s/it, training loss=0.0964]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 868/1835 [20:13<22:32,  1.40s/it, training loss=0.0612]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 869/1835 [20:13<22:31,  1.40s/it, training loss=0.0612]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 869/1835 [20:14<22:31,  1.40s/it, training loss=0.1418]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 870/1835 [20:14<22:28,  1.40s/it, training loss=0.1418]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 870/1835 [20:15<22:28,  1.40s/it, training loss=0.1423]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 871/1835 [20:15<22:26,  1.40s/it, training loss=0.1423]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 871/1835 [20:17<22:26,  1.40s/it, training loss=0.0566]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 872/1835 [20:17<22:23,  1.39s/it, training loss=0.0566]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 872/1835 [20:18<22:23,  1.39s/it, training loss=0.0417]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 873/1835 [20:18<22:22,  1.40s/it, training loss=0.0417]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 873/1835 [20:20<22:22,  1.40s/it, training loss=0.2130]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 874/1835 [20:20<22:22,  1.40s/it, training loss=0.2130]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 874/1835 [20:21<22:22,  1.40s/it, training loss=0.0634]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 875/1835 [20:21<22:20,  1.40s/it, training loss=0.0634]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 875/1835 [20:22<22:20,  1.40s/it, training loss=0.0353]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 876/1835 [20:22<22:21,  1.40s/it, training loss=0.0353]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 876/1835 [20:24<22:21,  1.40s/it, training loss=0.0748]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 877/1835 [20:24<22:19,  1.40s/it, training loss=0.0748]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 877/1835 [20:25<22:19,  1.40s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 878/1835 [20:25<22:16,  1.40s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 878/1835 [20:27<22:16,  1.40s/it, training loss=0.0839]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 879/1835 [20:27<22:17,  1.40s/it, training loss=0.0839]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 879/1835 [20:28<22:17,  1.40s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 880/1835 [20:28<22:14,  1.40s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 880/1835 [20:29<22:14,  1.40s/it, training loss=0.0769]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 881/1835 [20:29<22:14,  1.40s/it, training loss=0.0769]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 881/1835 [20:31<22:14,  1.40s/it, training loss=0.1147]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 882/1835 [20:31<22:11,  1.40s/it, training loss=0.1147]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 882/1835 [20:32<22:11,  1.40s/it, training loss=0.1780]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 883/1835 [20:32<22:08,  1.40s/it, training loss=0.1780]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 883/1835 [20:34<22:08,  1.40s/it, training loss=0.1651]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 884/1835 [20:34<22:08,  1.40s/it, training loss=0.1651]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 884/1835 [20:35<22:08,  1.40s/it, training loss=0.1385]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 885/1835 [20:35<22:06,  1.40s/it, training loss=0.1385]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 885/1835 [20:36<22:06,  1.40s/it, training loss=0.0341]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 886/1835 [20:36<22:06,  1.40s/it, training loss=0.0341]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 886/1835 [20:38<22:06,  1.40s/it, training loss=0.1732]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 887/1835 [20:38<22:03,  1.40s/it, training loss=0.1732]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 887/1835 [20:39<22:03,  1.40s/it, training loss=0.0854]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 888/1835 [20:39<22:03,  1.40s/it, training loss=0.0854]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 888/1835 [20:41<22:03,  1.40s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 889/1835 [20:41<22:02,  1.40s/it, training loss=0.1237]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 889/1835 [20:42<22:02,  1.40s/it, training loss=0.1635]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 890/1835 [20:42<21:59,  1.40s/it, training loss=0.1635]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 890/1835 [20:43<21:59,  1.40s/it, training loss=0.0434]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 891/1835 [20:43<21:58,  1.40s/it, training loss=0.0434]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 891/1835 [20:45<21:58,  1.40s/it, training loss=0.1394]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 892/1835 [20:45<21:57,  1.40s/it, training loss=0.1394]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 892/1835 [20:46<21:57,  1.40s/it, training loss=0.0480]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 893/1835 [20:46<21:54,  1.40s/it, training loss=0.0480]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 893/1835 [20:48<21:54,  1.40s/it, training loss=0.0818]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 894/1835 [20:48<21:54,  1.40s/it, training loss=0.0818]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 894/1835 [20:49<21:54,  1.40s/it, training loss=0.0592]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 895/1835 [20:49<21:52,  1.40s/it, training loss=0.0592]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 895/1835 [20:50<21:52,  1.40s/it, training loss=0.1322]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 896/1835 [20:50<21:51,  1.40s/it, training loss=0.1322]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 896/1835 [20:52<21:51,  1.40s/it, training loss=0.1933]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 897/1835 [20:52<21:53,  1.40s/it, training loss=0.1933]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 897/1835 [20:53<21:53,  1.40s/it, training loss=0.1770]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 898/1835 [20:53<21:49,  1.40s/it, training loss=0.1770]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 898/1835 [20:55<21:49,  1.40s/it, training loss=0.0631]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 899/1835 [20:55<21:49,  1.40s/it, training loss=0.0631]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 899/1835 [20:56<21:49,  1.40s/it, training loss=0.1438]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 900/1835 [20:56<21:48,  1.40s/it, training loss=0.1438]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 900/1835 [20:57<21:48,  1.40s/it, training loss=0.0655]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 901/1835 [20:57<21:48,  1.40s/it, training loss=0.0655]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 901/1835 [20:59<21:48,  1.40s/it, training loss=0.0677]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 902/1835 [20:59<21:46,  1.40s/it, training loss=0.0677]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 902/1835 [21:00<21:46,  1.40s/it, training loss=0.0853]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 903/1835 [21:00<21:45,  1.40s/it, training loss=0.0853]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 903/1835 [21:02<21:45,  1.40s/it, training loss=0.0694]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 904/1835 [21:02<21:43,  1.40s/it, training loss=0.0694]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 904/1835 [21:03<21:43,  1.40s/it, training loss=0.0633]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 905/1835 [21:03<21:39,  1.40s/it, training loss=0.0633]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 905/1835 [21:04<21:39,  1.40s/it, training loss=0.0598]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 906/1835 [21:04<21:38,  1.40s/it, training loss=0.0598]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 906/1835 [21:06<21:38,  1.40s/it, training loss=0.1623]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 907/1835 [21:06<21:37,  1.40s/it, training loss=0.1623]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 907/1835 [21:07<21:37,  1.40s/it, training loss=0.0878]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 908/1835 [21:07<21:36,  1.40s/it, training loss=0.0878]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 908/1835 [21:09<21:36,  1.40s/it, training loss=0.0390]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 909/1835 [21:09<21:36,  1.40s/it, training loss=0.0390]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 909/1835 [21:10<21:36,  1.40s/it, training loss=0.1001]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 910/1835 [21:10<21:33,  1.40s/it, training loss=0.1001]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 910/1835 [21:11<21:33,  1.40s/it, training loss=0.0261]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 911/1835 [21:11<21:32,  1.40s/it, training loss=0.0261]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 911/1835 [21:13<21:32,  1.40s/it, training loss=0.1085]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 912/1835 [21:13<21:29,  1.40s/it, training loss=0.1085]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 912/1835 [21:14<21:29,  1.40s/it, training loss=0.1116]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 913/1835 [21:14<21:26,  1.40s/it, training loss=0.1116]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 913/1835 [21:16<21:26,  1.40s/it, training loss=0.0929]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 914/1835 [21:16<21:26,  1.40s/it, training loss=0.0929]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 914/1835 [21:17<21:26,  1.40s/it, training loss=0.1171]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 915/1835 [21:17<21:25,  1.40s/it, training loss=0.1171]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 915/1835 [21:18<21:25,  1.40s/it, training loss=0.1200]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 916/1835 [21:18<21:24,  1.40s/it, training loss=0.1200]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 916/1835 [21:20<21:24,  1.40s/it, training loss=0.1873]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 917/1835 [21:20<21:21,  1.40s/it, training loss=0.1873]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 917/1835 [21:21<21:21,  1.40s/it, training loss=0.1748]\u001b[A\n",
            "Epoch 3:  50%|█████     | 918/1835 [21:21<21:19,  1.40s/it, training loss=0.1748]\u001b[A\n",
            "Epoch 3:  50%|█████     | 918/1835 [21:23<21:19,  1.40s/it, training loss=0.2701]\u001b[A\n",
            "Epoch 3:  50%|█████     | 919/1835 [21:23<21:17,  1.39s/it, training loss=0.2701]\u001b[A\n",
            "Epoch 3:  50%|█████     | 919/1835 [21:24<21:17,  1.39s/it, training loss=0.2040]\u001b[A\n",
            "Epoch 3:  50%|█████     | 920/1835 [21:24<21:14,  1.39s/it, training loss=0.2040]\u001b[A\n",
            "Epoch 3:  50%|█████     | 920/1835 [21:25<21:14,  1.39s/it, training loss=0.0857]\u001b[A\n",
            "Epoch 3:  50%|█████     | 921/1835 [21:25<21:14,  1.39s/it, training loss=0.0857]\u001b[A\n",
            "Epoch 3:  50%|█████     | 921/1835 [21:27<21:14,  1.39s/it, training loss=0.1284]\u001b[A\n",
            "Epoch 3:  50%|█████     | 922/1835 [21:27<21:13,  1.40s/it, training loss=0.1284]\u001b[A\n",
            "Epoch 3:  50%|█████     | 922/1835 [21:28<21:13,  1.40s/it, training loss=0.1065]\u001b[A\n",
            "Epoch 3:  50%|█████     | 923/1835 [21:28<21:13,  1.40s/it, training loss=0.1065]\u001b[A\n",
            "Epoch 3:  50%|█████     | 923/1835 [21:29<21:13,  1.40s/it, training loss=0.0833]\u001b[A\n",
            "Epoch 3:  50%|█████     | 924/1835 [21:29<21:11,  1.40s/it, training loss=0.0833]\u001b[A\n",
            "Epoch 3:  50%|█████     | 924/1835 [21:31<21:11,  1.40s/it, training loss=0.1346]\u001b[A\n",
            "Epoch 3:  50%|█████     | 925/1835 [21:31<21:10,  1.40s/it, training loss=0.1346]\u001b[A\n",
            "Epoch 3:  50%|█████     | 925/1835 [21:32<21:10,  1.40s/it, training loss=0.1862]\u001b[A\n",
            "Epoch 3:  50%|█████     | 926/1835 [21:32<21:09,  1.40s/it, training loss=0.1862]\u001b[A\n",
            "Epoch 3:  50%|█████     | 926/1835 [21:34<21:09,  1.40s/it, training loss=0.2042]\u001b[A\n",
            "Epoch 3:  51%|█████     | 927/1835 [21:34<21:06,  1.39s/it, training loss=0.2042]\u001b[A\n",
            "Epoch 3:  51%|█████     | 927/1835 [21:35<21:06,  1.39s/it, training loss=0.1410]\u001b[A\n",
            "Epoch 3:  51%|█████     | 928/1835 [21:35<21:05,  1.40s/it, training loss=0.1410]\u001b[A\n",
            "Epoch 3:  51%|█████     | 928/1835 [21:36<21:05,  1.40s/it, training loss=0.1951]\u001b[A\n",
            "Epoch 3:  51%|█████     | 929/1835 [21:36<21:05,  1.40s/it, training loss=0.1951]\u001b[A\n",
            "Epoch 3:  51%|█████     | 929/1835 [21:38<21:05,  1.40s/it, training loss=0.1395]\u001b[A\n",
            "Epoch 3:  51%|█████     | 930/1835 [21:38<21:03,  1.40s/it, training loss=0.1395]\u001b[A\n",
            "Epoch 3:  51%|█████     | 930/1835 [21:39<21:03,  1.40s/it, training loss=0.0528]\u001b[A\n",
            "Epoch 3:  51%|█████     | 931/1835 [21:39<21:01,  1.39s/it, training loss=0.0528]\u001b[A\n",
            "Epoch 3:  51%|█████     | 931/1835 [21:41<21:01,  1.39s/it, training loss=0.0740]\u001b[A\n",
            "Epoch 3:  51%|█████     | 932/1835 [21:41<21:00,  1.40s/it, training loss=0.0740]\u001b[A\n",
            "Epoch 3:  51%|█████     | 932/1835 [21:42<21:00,  1.40s/it, training loss=0.1606]\u001b[A\n",
            "Epoch 3:  51%|█████     | 933/1835 [21:42<20:58,  1.40s/it, training loss=0.1606]\u001b[A\n",
            "Epoch 3:  51%|█████     | 933/1835 [21:43<20:58,  1.40s/it, training loss=0.1244]\u001b[A\n",
            "Epoch 3:  51%|█████     | 934/1835 [21:43<20:59,  1.40s/it, training loss=0.1244]\u001b[A\n",
            "Epoch 3:  51%|█████     | 934/1835 [21:45<20:59,  1.40s/it, training loss=0.0421]\u001b[A\n",
            "Epoch 3:  51%|█████     | 935/1835 [21:45<20:55,  1.40s/it, training loss=0.0421]\u001b[A\n",
            "Epoch 3:  51%|█████     | 935/1835 [21:46<20:55,  1.40s/it, training loss=0.2143]\u001b[A\n",
            "Epoch 3:  51%|█████     | 936/1835 [21:46<20:53,  1.39s/it, training loss=0.2143]\u001b[A\n",
            "Epoch 3:  51%|█████     | 936/1835 [21:48<20:53,  1.39s/it, training loss=0.0569]\u001b[A\n",
            "Epoch 3:  51%|█████     | 937/1835 [21:48<20:51,  1.39s/it, training loss=0.0569]\u001b[A\n",
            "Epoch 3:  51%|█████     | 937/1835 [21:49<20:51,  1.39s/it, training loss=0.0957]\u001b[A\n",
            "Epoch 3:  51%|█████     | 938/1835 [21:49<20:51,  1.40s/it, training loss=0.0957]\u001b[A\n",
            "Epoch 3:  51%|█████     | 938/1835 [21:50<20:51,  1.40s/it, training loss=0.0255]\u001b[A\n",
            "Epoch 3:  51%|█████     | 939/1835 [21:50<20:49,  1.39s/it, training loss=0.0255]\u001b[A\n",
            "Epoch 3:  51%|█████     | 939/1835 [21:52<20:49,  1.39s/it, training loss=0.0539]\u001b[A\n",
            "Epoch 3:  51%|█████     | 940/1835 [21:52<20:47,  1.39s/it, training loss=0.0539]\u001b[A\n",
            "Epoch 3:  51%|█████     | 940/1835 [21:53<20:47,  1.39s/it, training loss=0.0374]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 941/1835 [21:53<20:45,  1.39s/it, training loss=0.0374]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 941/1835 [21:55<20:45,  1.39s/it, training loss=0.1365]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 942/1835 [21:55<20:40,  1.39s/it, training loss=0.1365]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 942/1835 [21:56<20:40,  1.39s/it, training loss=0.1641]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 943/1835 [21:56<20:40,  1.39s/it, training loss=0.1641]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 943/1835 [21:57<20:40,  1.39s/it, training loss=0.0856]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 944/1835 [21:57<20:38,  1.39s/it, training loss=0.0856]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 944/1835 [21:59<20:38,  1.39s/it, training loss=0.0408]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 945/1835 [21:59<20:36,  1.39s/it, training loss=0.0408]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 945/1835 [22:00<20:36,  1.39s/it, training loss=0.1964]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 946/1835 [22:00<20:35,  1.39s/it, training loss=0.1964]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 946/1835 [22:02<20:35,  1.39s/it, training loss=0.0596]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 947/1835 [22:02<20:37,  1.39s/it, training loss=0.0596]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 947/1835 [22:03<20:37,  1.39s/it, training loss=0.0860]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 948/1835 [22:03<20:36,  1.39s/it, training loss=0.0860]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 948/1835 [22:04<20:36,  1.39s/it, training loss=0.1059]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 949/1835 [22:04<20:32,  1.39s/it, training loss=0.1059]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 949/1835 [22:06<20:32,  1.39s/it, training loss=0.0521]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 950/1835 [22:06<20:30,  1.39s/it, training loss=0.0521]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 950/1835 [22:07<20:30,  1.39s/it, training loss=0.1202]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 951/1835 [22:07<20:31,  1.39s/it, training loss=0.1202]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 951/1835 [22:09<20:31,  1.39s/it, training loss=0.1106]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 952/1835 [22:09<20:30,  1.39s/it, training loss=0.1106]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 952/1835 [22:10<20:30,  1.39s/it, training loss=0.0548]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 953/1835 [22:10<20:28,  1.39s/it, training loss=0.0548]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 953/1835 [22:11<20:28,  1.39s/it, training loss=0.0262]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 954/1835 [22:11<20:29,  1.40s/it, training loss=0.0262]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 954/1835 [22:13<20:29,  1.40s/it, training loss=0.0987]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 955/1835 [22:13<20:27,  1.39s/it, training loss=0.0987]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 955/1835 [22:14<20:27,  1.39s/it, training loss=0.1126]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 956/1835 [22:14<20:26,  1.40s/it, training loss=0.1126]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 956/1835 [22:15<20:26,  1.40s/it, training loss=0.1742]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 957/1835 [22:15<20:23,  1.39s/it, training loss=0.1742]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 957/1835 [22:17<20:23,  1.39s/it, training loss=0.0580]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 958/1835 [22:17<20:19,  1.39s/it, training loss=0.0580]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 958/1835 [22:18<20:19,  1.39s/it, training loss=0.0545]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 959/1835 [22:18<20:18,  1.39s/it, training loss=0.0545]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 959/1835 [22:20<20:18,  1.39s/it, training loss=0.1305]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 960/1835 [22:20<20:17,  1.39s/it, training loss=0.1305]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 960/1835 [22:21<20:17,  1.39s/it, training loss=0.0836]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 961/1835 [22:21<20:17,  1.39s/it, training loss=0.0836]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 961/1835 [22:22<20:17,  1.39s/it, training loss=0.0323]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 962/1835 [22:22<20:16,  1.39s/it, training loss=0.0323]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 962/1835 [22:24<20:16,  1.39s/it, training loss=0.2171]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 963/1835 [22:24<20:14,  1.39s/it, training loss=0.2171]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 963/1835 [22:25<20:14,  1.39s/it, training loss=0.2401]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 964/1835 [22:25<20:13,  1.39s/it, training loss=0.2401]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 964/1835 [22:27<20:13,  1.39s/it, training loss=0.1575]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 965/1835 [22:27<20:12,  1.39s/it, training loss=0.1575]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 965/1835 [22:28<20:12,  1.39s/it, training loss=0.1142]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 966/1835 [22:28<20:11,  1.39s/it, training loss=0.1142]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 966/1835 [22:29<20:11,  1.39s/it, training loss=0.0322]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 967/1835 [22:29<20:10,  1.39s/it, training loss=0.0322]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 967/1835 [22:31<20:10,  1.39s/it, training loss=0.0245]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 968/1835 [22:31<20:08,  1.39s/it, training loss=0.0245]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 968/1835 [22:32<20:08,  1.39s/it, training loss=0.0463]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 969/1835 [22:32<20:05,  1.39s/it, training loss=0.0463]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 969/1835 [22:34<20:05,  1.39s/it, training loss=0.0801]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 970/1835 [22:34<20:02,  1.39s/it, training loss=0.0801]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 970/1835 [22:35<20:02,  1.39s/it, training loss=0.1591]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 971/1835 [22:35<20:00,  1.39s/it, training loss=0.1591]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 971/1835 [22:36<20:00,  1.39s/it, training loss=0.0294]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 972/1835 [22:36<20:00,  1.39s/it, training loss=0.0294]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 972/1835 [22:38<20:00,  1.39s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 973/1835 [22:38<19:59,  1.39s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 973/1835 [22:39<19:59,  1.39s/it, training loss=0.1595]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 974/1835 [22:39<19:58,  1.39s/it, training loss=0.1595]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 974/1835 [22:41<19:58,  1.39s/it, training loss=0.1658]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 975/1835 [22:41<19:58,  1.39s/it, training loss=0.1658]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 975/1835 [22:42<19:58,  1.39s/it, training loss=0.0933]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 976/1835 [22:42<19:57,  1.39s/it, training loss=0.0933]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 976/1835 [22:43<19:57,  1.39s/it, training loss=0.1438]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 977/1835 [22:43<19:58,  1.40s/it, training loss=0.1438]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 977/1835 [22:45<19:58,  1.40s/it, training loss=0.0817]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 978/1835 [22:45<19:56,  1.40s/it, training loss=0.0817]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 978/1835 [22:46<19:56,  1.40s/it, training loss=0.0425]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 979/1835 [22:46<19:55,  1.40s/it, training loss=0.0425]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 979/1835 [22:48<19:55,  1.40s/it, training loss=0.1473]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 980/1835 [22:48<19:53,  1.40s/it, training loss=0.1473]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 980/1835 [22:49<19:53,  1.40s/it, training loss=0.2498]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 981/1835 [22:49<19:52,  1.40s/it, training loss=0.2498]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 981/1835 [22:50<19:52,  1.40s/it, training loss=0.1276]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 982/1835 [22:50<19:50,  1.40s/it, training loss=0.1276]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 982/1835 [22:52<19:50,  1.40s/it, training loss=0.0109]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 983/1835 [22:52<19:48,  1.40s/it, training loss=0.0109]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 983/1835 [22:53<19:48,  1.40s/it, training loss=0.1517]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 984/1835 [22:53<19:47,  1.40s/it, training loss=0.1517]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 984/1835 [22:54<19:47,  1.40s/it, training loss=0.1942]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 985/1835 [22:55<19:45,  1.39s/it, training loss=0.1942]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 985/1835 [22:56<19:45,  1.39s/it, training loss=0.1103]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 986/1835 [22:56<19:43,  1.39s/it, training loss=0.1103]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 986/1835 [22:57<19:43,  1.39s/it, training loss=0.0552]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 987/1835 [22:57<19:40,  1.39s/it, training loss=0.0552]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 987/1835 [22:59<19:40,  1.39s/it, training loss=0.1290]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 988/1835 [22:59<19:40,  1.39s/it, training loss=0.1290]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 988/1835 [23:00<19:40,  1.39s/it, training loss=0.0458]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 989/1835 [23:00<19:39,  1.39s/it, training loss=0.0458]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 989/1835 [23:01<19:39,  1.39s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 990/1835 [23:01<19:36,  1.39s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 990/1835 [23:03<19:36,  1.39s/it, training loss=0.1143]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 991/1835 [23:03<19:34,  1.39s/it, training loss=0.1143]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 991/1835 [23:04<19:34,  1.39s/it, training loss=0.0900]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 992/1835 [23:04<19:35,  1.39s/it, training loss=0.0900]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 992/1835 [23:06<19:35,  1.39s/it, training loss=0.0525]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 993/1835 [23:06<19:31,  1.39s/it, training loss=0.0525]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 993/1835 [23:07<19:31,  1.39s/it, training loss=0.2788]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 994/1835 [23:07<19:29,  1.39s/it, training loss=0.2788]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 994/1835 [23:08<19:29,  1.39s/it, training loss=0.1193]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 995/1835 [23:08<19:28,  1.39s/it, training loss=0.1193]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 995/1835 [23:10<19:28,  1.39s/it, training loss=0.0481]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 996/1835 [23:10<19:27,  1.39s/it, training loss=0.0481]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 996/1835 [23:11<19:27,  1.39s/it, training loss=0.1945]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 997/1835 [23:11<19:29,  1.40s/it, training loss=0.1945]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 997/1835 [23:13<19:29,  1.40s/it, training loss=0.4006]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 998/1835 [23:13<19:29,  1.40s/it, training loss=0.4006]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 998/1835 [23:14<19:29,  1.40s/it, training loss=0.1236]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 999/1835 [23:14<19:27,  1.40s/it, training loss=0.1236]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 999/1835 [23:15<19:27,  1.40s/it, training loss=0.0389]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 1000/1835 [23:15<19:24,  1.39s/it, training loss=0.0389]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 1000/1835 [23:17<19:24,  1.39s/it, training loss=0.0597]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1001/1835 [23:17<19:24,  1.40s/it, training loss=0.0597]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1001/1835 [23:18<19:24,  1.40s/it, training loss=0.0209]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1002/1835 [23:18<19:22,  1.40s/it, training loss=0.0209]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1002/1835 [23:20<19:22,  1.40s/it, training loss=0.1693]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1003/1835 [23:20<19:23,  1.40s/it, training loss=0.1693]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1003/1835 [23:21<19:23,  1.40s/it, training loss=0.0562]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1004/1835 [23:21<19:20,  1.40s/it, training loss=0.0562]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1004/1835 [23:22<19:20,  1.40s/it, training loss=0.1740]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1005/1835 [23:22<19:19,  1.40s/it, training loss=0.1740]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1005/1835 [23:24<19:19,  1.40s/it, training loss=0.0563]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1006/1835 [23:24<19:18,  1.40s/it, training loss=0.0563]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1006/1835 [23:25<19:18,  1.40s/it, training loss=0.0996]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1007/1835 [23:25<19:18,  1.40s/it, training loss=0.0996]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1007/1835 [23:27<19:18,  1.40s/it, training loss=0.0691]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1008/1835 [23:27<19:16,  1.40s/it, training loss=0.0691]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1008/1835 [23:28<19:16,  1.40s/it, training loss=0.1309]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1009/1835 [23:28<19:13,  1.40s/it, training loss=0.1309]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 1009/1835 [23:29<19:13,  1.40s/it, training loss=0.2820]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1010/1835 [23:29<19:12,  1.40s/it, training loss=0.2820]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1010/1835 [23:31<19:12,  1.40s/it, training loss=0.1875]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1011/1835 [23:31<19:14,  1.40s/it, training loss=0.1875]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1011/1835 [23:32<19:14,  1.40s/it, training loss=0.2273]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1012/1835 [23:32<19:12,  1.40s/it, training loss=0.2273]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1012/1835 [23:34<19:12,  1.40s/it, training loss=0.0961]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1013/1835 [23:34<19:12,  1.40s/it, training loss=0.0961]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1013/1835 [23:35<19:12,  1.40s/it, training loss=0.1502]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1014/1835 [23:35<19:10,  1.40s/it, training loss=0.1502]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1014/1835 [23:36<19:10,  1.40s/it, training loss=0.0646]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1015/1835 [23:36<19:06,  1.40s/it, training loss=0.0646]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1015/1835 [23:38<19:06,  1.40s/it, training loss=0.0234]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1016/1835 [23:38<19:03,  1.40s/it, training loss=0.0234]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1016/1835 [23:39<19:03,  1.40s/it, training loss=0.1619]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1017/1835 [23:39<19:02,  1.40s/it, training loss=0.1619]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1017/1835 [23:41<19:02,  1.40s/it, training loss=0.0959]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1018/1835 [23:41<19:02,  1.40s/it, training loss=0.0959]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 1018/1835 [23:42<19:02,  1.40s/it, training loss=0.0882]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1019/1835 [23:42<19:02,  1.40s/it, training loss=0.0882]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1019/1835 [23:43<19:02,  1.40s/it, training loss=0.0954]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1020/1835 [23:43<18:59,  1.40s/it, training loss=0.0954]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1020/1835 [23:45<18:59,  1.40s/it, training loss=0.0173]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1021/1835 [23:45<18:57,  1.40s/it, training loss=0.0173]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1021/1835 [23:46<18:57,  1.40s/it, training loss=0.1398]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1022/1835 [23:46<18:57,  1.40s/it, training loss=0.1398]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1022/1835 [23:48<18:57,  1.40s/it, training loss=0.1728]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1023/1835 [23:48<18:55,  1.40s/it, training loss=0.1728]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1023/1835 [23:49<18:55,  1.40s/it, training loss=0.2175]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1024/1835 [23:49<18:54,  1.40s/it, training loss=0.2175]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1024/1835 [23:50<18:54,  1.40s/it, training loss=0.0490]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1025/1835 [23:50<18:53,  1.40s/it, training loss=0.0490]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1025/1835 [23:52<18:53,  1.40s/it, training loss=0.0640]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1026/1835 [23:52<18:50,  1.40s/it, training loss=0.0640]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1026/1835 [23:53<18:50,  1.40s/it, training loss=0.1615]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1027/1835 [23:53<18:49,  1.40s/it, training loss=0.1615]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1027/1835 [23:55<18:49,  1.40s/it, training loss=0.0519]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1028/1835 [23:55<18:46,  1.40s/it, training loss=0.0519]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1028/1835 [23:56<18:46,  1.40s/it, training loss=0.0358]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1029/1835 [23:56<18:45,  1.40s/it, training loss=0.0358]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1029/1835 [23:57<18:45,  1.40s/it, training loss=0.0443]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1030/1835 [23:57<18:44,  1.40s/it, training loss=0.0443]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1030/1835 [23:59<18:44,  1.40s/it, training loss=0.1776]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1031/1835 [23:59<18:43,  1.40s/it, training loss=0.1776]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1031/1835 [24:00<18:43,  1.40s/it, training loss=0.0203]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1032/1835 [24:00<18:44,  1.40s/it, training loss=0.0203]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 1032/1835 [24:02<18:44,  1.40s/it, training loss=0.3077]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 1033/1835 [24:02<18:42,  1.40s/it, training loss=0.3077]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 1033/1835 [24:03<18:42,  1.40s/it, training loss=0.0878]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 1034/1835 [24:03<18:41,  1.40s/it, training loss=0.0878]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 1034/1835 [24:04<18:41,  1.40s/it, training loss=0.1093]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 1035/1835 [24:04<18:39,  1.40s/it, training loss=0.1093]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 1035/1835 [24:06<18:39,  1.40s/it, training loss=0.2212]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 1036/1835 [24:06<18:37,  1.40s/it, training loss=0.2212]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 1036/1835 [24:07<18:37,  1.40s/it, training loss=0.1493]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1037/1835 [24:07<18:35,  1.40s/it, training loss=0.1493]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1037/1835 [24:09<18:35,  1.40s/it, training loss=0.0450]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1038/1835 [24:09<18:32,  1.40s/it, training loss=0.0450]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1038/1835 [24:10<18:32,  1.40s/it, training loss=0.0879]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1039/1835 [24:10<18:30,  1.40s/it, training loss=0.0879]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1039/1835 [24:11<18:30,  1.40s/it, training loss=0.1239]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1040/1835 [24:11<18:27,  1.39s/it, training loss=0.1239]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1040/1835 [24:13<18:27,  1.39s/it, training loss=0.2864]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1041/1835 [24:13<18:26,  1.39s/it, training loss=0.2864]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1041/1835 [24:14<18:26,  1.39s/it, training loss=0.1356]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1042/1835 [24:14<18:26,  1.40s/it, training loss=0.1356]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1042/1835 [24:16<18:26,  1.40s/it, training loss=0.1568]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1043/1835 [24:16<18:24,  1.39s/it, training loss=0.1568]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1043/1835 [24:17<18:24,  1.39s/it, training loss=0.1219]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1044/1835 [24:17<18:23,  1.40s/it, training loss=0.1219]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1044/1835 [24:18<18:23,  1.40s/it, training loss=0.0366]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1045/1835 [24:18<18:23,  1.40s/it, training loss=0.0366]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1045/1835 [24:20<18:23,  1.40s/it, training loss=0.0887]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1046/1835 [24:20<18:19,  1.39s/it, training loss=0.0887]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1046/1835 [24:21<18:19,  1.39s/it, training loss=0.0781]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1047/1835 [24:21<18:17,  1.39s/it, training loss=0.0781]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1047/1835 [24:22<18:17,  1.39s/it, training loss=0.1344]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1048/1835 [24:22<18:17,  1.39s/it, training loss=0.1344]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1048/1835 [24:24<18:17,  1.39s/it, training loss=0.0721]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1049/1835 [24:24<18:14,  1.39s/it, training loss=0.0721]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1049/1835 [24:25<18:14,  1.39s/it, training loss=0.1729]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1050/1835 [24:25<18:14,  1.39s/it, training loss=0.1729]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1050/1835 [24:27<18:14,  1.39s/it, training loss=0.1164]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1051/1835 [24:27<18:13,  1.40s/it, training loss=0.1164]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1051/1835 [24:28<18:13,  1.40s/it, training loss=0.1022]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1052/1835 [24:28<18:12,  1.39s/it, training loss=0.1022]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1052/1835 [24:29<18:12,  1.39s/it, training loss=0.1610]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1053/1835 [24:29<18:11,  1.40s/it, training loss=0.1610]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1053/1835 [24:31<18:11,  1.40s/it, training loss=0.0269]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1054/1835 [24:31<18:10,  1.40s/it, training loss=0.0269]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1054/1835 [24:32<18:10,  1.40s/it, training loss=0.1578]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1055/1835 [24:32<18:10,  1.40s/it, training loss=0.1578]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 1055/1835 [24:34<18:10,  1.40s/it, training loss=0.1913]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1056/1835 [24:34<18:08,  1.40s/it, training loss=0.1913]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1056/1835 [24:35<18:08,  1.40s/it, training loss=0.1123]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1057/1835 [24:35<18:04,  1.39s/it, training loss=0.1123]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1057/1835 [24:36<18:04,  1.39s/it, training loss=0.0165]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1058/1835 [24:36<18:03,  1.39s/it, training loss=0.0165]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1058/1835 [24:38<18:03,  1.39s/it, training loss=0.0995]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1059/1835 [24:38<18:03,  1.40s/it, training loss=0.0995]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1059/1835 [24:39<18:03,  1.40s/it, training loss=0.1543]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1060/1835 [24:39<18:00,  1.39s/it, training loss=0.1543]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1060/1835 [24:41<18:00,  1.39s/it, training loss=0.1623]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1061/1835 [24:41<17:59,  1.40s/it, training loss=0.1623]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1061/1835 [24:42<17:59,  1.40s/it, training loss=0.1433]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1062/1835 [24:42<17:56,  1.39s/it, training loss=0.1433]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1062/1835 [24:43<17:56,  1.39s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1063/1835 [24:43<17:53,  1.39s/it, training loss=0.1136]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1063/1835 [24:45<17:53,  1.39s/it, training loss=0.1493]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1064/1835 [24:45<17:53,  1.39s/it, training loss=0.1493]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1064/1835 [24:46<17:53,  1.39s/it, training loss=0.0181]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1065/1835 [24:46<17:52,  1.39s/it, training loss=0.0181]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1065/1835 [24:48<17:52,  1.39s/it, training loss=0.0157]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1066/1835 [24:48<17:50,  1.39s/it, training loss=0.0157]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1066/1835 [24:49<17:50,  1.39s/it, training loss=0.1586]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1067/1835 [24:49<17:50,  1.39s/it, training loss=0.1586]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1067/1835 [24:50<17:50,  1.39s/it, training loss=0.0887]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1068/1835 [24:50<17:48,  1.39s/it, training loss=0.0887]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1068/1835 [24:52<17:48,  1.39s/it, training loss=0.0901]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1069/1835 [24:52<17:46,  1.39s/it, training loss=0.0901]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1069/1835 [24:53<17:46,  1.39s/it, training loss=0.2094]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1070/1835 [24:53<17:44,  1.39s/it, training loss=0.2094]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1070/1835 [24:55<17:44,  1.39s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1071/1835 [24:55<17:43,  1.39s/it, training loss=0.1135]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1071/1835 [24:56<17:43,  1.39s/it, training loss=0.0619]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1072/1835 [24:56<17:41,  1.39s/it, training loss=0.0619]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1072/1835 [24:57<17:41,  1.39s/it, training loss=0.1757]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1073/1835 [24:57<17:42,  1.39s/it, training loss=0.1757]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 1073/1835 [24:59<17:42,  1.39s/it, training loss=0.2617]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 1074/1835 [24:59<17:39,  1.39s/it, training loss=0.2617]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 1074/1835 [25:00<17:39,  1.39s/it, training loss=0.1006]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 1075/1835 [25:00<17:38,  1.39s/it, training loss=0.1006]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 1075/1835 [25:01<17:38,  1.39s/it, training loss=0.0572]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 1076/1835 [25:02<17:37,  1.39s/it, training loss=0.0572]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 1076/1835 [25:03<17:37,  1.39s/it, training loss=0.1722]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 1077/1835 [25:03<17:35,  1.39s/it, training loss=0.1722]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 1077/1835 [25:04<17:35,  1.39s/it, training loss=0.0285]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 1078/1835 [25:04<17:34,  1.39s/it, training loss=0.0285]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 1078/1835 [25:06<17:34,  1.39s/it, training loss=0.0754]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1079/1835 [25:06<17:32,  1.39s/it, training loss=0.0754]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1079/1835 [25:07<17:32,  1.39s/it, training loss=0.0936]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1080/1835 [25:07<17:32,  1.39s/it, training loss=0.0936]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1080/1835 [25:08<17:32,  1.39s/it, training loss=0.0804]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1081/1835 [25:08<17:30,  1.39s/it, training loss=0.0804]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1081/1835 [25:10<17:30,  1.39s/it, training loss=0.2409]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1082/1835 [25:10<17:29,  1.39s/it, training loss=0.2409]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1082/1835 [25:11<17:29,  1.39s/it, training loss=0.0550]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1083/1835 [25:11<17:26,  1.39s/it, training loss=0.0550]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1083/1835 [25:13<17:26,  1.39s/it, training loss=0.0678]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1084/1835 [25:13<17:24,  1.39s/it, training loss=0.0678]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1084/1835 [25:14<17:24,  1.39s/it, training loss=0.1425]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1085/1835 [25:14<17:24,  1.39s/it, training loss=0.1425]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1085/1835 [25:15<17:24,  1.39s/it, training loss=0.1188]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1086/1835 [25:15<17:24,  1.39s/it, training loss=0.1188]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1086/1835 [25:17<17:24,  1.39s/it, training loss=0.0908]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1087/1835 [25:17<17:23,  1.40s/it, training loss=0.0908]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1087/1835 [25:18<17:23,  1.40s/it, training loss=0.1311]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1088/1835 [25:18<17:20,  1.39s/it, training loss=0.1311]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1088/1835 [25:20<17:20,  1.39s/it, training loss=0.1615]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1089/1835 [25:20<17:19,  1.39s/it, training loss=0.1615]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1089/1835 [25:21<17:19,  1.39s/it, training loss=0.0923]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1090/1835 [25:21<17:17,  1.39s/it, training loss=0.0923]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1090/1835 [25:22<17:17,  1.39s/it, training loss=0.1310]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1091/1835 [25:22<17:15,  1.39s/it, training loss=0.1310]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 1091/1835 [25:24<17:15,  1.39s/it, training loss=0.2193]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1092/1835 [25:24<17:15,  1.39s/it, training loss=0.2193]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1092/1835 [25:25<17:15,  1.39s/it, training loss=0.0568]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1093/1835 [25:25<17:13,  1.39s/it, training loss=0.0568]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1093/1835 [25:27<17:13,  1.39s/it, training loss=0.0661]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1094/1835 [25:27<17:12,  1.39s/it, training loss=0.0661]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1094/1835 [25:28<17:12,  1.39s/it, training loss=0.2627]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1095/1835 [25:28<17:10,  1.39s/it, training loss=0.2627]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1095/1835 [25:29<17:10,  1.39s/it, training loss=0.2017]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1096/1835 [25:29<17:09,  1.39s/it, training loss=0.2017]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1096/1835 [25:31<17:09,  1.39s/it, training loss=0.0812]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1097/1835 [25:31<17:09,  1.40s/it, training loss=0.0812]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1097/1835 [25:32<17:09,  1.40s/it, training loss=0.1796]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1098/1835 [25:32<17:07,  1.39s/it, training loss=0.1796]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1098/1835 [25:34<17:07,  1.39s/it, training loss=0.0240]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1099/1835 [25:34<17:04,  1.39s/it, training loss=0.0240]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1099/1835 [25:35<17:04,  1.39s/it, training loss=0.1216]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1100/1835 [25:35<17:02,  1.39s/it, training loss=0.1216]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 1100/1835 [25:36<17:02,  1.39s/it, training loss=0.0765]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1101/1835 [25:36<17:01,  1.39s/it, training loss=0.0765]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1101/1835 [25:38<17:01,  1.39s/it, training loss=0.0395]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1102/1835 [25:38<17:00,  1.39s/it, training loss=0.0395]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1102/1835 [25:39<17:00,  1.39s/it, training loss=0.1229]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1103/1835 [25:39<16:58,  1.39s/it, training loss=0.1229]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1103/1835 [25:40<16:58,  1.39s/it, training loss=0.0261]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1104/1835 [25:41<16:57,  1.39s/it, training loss=0.0261]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1104/1835 [25:42<16:57,  1.39s/it, training loss=0.2229]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1105/1835 [25:42<17:00,  1.40s/it, training loss=0.2229]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1105/1835 [25:43<17:00,  1.40s/it, training loss=0.1030]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1106/1835 [25:43<16:57,  1.40s/it, training loss=0.1030]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1106/1835 [25:45<16:57,  1.40s/it, training loss=0.0613]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1107/1835 [25:45<16:56,  1.40s/it, training loss=0.0613]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1107/1835 [25:46<16:56,  1.40s/it, training loss=0.0801]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1108/1835 [25:46<16:56,  1.40s/it, training loss=0.0801]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1108/1835 [25:47<16:56,  1.40s/it, training loss=0.0623]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1109/1835 [25:48<16:54,  1.40s/it, training loss=0.0623]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1109/1835 [25:49<16:54,  1.40s/it, training loss=0.1680]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1110/1835 [25:49<16:53,  1.40s/it, training loss=0.1680]\u001b[A\n",
            "Epoch 3:  60%|██████    | 1110/1835 [25:50<16:53,  1.40s/it, training loss=0.0156]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1111/1835 [25:50<16:51,  1.40s/it, training loss=0.0156]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1111/1835 [25:52<16:51,  1.40s/it, training loss=0.0702]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1112/1835 [25:52<16:50,  1.40s/it, training loss=0.0702]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1112/1835 [25:53<16:50,  1.40s/it, training loss=0.2339]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1113/1835 [25:53<16:48,  1.40s/it, training loss=0.2339]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1113/1835 [25:54<16:48,  1.40s/it, training loss=0.0637]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1114/1835 [25:54<16:46,  1.40s/it, training loss=0.0637]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1114/1835 [25:56<16:46,  1.40s/it, training loss=0.2010]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1115/1835 [25:56<16:45,  1.40s/it, training loss=0.2010]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1115/1835 [25:57<16:45,  1.40s/it, training loss=0.0499]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1116/1835 [25:57<16:43,  1.40s/it, training loss=0.0499]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1116/1835 [25:59<16:43,  1.40s/it, training loss=0.0440]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1117/1835 [25:59<16:40,  1.39s/it, training loss=0.0440]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1117/1835 [26:00<16:40,  1.39s/it, training loss=0.1087]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1118/1835 [26:00<16:37,  1.39s/it, training loss=0.1087]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1118/1835 [26:01<16:37,  1.39s/it, training loss=0.1605]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1119/1835 [26:01<16:35,  1.39s/it, training loss=0.1605]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1119/1835 [26:03<16:35,  1.39s/it, training loss=0.1622]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1120/1835 [26:03<16:33,  1.39s/it, training loss=0.1622]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1120/1835 [26:04<16:33,  1.39s/it, training loss=0.0888]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1121/1835 [26:04<16:34,  1.39s/it, training loss=0.0888]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1121/1835 [26:06<16:34,  1.39s/it, training loss=0.0698]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1122/1835 [26:06<16:33,  1.39s/it, training loss=0.0698]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1122/1835 [26:07<16:33,  1.39s/it, training loss=0.1699]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1123/1835 [26:07<16:32,  1.39s/it, training loss=0.1699]\u001b[A\n",
            "Epoch 3:  61%|██████    | 1123/1835 [26:08<16:32,  1.39s/it, training loss=0.1401]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 1124/1835 [26:08<16:31,  1.40s/it, training loss=0.1401]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 1124/1835 [26:10<16:31,  1.40s/it, training loss=0.1425]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 1125/1835 [26:10<16:31,  1.40s/it, training loss=0.1425]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 1125/1835 [26:11<16:31,  1.40s/it, training loss=0.0443]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 1126/1835 [26:11<16:29,  1.40s/it, training loss=0.0443]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 1126/1835 [26:13<16:29,  1.40s/it, training loss=0.1435]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 1127/1835 [26:13<16:28,  1.40s/it, training loss=0.1435]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 1127/1835 [26:14<16:28,  1.40s/it, training loss=0.0501]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 1128/1835 [26:14<16:26,  1.40s/it, training loss=0.0501]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 1128/1835 [26:15<16:26,  1.40s/it, training loss=0.1233]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1129/1835 [26:15<16:25,  1.40s/it, training loss=0.1233]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1129/1835 [26:17<16:25,  1.40s/it, training loss=0.1062]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1130/1835 [26:17<16:24,  1.40s/it, training loss=0.1062]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1130/1835 [26:18<16:24,  1.40s/it, training loss=0.0558]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1131/1835 [26:18<16:23,  1.40s/it, training loss=0.0558]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1131/1835 [26:20<16:23,  1.40s/it, training loss=0.0498]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1132/1835 [26:20<16:22,  1.40s/it, training loss=0.0498]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1132/1835 [26:21<16:22,  1.40s/it, training loss=0.1720]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1133/1835 [26:21<16:20,  1.40s/it, training loss=0.1720]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1133/1835 [26:22<16:20,  1.40s/it, training loss=0.1405]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1134/1835 [26:22<16:20,  1.40s/it, training loss=0.1405]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1134/1835 [26:24<16:20,  1.40s/it, training loss=0.0705]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1135/1835 [26:24<16:18,  1.40s/it, training loss=0.0705]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1135/1835 [26:25<16:18,  1.40s/it, training loss=0.1445]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1136/1835 [26:25<16:16,  1.40s/it, training loss=0.1445]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1136/1835 [26:27<16:16,  1.40s/it, training loss=0.0996]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1137/1835 [26:27<16:13,  1.40s/it, training loss=0.0996]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1137/1835 [26:28<16:13,  1.40s/it, training loss=0.0828]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1138/1835 [26:28<16:14,  1.40s/it, training loss=0.0828]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1138/1835 [26:29<16:14,  1.40s/it, training loss=0.1041]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1139/1835 [26:29<16:11,  1.40s/it, training loss=0.1041]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1139/1835 [26:31<16:11,  1.40s/it, training loss=0.1679]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1140/1835 [26:31<16:09,  1.40s/it, training loss=0.1679]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1140/1835 [26:32<16:09,  1.40s/it, training loss=0.0586]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1141/1835 [26:32<16:11,  1.40s/it, training loss=0.0586]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1141/1835 [26:34<16:11,  1.40s/it, training loss=0.1061]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1142/1835 [26:34<16:09,  1.40s/it, training loss=0.1061]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1142/1835 [26:35<16:09,  1.40s/it, training loss=0.2073]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1143/1835 [26:35<16:06,  1.40s/it, training loss=0.2073]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1143/1835 [26:36<16:06,  1.40s/it, training loss=0.1370]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1144/1835 [26:36<16:04,  1.40s/it, training loss=0.1370]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1144/1835 [26:38<16:04,  1.40s/it, training loss=0.0335]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1145/1835 [26:38<16:01,  1.39s/it, training loss=0.0335]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1145/1835 [26:39<16:01,  1.39s/it, training loss=0.0550]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1146/1835 [26:39<16:00,  1.39s/it, training loss=0.0550]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 1146/1835 [26:41<16:00,  1.39s/it, training loss=0.0221]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1147/1835 [26:41<15:58,  1.39s/it, training loss=0.0221]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1147/1835 [26:42<15:58,  1.39s/it, training loss=0.0390]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1148/1835 [26:42<15:56,  1.39s/it, training loss=0.0390]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1148/1835 [26:43<15:56,  1.39s/it, training loss=0.1950]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1149/1835 [26:43<15:55,  1.39s/it, training loss=0.1950]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1149/1835 [26:45<15:55,  1.39s/it, training loss=0.1212]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1150/1835 [26:45<15:54,  1.39s/it, training loss=0.1212]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1150/1835 [26:46<15:54,  1.39s/it, training loss=0.2238]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1151/1835 [26:46<15:52,  1.39s/it, training loss=0.2238]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1151/1835 [26:47<15:52,  1.39s/it, training loss=0.0484]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1152/1835 [26:47<15:52,  1.40s/it, training loss=0.0484]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1152/1835 [26:49<15:52,  1.40s/it, training loss=0.0499]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1153/1835 [26:49<15:51,  1.40s/it, training loss=0.0499]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1153/1835 [26:50<15:51,  1.40s/it, training loss=0.1139]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1154/1835 [26:50<15:48,  1.39s/it, training loss=0.1139]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1154/1835 [26:52<15:48,  1.39s/it, training loss=0.2113]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1155/1835 [26:52<15:49,  1.40s/it, training loss=0.2113]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1155/1835 [26:53<15:49,  1.40s/it, training loss=0.0858]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1156/1835 [26:53<15:48,  1.40s/it, training loss=0.0858]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1156/1835 [26:54<15:48,  1.40s/it, training loss=0.1665]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1157/1835 [26:54<15:48,  1.40s/it, training loss=0.1665]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1157/1835 [26:56<15:48,  1.40s/it, training loss=0.2136]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1158/1835 [26:56<15:45,  1.40s/it, training loss=0.2136]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1158/1835 [26:57<15:45,  1.40s/it, training loss=0.1551]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1159/1835 [26:57<15:42,  1.39s/it, training loss=0.1551]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1159/1835 [26:59<15:42,  1.39s/it, training loss=0.0757]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1160/1835 [26:59<15:40,  1.39s/it, training loss=0.0757]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1160/1835 [27:00<15:40,  1.39s/it, training loss=0.0942]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1161/1835 [27:00<15:40,  1.40s/it, training loss=0.0942]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1161/1835 [27:01<15:40,  1.40s/it, training loss=0.0711]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1162/1835 [27:01<15:39,  1.40s/it, training loss=0.0711]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1162/1835 [27:03<15:39,  1.40s/it, training loss=0.0203]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1163/1835 [27:03<15:37,  1.40s/it, training loss=0.0203]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1163/1835 [27:04<15:37,  1.40s/it, training loss=0.0449]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1164/1835 [27:04<15:35,  1.39s/it, training loss=0.0449]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1164/1835 [27:06<15:35,  1.39s/it, training loss=0.2742]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1165/1835 [27:06<15:36,  1.40s/it, training loss=0.2742]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 1165/1835 [27:07<15:36,  1.40s/it, training loss=0.1609]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 1166/1835 [27:07<15:33,  1.40s/it, training loss=0.1609]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 1166/1835 [27:08<15:33,  1.40s/it, training loss=0.1429]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 1167/1835 [27:08<15:30,  1.39s/it, training loss=0.1429]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 1167/1835 [27:10<15:30,  1.39s/it, training loss=0.0712]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 1168/1835 [27:10<15:28,  1.39s/it, training loss=0.0712]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 1168/1835 [27:11<15:28,  1.39s/it, training loss=0.0779]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 1169/1835 [27:11<15:26,  1.39s/it, training loss=0.0779]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 1169/1835 [27:13<15:26,  1.39s/it, training loss=0.2892]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1170/1835 [27:13<15:24,  1.39s/it, training loss=0.2892]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1170/1835 [27:14<15:24,  1.39s/it, training loss=0.1233]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1171/1835 [27:14<15:22,  1.39s/it, training loss=0.1233]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1171/1835 [27:15<15:22,  1.39s/it, training loss=0.0464]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1172/1835 [27:15<15:23,  1.39s/it, training loss=0.0464]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1172/1835 [27:17<15:23,  1.39s/it, training loss=0.2705]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1173/1835 [27:17<15:21,  1.39s/it, training loss=0.2705]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1173/1835 [27:18<15:21,  1.39s/it, training loss=0.2468]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1174/1835 [27:18<15:18,  1.39s/it, training loss=0.2468]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1174/1835 [27:20<15:18,  1.39s/it, training loss=0.1510]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1175/1835 [27:20<15:16,  1.39s/it, training loss=0.1510]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1175/1835 [27:21<15:16,  1.39s/it, training loss=0.2342]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1176/1835 [27:21<15:14,  1.39s/it, training loss=0.2342]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1176/1835 [27:22<15:14,  1.39s/it, training loss=0.0411]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1177/1835 [27:22<15:14,  1.39s/it, training loss=0.0411]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1177/1835 [27:24<15:14,  1.39s/it, training loss=0.1845]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1178/1835 [27:24<15:14,  1.39s/it, training loss=0.1845]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1178/1835 [27:25<15:14,  1.39s/it, training loss=0.0840]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1179/1835 [27:25<15:12,  1.39s/it, training loss=0.0840]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1179/1835 [27:26<15:12,  1.39s/it, training loss=0.1472]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1180/1835 [27:26<15:11,  1.39s/it, training loss=0.1472]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1180/1835 [27:28<15:11,  1.39s/it, training loss=0.1068]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1181/1835 [27:28<15:10,  1.39s/it, training loss=0.1068]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1181/1835 [27:29<15:10,  1.39s/it, training loss=0.0916]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1182/1835 [27:29<15:10,  1.39s/it, training loss=0.0916]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1182/1835 [27:31<15:10,  1.39s/it, training loss=0.0778]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1183/1835 [27:31<15:09,  1.39s/it, training loss=0.0778]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 1183/1835 [27:32<15:09,  1.39s/it, training loss=0.1535]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1184/1835 [27:32<15:09,  1.40s/it, training loss=0.1535]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1184/1835 [27:33<15:09,  1.40s/it, training loss=0.1570]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1185/1835 [27:33<15:08,  1.40s/it, training loss=0.1570]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1185/1835 [27:35<15:08,  1.40s/it, training loss=0.1424]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1186/1835 [27:35<15:06,  1.40s/it, training loss=0.1424]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1186/1835 [27:36<15:06,  1.40s/it, training loss=0.1512]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1187/1835 [27:36<15:04,  1.40s/it, training loss=0.1512]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1187/1835 [27:38<15:04,  1.40s/it, training loss=0.2639]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1188/1835 [27:38<15:03,  1.40s/it, training loss=0.2639]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1188/1835 [27:39<15:03,  1.40s/it, training loss=0.1946]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1189/1835 [27:39<15:01,  1.40s/it, training loss=0.1946]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1189/1835 [27:40<15:01,  1.40s/it, training loss=0.0460]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1190/1835 [27:40<15:00,  1.40s/it, training loss=0.0460]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1190/1835 [27:42<15:00,  1.40s/it, training loss=0.1117]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1191/1835 [27:42<14:58,  1.40s/it, training loss=0.1117]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1191/1835 [27:43<14:58,  1.40s/it, training loss=0.1013]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1192/1835 [27:43<14:57,  1.40s/it, training loss=0.1013]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 1192/1835 [27:45<14:57,  1.40s/it, training loss=0.1774]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1193/1835 [27:45<14:56,  1.40s/it, training loss=0.1774]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1193/1835 [27:46<14:56,  1.40s/it, training loss=0.0490]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1194/1835 [27:46<14:53,  1.39s/it, training loss=0.0490]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1194/1835 [27:47<14:53,  1.39s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1195/1835 [27:47<14:53,  1.40s/it, training loss=0.1710]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1195/1835 [27:49<14:53,  1.40s/it, training loss=0.0395]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1196/1835 [27:49<14:52,  1.40s/it, training loss=0.0395]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1196/1835 [27:50<14:52,  1.40s/it, training loss=0.0374]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1197/1835 [27:50<14:50,  1.40s/it, training loss=0.0374]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1197/1835 [27:52<14:50,  1.40s/it, training loss=0.1360]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1198/1835 [27:52<14:50,  1.40s/it, training loss=0.1360]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1198/1835 [27:53<14:50,  1.40s/it, training loss=0.0274]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1199/1835 [27:53<14:48,  1.40s/it, training loss=0.0274]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1199/1835 [27:54<14:48,  1.40s/it, training loss=0.0859]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1200/1835 [27:54<14:46,  1.40s/it, training loss=0.0859]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1200/1835 [27:56<14:46,  1.40s/it, training loss=0.0911]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1201/1835 [27:56<14:46,  1.40s/it, training loss=0.0911]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 1201/1835 [27:57<14:46,  1.40s/it, training loss=0.0785]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1202/1835 [27:57<14:44,  1.40s/it, training loss=0.0785]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1202/1835 [27:59<14:44,  1.40s/it, training loss=0.0943]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1203/1835 [27:59<14:42,  1.40s/it, training loss=0.0943]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1203/1835 [28:00<14:42,  1.40s/it, training loss=0.0927]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1204/1835 [28:00<14:39,  1.39s/it, training loss=0.0927]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1204/1835 [28:01<14:39,  1.39s/it, training loss=0.3158]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1205/1835 [28:01<14:39,  1.40s/it, training loss=0.3158]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1205/1835 [28:03<14:39,  1.40s/it, training loss=0.1451]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1206/1835 [28:03<14:39,  1.40s/it, training loss=0.1451]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1206/1835 [28:04<14:39,  1.40s/it, training loss=0.0256]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1207/1835 [28:04<14:38,  1.40s/it, training loss=0.0256]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1207/1835 [28:06<14:38,  1.40s/it, training loss=0.0547]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1208/1835 [28:06<14:36,  1.40s/it, training loss=0.0547]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1208/1835 [28:07<14:36,  1.40s/it, training loss=0.0638]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1209/1835 [28:07<14:36,  1.40s/it, training loss=0.0638]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1209/1835 [28:08<14:36,  1.40s/it, training loss=0.0897]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1210/1835 [28:08<14:36,  1.40s/it, training loss=0.0897]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1210/1835 [28:10<14:36,  1.40s/it, training loss=0.1858]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1211/1835 [28:10<14:34,  1.40s/it, training loss=0.1858]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1211/1835 [28:11<14:34,  1.40s/it, training loss=0.1059]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1212/1835 [28:11<14:33,  1.40s/it, training loss=0.1059]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1212/1835 [28:13<14:33,  1.40s/it, training loss=0.0909]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1213/1835 [28:13<14:30,  1.40s/it, training loss=0.0909]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1213/1835 [28:14<14:30,  1.40s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1214/1835 [28:14<14:27,  1.40s/it, training loss=0.1179]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1214/1835 [28:15<14:27,  1.40s/it, training loss=0.0343]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1215/1835 [28:15<14:26,  1.40s/it, training loss=0.0343]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 1215/1835 [28:17<14:26,  1.40s/it, training loss=0.1140]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 1216/1835 [28:17<14:25,  1.40s/it, training loss=0.1140]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 1216/1835 [28:18<14:25,  1.40s/it, training loss=0.0161]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 1217/1835 [28:18<14:23,  1.40s/it, training loss=0.0161]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 1217/1835 [28:20<14:23,  1.40s/it, training loss=0.1364]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 1218/1835 [28:20<14:21,  1.40s/it, training loss=0.1364]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 1218/1835 [28:21<14:21,  1.40s/it, training loss=0.1018]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 1219/1835 [28:21<14:21,  1.40s/it, training loss=0.1018]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 1219/1835 [28:22<14:21,  1.40s/it, training loss=0.1569]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 1220/1835 [28:22<14:20,  1.40s/it, training loss=0.1569]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 1220/1835 [28:24<14:20,  1.40s/it, training loss=0.1178]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1221/1835 [28:24<14:17,  1.40s/it, training loss=0.1178]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1221/1835 [28:25<14:17,  1.40s/it, training loss=0.1029]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1222/1835 [28:25<14:19,  1.40s/it, training loss=0.1029]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1222/1835 [28:27<14:19,  1.40s/it, training loss=0.1358]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1223/1835 [28:27<14:17,  1.40s/it, training loss=0.1358]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1223/1835 [28:28<14:17,  1.40s/it, training loss=0.1601]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1224/1835 [28:28<14:15,  1.40s/it, training loss=0.1601]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1224/1835 [28:29<14:15,  1.40s/it, training loss=0.0364]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1225/1835 [28:29<14:12,  1.40s/it, training loss=0.0364]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1225/1835 [28:31<14:12,  1.40s/it, training loss=0.0723]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1226/1835 [28:31<14:10,  1.40s/it, training loss=0.0723]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1226/1835 [28:32<14:10,  1.40s/it, training loss=0.1360]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1227/1835 [28:32<14:09,  1.40s/it, training loss=0.1360]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1227/1835 [28:34<14:09,  1.40s/it, training loss=0.0673]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1228/1835 [28:34<14:09,  1.40s/it, training loss=0.0673]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1228/1835 [28:35<14:09,  1.40s/it, training loss=0.0731]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1229/1835 [28:35<14:07,  1.40s/it, training loss=0.0731]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1229/1835 [28:36<14:07,  1.40s/it, training loss=0.0732]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1230/1835 [28:36<14:04,  1.40s/it, training loss=0.0732]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1230/1835 [28:38<14:04,  1.40s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1231/1835 [28:38<14:03,  1.40s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1231/1835 [28:39<14:03,  1.40s/it, training loss=0.0714]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1232/1835 [28:39<14:02,  1.40s/it, training loss=0.0714]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1232/1835 [28:41<14:02,  1.40s/it, training loss=0.2075]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1233/1835 [28:41<14:00,  1.40s/it, training loss=0.2075]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1233/1835 [28:42<14:00,  1.40s/it, training loss=0.0452]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1234/1835 [28:42<13:59,  1.40s/it, training loss=0.0452]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1234/1835 [28:43<13:59,  1.40s/it, training loss=0.0882]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1235/1835 [28:43<13:57,  1.40s/it, training loss=0.0882]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1235/1835 [28:45<13:57,  1.40s/it, training loss=0.1249]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1236/1835 [28:45<13:56,  1.40s/it, training loss=0.1249]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1236/1835 [28:46<13:56,  1.40s/it, training loss=0.2460]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1237/1835 [28:46<13:55,  1.40s/it, training loss=0.2460]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1237/1835 [28:48<13:55,  1.40s/it, training loss=0.0285]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1238/1835 [28:48<13:53,  1.40s/it, training loss=0.0285]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 1238/1835 [28:49<13:53,  1.40s/it, training loss=0.2486]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1239/1835 [28:49<13:52,  1.40s/it, training loss=0.2486]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1239/1835 [28:50<13:52,  1.40s/it, training loss=0.2263]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1240/1835 [28:50<13:51,  1.40s/it, training loss=0.2263]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1240/1835 [28:52<13:51,  1.40s/it, training loss=0.0626]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1241/1835 [28:52<13:50,  1.40s/it, training loss=0.0626]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1241/1835 [28:53<13:50,  1.40s/it, training loss=0.2940]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1242/1835 [28:53<13:49,  1.40s/it, training loss=0.2940]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1242/1835 [28:55<13:49,  1.40s/it, training loss=0.0872]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1243/1835 [28:55<13:47,  1.40s/it, training loss=0.0872]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1243/1835 [28:56<13:47,  1.40s/it, training loss=0.1031]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1244/1835 [28:56<13:45,  1.40s/it, training loss=0.1031]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1244/1835 [28:57<13:45,  1.40s/it, training loss=0.1204]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1245/1835 [28:57<13:44,  1.40s/it, training loss=0.1204]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1245/1835 [28:59<13:44,  1.40s/it, training loss=0.1061]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1246/1835 [28:59<13:42,  1.40s/it, training loss=0.1061]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1246/1835 [29:00<13:42,  1.40s/it, training loss=0.0272]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1247/1835 [29:00<13:41,  1.40s/it, training loss=0.0272]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1247/1835 [29:02<13:41,  1.40s/it, training loss=0.0794]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1248/1835 [29:02<13:40,  1.40s/it, training loss=0.0794]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1248/1835 [29:03<13:40,  1.40s/it, training loss=0.1825]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1249/1835 [29:03<13:39,  1.40s/it, training loss=0.1825]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1249/1835 [29:04<13:39,  1.40s/it, training loss=0.1884]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1250/1835 [29:04<13:36,  1.40s/it, training loss=0.1884]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1250/1835 [29:06<13:36,  1.40s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1251/1835 [29:06<13:34,  1.40s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1251/1835 [29:07<13:34,  1.40s/it, training loss=0.1546]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1252/1835 [29:07<13:34,  1.40s/it, training loss=0.1546]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1252/1835 [29:09<13:34,  1.40s/it, training loss=0.1051]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1253/1835 [29:09<13:33,  1.40s/it, training loss=0.1051]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1253/1835 [29:10<13:33,  1.40s/it, training loss=0.0727]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1254/1835 [29:10<13:30,  1.40s/it, training loss=0.0727]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1254/1835 [29:11<13:30,  1.40s/it, training loss=0.0865]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1255/1835 [29:11<13:28,  1.39s/it, training loss=0.0865]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1255/1835 [29:13<13:28,  1.39s/it, training loss=0.0934]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1256/1835 [29:13<13:26,  1.39s/it, training loss=0.0934]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 1256/1835 [29:14<13:26,  1.39s/it, training loss=0.0422]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 1257/1835 [29:14<13:26,  1.39s/it, training loss=0.0422]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 1257/1835 [29:15<13:26,  1.39s/it, training loss=0.0924]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 1258/1835 [29:15<13:23,  1.39s/it, training loss=0.0924]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 1258/1835 [29:17<13:23,  1.39s/it, training loss=0.0169]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 1259/1835 [29:17<13:22,  1.39s/it, training loss=0.0169]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 1259/1835 [29:18<13:22,  1.39s/it, training loss=0.2262]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 1260/1835 [29:18<13:20,  1.39s/it, training loss=0.2262]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 1260/1835 [29:20<13:20,  1.39s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 1261/1835 [29:20<13:20,  1.39s/it, training loss=0.1886]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 1261/1835 [29:21<13:20,  1.39s/it, training loss=0.0801]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1262/1835 [29:21<13:18,  1.39s/it, training loss=0.0801]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1262/1835 [29:22<13:18,  1.39s/it, training loss=0.0863]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1263/1835 [29:22<13:16,  1.39s/it, training loss=0.0863]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1263/1835 [29:24<13:16,  1.39s/it, training loss=0.0799]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1264/1835 [29:24<13:16,  1.40s/it, training loss=0.0799]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1264/1835 [29:25<13:16,  1.40s/it, training loss=0.0571]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1265/1835 [29:25<13:15,  1.40s/it, training loss=0.0571]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1265/1835 [29:27<13:15,  1.40s/it, training loss=0.1774]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1266/1835 [29:27<13:15,  1.40s/it, training loss=0.1774]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1266/1835 [29:28<13:15,  1.40s/it, training loss=0.1763]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1267/1835 [29:28<13:13,  1.40s/it, training loss=0.1763]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1267/1835 [29:29<13:13,  1.40s/it, training loss=0.1618]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1268/1835 [29:29<13:13,  1.40s/it, training loss=0.1618]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1268/1835 [29:31<13:13,  1.40s/it, training loss=0.0786]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1269/1835 [29:31<13:11,  1.40s/it, training loss=0.0786]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1269/1835 [29:32<13:11,  1.40s/it, training loss=0.0582]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1270/1835 [29:32<13:09,  1.40s/it, training loss=0.0582]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1270/1835 [29:34<13:09,  1.40s/it, training loss=0.1769]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1271/1835 [29:34<13:07,  1.40s/it, training loss=0.1769]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1271/1835 [29:35<13:07,  1.40s/it, training loss=0.0591]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1272/1835 [29:35<13:05,  1.40s/it, training loss=0.0591]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1272/1835 [29:36<13:05,  1.40s/it, training loss=0.0955]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1273/1835 [29:36<13:04,  1.40s/it, training loss=0.0955]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1273/1835 [29:38<13:04,  1.40s/it, training loss=0.2192]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1274/1835 [29:38<13:02,  1.39s/it, training loss=0.2192]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1274/1835 [29:39<13:02,  1.39s/it, training loss=0.0592]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1275/1835 [29:39<12:59,  1.39s/it, training loss=0.0592]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 1275/1835 [29:41<12:59,  1.39s/it, training loss=0.1078]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1276/1835 [29:41<12:58,  1.39s/it, training loss=0.1078]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1276/1835 [29:42<12:58,  1.39s/it, training loss=0.1182]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1277/1835 [29:42<12:58,  1.39s/it, training loss=0.1182]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1277/1835 [29:43<12:58,  1.39s/it, training loss=0.3573]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1278/1835 [29:43<12:55,  1.39s/it, training loss=0.3573]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1278/1835 [29:45<12:55,  1.39s/it, training loss=0.2927]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1279/1835 [29:45<12:55,  1.39s/it, training loss=0.2927]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1279/1835 [29:46<12:55,  1.39s/it, training loss=0.0994]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1280/1835 [29:46<12:52,  1.39s/it, training loss=0.0994]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1280/1835 [29:48<12:52,  1.39s/it, training loss=0.0498]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1281/1835 [29:48<12:51,  1.39s/it, training loss=0.0498]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1281/1835 [29:49<12:51,  1.39s/it, training loss=0.1012]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1282/1835 [29:49<12:48,  1.39s/it, training loss=0.1012]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1282/1835 [29:50<12:48,  1.39s/it, training loss=0.0665]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1283/1835 [29:50<12:48,  1.39s/it, training loss=0.0665]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1283/1835 [29:52<12:48,  1.39s/it, training loss=0.1027]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1284/1835 [29:52<12:47,  1.39s/it, training loss=0.1027]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 1284/1835 [29:53<12:47,  1.39s/it, training loss=0.1053]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1285/1835 [29:53<12:46,  1.39s/it, training loss=0.1053]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1285/1835 [29:55<12:46,  1.39s/it, training loss=0.1323]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1286/1835 [29:55<12:45,  1.39s/it, training loss=0.1323]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1286/1835 [29:56<12:45,  1.39s/it, training loss=0.0752]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1287/1835 [29:56<12:43,  1.39s/it, training loss=0.0752]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1287/1835 [29:57<12:43,  1.39s/it, training loss=0.1812]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1288/1835 [29:57<12:42,  1.39s/it, training loss=0.1812]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1288/1835 [29:59<12:42,  1.39s/it, training loss=0.1229]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1289/1835 [29:59<12:41,  1.39s/it, training loss=0.1229]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1289/1835 [30:00<12:41,  1.39s/it, training loss=0.2703]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1290/1835 [30:00<12:41,  1.40s/it, training loss=0.2703]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1290/1835 [30:01<12:41,  1.40s/it, training loss=0.1032]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1291/1835 [30:02<12:39,  1.40s/it, training loss=0.1032]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1291/1835 [30:03<12:39,  1.40s/it, training loss=0.1612]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1292/1835 [30:03<12:38,  1.40s/it, training loss=0.1612]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1292/1835 [30:04<12:38,  1.40s/it, training loss=0.1083]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1293/1835 [30:04<12:38,  1.40s/it, training loss=0.1083]\u001b[A\n",
            "Epoch 3:  70%|███████   | 1293/1835 [30:06<12:38,  1.40s/it, training loss=0.2224]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1294/1835 [30:06<12:37,  1.40s/it, training loss=0.2224]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1294/1835 [30:07<12:37,  1.40s/it, training loss=0.1452]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1295/1835 [30:07<12:35,  1.40s/it, training loss=0.1452]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1295/1835 [30:09<12:35,  1.40s/it, training loss=0.1949]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1296/1835 [30:09<12:34,  1.40s/it, training loss=0.1949]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1296/1835 [30:10<12:34,  1.40s/it, training loss=0.0773]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1297/1835 [30:10<12:32,  1.40s/it, training loss=0.0773]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1297/1835 [30:11<12:32,  1.40s/it, training loss=0.1311]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1298/1835 [30:11<12:29,  1.40s/it, training loss=0.1311]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1298/1835 [30:13<12:29,  1.40s/it, training loss=0.1088]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1299/1835 [30:13<12:29,  1.40s/it, training loss=0.1088]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1299/1835 [30:14<12:29,  1.40s/it, training loss=0.0620]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1300/1835 [30:14<12:26,  1.40s/it, training loss=0.0620]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1300/1835 [30:15<12:26,  1.40s/it, training loss=0.1772]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1301/1835 [30:15<12:25,  1.40s/it, training loss=0.1772]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1301/1835 [30:17<12:25,  1.40s/it, training loss=0.1783]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1302/1835 [30:17<12:24,  1.40s/it, training loss=0.1783]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1302/1835 [30:18<12:24,  1.40s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1303/1835 [30:18<12:24,  1.40s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1303/1835 [30:20<12:24,  1.40s/it, training loss=0.0909]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1304/1835 [30:20<12:21,  1.40s/it, training loss=0.0909]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1304/1835 [30:21<12:21,  1.40s/it, training loss=0.0963]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1305/1835 [30:21<12:19,  1.40s/it, training loss=0.0963]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1305/1835 [30:22<12:19,  1.40s/it, training loss=0.1570]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1306/1835 [30:22<12:18,  1.40s/it, training loss=0.1570]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1306/1835 [30:24<12:18,  1.40s/it, training loss=0.1080]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1307/1835 [30:24<12:16,  1.39s/it, training loss=0.1080]\u001b[A\n",
            "Epoch 3:  71%|███████   | 1307/1835 [30:25<12:16,  1.39s/it, training loss=0.0645]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 1308/1835 [30:25<12:13,  1.39s/it, training loss=0.0645]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 1308/1835 [30:27<12:13,  1.39s/it, training loss=0.0645]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 1309/1835 [30:27<12:14,  1.40s/it, training loss=0.0645]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 1309/1835 [30:28<12:14,  1.40s/it, training loss=0.0996]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 1310/1835 [30:28<12:12,  1.40s/it, training loss=0.0996]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 1310/1835 [30:29<12:12,  1.40s/it, training loss=0.0713]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 1311/1835 [30:29<12:11,  1.40s/it, training loss=0.0713]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 1311/1835 [30:31<12:11,  1.40s/it, training loss=0.1017]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 1312/1835 [30:31<12:10,  1.40s/it, training loss=0.1017]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 1312/1835 [30:32<12:10,  1.40s/it, training loss=0.1775]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1313/1835 [30:32<12:08,  1.40s/it, training loss=0.1775]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1313/1835 [30:34<12:08,  1.40s/it, training loss=0.1221]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1314/1835 [30:34<12:08,  1.40s/it, training loss=0.1221]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1314/1835 [30:35<12:08,  1.40s/it, training loss=0.1104]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1315/1835 [30:35<12:07,  1.40s/it, training loss=0.1104]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1315/1835 [30:36<12:07,  1.40s/it, training loss=0.1118]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1316/1835 [30:36<12:06,  1.40s/it, training loss=0.1118]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1316/1835 [30:38<12:06,  1.40s/it, training loss=0.0482]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1317/1835 [30:38<12:05,  1.40s/it, training loss=0.0482]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1317/1835 [30:39<12:05,  1.40s/it, training loss=0.1073]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1318/1835 [30:39<12:04,  1.40s/it, training loss=0.1073]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1318/1835 [30:41<12:04,  1.40s/it, training loss=0.0306]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1319/1835 [30:41<12:01,  1.40s/it, training loss=0.0306]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1319/1835 [30:42<12:01,  1.40s/it, training loss=0.0716]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1320/1835 [30:42<12:02,  1.40s/it, training loss=0.0716]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1320/1835 [30:43<12:02,  1.40s/it, training loss=0.1104]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1321/1835 [30:43<12:00,  1.40s/it, training loss=0.1104]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1321/1835 [30:45<12:00,  1.40s/it, training loss=0.1811]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1322/1835 [30:45<11:57,  1.40s/it, training loss=0.1811]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1322/1835 [30:46<11:57,  1.40s/it, training loss=0.1835]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1323/1835 [30:46<11:55,  1.40s/it, training loss=0.1835]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1323/1835 [30:48<11:55,  1.40s/it, training loss=0.0913]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1324/1835 [30:48<11:53,  1.40s/it, training loss=0.0913]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1324/1835 [30:49<11:53,  1.40s/it, training loss=0.1198]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1325/1835 [30:49<11:52,  1.40s/it, training loss=0.1198]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1325/1835 [30:50<11:52,  1.40s/it, training loss=0.0518]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1326/1835 [30:50<11:49,  1.39s/it, training loss=0.0518]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1326/1835 [30:52<11:49,  1.39s/it, training loss=0.0477]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1327/1835 [30:52<11:46,  1.39s/it, training loss=0.0477]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1327/1835 [30:53<11:46,  1.39s/it, training loss=0.0233]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1328/1835 [30:53<11:46,  1.39s/it, training loss=0.0233]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1328/1835 [30:55<11:46,  1.39s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1329/1835 [30:55<11:44,  1.39s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1329/1835 [30:56<11:44,  1.39s/it, training loss=0.0397]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1330/1835 [30:56<11:43,  1.39s/it, training loss=0.0397]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 1330/1835 [30:57<11:43,  1.39s/it, training loss=0.0879]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1331/1835 [30:57<11:42,  1.39s/it, training loss=0.0879]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1331/1835 [30:59<11:42,  1.39s/it, training loss=0.1867]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1332/1835 [30:59<11:40,  1.39s/it, training loss=0.1867]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1332/1835 [31:00<11:40,  1.39s/it, training loss=0.1444]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1333/1835 [31:00<11:39,  1.39s/it, training loss=0.1444]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1333/1835 [31:02<11:39,  1.39s/it, training loss=0.0545]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1334/1835 [31:02<11:39,  1.40s/it, training loss=0.0545]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1334/1835 [31:03<11:39,  1.40s/it, training loss=0.0937]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1335/1835 [31:03<11:37,  1.40s/it, training loss=0.0937]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1335/1835 [31:04<11:37,  1.40s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1336/1835 [31:04<11:36,  1.40s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1336/1835 [31:06<11:36,  1.40s/it, training loss=0.0458]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1337/1835 [31:06<11:35,  1.40s/it, training loss=0.0458]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1337/1835 [31:07<11:35,  1.40s/it, training loss=0.1370]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1338/1835 [31:07<11:33,  1.40s/it, training loss=0.1370]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1338/1835 [31:09<11:33,  1.40s/it, training loss=0.2095]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1339/1835 [31:09<11:32,  1.40s/it, training loss=0.2095]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1339/1835 [31:10<11:32,  1.40s/it, training loss=0.0570]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1340/1835 [31:10<11:31,  1.40s/it, training loss=0.0570]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1340/1835 [31:11<11:31,  1.40s/it, training loss=0.2019]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1341/1835 [31:11<11:29,  1.39s/it, training loss=0.2019]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1341/1835 [31:13<11:29,  1.39s/it, training loss=0.0594]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1342/1835 [31:13<11:27,  1.39s/it, training loss=0.0594]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1342/1835 [31:14<11:27,  1.39s/it, training loss=0.0993]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1343/1835 [31:14<11:25,  1.39s/it, training loss=0.0993]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1343/1835 [31:16<11:25,  1.39s/it, training loss=0.1199]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1344/1835 [31:16<11:24,  1.39s/it, training loss=0.1199]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1344/1835 [31:17<11:24,  1.39s/it, training loss=0.0254]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1345/1835 [31:17<11:24,  1.40s/it, training loss=0.0254]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1345/1835 [31:18<11:24,  1.40s/it, training loss=0.1202]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1346/1835 [31:18<11:22,  1.40s/it, training loss=0.1202]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1346/1835 [31:20<11:22,  1.40s/it, training loss=0.1311]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1347/1835 [31:20<11:21,  1.40s/it, training loss=0.1311]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1347/1835 [31:21<11:21,  1.40s/it, training loss=0.2431]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1348/1835 [31:21<11:19,  1.40s/it, training loss=0.2431]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 1348/1835 [31:23<11:19,  1.40s/it, training loss=0.0727]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 1349/1835 [31:23<11:19,  1.40s/it, training loss=0.0727]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 1349/1835 [31:24<11:19,  1.40s/it, training loss=0.1182]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 1350/1835 [31:24<11:17,  1.40s/it, training loss=0.1182]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 1350/1835 [31:25<11:17,  1.40s/it, training loss=0.0394]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 1351/1835 [31:25<11:16,  1.40s/it, training loss=0.0394]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 1351/1835 [31:27<11:16,  1.40s/it, training loss=0.0636]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 1352/1835 [31:27<11:14,  1.40s/it, training loss=0.0636]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 1352/1835 [31:28<11:14,  1.40s/it, training loss=0.1437]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 1353/1835 [31:28<11:13,  1.40s/it, training loss=0.1437]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 1353/1835 [31:29<11:13,  1.40s/it, training loss=0.1578]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1354/1835 [31:29<11:12,  1.40s/it, training loss=0.1578]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1354/1835 [31:31<11:12,  1.40s/it, training loss=0.0166]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1355/1835 [31:31<11:08,  1.39s/it, training loss=0.0166]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1355/1835 [31:32<11:08,  1.39s/it, training loss=0.1152]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1356/1835 [31:32<11:07,  1.39s/it, training loss=0.1152]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1356/1835 [31:34<11:07,  1.39s/it, training loss=0.0258]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1357/1835 [31:34<11:07,  1.40s/it, training loss=0.0258]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1357/1835 [31:35<11:07,  1.40s/it, training loss=0.0496]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1358/1835 [31:35<11:05,  1.39s/it, training loss=0.0496]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1358/1835 [31:36<11:05,  1.39s/it, training loss=0.0789]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1359/1835 [31:36<11:03,  1.39s/it, training loss=0.0789]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1359/1835 [31:38<11:03,  1.39s/it, training loss=0.1278]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1360/1835 [31:38<11:02,  1.39s/it, training loss=0.1278]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1360/1835 [31:39<11:02,  1.39s/it, training loss=0.1880]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1361/1835 [31:39<10:59,  1.39s/it, training loss=0.1880]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1361/1835 [31:41<10:59,  1.39s/it, training loss=0.1074]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1362/1835 [31:41<10:58,  1.39s/it, training loss=0.1074]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1362/1835 [31:42<10:58,  1.39s/it, training loss=0.0484]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1363/1835 [31:42<10:57,  1.39s/it, training loss=0.0484]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1363/1835 [31:43<10:57,  1.39s/it, training loss=0.0523]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1364/1835 [31:43<10:56,  1.39s/it, training loss=0.0523]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1364/1835 [31:45<10:56,  1.39s/it, training loss=0.1177]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1365/1835 [31:45<10:55,  1.39s/it, training loss=0.1177]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1365/1835 [31:46<10:55,  1.39s/it, training loss=0.1301]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1366/1835 [31:46<10:53,  1.39s/it, training loss=0.1301]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1366/1835 [31:48<10:53,  1.39s/it, training loss=0.1213]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1367/1835 [31:48<10:51,  1.39s/it, training loss=0.1213]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 1367/1835 [31:49<10:51,  1.39s/it, training loss=0.2343]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1368/1835 [31:49<10:50,  1.39s/it, training loss=0.2343]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1368/1835 [31:50<10:50,  1.39s/it, training loss=0.1333]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1369/1835 [31:50<10:49,  1.39s/it, training loss=0.1333]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1369/1835 [31:52<10:49,  1.39s/it, training loss=0.2338]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1370/1835 [31:52<10:48,  1.39s/it, training loss=0.2338]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1370/1835 [31:53<10:48,  1.39s/it, training loss=0.1172]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1371/1835 [31:53<10:46,  1.39s/it, training loss=0.1172]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1371/1835 [31:55<10:46,  1.39s/it, training loss=0.1191]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1372/1835 [31:55<10:45,  1.39s/it, training loss=0.1191]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1372/1835 [31:56<10:45,  1.39s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1373/1835 [31:56<10:45,  1.40s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1373/1835 [31:57<10:45,  1.40s/it, training loss=0.0442]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1374/1835 [31:57<10:44,  1.40s/it, training loss=0.0442]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1374/1835 [31:59<10:44,  1.40s/it, training loss=0.0932]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1375/1835 [31:59<10:44,  1.40s/it, training loss=0.0932]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1375/1835 [32:00<10:44,  1.40s/it, training loss=0.1619]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1376/1835 [32:00<10:41,  1.40s/it, training loss=0.1619]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 1376/1835 [32:02<10:41,  1.40s/it, training loss=0.1464]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1377/1835 [32:02<10:39,  1.40s/it, training loss=0.1464]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1377/1835 [32:03<10:39,  1.40s/it, training loss=0.1636]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1378/1835 [32:03<10:38,  1.40s/it, training loss=0.1636]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1378/1835 [32:04<10:38,  1.40s/it, training loss=0.0523]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1379/1835 [32:04<10:36,  1.40s/it, training loss=0.0523]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1379/1835 [32:06<10:36,  1.40s/it, training loss=0.0826]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1380/1835 [32:06<10:35,  1.40s/it, training loss=0.0826]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1380/1835 [32:07<10:35,  1.40s/it, training loss=0.1482]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1381/1835 [32:07<10:34,  1.40s/it, training loss=0.1482]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1381/1835 [32:09<10:34,  1.40s/it, training loss=0.0703]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1382/1835 [32:09<10:31,  1.39s/it, training loss=0.0703]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1382/1835 [32:10<10:31,  1.39s/it, training loss=0.0299]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1383/1835 [32:10<10:28,  1.39s/it, training loss=0.0299]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1383/1835 [32:11<10:28,  1.39s/it, training loss=0.1861]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1384/1835 [32:11<10:28,  1.39s/it, training loss=0.1861]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1384/1835 [32:13<10:28,  1.39s/it, training loss=0.0669]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1385/1835 [32:13<10:25,  1.39s/it, training loss=0.0669]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 1385/1835 [32:14<10:25,  1.39s/it, training loss=0.1497]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1386/1835 [32:14<10:23,  1.39s/it, training loss=0.1497]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1386/1835 [32:15<10:23,  1.39s/it, training loss=0.0508]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1387/1835 [32:16<10:24,  1.39s/it, training loss=0.0508]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1387/1835 [32:17<10:24,  1.39s/it, training loss=0.0276]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1388/1835 [32:17<10:22,  1.39s/it, training loss=0.0276]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1388/1835 [32:18<10:22,  1.39s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1389/1835 [32:18<10:22,  1.40s/it, training loss=0.1701]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1389/1835 [32:20<10:22,  1.40s/it, training loss=0.2740]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1390/1835 [32:20<10:21,  1.40s/it, training loss=0.2740]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1390/1835 [32:21<10:21,  1.40s/it, training loss=0.2034]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1391/1835 [32:21<10:21,  1.40s/it, training loss=0.2034]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1391/1835 [32:22<10:21,  1.40s/it, training loss=0.0982]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1392/1835 [32:22<10:18,  1.40s/it, training loss=0.0982]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1392/1835 [32:24<10:18,  1.40s/it, training loss=0.1579]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1393/1835 [32:24<10:16,  1.39s/it, training loss=0.1579]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1393/1835 [32:25<10:16,  1.39s/it, training loss=0.0693]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1394/1835 [32:25<10:14,  1.39s/it, training loss=0.0693]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1394/1835 [32:27<10:14,  1.39s/it, training loss=0.0368]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1395/1835 [32:27<10:13,  1.39s/it, training loss=0.0368]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1395/1835 [32:28<10:13,  1.39s/it, training loss=0.0640]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1396/1835 [32:28<10:11,  1.39s/it, training loss=0.0640]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1396/1835 [32:29<10:11,  1.39s/it, training loss=0.1843]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1397/1835 [32:29<10:11,  1.40s/it, training loss=0.1843]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1397/1835 [32:31<10:11,  1.40s/it, training loss=0.2147]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1398/1835 [32:31<10:09,  1.40s/it, training loss=0.2147]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1398/1835 [32:32<10:09,  1.40s/it, training loss=0.1600]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1399/1835 [32:32<10:09,  1.40s/it, training loss=0.1600]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 1399/1835 [32:34<10:09,  1.40s/it, training loss=0.0635]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 1400/1835 [32:34<10:07,  1.40s/it, training loss=0.0635]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 1400/1835 [32:35<10:07,  1.40s/it, training loss=0.1806]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 1401/1835 [32:35<10:05,  1.40s/it, training loss=0.1806]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 1401/1835 [32:36<10:05,  1.40s/it, training loss=0.1391]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 1402/1835 [32:36<10:04,  1.40s/it, training loss=0.1391]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 1402/1835 [32:38<10:04,  1.40s/it, training loss=0.0584]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 1403/1835 [32:38<10:03,  1.40s/it, training loss=0.0584]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 1403/1835 [32:39<10:03,  1.40s/it, training loss=0.1655]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1404/1835 [32:39<10:00,  1.39s/it, training loss=0.1655]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1404/1835 [32:41<10:00,  1.39s/it, training loss=0.1485]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1405/1835 [32:41<09:59,  1.39s/it, training loss=0.1485]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1405/1835 [32:42<09:59,  1.39s/it, training loss=0.2139]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1406/1835 [32:42<09:58,  1.39s/it, training loss=0.2139]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1406/1835 [32:43<09:58,  1.39s/it, training loss=0.1109]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1407/1835 [32:43<09:57,  1.40s/it, training loss=0.1109]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1407/1835 [32:45<09:57,  1.40s/it, training loss=0.1261]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1408/1835 [32:45<09:55,  1.40s/it, training loss=0.1261]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1408/1835 [32:46<09:55,  1.40s/it, training loss=0.0672]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1409/1835 [32:46<09:54,  1.40s/it, training loss=0.0672]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1409/1835 [32:48<09:54,  1.40s/it, training loss=0.1652]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1410/1835 [32:48<09:54,  1.40s/it, training loss=0.1652]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1410/1835 [32:49<09:54,  1.40s/it, training loss=0.3249]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1411/1835 [32:49<09:51,  1.40s/it, training loss=0.3249]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1411/1835 [32:50<09:51,  1.40s/it, training loss=0.0875]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1412/1835 [32:50<09:50,  1.40s/it, training loss=0.0875]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1412/1835 [32:52<09:50,  1.40s/it, training loss=0.0112]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1413/1835 [32:52<09:48,  1.40s/it, training loss=0.0112]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1413/1835 [32:53<09:48,  1.40s/it, training loss=0.0711]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1414/1835 [32:53<09:47,  1.40s/it, training loss=0.0711]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1414/1835 [32:55<09:47,  1.40s/it, training loss=0.1004]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1415/1835 [32:55<09:46,  1.40s/it, training loss=0.1004]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1415/1835 [32:56<09:46,  1.40s/it, training loss=0.1314]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1416/1835 [32:56<09:46,  1.40s/it, training loss=0.1314]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1416/1835 [32:57<09:46,  1.40s/it, training loss=0.2040]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1417/1835 [32:57<09:44,  1.40s/it, training loss=0.2040]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1417/1835 [32:59<09:44,  1.40s/it, training loss=0.0423]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1418/1835 [32:59<09:43,  1.40s/it, training loss=0.0423]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1418/1835 [33:00<09:43,  1.40s/it, training loss=0.0118]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1419/1835 [33:00<09:42,  1.40s/it, training loss=0.0118]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1419/1835 [33:02<09:42,  1.40s/it, training loss=0.1417]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1420/1835 [33:02<09:41,  1.40s/it, training loss=0.1417]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1420/1835 [33:03<09:41,  1.40s/it, training loss=0.1663]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1421/1835 [33:03<09:40,  1.40s/it, training loss=0.1663]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1421/1835 [33:04<09:40,  1.40s/it, training loss=0.1471]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1422/1835 [33:04<09:38,  1.40s/it, training loss=0.1471]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 1422/1835 [33:06<09:38,  1.40s/it, training loss=0.0883]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1423/1835 [33:06<09:36,  1.40s/it, training loss=0.0883]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1423/1835 [33:07<09:36,  1.40s/it, training loss=0.1250]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1424/1835 [33:07<09:34,  1.40s/it, training loss=0.1250]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1424/1835 [33:09<09:34,  1.40s/it, training loss=0.0740]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1425/1835 [33:09<09:34,  1.40s/it, training loss=0.0740]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1425/1835 [33:10<09:34,  1.40s/it, training loss=0.0612]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1426/1835 [33:10<09:32,  1.40s/it, training loss=0.0612]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1426/1835 [33:11<09:32,  1.40s/it, training loss=0.1154]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1427/1835 [33:11<09:31,  1.40s/it, training loss=0.1154]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1427/1835 [33:13<09:31,  1.40s/it, training loss=0.0922]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1428/1835 [33:13<09:29,  1.40s/it, training loss=0.0922]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1428/1835 [33:14<09:29,  1.40s/it, training loss=0.1009]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1429/1835 [33:14<09:27,  1.40s/it, training loss=0.1009]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1429/1835 [33:16<09:27,  1.40s/it, training loss=0.1503]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1430/1835 [33:16<09:25,  1.40s/it, training loss=0.1503]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1430/1835 [33:17<09:25,  1.40s/it, training loss=0.0501]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1431/1835 [33:17<09:23,  1.40s/it, training loss=0.0501]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1431/1835 [33:18<09:23,  1.40s/it, training loss=0.1262]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1432/1835 [33:18<09:22,  1.40s/it, training loss=0.1262]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1432/1835 [33:20<09:22,  1.40s/it, training loss=0.0894]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1433/1835 [33:20<09:20,  1.39s/it, training loss=0.0894]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1433/1835 [33:21<09:20,  1.39s/it, training loss=0.0743]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1434/1835 [33:21<09:18,  1.39s/it, training loss=0.0743]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1434/1835 [33:23<09:18,  1.39s/it, training loss=0.0993]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1435/1835 [33:23<09:18,  1.40s/it, training loss=0.0993]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1435/1835 [33:24<09:18,  1.40s/it, training loss=0.0704]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1436/1835 [33:24<09:17,  1.40s/it, training loss=0.0704]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1436/1835 [33:25<09:17,  1.40s/it, training loss=0.2051]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1437/1835 [33:25<09:15,  1.40s/it, training loss=0.2051]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1437/1835 [33:27<09:15,  1.40s/it, training loss=0.1166]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1438/1835 [33:27<09:15,  1.40s/it, training loss=0.1166]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1438/1835 [33:28<09:15,  1.40s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1439/1835 [33:28<09:12,  1.39s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1439/1835 [33:30<09:12,  1.39s/it, training loss=0.0966]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1440/1835 [33:30<09:10,  1.39s/it, training loss=0.0966]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 1440/1835 [33:31<09:10,  1.39s/it, training loss=0.0863]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 1441/1835 [33:31<09:08,  1.39s/it, training loss=0.0863]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 1441/1835 [33:32<09:08,  1.39s/it, training loss=0.1128]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 1442/1835 [33:32<09:07,  1.39s/it, training loss=0.1128]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 1442/1835 [33:34<09:07,  1.39s/it, training loss=0.1752]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 1443/1835 [33:34<09:05,  1.39s/it, training loss=0.1752]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 1443/1835 [33:35<09:05,  1.39s/it, training loss=0.1102]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 1444/1835 [33:35<09:04,  1.39s/it, training loss=0.1102]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 1444/1835 [33:36<09:04,  1.39s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 1445/1835 [33:36<09:03,  1.39s/it, training loss=0.1230]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 1445/1835 [33:38<09:03,  1.39s/it, training loss=0.1627]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1446/1835 [33:38<09:02,  1.39s/it, training loss=0.1627]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1446/1835 [33:39<09:02,  1.39s/it, training loss=0.0646]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1447/1835 [33:39<09:00,  1.39s/it, training loss=0.0646]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1447/1835 [33:41<09:00,  1.39s/it, training loss=0.1652]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1448/1835 [33:41<08:59,  1.39s/it, training loss=0.1652]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1448/1835 [33:42<08:59,  1.39s/it, training loss=0.0448]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1449/1835 [33:42<08:57,  1.39s/it, training loss=0.0448]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1449/1835 [33:43<08:57,  1.39s/it, training loss=0.1684]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1450/1835 [33:43<08:57,  1.40s/it, training loss=0.1684]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1450/1835 [33:45<08:57,  1.40s/it, training loss=0.0435]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1451/1835 [33:45<08:55,  1.39s/it, training loss=0.0435]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1451/1835 [33:46<08:55,  1.39s/it, training loss=0.1718]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1452/1835 [33:46<08:54,  1.40s/it, training loss=0.1718]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1452/1835 [33:48<08:54,  1.40s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1453/1835 [33:48<08:52,  1.39s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1453/1835 [33:49<08:52,  1.39s/it, training loss=0.1056]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1454/1835 [33:49<08:50,  1.39s/it, training loss=0.1056]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1454/1835 [33:50<08:50,  1.39s/it, training loss=0.0674]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1455/1835 [33:50<08:49,  1.39s/it, training loss=0.0674]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1455/1835 [33:52<08:49,  1.39s/it, training loss=0.0292]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1456/1835 [33:52<08:48,  1.39s/it, training loss=0.0292]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1456/1835 [33:53<08:48,  1.39s/it, training loss=0.0769]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1457/1835 [33:53<08:46,  1.39s/it, training loss=0.0769]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1457/1835 [33:55<08:46,  1.39s/it, training loss=0.0794]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1458/1835 [33:55<08:44,  1.39s/it, training loss=0.0794]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 1458/1835 [33:56<08:44,  1.39s/it, training loss=0.0668]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1459/1835 [33:56<08:43,  1.39s/it, training loss=0.0668]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1459/1835 [33:57<08:43,  1.39s/it, training loss=0.0972]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1460/1835 [33:57<08:42,  1.39s/it, training loss=0.0972]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1460/1835 [33:59<08:42,  1.39s/it, training loss=0.1057]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1461/1835 [33:59<08:40,  1.39s/it, training loss=0.1057]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1461/1835 [34:00<08:40,  1.39s/it, training loss=0.1288]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1462/1835 [34:00<08:37,  1.39s/it, training loss=0.1288]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1462/1835 [34:02<08:37,  1.39s/it, training loss=0.0372]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1463/1835 [34:02<08:37,  1.39s/it, training loss=0.0372]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1463/1835 [34:03<08:37,  1.39s/it, training loss=0.0304]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1464/1835 [34:03<08:35,  1.39s/it, training loss=0.0304]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1464/1835 [34:04<08:35,  1.39s/it, training loss=0.0433]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1465/1835 [34:04<08:35,  1.39s/it, training loss=0.0433]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1465/1835 [34:06<08:35,  1.39s/it, training loss=0.1941]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1466/1835 [34:06<08:33,  1.39s/it, training loss=0.1941]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1466/1835 [34:07<08:33,  1.39s/it, training loss=0.0637]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1467/1835 [34:07<08:32,  1.39s/it, training loss=0.0637]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 1467/1835 [34:09<08:32,  1.39s/it, training loss=0.0294]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1468/1835 [34:09<08:31,  1.39s/it, training loss=0.0294]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1468/1835 [34:10<08:31,  1.39s/it, training loss=0.1976]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1469/1835 [34:10<08:30,  1.40s/it, training loss=0.1976]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1469/1835 [34:11<08:30,  1.40s/it, training loss=0.1367]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1470/1835 [34:11<08:29,  1.40s/it, training loss=0.1367]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1470/1835 [34:13<08:29,  1.40s/it, training loss=0.0621]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1471/1835 [34:13<08:27,  1.40s/it, training loss=0.0621]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1471/1835 [34:14<08:27,  1.40s/it, training loss=0.0781]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1472/1835 [34:14<08:26,  1.39s/it, training loss=0.0781]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1472/1835 [34:16<08:26,  1.39s/it, training loss=0.0946]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1473/1835 [34:16<08:25,  1.40s/it, training loss=0.0946]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1473/1835 [34:17<08:25,  1.40s/it, training loss=0.0675]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1474/1835 [34:17<08:24,  1.40s/it, training loss=0.0675]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1474/1835 [34:18<08:24,  1.40s/it, training loss=0.0714]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1475/1835 [34:18<08:21,  1.39s/it, training loss=0.0714]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1475/1835 [34:20<08:21,  1.39s/it, training loss=0.0434]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1476/1835 [34:20<08:20,  1.39s/it, training loss=0.0434]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1476/1835 [34:21<08:20,  1.39s/it, training loss=0.2281]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1477/1835 [34:21<08:19,  1.40s/it, training loss=0.2281]\u001b[A\n",
            "Epoch 3:  80%|████████  | 1477/1835 [34:22<08:19,  1.40s/it, training loss=0.0326]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1478/1835 [34:22<08:19,  1.40s/it, training loss=0.0326]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1478/1835 [34:24<08:19,  1.40s/it, training loss=0.1313]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1479/1835 [34:24<08:17,  1.40s/it, training loss=0.1313]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1479/1835 [34:25<08:17,  1.40s/it, training loss=0.0643]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1480/1835 [34:25<08:16,  1.40s/it, training loss=0.0643]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1480/1835 [34:27<08:16,  1.40s/it, training loss=0.0376]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1481/1835 [34:27<08:14,  1.40s/it, training loss=0.0376]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1481/1835 [34:28<08:14,  1.40s/it, training loss=0.0370]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1482/1835 [34:28<08:13,  1.40s/it, training loss=0.0370]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1482/1835 [34:29<08:13,  1.40s/it, training loss=0.1812]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1483/1835 [34:29<08:11,  1.40s/it, training loss=0.1812]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1483/1835 [34:31<08:11,  1.40s/it, training loss=0.0725]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1484/1835 [34:31<08:09,  1.39s/it, training loss=0.0725]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1484/1835 [34:32<08:09,  1.39s/it, training loss=0.0398]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1485/1835 [34:32<08:09,  1.40s/it, training loss=0.0398]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1485/1835 [34:34<08:09,  1.40s/it, training loss=0.0363]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1486/1835 [34:34<08:06,  1.39s/it, training loss=0.0363]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1486/1835 [34:35<08:06,  1.39s/it, training loss=0.1855]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1487/1835 [34:35<08:05,  1.40s/it, training loss=0.1855]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1487/1835 [34:36<08:05,  1.40s/it, training loss=0.0614]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1488/1835 [34:36<08:04,  1.40s/it, training loss=0.0614]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1488/1835 [34:38<08:04,  1.40s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1489/1835 [34:38<08:02,  1.39s/it, training loss=0.1160]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1489/1835 [34:39<08:02,  1.39s/it, training loss=0.2601]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1490/1835 [34:39<08:02,  1.40s/it, training loss=0.2601]\u001b[A\n",
            "Epoch 3:  81%|████████  | 1490/1835 [34:41<08:02,  1.40s/it, training loss=0.1037]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 1491/1835 [34:41<08:00,  1.40s/it, training loss=0.1037]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 1491/1835 [34:42<08:00,  1.40s/it, training loss=0.0620]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 1492/1835 [34:42<07:58,  1.40s/it, training loss=0.0620]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 1492/1835 [34:43<07:58,  1.40s/it, training loss=0.1280]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 1493/1835 [34:43<07:57,  1.39s/it, training loss=0.1280]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 1493/1835 [34:45<07:57,  1.39s/it, training loss=0.0557]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 1494/1835 [34:45<07:55,  1.39s/it, training loss=0.0557]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 1494/1835 [34:46<07:55,  1.39s/it, training loss=0.1396]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 1495/1835 [34:46<07:53,  1.39s/it, training loss=0.1396]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 1495/1835 [34:48<07:53,  1.39s/it, training loss=0.1798]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1496/1835 [34:48<07:52,  1.39s/it, training loss=0.1798]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1496/1835 [34:49<07:52,  1.39s/it, training loss=0.1774]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1497/1835 [34:49<07:50,  1.39s/it, training loss=0.1774]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1497/1835 [34:50<07:50,  1.39s/it, training loss=0.0964]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1498/1835 [34:50<07:49,  1.39s/it, training loss=0.0964]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1498/1835 [34:52<07:49,  1.39s/it, training loss=0.0552]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1499/1835 [34:52<07:48,  1.39s/it, training loss=0.0552]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1499/1835 [34:53<07:48,  1.39s/it, training loss=0.0619]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1500/1835 [34:53<07:47,  1.40s/it, training loss=0.0619]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1500/1835 [34:55<07:47,  1.40s/it, training loss=0.1039]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1501/1835 [34:55<07:46,  1.40s/it, training loss=0.1039]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1501/1835 [34:56<07:46,  1.40s/it, training loss=0.0688]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1502/1835 [34:56<07:44,  1.39s/it, training loss=0.0688]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1502/1835 [34:57<07:44,  1.39s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1503/1835 [34:57<07:42,  1.39s/it, training loss=0.1327]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1503/1835 [34:59<07:42,  1.39s/it, training loss=0.0528]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1504/1835 [34:59<07:41,  1.39s/it, training loss=0.0528]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1504/1835 [35:00<07:41,  1.39s/it, training loss=0.0948]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1505/1835 [35:00<07:40,  1.39s/it, training loss=0.0948]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1505/1835 [35:02<07:40,  1.39s/it, training loss=0.0872]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1506/1835 [35:02<07:38,  1.40s/it, training loss=0.0872]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1506/1835 [35:03<07:38,  1.40s/it, training loss=0.1919]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1507/1835 [35:03<07:37,  1.39s/it, training loss=0.1919]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1507/1835 [35:04<07:37,  1.39s/it, training loss=0.0292]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1508/1835 [35:04<07:36,  1.40s/it, training loss=0.0292]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1508/1835 [35:06<07:36,  1.40s/it, training loss=0.2489]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1509/1835 [35:06<07:35,  1.40s/it, training loss=0.2489]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1509/1835 [35:07<07:35,  1.40s/it, training loss=0.2317]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1510/1835 [35:07<07:34,  1.40s/it, training loss=0.2317]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1510/1835 [35:09<07:34,  1.40s/it, training loss=0.0409]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1511/1835 [35:09<07:33,  1.40s/it, training loss=0.0409]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1511/1835 [35:10<07:33,  1.40s/it, training loss=0.0208]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1512/1835 [35:10<07:30,  1.40s/it, training loss=0.0208]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1512/1835 [35:11<07:30,  1.40s/it, training loss=0.1174]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1513/1835 [35:11<07:28,  1.39s/it, training loss=0.1174]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 1513/1835 [35:13<07:28,  1.39s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1514/1835 [35:13<07:27,  1.39s/it, training loss=0.0970]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1514/1835 [35:14<07:27,  1.39s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1515/1835 [35:14<07:25,  1.39s/it, training loss=0.1538]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1515/1835 [35:16<07:25,  1.39s/it, training loss=0.1038]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1516/1835 [35:16<07:23,  1.39s/it, training loss=0.1038]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1516/1835 [35:17<07:23,  1.39s/it, training loss=0.1296]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1517/1835 [35:17<07:22,  1.39s/it, training loss=0.1296]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1517/1835 [35:18<07:22,  1.39s/it, training loss=0.1522]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1518/1835 [35:18<07:22,  1.40s/it, training loss=0.1522]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1518/1835 [35:20<07:22,  1.40s/it, training loss=0.0470]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1519/1835 [35:20<07:21,  1.40s/it, training loss=0.0470]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1519/1835 [35:21<07:21,  1.40s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1520/1835 [35:21<07:18,  1.39s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1520/1835 [35:22<07:18,  1.39s/it, training loss=0.1506]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1521/1835 [35:22<07:17,  1.39s/it, training loss=0.1506]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1521/1835 [35:24<07:17,  1.39s/it, training loss=0.0270]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1522/1835 [35:24<07:16,  1.39s/it, training loss=0.0270]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1522/1835 [35:25<07:16,  1.39s/it, training loss=0.0093]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1523/1835 [35:25<07:15,  1.40s/it, training loss=0.0093]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1523/1835 [35:27<07:15,  1.40s/it, training loss=0.2363]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1524/1835 [35:27<07:13,  1.40s/it, training loss=0.2363]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1524/1835 [35:28<07:13,  1.40s/it, training loss=0.0470]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1525/1835 [35:28<07:13,  1.40s/it, training loss=0.0470]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1525/1835 [35:29<07:13,  1.40s/it, training loss=0.1089]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1526/1835 [35:29<07:11,  1.40s/it, training loss=0.1089]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1526/1835 [35:31<07:11,  1.40s/it, training loss=0.1364]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1527/1835 [35:31<07:09,  1.39s/it, training loss=0.1364]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1527/1835 [35:32<07:09,  1.39s/it, training loss=0.1728]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1528/1835 [35:32<07:08,  1.39s/it, training loss=0.1728]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1528/1835 [35:34<07:08,  1.39s/it, training loss=0.0196]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1529/1835 [35:34<07:07,  1.40s/it, training loss=0.0196]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1529/1835 [35:35<07:07,  1.40s/it, training loss=0.0318]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1530/1835 [35:35<07:05,  1.40s/it, training loss=0.0318]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1530/1835 [35:36<07:05,  1.40s/it, training loss=0.1150]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1531/1835 [35:36<07:03,  1.39s/it, training loss=0.1150]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1531/1835 [35:38<07:03,  1.39s/it, training loss=0.1127]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1532/1835 [35:38<07:02,  1.39s/it, training loss=0.1127]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 1532/1835 [35:39<07:02,  1.39s/it, training loss=0.0558]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 1533/1835 [35:39<07:00,  1.39s/it, training loss=0.0558]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 1533/1835 [35:41<07:00,  1.39s/it, training loss=0.1282]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 1534/1835 [35:41<06:59,  1.40s/it, training loss=0.1282]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 1534/1835 [35:42<06:59,  1.40s/it, training loss=0.0698]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 1535/1835 [35:42<06:58,  1.40s/it, training loss=0.0698]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 1535/1835 [35:43<06:58,  1.40s/it, training loss=0.0544]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 1536/1835 [35:43<06:56,  1.39s/it, training loss=0.0544]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 1536/1835 [35:45<06:56,  1.39s/it, training loss=0.0266]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1537/1835 [35:45<06:55,  1.39s/it, training loss=0.0266]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1537/1835 [35:46<06:55,  1.39s/it, training loss=0.0975]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1538/1835 [35:46<06:54,  1.40s/it, training loss=0.0975]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1538/1835 [35:48<06:54,  1.40s/it, training loss=0.1451]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1539/1835 [35:48<06:54,  1.40s/it, training loss=0.1451]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1539/1835 [35:49<06:54,  1.40s/it, training loss=0.1503]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1540/1835 [35:49<06:52,  1.40s/it, training loss=0.1503]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1540/1835 [35:50<06:52,  1.40s/it, training loss=0.0555]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1541/1835 [35:50<06:50,  1.40s/it, training loss=0.0555]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1541/1835 [35:52<06:50,  1.40s/it, training loss=0.0878]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1542/1835 [35:52<06:48,  1.40s/it, training loss=0.0878]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1542/1835 [35:53<06:48,  1.40s/it, training loss=0.0130]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1543/1835 [35:53<06:46,  1.39s/it, training loss=0.0130]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1543/1835 [35:55<06:46,  1.39s/it, training loss=0.0348]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1544/1835 [35:55<06:45,  1.39s/it, training loss=0.0348]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1544/1835 [35:56<06:45,  1.39s/it, training loss=0.2366]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1545/1835 [35:56<06:44,  1.39s/it, training loss=0.2366]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1545/1835 [35:57<06:44,  1.39s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1546/1835 [35:57<06:42,  1.39s/it, training loss=0.1180]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1546/1835 [35:59<06:42,  1.39s/it, training loss=0.2050]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1547/1835 [35:59<06:42,  1.40s/it, training loss=0.2050]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1547/1835 [36:00<06:42,  1.40s/it, training loss=0.1845]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1548/1835 [36:00<06:40,  1.39s/it, training loss=0.1845]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1548/1835 [36:02<06:40,  1.39s/it, training loss=0.1059]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1549/1835 [36:02<06:39,  1.40s/it, training loss=0.1059]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1549/1835 [36:03<06:39,  1.40s/it, training loss=0.1397]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1550/1835 [36:03<06:38,  1.40s/it, training loss=0.1397]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 1550/1835 [36:04<06:38,  1.40s/it, training loss=0.0744]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1551/1835 [36:04<06:36,  1.40s/it, training loss=0.0744]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1551/1835 [36:06<06:36,  1.40s/it, training loss=0.1328]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1552/1835 [36:06<06:35,  1.40s/it, training loss=0.1328]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1552/1835 [36:07<06:35,  1.40s/it, training loss=0.1173]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1553/1835 [36:07<06:34,  1.40s/it, training loss=0.1173]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1553/1835 [36:09<06:34,  1.40s/it, training loss=0.0382]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1554/1835 [36:09<06:32,  1.40s/it, training loss=0.0382]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1554/1835 [36:10<06:32,  1.40s/it, training loss=0.0459]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1555/1835 [36:10<06:31,  1.40s/it, training loss=0.0459]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1555/1835 [36:11<06:31,  1.40s/it, training loss=0.0419]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1556/1835 [36:11<06:29,  1.39s/it, training loss=0.0419]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1556/1835 [36:13<06:29,  1.39s/it, training loss=0.0414]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1557/1835 [36:13<06:28,  1.40s/it, training loss=0.0414]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1557/1835 [36:14<06:28,  1.40s/it, training loss=0.0281]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1558/1835 [36:14<06:26,  1.40s/it, training loss=0.0281]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1558/1835 [36:16<06:26,  1.40s/it, training loss=0.0411]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1559/1835 [36:16<06:25,  1.40s/it, training loss=0.0411]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 1559/1835 [36:17<06:25,  1.40s/it, training loss=0.1470]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1560/1835 [36:17<06:23,  1.40s/it, training loss=0.1470]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1560/1835 [36:18<06:23,  1.40s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1561/1835 [36:18<06:22,  1.40s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1561/1835 [36:20<06:22,  1.40s/it, training loss=0.1673]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1562/1835 [36:20<06:20,  1.39s/it, training loss=0.1673]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1562/1835 [36:21<06:20,  1.39s/it, training loss=0.0635]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1563/1835 [36:21<06:19,  1.40s/it, training loss=0.0635]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1563/1835 [36:23<06:19,  1.40s/it, training loss=0.1341]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1564/1835 [36:23<06:19,  1.40s/it, training loss=0.1341]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1564/1835 [36:24<06:19,  1.40s/it, training loss=0.0446]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1565/1835 [36:24<06:17,  1.40s/it, training loss=0.0446]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1565/1835 [36:25<06:17,  1.40s/it, training loss=0.1280]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1566/1835 [36:25<06:15,  1.40s/it, training loss=0.1280]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1566/1835 [36:27<06:15,  1.40s/it, training loss=0.2102]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1567/1835 [36:27<06:14,  1.40s/it, training loss=0.2102]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1567/1835 [36:28<06:14,  1.40s/it, training loss=0.1000]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1568/1835 [36:28<06:12,  1.40s/it, training loss=0.1000]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 1568/1835 [36:29<06:12,  1.40s/it, training loss=0.1280]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1569/1835 [36:29<06:11,  1.40s/it, training loss=0.1280]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1569/1835 [36:31<06:11,  1.40s/it, training loss=0.0262]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1570/1835 [36:31<06:09,  1.40s/it, training loss=0.0262]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1570/1835 [36:32<06:09,  1.40s/it, training loss=0.0540]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1571/1835 [36:32<06:08,  1.39s/it, training loss=0.0540]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1571/1835 [36:34<06:08,  1.39s/it, training loss=0.0168]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1572/1835 [36:34<06:06,  1.39s/it, training loss=0.0168]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1572/1835 [36:35<06:06,  1.39s/it, training loss=0.0332]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1573/1835 [36:35<06:04,  1.39s/it, training loss=0.0332]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1573/1835 [36:36<06:04,  1.39s/it, training loss=0.0279]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1574/1835 [36:36<06:04,  1.40s/it, training loss=0.0279]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1574/1835 [36:38<06:04,  1.40s/it, training loss=0.1109]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1575/1835 [36:38<06:02,  1.40s/it, training loss=0.1109]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1575/1835 [36:39<06:02,  1.40s/it, training loss=0.1464]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1576/1835 [36:39<06:01,  1.40s/it, training loss=0.1464]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1576/1835 [36:41<06:01,  1.40s/it, training loss=0.0383]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1577/1835 [36:41<06:00,  1.40s/it, training loss=0.0383]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1577/1835 [36:42<06:00,  1.40s/it, training loss=0.0564]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1578/1835 [36:42<05:59,  1.40s/it, training loss=0.0564]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1578/1835 [36:43<05:59,  1.40s/it, training loss=0.0695]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1579/1835 [36:43<05:57,  1.40s/it, training loss=0.0695]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1579/1835 [36:45<05:57,  1.40s/it, training loss=0.0448]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1580/1835 [36:45<05:56,  1.40s/it, training loss=0.0448]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1580/1835 [36:46<05:56,  1.40s/it, training loss=0.0847]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1581/1835 [36:46<05:54,  1.40s/it, training loss=0.0847]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1581/1835 [36:48<05:54,  1.40s/it, training loss=0.0865]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1582/1835 [36:48<05:53,  1.40s/it, training loss=0.0865]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 1582/1835 [36:49<05:53,  1.40s/it, training loss=0.0604]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 1583/1835 [36:49<05:52,  1.40s/it, training loss=0.0604]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 1583/1835 [36:50<05:52,  1.40s/it, training loss=0.1240]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 1584/1835 [36:50<05:51,  1.40s/it, training loss=0.1240]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 1584/1835 [36:52<05:51,  1.40s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 1585/1835 [36:52<05:49,  1.40s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 1585/1835 [36:53<05:49,  1.40s/it, training loss=0.2384]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 1586/1835 [36:53<05:47,  1.40s/it, training loss=0.2384]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 1586/1835 [36:55<05:47,  1.40s/it, training loss=0.0269]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 1587/1835 [36:55<05:46,  1.40s/it, training loss=0.0269]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 1587/1835 [36:56<05:46,  1.40s/it, training loss=0.1540]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1588/1835 [36:56<05:44,  1.40s/it, training loss=0.1540]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1588/1835 [36:57<05:44,  1.40s/it, training loss=0.1885]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1589/1835 [36:57<05:43,  1.40s/it, training loss=0.1885]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1589/1835 [36:59<05:43,  1.40s/it, training loss=0.0708]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1590/1835 [36:59<05:41,  1.40s/it, training loss=0.0708]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1590/1835 [37:00<05:41,  1.40s/it, training loss=0.0653]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1591/1835 [37:00<05:40,  1.39s/it, training loss=0.0653]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1591/1835 [37:02<05:40,  1.39s/it, training loss=0.0366]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1592/1835 [37:02<05:38,  1.39s/it, training loss=0.0366]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1592/1835 [37:03<05:38,  1.39s/it, training loss=0.0276]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1593/1835 [37:03<05:37,  1.39s/it, training loss=0.0276]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1593/1835 [37:04<05:37,  1.39s/it, training loss=0.0734]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1594/1835 [37:04<05:35,  1.39s/it, training loss=0.0734]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1594/1835 [37:06<05:35,  1.39s/it, training loss=0.1194]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1595/1835 [37:06<05:34,  1.39s/it, training loss=0.1194]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1595/1835 [37:07<05:34,  1.39s/it, training loss=0.1204]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1596/1835 [37:07<05:33,  1.40s/it, training loss=0.1204]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1596/1835 [37:09<05:33,  1.40s/it, training loss=0.1766]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1597/1835 [37:09<05:32,  1.40s/it, training loss=0.1766]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1597/1835 [37:10<05:32,  1.40s/it, training loss=0.0429]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1598/1835 [37:10<05:31,  1.40s/it, training loss=0.0429]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1598/1835 [37:11<05:31,  1.40s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1599/1835 [37:11<05:29,  1.40s/it, training loss=0.0981]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1599/1835 [37:13<05:29,  1.40s/it, training loss=0.2280]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1600/1835 [37:13<05:28,  1.40s/it, training loss=0.2280]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1600/1835 [37:14<05:28,  1.40s/it, training loss=0.1116]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1601/1835 [37:14<05:27,  1.40s/it, training loss=0.1116]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1601/1835 [37:16<05:27,  1.40s/it, training loss=0.0839]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1602/1835 [37:16<05:25,  1.40s/it, training loss=0.0839]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1602/1835 [37:17<05:25,  1.40s/it, training loss=0.0583]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1603/1835 [37:17<05:23,  1.40s/it, training loss=0.0583]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1603/1835 [37:18<05:23,  1.40s/it, training loss=0.2285]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1604/1835 [37:18<05:22,  1.40s/it, training loss=0.2285]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1604/1835 [37:20<05:22,  1.40s/it, training loss=0.1108]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1605/1835 [37:20<05:21,  1.40s/it, training loss=0.1108]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 1605/1835 [37:21<05:21,  1.40s/it, training loss=0.1361]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1606/1835 [37:21<05:20,  1.40s/it, training loss=0.1361]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1606/1835 [37:23<05:20,  1.40s/it, training loss=0.0638]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1607/1835 [37:23<05:19,  1.40s/it, training loss=0.0638]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1607/1835 [37:24<05:19,  1.40s/it, training loss=0.0201]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1608/1835 [37:24<05:17,  1.40s/it, training loss=0.0201]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1608/1835 [37:25<05:17,  1.40s/it, training loss=0.0643]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1609/1835 [37:25<05:16,  1.40s/it, training loss=0.0643]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1609/1835 [37:27<05:16,  1.40s/it, training loss=0.0185]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1610/1835 [37:27<05:14,  1.40s/it, training loss=0.0185]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1610/1835 [37:28<05:14,  1.40s/it, training loss=0.0551]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1611/1835 [37:28<05:13,  1.40s/it, training loss=0.0551]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1611/1835 [37:30<05:13,  1.40s/it, training loss=0.1753]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1612/1835 [37:30<05:11,  1.40s/it, training loss=0.1753]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1612/1835 [37:31<05:11,  1.40s/it, training loss=0.0861]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1613/1835 [37:31<05:09,  1.40s/it, training loss=0.0861]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1613/1835 [37:32<05:09,  1.40s/it, training loss=0.0492]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1614/1835 [37:32<05:08,  1.39s/it, training loss=0.0492]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1614/1835 [37:34<05:08,  1.39s/it, training loss=0.2087]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1615/1835 [37:34<05:07,  1.40s/it, training loss=0.2087]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1615/1835 [37:35<05:07,  1.40s/it, training loss=0.0626]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1616/1835 [37:35<05:05,  1.40s/it, training loss=0.0626]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1616/1835 [37:37<05:05,  1.40s/it, training loss=0.0577]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1617/1835 [37:37<05:04,  1.40s/it, training loss=0.0577]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1617/1835 [37:38<05:04,  1.40s/it, training loss=0.1426]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1618/1835 [37:38<05:02,  1.40s/it, training loss=0.1426]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1618/1835 [37:39<05:02,  1.40s/it, training loss=0.1637]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1619/1835 [37:39<05:01,  1.40s/it, training loss=0.1637]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1619/1835 [37:41<05:01,  1.40s/it, training loss=0.1572]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1620/1835 [37:41<04:59,  1.39s/it, training loss=0.1572]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1620/1835 [37:42<04:59,  1.39s/it, training loss=0.0440]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1621/1835 [37:42<04:58,  1.39s/it, training loss=0.0440]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1621/1835 [37:43<04:58,  1.39s/it, training loss=0.0505]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1622/1835 [37:43<04:56,  1.39s/it, training loss=0.0505]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1622/1835 [37:45<04:56,  1.39s/it, training loss=0.1780]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1623/1835 [37:45<04:55,  1.40s/it, training loss=0.1780]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 1623/1835 [37:46<04:55,  1.40s/it, training loss=0.1670]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 1624/1835 [37:46<04:54,  1.40s/it, training loss=0.1670]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 1624/1835 [37:48<04:54,  1.40s/it, training loss=0.1548]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 1625/1835 [37:48<04:53,  1.40s/it, training loss=0.1548]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 1625/1835 [37:49<04:53,  1.40s/it, training loss=0.2181]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 1626/1835 [37:49<04:52,  1.40s/it, training loss=0.2181]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 1626/1835 [37:50<04:52,  1.40s/it, training loss=0.0362]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 1627/1835 [37:50<04:51,  1.40s/it, training loss=0.0362]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 1627/1835 [37:52<04:51,  1.40s/it, training loss=0.0777]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 1628/1835 [37:52<04:49,  1.40s/it, training loss=0.0777]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 1628/1835 [37:53<04:49,  1.40s/it, training loss=0.1052]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1629/1835 [37:53<04:47,  1.40s/it, training loss=0.1052]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1629/1835 [37:55<04:47,  1.40s/it, training loss=0.0988]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1630/1835 [37:55<04:46,  1.40s/it, training loss=0.0988]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1630/1835 [37:56<04:46,  1.40s/it, training loss=0.0741]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1631/1835 [37:56<04:45,  1.40s/it, training loss=0.0741]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1631/1835 [37:57<04:45,  1.40s/it, training loss=0.0427]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1632/1835 [37:57<04:44,  1.40s/it, training loss=0.0427]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1632/1835 [37:59<04:44,  1.40s/it, training loss=0.1848]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1633/1835 [37:59<04:43,  1.40s/it, training loss=0.1848]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1633/1835 [38:00<04:43,  1.40s/it, training loss=0.1919]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1634/1835 [38:00<04:41,  1.40s/it, training loss=0.1919]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1634/1835 [38:02<04:41,  1.40s/it, training loss=0.0670]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1635/1835 [38:02<04:40,  1.40s/it, training loss=0.0670]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1635/1835 [38:03<04:40,  1.40s/it, training loss=0.1698]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1636/1835 [38:03<04:38,  1.40s/it, training loss=0.1698]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1636/1835 [38:04<04:38,  1.40s/it, training loss=0.1785]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1637/1835 [38:04<04:36,  1.40s/it, training loss=0.1785]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1637/1835 [38:06<04:36,  1.40s/it, training loss=0.1837]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1638/1835 [38:06<04:35,  1.40s/it, training loss=0.1837]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1638/1835 [38:07<04:35,  1.40s/it, training loss=0.0257]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1639/1835 [38:07<04:34,  1.40s/it, training loss=0.0257]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1639/1835 [38:09<04:34,  1.40s/it, training loss=0.0854]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1640/1835 [38:09<04:32,  1.40s/it, training loss=0.0854]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1640/1835 [38:10<04:32,  1.40s/it, training loss=0.1615]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1641/1835 [38:10<04:30,  1.40s/it, training loss=0.1615]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1641/1835 [38:11<04:30,  1.40s/it, training loss=0.1537]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1642/1835 [38:11<04:29,  1.40s/it, training loss=0.1537]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 1642/1835 [38:13<04:29,  1.40s/it, training loss=0.0620]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1643/1835 [38:13<04:28,  1.40s/it, training loss=0.0620]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1643/1835 [38:14<04:28,  1.40s/it, training loss=0.0341]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1644/1835 [38:14<04:26,  1.40s/it, training loss=0.0341]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1644/1835 [38:16<04:26,  1.40s/it, training loss=0.0712]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1645/1835 [38:16<04:25,  1.40s/it, training loss=0.0712]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1645/1835 [38:17<04:25,  1.40s/it, training loss=0.0351]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1646/1835 [38:17<04:24,  1.40s/it, training loss=0.0351]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1646/1835 [38:18<04:24,  1.40s/it, training loss=0.3022]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1647/1835 [38:18<04:23,  1.40s/it, training loss=0.3022]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1647/1835 [38:20<04:23,  1.40s/it, training loss=0.1161]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1648/1835 [38:20<04:21,  1.40s/it, training loss=0.1161]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1648/1835 [38:21<04:21,  1.40s/it, training loss=0.0600]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1649/1835 [38:21<04:20,  1.40s/it, training loss=0.0600]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1649/1835 [38:23<04:20,  1.40s/it, training loss=0.1709]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1650/1835 [38:23<04:18,  1.40s/it, training loss=0.1709]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1650/1835 [38:24<04:18,  1.40s/it, training loss=0.0821]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1651/1835 [38:24<04:17,  1.40s/it, training loss=0.0821]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 1651/1835 [38:25<04:17,  1.40s/it, training loss=0.1214]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1652/1835 [38:25<04:15,  1.40s/it, training loss=0.1214]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1652/1835 [38:27<04:15,  1.40s/it, training loss=0.1723]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1653/1835 [38:27<04:14,  1.40s/it, training loss=0.1723]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1653/1835 [38:28<04:14,  1.40s/it, training loss=0.0373]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1654/1835 [38:28<04:12,  1.40s/it, training loss=0.0373]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1654/1835 [38:30<04:12,  1.40s/it, training loss=0.1560]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1655/1835 [38:30<04:11,  1.40s/it, training loss=0.1560]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1655/1835 [38:31<04:11,  1.40s/it, training loss=0.0402]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1656/1835 [38:31<04:10,  1.40s/it, training loss=0.0402]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1656/1835 [38:32<04:10,  1.40s/it, training loss=0.0649]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1657/1835 [38:32<04:09,  1.40s/it, training loss=0.0649]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1657/1835 [38:34<04:09,  1.40s/it, training loss=0.1973]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1658/1835 [38:34<04:07,  1.40s/it, training loss=0.1973]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1658/1835 [38:35<04:07,  1.40s/it, training loss=0.1024]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1659/1835 [38:35<04:06,  1.40s/it, training loss=0.1024]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1659/1835 [38:37<04:06,  1.40s/it, training loss=0.1100]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1660/1835 [38:37<04:04,  1.40s/it, training loss=0.1100]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 1660/1835 [38:38<04:04,  1.40s/it, training loss=0.1731]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1661/1835 [38:38<04:03,  1.40s/it, training loss=0.1731]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1661/1835 [38:39<04:03,  1.40s/it, training loss=0.1464]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1662/1835 [38:39<04:01,  1.40s/it, training loss=0.1464]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1662/1835 [38:41<04:01,  1.40s/it, training loss=0.1972]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1663/1835 [38:41<04:00,  1.40s/it, training loss=0.1972]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1663/1835 [38:42<04:00,  1.40s/it, training loss=0.1789]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1664/1835 [38:42<03:59,  1.40s/it, training loss=0.1789]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1664/1835 [38:44<03:59,  1.40s/it, training loss=0.0523]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1665/1835 [38:44<03:57,  1.40s/it, training loss=0.0523]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1665/1835 [38:45<03:57,  1.40s/it, training loss=0.0534]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1666/1835 [38:45<03:55,  1.40s/it, training loss=0.0534]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1666/1835 [38:46<03:55,  1.40s/it, training loss=0.1363]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1667/1835 [38:46<03:54,  1.40s/it, training loss=0.1363]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1667/1835 [38:48<03:54,  1.40s/it, training loss=0.1537]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1668/1835 [38:48<03:52,  1.40s/it, training loss=0.1537]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1668/1835 [38:49<03:52,  1.40s/it, training loss=0.1619]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1669/1835 [38:49<03:51,  1.40s/it, training loss=0.1619]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1669/1835 [38:51<03:51,  1.40s/it, training loss=0.0402]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1670/1835 [38:51<03:50,  1.40s/it, training loss=0.0402]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1670/1835 [38:52<03:50,  1.40s/it, training loss=0.0680]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1671/1835 [38:52<03:49,  1.40s/it, training loss=0.0680]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1671/1835 [38:53<03:49,  1.40s/it, training loss=0.1284]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1672/1835 [38:53<03:47,  1.40s/it, training loss=0.1284]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1672/1835 [38:55<03:47,  1.40s/it, training loss=0.0846]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1673/1835 [38:55<03:46,  1.40s/it, training loss=0.0846]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1673/1835 [38:56<03:46,  1.40s/it, training loss=0.1994]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1674/1835 [38:56<03:45,  1.40s/it, training loss=0.1994]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 1674/1835 [38:58<03:45,  1.40s/it, training loss=0.0184]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 1675/1835 [38:58<03:44,  1.40s/it, training loss=0.0184]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 1675/1835 [38:59<03:44,  1.40s/it, training loss=0.0717]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 1676/1835 [38:59<03:42,  1.40s/it, training loss=0.0717]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 1676/1835 [39:00<03:42,  1.40s/it, training loss=0.0707]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 1677/1835 [39:00<03:40,  1.40s/it, training loss=0.0707]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 1677/1835 [39:02<03:40,  1.40s/it, training loss=0.2311]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 1678/1835 [39:02<03:39,  1.40s/it, training loss=0.2311]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 1678/1835 [39:03<03:39,  1.40s/it, training loss=0.0668]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 1679/1835 [39:03<03:38,  1.40s/it, training loss=0.0668]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 1679/1835 [39:05<03:38,  1.40s/it, training loss=0.1003]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1680/1835 [39:05<03:36,  1.40s/it, training loss=0.1003]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1680/1835 [39:06<03:36,  1.40s/it, training loss=0.1583]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1681/1835 [39:06<03:34,  1.39s/it, training loss=0.1583]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1681/1835 [39:07<03:34,  1.39s/it, training loss=0.0572]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1682/1835 [39:07<03:33,  1.39s/it, training loss=0.0572]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1682/1835 [39:09<03:33,  1.39s/it, training loss=0.1568]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1683/1835 [39:09<03:31,  1.39s/it, training loss=0.1568]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1683/1835 [39:10<03:31,  1.39s/it, training loss=0.0999]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1684/1835 [39:10<03:30,  1.39s/it, training loss=0.0999]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1684/1835 [39:12<03:30,  1.39s/it, training loss=0.1449]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1685/1835 [39:12<03:29,  1.39s/it, training loss=0.1449]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1685/1835 [39:13<03:29,  1.39s/it, training loss=0.1311]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1686/1835 [39:13<03:27,  1.39s/it, training loss=0.1311]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1686/1835 [39:14<03:27,  1.39s/it, training loss=0.0953]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1687/1835 [39:14<03:26,  1.39s/it, training loss=0.0953]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1687/1835 [39:16<03:26,  1.39s/it, training loss=0.1573]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1688/1835 [39:16<03:25,  1.40s/it, training loss=0.1573]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1688/1835 [39:17<03:25,  1.40s/it, training loss=0.0555]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1689/1835 [39:17<03:23,  1.40s/it, training loss=0.0555]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1689/1835 [39:19<03:23,  1.40s/it, training loss=0.0668]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1690/1835 [39:19<03:22,  1.40s/it, training loss=0.0668]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1690/1835 [39:20<03:22,  1.40s/it, training loss=0.0964]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1691/1835 [39:20<03:21,  1.40s/it, training loss=0.0964]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1691/1835 [39:21<03:21,  1.40s/it, training loss=0.1760]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1692/1835 [39:21<03:19,  1.40s/it, training loss=0.1760]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1692/1835 [39:23<03:19,  1.40s/it, training loss=0.1213]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1693/1835 [39:23<03:18,  1.40s/it, training loss=0.1213]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1693/1835 [39:24<03:18,  1.40s/it, training loss=0.0763]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1694/1835 [39:24<03:16,  1.39s/it, training loss=0.0763]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1694/1835 [39:26<03:16,  1.39s/it, training loss=0.0365]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1695/1835 [39:26<03:15,  1.40s/it, training loss=0.0365]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1695/1835 [39:27<03:15,  1.40s/it, training loss=0.1439]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1696/1835 [39:27<03:13,  1.39s/it, training loss=0.1439]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1696/1835 [39:28<03:13,  1.39s/it, training loss=0.0988]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1697/1835 [39:28<03:12,  1.40s/it, training loss=0.0988]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 1697/1835 [39:30<03:12,  1.40s/it, training loss=0.0162]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1698/1835 [39:30<03:11,  1.39s/it, training loss=0.0162]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1698/1835 [39:31<03:11,  1.39s/it, training loss=0.0377]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1699/1835 [39:31<03:09,  1.39s/it, training loss=0.0377]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1699/1835 [39:32<03:09,  1.39s/it, training loss=0.0782]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1700/1835 [39:33<03:08,  1.40s/it, training loss=0.0782]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1700/1835 [39:34<03:08,  1.40s/it, training loss=0.1690]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1701/1835 [39:34<03:06,  1.40s/it, training loss=0.1690]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1701/1835 [39:35<03:06,  1.40s/it, training loss=0.0504]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1702/1835 [39:35<03:05,  1.39s/it, training loss=0.0504]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1702/1835 [39:37<03:05,  1.39s/it, training loss=0.0878]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1703/1835 [39:37<03:03,  1.39s/it, training loss=0.0878]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1703/1835 [39:38<03:03,  1.39s/it, training loss=0.0468]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1704/1835 [39:38<03:02,  1.39s/it, training loss=0.0468]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1704/1835 [39:39<03:02,  1.39s/it, training loss=0.1742]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1705/1835 [39:39<03:01,  1.39s/it, training loss=0.1742]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1705/1835 [39:41<03:01,  1.39s/it, training loss=0.1431]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1706/1835 [39:41<02:59,  1.39s/it, training loss=0.1431]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1706/1835 [39:42<02:59,  1.39s/it, training loss=0.0459]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1707/1835 [39:42<02:58,  1.39s/it, training loss=0.0459]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1707/1835 [39:44<02:58,  1.39s/it, training loss=0.0989]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1708/1835 [39:44<02:57,  1.40s/it, training loss=0.0989]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1708/1835 [39:45<02:57,  1.40s/it, training loss=0.1768]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1709/1835 [39:45<02:56,  1.40s/it, training loss=0.1768]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1709/1835 [39:46<02:56,  1.40s/it, training loss=0.0224]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1710/1835 [39:46<02:54,  1.40s/it, training loss=0.0224]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1710/1835 [39:48<02:54,  1.40s/it, training loss=0.0642]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1711/1835 [39:48<02:53,  1.40s/it, training loss=0.0642]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1711/1835 [39:49<02:53,  1.40s/it, training loss=0.0245]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1712/1835 [39:49<02:51,  1.40s/it, training loss=0.0245]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1712/1835 [39:51<02:51,  1.40s/it, training loss=0.2275]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1713/1835 [39:51<02:50,  1.40s/it, training loss=0.2275]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1713/1835 [39:52<02:50,  1.40s/it, training loss=0.0630]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1714/1835 [39:52<02:48,  1.40s/it, training loss=0.0630]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1714/1835 [39:53<02:48,  1.40s/it, training loss=0.1690]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1715/1835 [39:53<02:47,  1.40s/it, training loss=0.1690]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 1715/1835 [39:55<02:47,  1.40s/it, training loss=0.1435]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 1716/1835 [39:55<02:46,  1.40s/it, training loss=0.1435]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 1716/1835 [39:56<02:46,  1.40s/it, training loss=0.1817]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 1717/1835 [39:56<02:44,  1.40s/it, training loss=0.1817]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 1717/1835 [39:58<02:44,  1.40s/it, training loss=0.2063]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 1718/1835 [39:58<02:43,  1.40s/it, training loss=0.2063]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 1718/1835 [39:59<02:43,  1.40s/it, training loss=0.1632]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 1719/1835 [39:59<02:42,  1.40s/it, training loss=0.1632]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 1719/1835 [40:00<02:42,  1.40s/it, training loss=0.1321]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 1720/1835 [40:00<02:40,  1.40s/it, training loss=0.1321]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 1720/1835 [40:02<02:40,  1.40s/it, training loss=0.0286]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1721/1835 [40:02<02:39,  1.40s/it, training loss=0.0286]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1721/1835 [40:03<02:39,  1.40s/it, training loss=0.1613]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1722/1835 [40:03<02:37,  1.40s/it, training loss=0.1613]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1722/1835 [40:05<02:37,  1.40s/it, training loss=0.1500]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1723/1835 [40:05<02:36,  1.39s/it, training loss=0.1500]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1723/1835 [40:06<02:36,  1.39s/it, training loss=0.1561]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1724/1835 [40:06<02:34,  1.39s/it, training loss=0.1561]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1724/1835 [40:07<02:34,  1.39s/it, training loss=0.1125]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1725/1835 [40:07<02:33,  1.40s/it, training loss=0.1125]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1725/1835 [40:09<02:33,  1.40s/it, training loss=0.0642]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1726/1835 [40:09<02:31,  1.39s/it, training loss=0.0642]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1726/1835 [40:10<02:31,  1.39s/it, training loss=0.0152]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1727/1835 [40:10<02:30,  1.39s/it, training loss=0.0152]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1727/1835 [40:12<02:30,  1.39s/it, training loss=0.1725]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1728/1835 [40:12<02:29,  1.39s/it, training loss=0.1725]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1728/1835 [40:13<02:29,  1.39s/it, training loss=0.1145]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1729/1835 [40:13<02:27,  1.39s/it, training loss=0.1145]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1729/1835 [40:14<02:27,  1.39s/it, training loss=0.0508]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1730/1835 [40:14<02:26,  1.39s/it, training loss=0.0508]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1730/1835 [40:16<02:26,  1.39s/it, training loss=0.0393]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1731/1835 [40:16<02:24,  1.39s/it, training loss=0.0393]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1731/1835 [40:17<02:24,  1.39s/it, training loss=0.1088]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1732/1835 [40:17<02:23,  1.39s/it, training loss=0.1088]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1732/1835 [40:19<02:23,  1.39s/it, training loss=0.0561]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1733/1835 [40:19<02:22,  1.39s/it, training loss=0.0561]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1733/1835 [40:20<02:22,  1.39s/it, training loss=0.2397]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1734/1835 [40:20<02:20,  1.39s/it, training loss=0.2397]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 1734/1835 [40:21<02:20,  1.39s/it, training loss=0.1013]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1735/1835 [40:21<02:19,  1.39s/it, training loss=0.1013]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1735/1835 [40:23<02:19,  1.39s/it, training loss=0.0780]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1736/1835 [40:23<02:18,  1.40s/it, training loss=0.0780]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1736/1835 [40:24<02:18,  1.40s/it, training loss=0.2051]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1737/1835 [40:24<02:16,  1.39s/it, training loss=0.2051]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1737/1835 [40:26<02:16,  1.39s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1738/1835 [40:26<02:15,  1.39s/it, training loss=0.1498]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1738/1835 [40:27<02:15,  1.39s/it, training loss=0.1038]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1739/1835 [40:27<02:13,  1.39s/it, training loss=0.1038]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1739/1835 [40:28<02:13,  1.39s/it, training loss=0.1824]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1740/1835 [40:28<02:12,  1.39s/it, training loss=0.1824]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1740/1835 [40:30<02:12,  1.39s/it, training loss=0.1068]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1741/1835 [40:30<02:10,  1.39s/it, training loss=0.1068]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1741/1835 [40:31<02:10,  1.39s/it, training loss=0.1051]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1742/1835 [40:31<02:09,  1.40s/it, training loss=0.1051]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1742/1835 [40:32<02:09,  1.40s/it, training loss=0.0915]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1743/1835 [40:32<02:08,  1.39s/it, training loss=0.0915]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 1743/1835 [40:34<02:08,  1.39s/it, training loss=0.0652]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1744/1835 [40:34<02:06,  1.39s/it, training loss=0.0652]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1744/1835 [40:35<02:06,  1.39s/it, training loss=0.1395]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1745/1835 [40:35<02:05,  1.40s/it, training loss=0.1395]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1745/1835 [40:37<02:05,  1.40s/it, training loss=0.1821]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1746/1835 [40:37<02:04,  1.39s/it, training loss=0.1821]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1746/1835 [40:38<02:04,  1.39s/it, training loss=0.2408]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1747/1835 [40:38<02:02,  1.39s/it, training loss=0.2408]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1747/1835 [40:39<02:02,  1.39s/it, training loss=0.1198]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1748/1835 [40:39<02:01,  1.40s/it, training loss=0.1198]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1748/1835 [40:41<02:01,  1.40s/it, training loss=0.0217]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1749/1835 [40:41<01:59,  1.39s/it, training loss=0.0217]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1749/1835 [40:42<01:59,  1.39s/it, training loss=0.2713]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1750/1835 [40:42<01:58,  1.39s/it, training loss=0.2713]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1750/1835 [40:44<01:58,  1.39s/it, training loss=0.0828]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1751/1835 [40:44<01:57,  1.39s/it, training loss=0.0828]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1751/1835 [40:45<01:57,  1.39s/it, training loss=0.1270]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1752/1835 [40:45<01:55,  1.39s/it, training loss=0.1270]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 1752/1835 [40:46<01:55,  1.39s/it, training loss=0.0822]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1753/1835 [40:46<01:54,  1.39s/it, training loss=0.0822]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1753/1835 [40:48<01:54,  1.39s/it, training loss=0.1271]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1754/1835 [40:48<01:52,  1.39s/it, training loss=0.1271]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1754/1835 [40:49<01:52,  1.39s/it, training loss=0.0197]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1755/1835 [40:49<01:51,  1.39s/it, training loss=0.0197]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1755/1835 [40:51<01:51,  1.39s/it, training loss=0.1533]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1756/1835 [40:51<01:50,  1.39s/it, training loss=0.1533]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1756/1835 [40:52<01:50,  1.39s/it, training loss=0.0886]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1757/1835 [40:52<01:48,  1.40s/it, training loss=0.0886]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1757/1835 [40:53<01:48,  1.40s/it, training loss=0.0741]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1758/1835 [40:53<01:47,  1.40s/it, training loss=0.0741]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1758/1835 [40:55<01:47,  1.40s/it, training loss=0.0200]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1759/1835 [40:55<01:46,  1.40s/it, training loss=0.0200]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1759/1835 [40:56<01:46,  1.40s/it, training loss=0.1572]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1760/1835 [40:56<01:44,  1.40s/it, training loss=0.1572]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1760/1835 [40:58<01:44,  1.40s/it, training loss=0.2119]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1761/1835 [40:58<01:43,  1.40s/it, training loss=0.2119]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1761/1835 [40:59<01:43,  1.40s/it, training loss=0.0294]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1762/1835 [40:59<01:42,  1.41s/it, training loss=0.0294]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1762/1835 [41:00<01:42,  1.41s/it, training loss=0.1464]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1763/1835 [41:00<01:41,  1.41s/it, training loss=0.1464]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1763/1835 [41:02<01:41,  1.41s/it, training loss=0.0161]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1764/1835 [41:02<01:39,  1.40s/it, training loss=0.0161]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1764/1835 [41:03<01:39,  1.40s/it, training loss=0.0942]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1765/1835 [41:03<01:38,  1.41s/it, training loss=0.0942]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1765/1835 [41:05<01:38,  1.41s/it, training loss=0.1270]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1766/1835 [41:05<01:36,  1.40s/it, training loss=0.1270]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 1766/1835 [41:06<01:36,  1.40s/it, training loss=0.0752]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 1767/1835 [41:06<01:35,  1.40s/it, training loss=0.0752]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 1767/1835 [41:07<01:35,  1.40s/it, training loss=0.1291]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 1768/1835 [41:07<01:33,  1.40s/it, training loss=0.1291]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 1768/1835 [41:09<01:33,  1.40s/it, training loss=0.0229]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 1769/1835 [41:09<01:32,  1.40s/it, training loss=0.0229]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 1769/1835 [41:10<01:32,  1.40s/it, training loss=0.0284]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 1770/1835 [41:10<01:31,  1.40s/it, training loss=0.0284]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 1770/1835 [41:12<01:31,  1.40s/it, training loss=0.0175]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1771/1835 [41:12<01:29,  1.40s/it, training loss=0.0175]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1771/1835 [41:13<01:29,  1.40s/it, training loss=0.0407]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1772/1835 [41:13<01:28,  1.40s/it, training loss=0.0407]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1772/1835 [41:14<01:28,  1.40s/it, training loss=0.1181]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1773/1835 [41:14<01:26,  1.40s/it, training loss=0.1181]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1773/1835 [41:16<01:26,  1.40s/it, training loss=0.0224]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1774/1835 [41:16<01:25,  1.40s/it, training loss=0.0224]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1774/1835 [41:17<01:25,  1.40s/it, training loss=0.1087]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1775/1835 [41:17<01:23,  1.40s/it, training loss=0.1087]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1775/1835 [41:19<01:23,  1.40s/it, training loss=0.0952]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1776/1835 [41:19<01:22,  1.40s/it, training loss=0.0952]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1776/1835 [41:20<01:22,  1.40s/it, training loss=0.0270]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1777/1835 [41:20<01:21,  1.40s/it, training loss=0.0270]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1777/1835 [41:21<01:21,  1.40s/it, training loss=0.0521]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1778/1835 [41:21<01:19,  1.40s/it, training loss=0.0521]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1778/1835 [41:23<01:19,  1.40s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1779/1835 [41:23<01:18,  1.40s/it, training loss=0.1307]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1779/1835 [41:24<01:18,  1.40s/it, training loss=0.0767]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1780/1835 [41:24<01:16,  1.40s/it, training loss=0.0767]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1780/1835 [41:26<01:16,  1.40s/it, training loss=0.1620]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1781/1835 [41:26<01:15,  1.40s/it, training loss=0.1620]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1781/1835 [41:27<01:15,  1.40s/it, training loss=0.0615]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1782/1835 [41:27<01:14,  1.40s/it, training loss=0.0615]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1782/1835 [41:28<01:14,  1.40s/it, training loss=0.0799]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1783/1835 [41:28<01:12,  1.40s/it, training loss=0.0799]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1783/1835 [41:30<01:12,  1.40s/it, training loss=0.0891]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1784/1835 [41:30<01:11,  1.40s/it, training loss=0.0891]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1784/1835 [41:31<01:11,  1.40s/it, training loss=0.1788]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1785/1835 [41:31<01:09,  1.40s/it, training loss=0.1788]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1785/1835 [41:33<01:09,  1.40s/it, training loss=0.1371]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1786/1835 [41:33<01:08,  1.40s/it, training loss=0.1371]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1786/1835 [41:34<01:08,  1.40s/it, training loss=0.1590]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1787/1835 [41:34<01:07,  1.40s/it, training loss=0.1590]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1787/1835 [41:35<01:07,  1.40s/it, training loss=0.0898]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1788/1835 [41:35<01:05,  1.40s/it, training loss=0.0898]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1788/1835 [41:37<01:05,  1.40s/it, training loss=0.2007]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1789/1835 [41:37<01:04,  1.40s/it, training loss=0.2007]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 1789/1835 [41:38<01:04,  1.40s/it, training loss=0.0401]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1790/1835 [41:38<01:02,  1.40s/it, training loss=0.0401]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1790/1835 [41:40<01:02,  1.40s/it, training loss=0.1546]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1791/1835 [41:40<01:01,  1.40s/it, training loss=0.1546]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1791/1835 [41:41<01:01,  1.40s/it, training loss=0.1310]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1792/1835 [41:41<01:00,  1.40s/it, training loss=0.1310]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1792/1835 [41:42<01:00,  1.40s/it, training loss=0.0803]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1793/1835 [41:42<00:58,  1.40s/it, training loss=0.0803]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1793/1835 [41:44<00:58,  1.40s/it, training loss=0.0558]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1794/1835 [41:44<00:57,  1.40s/it, training loss=0.0558]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1794/1835 [41:45<00:57,  1.40s/it, training loss=0.0833]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1795/1835 [41:45<00:55,  1.40s/it, training loss=0.0833]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1795/1835 [41:47<00:55,  1.40s/it, training loss=0.1706]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1796/1835 [41:47<00:54,  1.40s/it, training loss=0.1706]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1796/1835 [41:48<00:54,  1.40s/it, training loss=0.0957]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1797/1835 [41:48<00:53,  1.40s/it, training loss=0.0957]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1797/1835 [41:49<00:53,  1.40s/it, training loss=0.1765]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1798/1835 [41:49<00:51,  1.40s/it, training loss=0.1765]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1798/1835 [41:51<00:51,  1.40s/it, training loss=0.2127]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1799/1835 [41:51<00:50,  1.40s/it, training loss=0.2127]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1799/1835 [41:52<00:50,  1.40s/it, training loss=0.1198]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1800/1835 [41:52<00:48,  1.40s/it, training loss=0.1198]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1800/1835 [41:54<00:48,  1.40s/it, training loss=0.0520]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1801/1835 [41:54<00:47,  1.40s/it, training loss=0.0520]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1801/1835 [41:55<00:47,  1.40s/it, training loss=0.1181]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1802/1835 [41:55<00:46,  1.40s/it, training loss=0.1181]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1802/1835 [41:56<00:46,  1.40s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1803/1835 [41:56<00:44,  1.40s/it, training loss=0.1877]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1803/1835 [41:58<00:44,  1.40s/it, training loss=0.0715]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1804/1835 [41:58<00:43,  1.40s/it, training loss=0.0715]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1804/1835 [41:59<00:43,  1.40s/it, training loss=0.0691]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1805/1835 [41:59<00:41,  1.40s/it, training loss=0.0691]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1805/1835 [42:01<00:41,  1.40s/it, training loss=0.2056]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1806/1835 [42:01<00:40,  1.39s/it, training loss=0.2056]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1806/1835 [42:02<00:40,  1.39s/it, training loss=0.2383]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1807/1835 [42:02<00:39,  1.39s/it, training loss=0.2383]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 1807/1835 [42:03<00:39,  1.39s/it, training loss=0.0721]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 1808/1835 [42:03<00:37,  1.39s/it, training loss=0.0721]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 1808/1835 [42:05<00:37,  1.39s/it, training loss=0.0109]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 1809/1835 [42:05<00:36,  1.39s/it, training loss=0.0109]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 1809/1835 [42:06<00:36,  1.39s/it, training loss=0.0560]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 1810/1835 [42:06<00:34,  1.39s/it, training loss=0.0560]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 1810/1835 [42:07<00:34,  1.39s/it, training loss=0.1112]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 1811/1835 [42:07<00:33,  1.39s/it, training loss=0.1112]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 1811/1835 [42:09<00:33,  1.39s/it, training loss=0.2364]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 1812/1835 [42:09<00:32,  1.39s/it, training loss=0.2364]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 1812/1835 [42:10<00:32,  1.39s/it, training loss=0.1561]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1813/1835 [42:10<00:30,  1.40s/it, training loss=0.1561]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1813/1835 [42:12<00:30,  1.40s/it, training loss=0.1128]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1814/1835 [42:12<00:29,  1.40s/it, training loss=0.1128]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1814/1835 [42:13<00:29,  1.40s/it, training loss=0.1236]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1815/1835 [42:13<00:27,  1.39s/it, training loss=0.1236]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1815/1835 [42:14<00:27,  1.39s/it, training loss=0.1780]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1816/1835 [42:14<00:26,  1.40s/it, training loss=0.1780]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1816/1835 [42:16<00:26,  1.40s/it, training loss=0.0868]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1817/1835 [42:16<00:25,  1.39s/it, training loss=0.0868]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1817/1835 [42:17<00:25,  1.39s/it, training loss=0.2135]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1818/1835 [42:17<00:23,  1.40s/it, training loss=0.2135]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1818/1835 [42:19<00:23,  1.40s/it, training loss=0.2657]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1819/1835 [42:19<00:22,  1.40s/it, training loss=0.2657]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1819/1835 [42:20<00:22,  1.40s/it, training loss=0.1261]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1820/1835 [42:20<00:20,  1.39s/it, training loss=0.1261]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1820/1835 [42:21<00:20,  1.39s/it, training loss=0.0471]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1821/1835 [42:21<00:19,  1.40s/it, training loss=0.0471]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1821/1835 [42:23<00:19,  1.40s/it, training loss=0.0288]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1822/1835 [42:23<00:18,  1.40s/it, training loss=0.0288]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1822/1835 [42:24<00:18,  1.40s/it, training loss=0.0302]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1823/1835 [42:24<00:16,  1.39s/it, training loss=0.0302]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1823/1835 [42:26<00:16,  1.39s/it, training loss=0.0994]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1824/1835 [42:26<00:15,  1.40s/it, training loss=0.0994]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1824/1835 [42:27<00:15,  1.40s/it, training loss=0.1294]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1825/1835 [42:27<00:13,  1.40s/it, training loss=0.1294]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 1825/1835 [42:28<00:13,  1.40s/it, training loss=0.0506]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1826/1835 [42:28<00:12,  1.40s/it, training loss=0.0506]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1826/1835 [42:30<00:12,  1.40s/it, training loss=0.1353]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1827/1835 [42:30<00:11,  1.40s/it, training loss=0.1353]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1827/1835 [42:31<00:11,  1.40s/it, training loss=0.0799]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1828/1835 [42:31<00:09,  1.40s/it, training loss=0.0799]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1828/1835 [42:33<00:09,  1.40s/it, training loss=0.1619]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1829/1835 [42:33<00:08,  1.40s/it, training loss=0.1619]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1829/1835 [42:34<00:08,  1.40s/it, training loss=0.1442]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1830/1835 [42:34<00:06,  1.40s/it, training loss=0.1442]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1830/1835 [42:35<00:06,  1.40s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1831/1835 [42:35<00:05,  1.40s/it, training loss=0.0602]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1831/1835 [42:37<00:05,  1.40s/it, training loss=0.0633]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1832/1835 [42:37<00:04,  1.39s/it, training loss=0.0633]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1832/1835 [42:38<00:04,  1.39s/it, training loss=0.0291]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1833/1835 [42:38<00:02,  1.40s/it, training loss=0.0291]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1833/1835 [42:40<00:02,  1.40s/it, training loss=0.0636]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1834/1835 [42:40<00:01,  1.40s/it, training loss=0.0636]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 1834/1835 [42:40<00:01,  1.40s/it, training loss=0.0447]\u001b[A\n",
            "Epoch 3: 100%|██████████| 1835/1835 [42:40<00:00,  1.24s/it, training loss=0.0447]\u001b[A\n",
            " 67%|██████▋   | 2/3 [2:11:35<44:27, 2667.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch {epoch}\n",
            "Training loss: 0.33602390468161175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [2:13:20<00:00, 2666.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.6247609762803596\n",
            "F1 Score (weighted): 0.7880614701008887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rPa0IpCPYZdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "get_accuracy_perclass(predictions, true_vals)"
      ],
      "metadata": {
        "id": "CVBKj9ccVxDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a3bc887-e6b1-40aa-ab36-9e161461f011"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: positive\n",
            "Accuracy:1509/1741 = 0.8667432510051695\n",
            "\n",
            "Class: negative\n",
            "Accuracy:726/984 = 0.7378048780487805\n",
            "\n",
            "Class: neutral\n",
            "Accuracy:339/537 = 0.6312849162011173\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting on test data"
      ],
      "metadata": {
        "id": "T_84SqSH5NEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "label_dict = {\n",
        "    \"positive\":0,\n",
        "    \"negative\":1,\n",
        "    \"neutral\":2\n",
        "}\n",
        "Y_test = test_df[\"label\"]\n",
        "Y_test.label = Y_test.map(label_dict)"
      ],
      "metadata": {
        "id": "FUSqrlmh5Q3w"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "test_encoding_texts = tokenizer.batch_encode_plus(test_text, padding=\"max_length\", truncation=True, return_tensors=\"pt\",)"
      ],
      "metadata": {
        "id": "XI2jUdrF4obh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "test_input = test_encoding_texts['input_ids']\n",
        "test_attention = test_encoding_texts['attention_mask']\n",
        "test_labels = torch.tensor(Y_test.values)"
      ],
      "metadata": {
        "id": "KKIuQc2T7h91"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "test_tensor_data = TensorDataset(test_input, test_attention, test_labels)"
      ],
      "metadata": {
        "id": "IUH4EpiU7oUe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "batch_size = 16\n",
        "dataloader_test = DataLoader(\n",
        "    test_tensor_data,\n",
        "    sampler=RandomSampler(test_tensor_data),\n",
        "    batch_size=batch_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "JB3P9XNW8nCR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "test_loss, test_predictions, test_true_vals = evaluate(dataloader_test)"
      ],
      "metadata": {
        "id": "0Cvue1_p9fOK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "get_accuracy_perclass(test_predictions, test_true_vals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzwvbJPM-j0l",
        "outputId": "44b30fde-6662-4160-8868-48feabc287c0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: positive\n",
            "Accuracy:1895/2104 = 0.9006653992395437\n",
            "\n",
            "Class: negative\n",
            "Accuracy:966/1262 = 0.7654516640253566\n",
            "\n",
            "Class: neutral\n",
            "Accuracy:440/677 = 0.6499261447562777\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "#F1 Score it is important as the dataset is highly imbalanced\n",
        "\n",
        "print(get_f1_score(test_predictions, test_true_vals))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKKHobQe-7np",
        "outputId": "54d6bfa2-e281-43cf-9090-4977ed0bb326"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8143053043344404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VSWLz-MNYKCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code by Vamsi Pusapati\n",
        "#Confusion Matrix\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "class_names = [\"Positive\", \"Negative\", \"Neutral\"]\n",
        "\n",
        "test_preds = np.argmax(test_predictions, axis=1).flatten()\n",
        "conf_matrix = confusion_matrix(test_true_vals, test_preds)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig('test_confusion_matrix.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "euCuVlt8_SYB",
        "outputId": "fb782513-a146-41f9-fbf8-2a69c501d096"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "f1 = classification_report(test_true_vals, test_preds, target_names=[\n",
        "                            \"positive\", \"negative\", \"neutral\"])\n",
        "\n",
        "\n",
        "print(f\"\\nF1 Score:\\n{f1}\")\n"
      ],
      "metadata": {
        "id": "1sveVGSZYSu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d7f1360-2596-4811-c5b0-eff7015c62ec"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "F1 Score:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.85      0.90      0.87      2104\n",
            "    negative       0.81      0.77      0.79      1262\n",
            "     neutral       0.71      0.65      0.68       677\n",
            "\n",
            "    accuracy                           0.82      4043\n",
            "   macro avg       0.79      0.77      0.78      4043\n",
            "weighted avg       0.81      0.82      0.81      4043\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_Neutral_given_true_positive = conf_matrix[0][2]\n",
        "total_true_positives = sum(conf_matrix[0])\n",
        "\n",
        "percentage_of_false_Neutral_given_positive = predicted_Neutral_given_true_positive/total_true_positives\n",
        "\n",
        "\n",
        "print(\"percentage of predicted Neutral for a given Positive text = \" + str(percentage_of_false_Neutral_given_positive))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8rNbg7-CTKB",
        "outputId": "d73c049e-3479-4108-bf65-8c443a4a71ee"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "percentage of predicted Neutral for a given Positive text = 0.03802281368821293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_Neutral_given_true_negative = conf_matrix[1][2]\n",
        "total_true_negatives = sum(conf_matrix[1])\n",
        "\n",
        "percentage_of_false_Neutral_given_negative = predicted_Neutral_given_true_negative/total_true_negatives\n",
        "\n",
        "\n",
        "print(\"percentage of predicted Neutral for a given Negative text = \" + str(percentage_of_false_Neutral_given_negative))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PpTuCLnFPFN",
        "outputId": "8968d92a-c824-42c7-96ab-df3e216e489c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "percentage of predicted Neutral for a given Negative text = 0.07765451664025357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations\n"
      ],
      "metadata": {
        "id": "nl7lFzI8B5Bv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have created a baseline BERT model using inbuilt pytorch models. I have loaded the train and test csv files. For the test csv i further split the data to have a train dataset and a validation dataset (0.9 split). And I trained the model. The below are the observations of the model that ran on the test dataset. (The test data is not included in my training process).\n",
        "\n",
        "1. The model performed decently on all the three labels ie. on (Positive, Negative, Neutral) with accuracy of 90.00% (1894/2104) on Positive texts, 76.46%(965/1262) on the Negative texts, 63.95(433/677) on Neutral Texts\n",
        "\n",
        "2. As the data is highly imbalanced overall accuracy does not show the true performance of the model, so i calculated the F1 score. The F1 Score for the model that ran on test data is around 0.8117. For this f1 score the baseline model is perfroming decently in classifying the texts\n",
        "\n",
        "3. The model is silghtly biased towards the Positive comments. From the confusion matrix we can see that the most of the mis-classified Negative and Neutral comments are classified as positive comments. (It is expected as we have more number of positive data and due to GPU restraint I trained only for 3 epochs. Based on the losses from each epoch the model still not converged after 3 epochs which shows the capability of the model to perform well on further training).\n",
        "\n"
      ],
      "metadata": {
        "id": "fvYsMubAB-VZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Future scope"
      ],
      "metadata": {
        "id": "bzcg8RHZGtmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. To increase the performance of the model the model need to be trained further by increasing the number of epochs.\n",
        "\n",
        "2. The model can be fine tuned by changing the learning rate (lr), number of training steps\n",
        "\n",
        "3. To further classify the emotions we can create a two or multi stage ensembled model which further classify the text into minute detail emotions on the second or further stages (based on the ensemble)"
      ],
      "metadata": {
        "id": "fT9o_qUsGyRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the Models and dataframes from colab"
      ],
      "metadata": {
        "id": "gCEjyTaUcLCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"berth_model_state_dict.pth\")"
      ],
      "metadata": {
        "id": "4jZXQa8XcSVy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"berth_model_state_dict.pt\")"
      ],
      "metadata": {
        "id": "QTbbTU9B0lsW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8gvfIi7_LI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('berth_model_state_dict.pth')"
      ],
      "metadata": {
        "id": "QqP0QVG6c7xG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "84edcb45-d565-4305-eeb8-37c004bba8a3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1258ba48-8076-4c31-bbbb-df55042bdba2\", \"berth_model_state_dict.pth\", 438022947)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "BwbGr1JidMO7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "cf88aa98-17fb-44c9-de5a-a02aba6a348e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Clean_text     emotion  label\n",
              "1    it is wonderful because it is awful at not with  admiration      0\n",
              "2  kings fan here good luck to you guys ! will be...  excitement      0\n",
              "3  i did not know that thank you for teaching me ...   gratitude      0\n",
              "5  thank you for asking questions and recognizing...   gratitude      0\n",
              "6                                    you are welcome   gratitude      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f994061-7f58-4bdb-a327-a03aa9e4d824\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clean_text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it is wonderful because it is awful at not with</td>\n",
              "      <td>admiration</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kings fan here good luck to you guys ! will be...</td>\n",
              "      <td>excitement</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i did not know that thank you for teaching me ...</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>thank you for asking questions and recognizing...</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>you are welcome</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f994061-7f58-4bdb-a327-a03aa9e4d824')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2f994061-7f58-4bdb-a327-a03aa9e4d824 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2f994061-7f58-4bdb-a327-a03aa9e4d824');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83a3ea22-e28f-4deb-b257-e6b2bbe87cd0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83a3ea22-e28f-4deb-b257-e6b2bbe87cd0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83a3ea22-e28f-4deb-b257-e6b2bbe87cd0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[\"predict_label\"] = test_preds"
      ],
      "metadata": {
        "id": "qeVpf41jovv9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "bks7aXBdo6LS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a37e43a8-39c0-441f-b04b-a0726c34133b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Clean_text     emotion  label  \\\n",
              "1    it is wonderful because it is awful at not with  admiration      0   \n",
              "2  kings fan here good luck to you guys ! will be...  excitement      0   \n",
              "3  i did not know that thank you for teaching me ...   gratitude      0   \n",
              "5  thank you for asking questions and recognizing...   gratitude      0   \n",
              "6                                    you are welcome   gratitude      0   \n",
              "\n",
              "   predict_label  \n",
              "1              1  \n",
              "2              1  \n",
              "3              2  \n",
              "5              0  \n",
              "6              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bbadc1c-3df5-4245-afd2-107219072d5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clean_text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>label</th>\n",
              "      <th>predict_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it is wonderful because it is awful at not with</td>\n",
              "      <td>admiration</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kings fan here good luck to you guys ! will be...</td>\n",
              "      <td>excitement</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i did not know that thank you for teaching me ...</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>thank you for asking questions and recognizing...</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>you are welcome</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bbadc1c-3df5-4245-afd2-107219072d5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2bbadc1c-3df5-4245-afd2-107219072d5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2bbadc1c-3df5-4245-afd2-107219072d5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db033347-ebfa-403d-ade5-13529c4faad2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db033347-ebfa-403d-ade5-13529c4faad2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db033347-ebfa-403d-ade5-13529c4faad2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rev_label_dict = {\n",
        "    0: \"positive\",\n",
        "    1: \"negative\",\n",
        "    2: \"neutral\"\n",
        "}\n",
        "go_emotions_test_prediction = test_df.copy()\n",
        "\n",
        "go_emotions_test_prediction.label = go_emotions_test_prediction.label.map(rev_label_dict)\n",
        "go_emotions_test_prediction.predict_label = go_emotions_test_prediction.predict_label.map(rev_label_dict)"
      ],
      "metadata": {
        "id": "AqhJAPSx1Ads"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "go_emotions_test_prediction.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1NiswXEr14PN",
        "outputId": "4c175ed4-9a57-4d22-d87b-c275e14a7761"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Clean_text     emotion     label  \\\n",
              "1    it is wonderful because it is awful at not with  admiration  positive   \n",
              "2  kings fan here good luck to you guys ! will be...  excitement  positive   \n",
              "3  i did not know that thank you for teaching me ...   gratitude  positive   \n",
              "5  thank you for asking questions and recognizing...   gratitude  positive   \n",
              "6                                    you are welcome   gratitude  positive   \n",
              "\n",
              "  predict_label  \n",
              "1      negative  \n",
              "2      negative  \n",
              "3       neutral  \n",
              "5      positive  \n",
              "6      positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db3ced38-787e-4665-91b1-d9c0e7c6a814\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clean_text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>label</th>\n",
              "      <th>predict_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it is wonderful because it is awful at not with</td>\n",
              "      <td>admiration</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kings fan here good luck to you guys ! will be...</td>\n",
              "      <td>excitement</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i did not know that thank you for teaching me ...</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>thank you for asking questions and recognizing...</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>you are welcome</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db3ced38-787e-4665-91b1-d9c0e7c6a814')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db3ced38-787e-4665-91b1-d9c0e7c6a814 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db3ced38-787e-4665-91b1-d9c0e7c6a814');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96272f77-943a-47f7-ab4c-b3752d0438d9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96272f77-943a-47f7-ab4c-b3752d0438d9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96272f77-943a-47f7-ab4c-b3752d0438d9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "go_emotions_test_prediction.to_csv(\"test_predicted_emotions.csv\")"
      ],
      "metadata": {
        "id": "8GF0rfzE2BLf"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUQuDC290MGz",
        "outputId": "60e32395-e453-4bf0-ebe3-d8428dd849bb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "go_emotions_test_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NWpwRn2N0gD3",
        "outputId": "4af5ddef-2890-41b1-d27d-fed54e578e3c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Clean_text      emotion  \\\n",
              "1       it is wonderful because it is awful at not with   admiration   \n",
              "2     kings fan here good luck to you guys ! will be...   excitement   \n",
              "3     i did not know that thank you for teaching me ...    gratitude   \n",
              "5     thank you for asking questions and recognizing...    gratitude   \n",
              "6                                       you are welcome    gratitude   \n",
              "...                                                 ...          ...   \n",
              "5386  the adventure starts in the year fuck wait rea...    curiosity   \n",
              "5394  dammit you know i proof read this and i though...    confusion   \n",
              "5399  can not believe me and my family were going to...     surprise   \n",
              "5400  now we just need to kill name if name was not ...  realization   \n",
              "5414  i know right ?! i was literally in tears satur...    curiosity   \n",
              "\n",
              "         label predict_label  \n",
              "1     positive      negative  \n",
              "2     positive      negative  \n",
              "3     positive       neutral  \n",
              "5     positive      positive  \n",
              "6     positive      positive  \n",
              "...        ...           ...  \n",
              "5386   neutral      negative  \n",
              "5394   neutral       neutral  \n",
              "5399   neutral      positive  \n",
              "5400   neutral      positive  \n",
              "5414   neutral      negative  \n",
              "\n",
              "[4043 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1531cb19-9ea9-4593-9b8a-43575e757aaf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clean_text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>label</th>\n",
              "      <th>predict_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it is wonderful because it is awful at not with</td>\n",
              "      <td>admiration</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kings fan here good luck to you guys ! will be...</td>\n",
              "      <td>excitement</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i did not know that thank you for teaching me ...</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>thank you for asking questions and recognizing...</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>you are welcome</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5386</th>\n",
              "      <td>the adventure starts in the year fuck wait rea...</td>\n",
              "      <td>curiosity</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5394</th>\n",
              "      <td>dammit you know i proof read this and i though...</td>\n",
              "      <td>confusion</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5399</th>\n",
              "      <td>can not believe me and my family were going to...</td>\n",
              "      <td>surprise</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5400</th>\n",
              "      <td>now we just need to kill name if name was not ...</td>\n",
              "      <td>realization</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5414</th>\n",
              "      <td>i know right ?! i was literally in tears satur...</td>\n",
              "      <td>curiosity</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4043 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1531cb19-9ea9-4593-9b8a-43575e757aaf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1531cb19-9ea9-4593-9b8a-43575e757aaf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1531cb19-9ea9-4593-9b8a-43575e757aaf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14dc5bde-6de3-4995-a665-c8c629a5f68b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14dc5bde-6de3-4995-a665-c8c629a5f68b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14dc5bde-6de3-4995-a665-c8c629a5f68b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "FEDllWlB7fgt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}